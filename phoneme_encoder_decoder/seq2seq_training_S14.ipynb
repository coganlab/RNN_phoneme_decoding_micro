{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in Data from .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from processing_utils.feature_data_from_mat import load_subject_high_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_trace, hg_map, phon_labels = load_subject_high_gamma('S14', sig_channel=False, zscore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 200, 111)\n",
      "(149, 8, 16, 200)\n",
      "(149, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(hg_trace.shape)\n",
    "print(hg_map.shape)\n",
    "print(phon_labels.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(hg_trace, axis=0), 'grey')\n",
    "plt.plot(np.mean(np.mean(hg_trace, axis=0), axis=1), 'black')\n",
    "plt.title('HG Trace by Channel')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data for use with 1/3 D CNN Bidirectional LSTM seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from processing_utils.sequence_processing import pad_sequence_teacher_forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hg_trace  # use HG traces (n_trials, n_channels, n_timepoints) for 1D CNN\n",
    "# X = hg_map  # use HG channel map stack (n_trials, n_channels_x, n_channels_y, n_timepoints) for 1D CNN\n",
    "X_prior, y, prior_labels, seq_labels = pad_sequence_teacher_forcing(phon_labels, n_output)  # first 2 outputs one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 200, 111) (149, 3, 10) (149, 3, 10) (149, 3) (149, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_prior.shape, y.shape, prior_labels.shape, seq_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 1D CNN Bidirectional LSTM seq2seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from seq2seq_models.rnn_models import (lstm_1Dcnn_model, gru_1Dcnn_model, \n",
    "                                       lstm_3Dcnn_model, gru_3Dcnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# 1D CNN\n",
    "n_input_time = X.shape[1]\n",
    "n_input_channel = X.shape[2]\n",
    "filter_size = 10\n",
    "\n",
    "# 3D CNN\n",
    "# n_input_channel = [X.shape[1], X.shape[2]]\n",
    "# n_input_time = X.shape[3]\n",
    "# filter_size = 2\n",
    "\n",
    "n_filters = 100\n",
    "n_units = 800\n",
    "reg_lambda = 1e-6\n",
    "bidir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model, inf_enc, inf_dec = lstm_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = lstm_3Dcnn_model(n_input_time, n_input_x, n_input_y, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = gru_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = gru_3Dcnn_model(n_input_time, n_input_x, n_input_y, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"training_lstm_final\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 111)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 20, 100)      111100      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 10)]   0           []                               \n",
      "                                                                                                  \n",
      " training_lstm_initial (Functio  (None, None, 10)    5486410     ['conv1d[0][0]',                 \n",
      " nal)                                                             'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,597,510\n",
      "Trainable params: 5,597,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"training_lstm_initial\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20, 100)]    0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 10)]   0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 800),        2883200     ['input_3[0][0]']                \n",
      "                                 (None, 800),                                                     \n",
      "                                 (None, 800)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 800),  2595200     ['input_2[0][0]',                \n",
      "                                 (None, 800),                     'lstm[1][1]',                   \n",
      "                                 (None, 800)]                     'lstm[1][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 10)     8010        ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,486,410\n",
      "Trainable params: 5,486,410\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"inf_enc_lstm_final\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 111)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 20, 100)           111100    \n",
      "                                                                 \n",
      " inf_enc_lstm_initial (Funct  [(None, 800),            2883200   \n",
      " ional)                       (None, 800)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,994,300\n",
      "Trainable params: 2,994,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"inf_enc_lstm_initial\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 20, 100)]         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 800),             2883200   \n",
      "                              (None, 800),                       \n",
      "                              (None, 800)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,883,200\n",
      "Trainable params: 2,883,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"inf_dec_lstm\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 10)]   0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 800)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 800)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 800),  2595200     ['input_2[0][0]',                \n",
      "                                 (None, 800),                     'input_5[0][0]',                \n",
      "                                 (None, 800)]                     'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 10)     8010        ['lstm_1[2][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,603,210\n",
      "Trainable params: 2,603,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_model.summary())\n",
    "print(train_model.layers[-1].summary())\n",
    "print(inf_enc.summary())\n",
    "print(inf_enc.layers[-1].summary())\n",
    "print(inf_dec.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from train.optimize import encDecHyperModel, encDecTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_model = encDecHyperModel(lstm_1Dcnn_model, n_input_time, n_input_channel, n_output)\n",
    "rnn_optimizer = encDecTuner(hypermodel=hyper_model, oracle=kt.oracles.RandomSearchOracle(objective=kt.Objective('val_accuracy', direction='max'), max_trials=200), directory='data/rnn_tuning', project_name='S14_1Dcnn_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 16m 45s]\n",
      "val_accuracy: 0.4132457163389977\n",
      "\n",
      "Best val_accuracy So Far: 0.4132457163389977\n",
      "Total elapsed time: 02h 18m 11s\n",
      "\n",
      "Search: Running Trial #13\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "20                |10                |num_filts\n",
      "4                 |4                 |filt_size\n",
      "500               |700               |rnn_units\n",
      "0.1               |1e-06             |reg_lambda\n",
      "0.0001            |0.0001            |learning_rate\n",
      "32                |32                |batch_size\n",
      "\n",
      "========== Fold 1 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 3s 235ms/step - loss: 210.4945 - accuracy: 0.0647 - val_loss: 207.8886 - val_accuracy: 0.1111\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 206.6918 - accuracy: 0.1194 - val_loss: 204.1626 - val_accuracy: 0.1556\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 203.0060 - accuracy: 0.0970 - val_loss: 200.5527 - val_accuracy: 0.2000\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 199.4385 - accuracy: 0.1194 - val_loss: 197.0638 - val_accuracy: 0.2000\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 195.9875 - accuracy: 0.1244 - val_loss: 193.6926 - val_accuracy: 0.2000\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 192.6555 - accuracy: 0.1194 - val_loss: 190.4365 - val_accuracy: 0.2000\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 189.4383 - accuracy: 0.1244 - val_loss: 187.2970 - val_accuracy: 0.2000\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 186.3353 - accuracy: 0.1169 - val_loss: 184.2671 - val_accuracy: 0.2000\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 183.3414 - accuracy: 0.1169 - val_loss: 181.3485 - val_accuracy: 0.1333\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 180.4538 - accuracy: 0.1095 - val_loss: 178.5381 - val_accuracy: 0.1778\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 177.6684 - accuracy: 0.1045 - val_loss: 175.8274 - val_accuracy: 0.1111\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 174.9822 - accuracy: 0.1318 - val_loss: 173.2083 - val_accuracy: 0.1111\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 172.3902 - accuracy: 0.1318 - val_loss: 170.6749 - val_accuracy: 0.1556\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 169.8885 - accuracy: 0.1343 - val_loss: 168.2289 - val_accuracy: 0.2444\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 167.4743 - accuracy: 0.1517 - val_loss: 165.8697 - val_accuracy: 0.1556\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 165.1434 - accuracy: 0.1468 - val_loss: 163.5931 - val_accuracy: 0.1333\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 162.8923 - accuracy: 0.1418 - val_loss: 161.3968 - val_accuracy: 0.1333\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 160.7175 - accuracy: 0.1443 - val_loss: 159.2745 - val_accuracy: 0.1111\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 158.6173 - accuracy: 0.1468 - val_loss: 157.2238 - val_accuracy: 0.1111\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 156.5877 - accuracy: 0.1443 - val_loss: 155.2413 - val_accuracy: 0.1111\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 154.6254 - accuracy: 0.1393 - val_loss: 153.3257 - val_accuracy: 0.1111\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 152.7286 - accuracy: 0.1617 - val_loss: 151.4728 - val_accuracy: 0.0667\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 150.8940 - accuracy: 0.1617 - val_loss: 149.6804 - val_accuracy: 0.0667\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 149.1205 - accuracy: 0.1642 - val_loss: 147.9442 - val_accuracy: 0.1111\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 147.4042 - accuracy: 0.1592 - val_loss: 146.2647 - val_accuracy: 0.1111\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 145.7440 - accuracy: 0.1567 - val_loss: 144.6353 - val_accuracy: 0.1556\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 144.1376 - accuracy: 0.1368 - val_loss: 143.0613 - val_accuracy: 0.1556\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 142.5832 - accuracy: 0.1418 - val_loss: 141.5397 - val_accuracy: 0.1556\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 141.0781 - accuracy: 0.1517 - val_loss: 140.0674 - val_accuracy: 0.1778\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 139.6208 - accuracy: 0.1766 - val_loss: 138.6416 - val_accuracy: 0.1556\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 138.2095 - accuracy: 0.1592 - val_loss: 137.2593 - val_accuracy: 0.2000\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 136.8432 - accuracy: 0.1642 - val_loss: 135.9218 - val_accuracy: 0.2000\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135.5196 - accuracy: 0.1617 - val_loss: 134.6282 - val_accuracy: 0.2000\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 134.2377 - accuracy: 0.1692 - val_loss: 133.3753 - val_accuracy: 0.1556\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 132.9955 - accuracy: 0.1642 - val_loss: 132.1633 - val_accuracy: 0.1333\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 131.7915 - accuracy: 0.1517 - val_loss: 130.9865 - val_accuracy: 0.1333\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 130.6252 - accuracy: 0.1517 - val_loss: 129.8465 - val_accuracy: 0.1111\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 129.4945 - accuracy: 0.1592 - val_loss: 128.7401 - val_accuracy: 0.1111\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 128.3991 - accuracy: 0.1667 - val_loss: 127.6631 - val_accuracy: 0.1778\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 127.3362 - accuracy: 0.1418 - val_loss: 126.6190 - val_accuracy: 0.1556\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 126.3052 - accuracy: 0.1368 - val_loss: 125.6077 - val_accuracy: 0.1556\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 125.3057 - accuracy: 0.1368 - val_loss: 124.6292 - val_accuracy: 0.1556\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 124.3359 - accuracy: 0.1393 - val_loss: 123.6837 - val_accuracy: 0.1111\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 123.3956 - accuracy: 0.1542 - val_loss: 122.7617 - val_accuracy: 0.1778\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 122.4817 - accuracy: 0.1617 - val_loss: 121.8681 - val_accuracy: 0.1333\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 121.5953 - accuracy: 0.1468 - val_loss: 121.0032 - val_accuracy: 0.1333\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 120.7361 - accuracy: 0.1542 - val_loss: 120.1637 - val_accuracy: 0.1333\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 119.9015 - accuracy: 0.1741 - val_loss: 119.3456 - val_accuracy: 0.2000\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 119.0910 - accuracy: 0.1816 - val_loss: 118.5509 - val_accuracy: 0.1556\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 118.3039 - accuracy: 0.1692 - val_loss: 117.7793 - val_accuracy: 0.1778\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 117.5400 - accuracy: 0.1443 - val_loss: 117.0285 - val_accuracy: 0.1778\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 116.7972 - accuracy: 0.1667 - val_loss: 116.2992 - val_accuracy: 0.2000\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 116.0767 - accuracy: 0.1567 - val_loss: 115.5909 - val_accuracy: 0.2000\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 115.3764 - accuracy: 0.1592 - val_loss: 114.9058 - val_accuracy: 0.2000\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 114.6955 - accuracy: 0.1617 - val_loss: 114.2389 - val_accuracy: 0.2000\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 114.0336 - accuracy: 0.1617 - val_loss: 113.5876 - val_accuracy: 0.2000\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 113.3900 - accuracy: 0.1592 - val_loss: 112.9498 - val_accuracy: 0.2000\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 112.7648 - accuracy: 0.1567 - val_loss: 112.3348 - val_accuracy: 0.2000\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 112.1560 - accuracy: 0.1667 - val_loss: 111.7404 - val_accuracy: 0.1556\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 111.5648 - accuracy: 0.1443 - val_loss: 111.1605 - val_accuracy: 0.1111\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 110.9888 - accuracy: 0.1617 - val_loss: 110.5957 - val_accuracy: 0.1111\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 110.4289 - accuracy: 0.1592 - val_loss: 110.0462 - val_accuracy: 0.1111\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 109.8843 - accuracy: 0.1592 - val_loss: 109.5104 - val_accuracy: 0.1111\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 109.3541 - accuracy: 0.1692 - val_loss: 108.9884 - val_accuracy: 0.2000\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 108.8376 - accuracy: 0.1592 - val_loss: 108.4810 - val_accuracy: 0.2000\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 108.3359 - accuracy: 0.1567 - val_loss: 107.9879 - val_accuracy: 0.2000\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 107.8466 - accuracy: 0.1567 - val_loss: 107.5069 - val_accuracy: 0.2000\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 107.3690 - accuracy: 0.1592 - val_loss: 107.0398 - val_accuracy: 0.2000\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 106.9055 - accuracy: 0.1592 - val_loss: 106.5843 - val_accuracy: 0.2000\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 106.4540 - accuracy: 0.1642 - val_loss: 106.1404 - val_accuracy: 0.2000\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 106.0132 - accuracy: 0.1716 - val_loss: 105.7053 - val_accuracy: 0.2444\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 105.5829 - accuracy: 0.1468 - val_loss: 105.2762 - val_accuracy: 0.2222\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 105.1653 - accuracy: 0.1418 - val_loss: 104.8610 - val_accuracy: 0.2222\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104.7572 - accuracy: 0.1418 - val_loss: 104.4624 - val_accuracy: 0.2222\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104.3581 - accuracy: 0.1418 - val_loss: 104.0730 - val_accuracy: 0.2444\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 103.9693 - accuracy: 0.1692 - val_loss: 103.6947 - val_accuracy: 0.1556\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 103.5901 - accuracy: 0.1567 - val_loss: 103.3278 - val_accuracy: 0.1111\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 103.2209 - accuracy: 0.1592 - val_loss: 102.9684 - val_accuracy: 0.1111\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 102.8605 - accuracy: 0.1741 - val_loss: 102.6151 - val_accuracy: 0.0667\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 102.5080 - accuracy: 0.1766 - val_loss: 102.2716 - val_accuracy: 0.1111\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 102.1646 - accuracy: 0.1542 - val_loss: 101.9300 - val_accuracy: 0.1333\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.8279 - accuracy: 0.1517 - val_loss: 101.5949 - val_accuracy: 0.1333\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.4989 - accuracy: 0.1517 - val_loss: 101.2710 - val_accuracy: 0.1333\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.1786 - accuracy: 0.1517 - val_loss: 100.9570 - val_accuracy: 0.1333\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100.8645 - accuracy: 0.1517 - val_loss: 100.6471 - val_accuracy: 0.1333\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100.5586 - accuracy: 0.1667 - val_loss: 100.3437 - val_accuracy: 0.1111\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100.2601 - accuracy: 0.1542 - val_loss: 100.0479 - val_accuracy: 0.1333\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.9670 - accuracy: 0.1592 - val_loss: 99.7612 - val_accuracy: 0.1111\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.6796 - accuracy: 0.1592 - val_loss: 99.4786 - val_accuracy: 0.1111\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 99.3990 - accuracy: 0.1592 - val_loss: 99.2032 - val_accuracy: 0.1111\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 99.1245 - accuracy: 0.1592 - val_loss: 98.9318 - val_accuracy: 0.1111\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.8568 - accuracy: 0.1642 - val_loss: 98.6635 - val_accuracy: 0.2000\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.5935 - accuracy: 0.1692 - val_loss: 98.4036 - val_accuracy: 0.2000\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.3353 - accuracy: 0.1567 - val_loss: 98.1466 - val_accuracy: 0.2000\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.0835 - accuracy: 0.1567 - val_loss: 97.8978 - val_accuracy: 0.2000\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.8368 - accuracy: 0.1567 - val_loss: 97.6561 - val_accuracy: 0.2000\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.5944 - accuracy: 0.1567 - val_loss: 97.4195 - val_accuracy: 0.2000\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.3565 - accuracy: 0.1567 - val_loss: 97.1833 - val_accuracy: 0.2000\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.1220 - accuracy: 0.1766 - val_loss: 96.9526 - val_accuracy: 0.1111\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96.8954 - accuracy: 0.1592 - val_loss: 96.7244 - val_accuracy: 0.1111\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.6712 - accuracy: 0.1667 - val_loss: 96.5014 - val_accuracy: 0.1778\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.4505 - accuracy: 0.1716 - val_loss: 96.2843 - val_accuracy: 0.1778\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.2356 - accuracy: 0.1493 - val_loss: 96.0711 - val_accuracy: 0.2000\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.0225 - accuracy: 0.1617 - val_loss: 95.8585 - val_accuracy: 0.2222\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.8141 - accuracy: 0.1443 - val_loss: 95.6566 - val_accuracy: 0.1556\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.6097 - accuracy: 0.1368 - val_loss: 95.4585 - val_accuracy: 0.1778\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.4089 - accuracy: 0.1592 - val_loss: 95.2662 - val_accuracy: 0.1111\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.2117 - accuracy: 0.1592 - val_loss: 95.0758 - val_accuracy: 0.1111\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95.0183 - accuracy: 0.1592 - val_loss: 94.8840 - val_accuracy: 0.1111\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.8271 - accuracy: 0.1592 - val_loss: 94.6958 - val_accuracy: 0.1333\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.6399 - accuracy: 0.1741 - val_loss: 94.5054 - val_accuracy: 0.2000\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.4550 - accuracy: 0.1567 - val_loss: 94.3166 - val_accuracy: 0.2000\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94.2735 - accuracy: 0.1567 - val_loss: 94.1325 - val_accuracy: 0.2000\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.0948 - accuracy: 0.1567 - val_loss: 93.9542 - val_accuracy: 0.2000\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9185 - accuracy: 0.1567 - val_loss: 93.7799 - val_accuracy: 0.2000\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.7462 - accuracy: 0.1567 - val_loss: 93.6103 - val_accuracy: 0.2000\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.5746 - accuracy: 0.1567 - val_loss: 93.4438 - val_accuracy: 0.2000\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.4060 - accuracy: 0.1567 - val_loss: 93.2776 - val_accuracy: 0.2000\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93.2402 - accuracy: 0.1567 - val_loss: 93.1137 - val_accuracy: 0.2000\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.0768 - accuracy: 0.1642 - val_loss: 92.9534 - val_accuracy: 0.1111\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.9156 - accuracy: 0.1592 - val_loss: 92.7937 - val_accuracy: 0.1111\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.7561 - accuracy: 0.1592 - val_loss: 92.6392 - val_accuracy: 0.1111\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.6002 - accuracy: 0.1592 - val_loss: 92.4887 - val_accuracy: 0.1111\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.4456 - accuracy: 0.1592 - val_loss: 92.3323 - val_accuracy: 0.1111\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.2927 - accuracy: 0.1592 - val_loss: 92.1765 - val_accuracy: 0.1111\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.1419 - accuracy: 0.1443 - val_loss: 92.0258 - val_accuracy: 0.2000\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.9926 - accuracy: 0.1567 - val_loss: 91.8783 - val_accuracy: 0.2000\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91.8462 - accuracy: 0.1567 - val_loss: 91.7338 - val_accuracy: 0.2000\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.7010 - accuracy: 0.1592 - val_loss: 91.5925 - val_accuracy: 0.1778\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91.5582 - accuracy: 0.1517 - val_loss: 91.4520 - val_accuracy: 0.1556\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.4169 - accuracy: 0.1368 - val_loss: 91.3116 - val_accuracy: 0.1556\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.2776 - accuracy: 0.1468 - val_loss: 91.1725 - val_accuracy: 0.2000\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.1378 - accuracy: 0.1493 - val_loss: 91.0343 - val_accuracy: 0.1111\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.0022 - accuracy: 0.1592 - val_loss: 90.8921 - val_accuracy: 0.1778\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.8656 - accuracy: 0.1493 - val_loss: 90.7553 - val_accuracy: 0.1556\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.7319 - accuracy: 0.1368 - val_loss: 90.6230 - val_accuracy: 0.1556\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.5999 - accuracy: 0.1393 - val_loss: 90.4908 - val_accuracy: 0.1778\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.4677 - accuracy: 0.1617 - val_loss: 90.3637 - val_accuracy: 0.1111\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.3379 - accuracy: 0.1617 - val_loss: 90.2399 - val_accuracy: 0.1333\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.2090 - accuracy: 0.1592 - val_loss: 90.1150 - val_accuracy: 0.0889\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.0816 - accuracy: 0.1368 - val_loss: 89.9922 - val_accuracy: 0.0889\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.9557 - accuracy: 0.1418 - val_loss: 89.8689 - val_accuracy: 0.1556\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.8300 - accuracy: 0.1368 - val_loss: 89.7429 - val_accuracy: 0.1556\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.7059 - accuracy: 0.1592 - val_loss: 89.6162 - val_accuracy: 0.2000\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.5830 - accuracy: 0.1567 - val_loss: 89.4900 - val_accuracy: 0.2000\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.4608 - accuracy: 0.1567 - val_loss: 89.3706 - val_accuracy: 0.2000\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.3404 - accuracy: 0.1567 - val_loss: 89.2536 - val_accuracy: 0.1556\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.2207 - accuracy: 0.1393 - val_loss: 89.1365 - val_accuracy: 0.1556\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.1019 - accuracy: 0.1517 - val_loss: 89.0170 - val_accuracy: 0.2000\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.9838 - accuracy: 0.1617 - val_loss: 88.8995 - val_accuracy: 0.2000\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.8670 - accuracy: 0.1343 - val_loss: 88.7791 - val_accuracy: 0.1111\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.7508 - accuracy: 0.1841 - val_loss: 88.6609 - val_accuracy: 0.2000\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.6349 - accuracy: 0.1567 - val_loss: 88.5439 - val_accuracy: 0.2000\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.5203 - accuracy: 0.1567 - val_loss: 88.4272 - val_accuracy: 0.2000\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.4074 - accuracy: 0.1567 - val_loss: 88.3096 - val_accuracy: 0.2000\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.2953 - accuracy: 0.1567 - val_loss: 88.1906 - val_accuracy: 0.2222\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.1840 - accuracy: 0.1716 - val_loss: 88.0745 - val_accuracy: 0.2444\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0724 - accuracy: 0.1493 - val_loss: 87.9655 - val_accuracy: 0.2222\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.9610 - accuracy: 0.1418 - val_loss: 87.8573 - val_accuracy: 0.2222\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.8507 - accuracy: 0.1517 - val_loss: 87.7498 - val_accuracy: 0.2222\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.7407 - accuracy: 0.1642 - val_loss: 87.6494 - val_accuracy: 0.2000\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.6334 - accuracy: 0.1567 - val_loss: 87.5495 - val_accuracy: 0.2000\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.5260 - accuracy: 0.1542 - val_loss: 87.4441 - val_accuracy: 0.1556\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.4191 - accuracy: 0.1468 - val_loss: 87.3307 - val_accuracy: 0.2000\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.3118 - accuracy: 0.1567 - val_loss: 87.2190 - val_accuracy: 0.2000\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.2051 - accuracy: 0.1567 - val_loss: 87.1103 - val_accuracy: 0.2000\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 87.0995 - accuracy: 0.1567 - val_loss: 87.0055 - val_accuracy: 0.2000\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.9949 - accuracy: 0.1592 - val_loss: 86.9042 - val_accuracy: 0.1778\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.8907 - accuracy: 0.1517 - val_loss: 86.7963 - val_accuracy: 0.2444\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.7868 - accuracy: 0.1517 - val_loss: 86.6909 - val_accuracy: 0.2222\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.6834 - accuracy: 0.1468 - val_loss: 86.5916 - val_accuracy: 0.2222\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.5801 - accuracy: 0.1617 - val_loss: 86.4948 - val_accuracy: 0.2000\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.4780 - accuracy: 0.1567 - val_loss: 86.3957 - val_accuracy: 0.2000\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.3768 - accuracy: 0.1617 - val_loss: 86.2971 - val_accuracy: 0.1556\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.2757 - accuracy: 0.1642 - val_loss: 86.1954 - val_accuracy: 0.1778\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.1748 - accuracy: 0.1716 - val_loss: 86.0907 - val_accuracy: 0.2000\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0740 - accuracy: 0.1567 - val_loss: 85.9919 - val_accuracy: 0.2000\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.9738 - accuracy: 0.1567 - val_loss: 85.8923 - val_accuracy: 0.2000\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.8739 - accuracy: 0.1567 - val_loss: 85.7929 - val_accuracy: 0.2000\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.7749 - accuracy: 0.1567 - val_loss: 85.6993 - val_accuracy: 0.2000\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.6757 - accuracy: 0.1567 - val_loss: 85.6039 - val_accuracy: 0.2000\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.5775 - accuracy: 0.1567 - val_loss: 85.5048 - val_accuracy: 0.2000\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.4792 - accuracy: 0.1567 - val_loss: 85.4013 - val_accuracy: 0.2000\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.3818 - accuracy: 0.1567 - val_loss: 85.2982 - val_accuracy: 0.2000\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.2840 - accuracy: 0.1617 - val_loss: 85.2020 - val_accuracy: 0.1111\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.1867 - accuracy: 0.1592 - val_loss: 85.1037 - val_accuracy: 0.1111\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.0903 - accuracy: 0.1592 - val_loss: 85.0094 - val_accuracy: 0.1111\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.9939 - accuracy: 0.1592 - val_loss: 84.9145 - val_accuracy: 0.1111\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84.8977 - accuracy: 0.1592 - val_loss: 84.8170 - val_accuracy: 0.1111\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.8024 - accuracy: 0.1592 - val_loss: 84.7189 - val_accuracy: 0.1111\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.7066 - accuracy: 0.1592 - val_loss: 84.6182 - val_accuracy: 0.1556\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.6124 - accuracy: 0.1368 - val_loss: 84.5217 - val_accuracy: 0.1556\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.5180 - accuracy: 0.1368 - val_loss: 84.4257 - val_accuracy: 0.1556\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.4235 - accuracy: 0.1318 - val_loss: 84.3328 - val_accuracy: 0.2222\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.3286 - accuracy: 0.1567 - val_loss: 84.2397 - val_accuracy: 0.2222\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.2352 - accuracy: 0.1592 - val_loss: 84.1505 - val_accuracy: 0.2000\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.1407 - accuracy: 0.1567 - val_loss: 84.0597 - val_accuracy: 0.2000\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.0479 - accuracy: 0.1493 - val_loss: 83.9692 - val_accuracy: 0.1111\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.9549 - accuracy: 0.1592 - val_loss: 83.8798 - val_accuracy: 0.1111\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.8613 - accuracy: 0.1592 - val_loss: 83.7838 - val_accuracy: 0.1111\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.7682 - accuracy: 0.1592 - val_loss: 83.6867 - val_accuracy: 0.1111\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.6761 - accuracy: 0.1443 - val_loss: 83.5946 - val_accuracy: 0.2000\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83.5832 - accuracy: 0.1567 - val_loss: 83.5070 - val_accuracy: 0.2000\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.4912 - accuracy: 0.1567 - val_loss: 83.4176 - val_accuracy: 0.2000\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3996 - accuracy: 0.1567 - val_loss: 83.3268 - val_accuracy: 0.2000\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3080 - accuracy: 0.1567 - val_loss: 83.2372 - val_accuracy: 0.1333\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.2169 - accuracy: 0.1393 - val_loss: 83.1467 - val_accuracy: 0.1111\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.1251 - accuracy: 0.1592 - val_loss: 83.0507 - val_accuracy: 0.1111\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.0344 - accuracy: 0.1592 - val_loss: 82.9594 - val_accuracy: 0.1111\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82.9447 - accuracy: 0.1592 - val_loss: 82.8668 - val_accuracy: 0.1111\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.8542 - accuracy: 0.1642 - val_loss: 82.7744 - val_accuracy: 0.2000\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.7646 - accuracy: 0.1567 - val_loss: 82.6844 - val_accuracy: 0.2000\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.6743 - accuracy: 0.1567 - val_loss: 82.5933 - val_accuracy: 0.2000\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.5839 - accuracy: 0.1567 - val_loss: 82.5028 - val_accuracy: 0.2000\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.4936 - accuracy: 0.1567 - val_loss: 82.4110 - val_accuracy: 0.2000\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.4038 - accuracy: 0.1592 - val_loss: 82.3204 - val_accuracy: 0.1111\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.3149 - accuracy: 0.1592 - val_loss: 82.2337 - val_accuracy: 0.1111\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2254 - accuracy: 0.1592 - val_loss: 82.1465 - val_accuracy: 0.1111\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.1361 - accuracy: 0.1592 - val_loss: 82.0593 - val_accuracy: 0.1111\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.0478 - accuracy: 0.1741 - val_loss: 81.9707 - val_accuracy: 0.1778\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.9584 - accuracy: 0.1692 - val_loss: 81.8785 - val_accuracy: 0.1778\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.8699 - accuracy: 0.1716 - val_loss: 81.7847 - val_accuracy: 0.1556\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.7815 - accuracy: 0.1368 - val_loss: 81.6941 - val_accuracy: 0.1556\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.6936 - accuracy: 0.1368 - val_loss: 81.6056 - val_accuracy: 0.1556\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.6042 - accuracy: 0.1517 - val_loss: 81.5244 - val_accuracy: 0.2000\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.5176 - accuracy: 0.1592 - val_loss: 81.4433 - val_accuracy: 0.2000\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.4286 - accuracy: 0.1567 - val_loss: 81.3548 - val_accuracy: 0.2000\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.3410 - accuracy: 0.1567 - val_loss: 81.2666 - val_accuracy: 0.1111\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.2550 - accuracy: 0.1542 - val_loss: 81.1783 - val_accuracy: 0.1333\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.1678 - accuracy: 0.1567 - val_loss: 81.0871 - val_accuracy: 0.2000\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.0810 - accuracy: 0.1567 - val_loss: 80.9958 - val_accuracy: 0.2000\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.9943 - accuracy: 0.1567 - val_loss: 80.9082 - val_accuracy: 0.2000\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.9054 - accuracy: 0.1567 - val_loss: 80.8258 - val_accuracy: 0.2000\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.8179 - accuracy: 0.1443 - val_loss: 80.7472 - val_accuracy: 0.1111\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80.7305 - accuracy: 0.1493 - val_loss: 80.6635 - val_accuracy: 0.1111\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.6442 - accuracy: 0.1592 - val_loss: 80.5777 - val_accuracy: 0.1111\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.5586 - accuracy: 0.1517 - val_loss: 80.4929 - val_accuracy: 0.2000\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.4723 - accuracy: 0.1915 - val_loss: 80.4047 - val_accuracy: 0.2000\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.3854 - accuracy: 0.1617 - val_loss: 80.3140 - val_accuracy: 0.1111\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.2995 - accuracy: 0.1567 - val_loss: 80.2266 - val_accuracy: 0.1111\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.2132 - accuracy: 0.1493 - val_loss: 80.1406 - val_accuracy: 0.2000\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1260 - accuracy: 0.1567 - val_loss: 80.0520 - val_accuracy: 0.2000\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.0403 - accuracy: 0.1567 - val_loss: 79.9658 - val_accuracy: 0.2000\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.9549 - accuracy: 0.1567 - val_loss: 79.8804 - val_accuracy: 0.1111\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8691 - accuracy: 0.1542 - val_loss: 79.7990 - val_accuracy: 0.1111\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.7846 - accuracy: 0.1592 - val_loss: 79.7193 - val_accuracy: 0.1111\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6989 - accuracy: 0.1692 - val_loss: 79.6354 - val_accuracy: 0.1111\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6137 - accuracy: 0.1542 - val_loss: 79.5509 - val_accuracy: 0.0667\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.5285 - accuracy: 0.1443 - val_loss: 79.4644 - val_accuracy: 0.0667\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.4438 - accuracy: 0.1368 - val_loss: 79.3810 - val_accuracy: 0.0667\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.3595 - accuracy: 0.1368 - val_loss: 79.2952 - val_accuracy: 0.0667\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.2745 - accuracy: 0.1567 - val_loss: 79.2058 - val_accuracy: 0.1111\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.1896 - accuracy: 0.1592 - val_loss: 79.1175 - val_accuracy: 0.1111\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.1051 - accuracy: 0.1592 - val_loss: 79.0289 - val_accuracy: 0.1111\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0196 - accuracy: 0.1567 - val_loss: 78.9404 - val_accuracy: 0.1778\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.9342 - accuracy: 0.1791 - val_loss: 78.8546 - val_accuracy: 0.2000\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.8507 - accuracy: 0.1567 - val_loss: 78.7737 - val_accuracy: 0.2000\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.7665 - accuracy: 0.1567 - val_loss: 78.6871 - val_accuracy: 0.2000\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.6823 - accuracy: 0.1567 - val_loss: 78.6010 - val_accuracy: 0.2000\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5983 - accuracy: 0.1567 - val_loss: 78.5202 - val_accuracy: 0.2000\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5141 - accuracy: 0.1567 - val_loss: 78.4400 - val_accuracy: 0.2000\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.4299 - accuracy: 0.1567 - val_loss: 78.3560 - val_accuracy: 0.2000\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.3461 - accuracy: 0.1567 - val_loss: 78.2714 - val_accuracy: 0.2000\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.2622 - accuracy: 0.1567 - val_loss: 78.1867 - val_accuracy: 0.2000\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.1791 - accuracy: 0.1567 - val_loss: 78.0995 - val_accuracy: 0.2000\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.0952 - accuracy: 0.1617 - val_loss: 78.0130 - val_accuracy: 0.2222\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.0121 - accuracy: 0.1418 - val_loss: 77.9309 - val_accuracy: 0.1556\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.9282 - accuracy: 0.1493 - val_loss: 77.8545 - val_accuracy: 0.1111\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.8451 - accuracy: 0.1592 - val_loss: 77.7747 - val_accuracy: 0.1111\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.7620 - accuracy: 0.1592 - val_loss: 77.6942 - val_accuracy: 0.1111\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6790 - accuracy: 0.1592 - val_loss: 77.6107 - val_accuracy: 0.1111\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5963 - accuracy: 0.1542 - val_loss: 77.5269 - val_accuracy: 0.1111\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5134 - accuracy: 0.1368 - val_loss: 77.4415 - val_accuracy: 0.1778\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.4307 - accuracy: 0.1617 - val_loss: 77.3569 - val_accuracy: 0.1111\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.3475 - accuracy: 0.1517 - val_loss: 77.2729 - val_accuracy: 0.1111\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.2648 - accuracy: 0.1443 - val_loss: 77.1906 - val_accuracy: 0.1778\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1821 - accuracy: 0.1592 - val_loss: 77.1097 - val_accuracy: 0.1111\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.0995 - accuracy: 0.1592 - val_loss: 77.0277 - val_accuracy: 0.1111\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.0176 - accuracy: 0.1592 - val_loss: 76.9417 - val_accuracy: 0.1111\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.9349 - accuracy: 0.1791 - val_loss: 76.8557 - val_accuracy: 0.2222\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.8531 - accuracy: 0.1567 - val_loss: 76.7731 - val_accuracy: 0.2000\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76.7705 - accuracy: 0.1567 - val_loss: 76.6933 - val_accuracy: 0.2000\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.6880 - accuracy: 0.1567 - val_loss: 76.6112 - val_accuracy: 0.2000\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.6058 - accuracy: 0.1517 - val_loss: 76.5328 - val_accuracy: 0.1111\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.5240 - accuracy: 0.1592 - val_loss: 76.4537 - val_accuracy: 0.1111\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.4424 - accuracy: 0.1592 - val_loss: 76.3754 - val_accuracy: 0.1111\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.3612 - accuracy: 0.1468 - val_loss: 76.2958 - val_accuracy: 0.2000\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.2794 - accuracy: 0.1642 - val_loss: 76.2153 - val_accuracy: 0.1778\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.1981 - accuracy: 0.1517 - val_loss: 76.1347 - val_accuracy: 0.1111\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.1163 - accuracy: 0.1592 - val_loss: 76.0488 - val_accuracy: 0.1111\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.0334 - accuracy: 0.1592 - val_loss: 75.9646 - val_accuracy: 0.1111\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.9523 - accuracy: 0.1592 - val_loss: 75.8830 - val_accuracy: 0.1111\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8710 - accuracy: 0.1592 - val_loss: 75.7998 - val_accuracy: 0.1778\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.7900 - accuracy: 0.1667 - val_loss: 75.7204 - val_accuracy: 0.1111\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7097 - accuracy: 0.1592 - val_loss: 75.6444 - val_accuracy: 0.1111\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.6279 - accuracy: 0.1692 - val_loss: 75.5613 - val_accuracy: 0.1778\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.5461 - accuracy: 0.1567 - val_loss: 75.4756 - val_accuracy: 0.2000\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.4652 - accuracy: 0.1567 - val_loss: 75.3892 - val_accuracy: 0.2000\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.3842 - accuracy: 0.1567 - val_loss: 75.3085 - val_accuracy: 0.2000\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.3034 - accuracy: 0.1592 - val_loss: 75.2289 - val_accuracy: 0.2000\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.2223 - accuracy: 0.1567 - val_loss: 75.1500 - val_accuracy: 0.2000\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.1413 - accuracy: 0.1567 - val_loss: 75.0695 - val_accuracy: 0.2000\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.0608 - accuracy: 0.1567 - val_loss: 74.9851 - val_accuracy: 0.2000\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.9804 - accuracy: 0.1567 - val_loss: 74.9054 - val_accuracy: 0.2000\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.9002 - accuracy: 0.1567 - val_loss: 74.8253 - val_accuracy: 0.2444\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8194 - accuracy: 0.1741 - val_loss: 74.7470 - val_accuracy: 0.1778\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7394 - accuracy: 0.1567 - val_loss: 74.6695 - val_accuracy: 0.1111\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.6596 - accuracy: 0.1592 - val_loss: 74.5886 - val_accuracy: 0.1111\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.5788 - accuracy: 0.1592 - val_loss: 74.5074 - val_accuracy: 0.1111\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.4984 - accuracy: 0.1592 - val_loss: 74.4290 - val_accuracy: 0.1111\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.4176 - accuracy: 0.1592 - val_loss: 74.3473 - val_accuracy: 0.1111\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.3375 - accuracy: 0.1592 - val_loss: 74.2643 - val_accuracy: 0.2444\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.2573 - accuracy: 0.1741 - val_loss: 74.1855 - val_accuracy: 0.2000\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.1772 - accuracy: 0.1567 - val_loss: 74.1080 - val_accuracy: 0.2000\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.0977 - accuracy: 0.1567 - val_loss: 74.0305 - val_accuracy: 0.2000\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.0174 - accuracy: 0.1567 - val_loss: 73.9546 - val_accuracy: 0.1778\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.9384 - accuracy: 0.1567 - val_loss: 73.8772 - val_accuracy: 0.1111\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.8588 - accuracy: 0.1592 - val_loss: 73.7985 - val_accuracy: 0.1111\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.7791 - accuracy: 0.1592 - val_loss: 73.7142 - val_accuracy: 0.1111\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.6995 - accuracy: 0.1592 - val_loss: 73.6335 - val_accuracy: 0.1111\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.6199 - accuracy: 0.1592 - val_loss: 73.5520 - val_accuracy: 0.1111\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.5407 - accuracy: 0.1592 - val_loss: 73.4711 - val_accuracy: 0.1111\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.4617 - accuracy: 0.1592 - val_loss: 73.3896 - val_accuracy: 0.1111\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3819 - accuracy: 0.1617 - val_loss: 73.3094 - val_accuracy: 0.1778\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3027 - accuracy: 0.1493 - val_loss: 73.2299 - val_accuracy: 0.1556\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.2234 - accuracy: 0.1368 - val_loss: 73.1545 - val_accuracy: 0.1778\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.1443 - accuracy: 0.1642 - val_loss: 73.0771 - val_accuracy: 0.1111\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.0650 - accuracy: 0.1542 - val_loss: 72.9974 - val_accuracy: 0.2000\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.9855 - accuracy: 0.1567 - val_loss: 72.9160 - val_accuracy: 0.2000\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.9065 - accuracy: 0.1567 - val_loss: 72.8387 - val_accuracy: 0.1778\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.8282 - accuracy: 0.1443 - val_loss: 72.7577 - val_accuracy: 0.1111\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.7496 - accuracy: 0.1592 - val_loss: 72.6810 - val_accuracy: 0.1111\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.6704 - accuracy: 0.1592 - val_loss: 72.6047 - val_accuracy: 0.1111\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5916 - accuracy: 0.1592 - val_loss: 72.5267 - val_accuracy: 0.1111\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.5134 - accuracy: 0.1692 - val_loss: 72.4472 - val_accuracy: 0.1778\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.4343 - accuracy: 0.1617 - val_loss: 72.3671 - val_accuracy: 0.1778\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.3559 - accuracy: 0.1617 - val_loss: 72.2856 - val_accuracy: 0.1778\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.2776 - accuracy: 0.1667 - val_loss: 72.2117 - val_accuracy: 0.1778\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.2001 - accuracy: 0.1542 - val_loss: 72.1402 - val_accuracy: 0.1111\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.1208 - accuracy: 0.1592 - val_loss: 72.0647 - val_accuracy: 0.1111\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.0429 - accuracy: 0.1592 - val_loss: 71.9850 - val_accuracy: 0.1111\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9649 - accuracy: 0.1592 - val_loss: 71.9069 - val_accuracy: 0.1111\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8867 - accuracy: 0.1592 - val_loss: 71.8308 - val_accuracy: 0.1111\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.8091 - accuracy: 0.1368 - val_loss: 71.7480 - val_accuracy: 0.1778\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.7306 - accuracy: 0.1592 - val_loss: 71.6704 - val_accuracy: 0.1111\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.6525 - accuracy: 0.1592 - val_loss: 71.5972 - val_accuracy: 0.1111\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 71.5752 - accuracy: 0.1592 - val_loss: 71.5224 - val_accuracy: 0.1111\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4980 - accuracy: 0.1592 - val_loss: 71.4467 - val_accuracy: 0.1111\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4191 - accuracy: 0.1493 - val_loss: 71.3614 - val_accuracy: 0.1778\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.3412 - accuracy: 0.1493 - val_loss: 71.2795 - val_accuracy: 0.2000\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.2631 - accuracy: 0.1542 - val_loss: 71.1984 - val_accuracy: 0.1778\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1852 - accuracy: 0.1567 - val_loss: 71.1169 - val_accuracy: 0.1111\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.1088 - accuracy: 0.1468 - val_loss: 71.0316 - val_accuracy: 0.1556\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.0322 - accuracy: 0.1368 - val_loss: 70.9508 - val_accuracy: 0.1556\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 70.9558 - accuracy: 0.1368 - val_loss: 70.8714 - val_accuracy: 0.1556\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70.8779 - accuracy: 0.1368 - val_loss: 70.7958 - val_accuracy: 0.1556\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.7997 - accuracy: 0.1368 - val_loss: 70.7192 - val_accuracy: 0.2222\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.7217 - accuracy: 0.1418 - val_loss: 70.6460 - val_accuracy: 0.2222\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.6441 - accuracy: 0.1468 - val_loss: 70.5769 - val_accuracy: 0.2000\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.5681 - accuracy: 0.1567 - val_loss: 70.5092 - val_accuracy: 0.2000\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.4916 - accuracy: 0.1816 - val_loss: 70.4388 - val_accuracy: 0.2000\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.4143 - accuracy: 0.1766 - val_loss: 70.3627 - val_accuracy: 0.2000\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.3375 - accuracy: 0.1567 - val_loss: 70.2817 - val_accuracy: 0.2000\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.2607 - accuracy: 0.1567 - val_loss: 70.2021 - val_accuracy: 0.2000\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.1839 - accuracy: 0.1592 - val_loss: 70.1241 - val_accuracy: 0.2000\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.1076 - accuracy: 0.1716 - val_loss: 70.0475 - val_accuracy: 0.2000\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0311 - accuracy: 0.1716 - val_loss: 69.9690 - val_accuracy: 0.2000\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.9542 - accuracy: 0.1667 - val_loss: 69.8935 - val_accuracy: 0.2000\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8770 - accuracy: 0.1567 - val_loss: 69.8168 - val_accuracy: 0.2000\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8002 - accuracy: 0.1567 - val_loss: 69.7364 - val_accuracy: 0.2000\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.7238 - accuracy: 0.1567 - val_loss: 69.6584 - val_accuracy: 0.2000\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.6472 - accuracy: 0.1567 - val_loss: 69.5804 - val_accuracy: 0.2000\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.5707 - accuracy: 0.1592 - val_loss: 69.5057 - val_accuracy: 0.1778\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4944 - accuracy: 0.1542 - val_loss: 69.4274 - val_accuracy: 0.1111\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4179 - accuracy: 0.1592 - val_loss: 69.3467 - val_accuracy: 0.1111\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.3417 - accuracy: 0.1592 - val_loss: 69.2674 - val_accuracy: 0.1111\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.2657 - accuracy: 0.1592 - val_loss: 69.1924 - val_accuracy: 0.1111\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.1890 - accuracy: 0.1592 - val_loss: 69.1169 - val_accuracy: 0.1778\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.1123 - accuracy: 0.1692 - val_loss: 69.0442 - val_accuracy: 0.1778\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69.0366 - accuracy: 0.1443 - val_loss: 68.9686 - val_accuracy: 0.1778\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.9607 - accuracy: 0.1592 - val_loss: 68.8916 - val_accuracy: 0.1778\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.8856 - accuracy: 0.1468 - val_loss: 68.8166 - val_accuracy: 0.1778\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.8089 - accuracy: 0.1493 - val_loss: 68.7425 - val_accuracy: 0.2000\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.7338 - accuracy: 0.1567 - val_loss: 68.6668 - val_accuracy: 0.2000\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.6572 - accuracy: 0.1542 - val_loss: 68.5883 - val_accuracy: 0.1778\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.5811 - accuracy: 0.1567 - val_loss: 68.5098 - val_accuracy: 0.1778\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.5056 - accuracy: 0.1667 - val_loss: 68.4298 - val_accuracy: 0.2444\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.4309 - accuracy: 0.1542 - val_loss: 68.3520 - val_accuracy: 0.1778\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.3555 - accuracy: 0.1567 - val_loss: 68.2800 - val_accuracy: 0.1111\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2795 - accuracy: 0.1592 - val_loss: 68.2098 - val_accuracy: 0.1111\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2042 - accuracy: 0.1592 - val_loss: 68.1389 - val_accuracy: 0.1111\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.1287 - accuracy: 0.1592 - val_loss: 68.0643 - val_accuracy: 0.1111\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.0543 - accuracy: 0.1592 - val_loss: 67.9916 - val_accuracy: 0.1778\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67.9782 - accuracy: 0.1542 - val_loss: 67.9115 - val_accuracy: 0.2000\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9034 - accuracy: 0.1567 - val_loss: 67.8300 - val_accuracy: 0.2000\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.8283 - accuracy: 0.1567 - val_loss: 67.7545 - val_accuracy: 0.2000\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.7531 - accuracy: 0.1617 - val_loss: 67.6850 - val_accuracy: 0.1778\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.6783 - accuracy: 0.1692 - val_loss: 67.6124 - val_accuracy: 0.1778\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.6050 - accuracy: 0.1692 - val_loss: 67.5362 - val_accuracy: 0.1778\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.5295 - accuracy: 0.1493 - val_loss: 67.4616 - val_accuracy: 0.1111\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.4541 - accuracy: 0.1592 - val_loss: 67.3879 - val_accuracy: 0.1111\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3789 - accuracy: 0.1592 - val_loss: 67.3151 - val_accuracy: 0.1111\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3039 - accuracy: 0.1592 - val_loss: 67.2375 - val_accuracy: 0.1111\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.2297 - accuracy: 0.1542 - val_loss: 67.1572 - val_accuracy: 0.1778\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.1558 - accuracy: 0.1567 - val_loss: 67.0831 - val_accuracy: 0.2000\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.0808 - accuracy: 0.1567 - val_loss: 67.0137 - val_accuracy: 0.2000\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.0058 - accuracy: 0.1617 - val_loss: 66.9445 - val_accuracy: 0.2000\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9324 - accuracy: 0.1816 - val_loss: 66.8732 - val_accuracy: 0.2000\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8571 - accuracy: 0.1567 - val_loss: 66.7971 - val_accuracy: 0.2000\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.7825 - accuracy: 0.1567 - val_loss: 66.7181 - val_accuracy: 0.1778\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.7083 - accuracy: 0.1542 - val_loss: 66.6412 - val_accuracy: 0.1778\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6342 - accuracy: 0.1617 - val_loss: 66.5683 - val_accuracy: 0.1778\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5601 - accuracy: 0.1517 - val_loss: 66.4926 - val_accuracy: 0.1778\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.4854 - accuracy: 0.1542 - val_loss: 66.4184 - val_accuracy: 0.1778\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.4109 - accuracy: 0.1493 - val_loss: 66.3437 - val_accuracy: 0.2000\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3376 - accuracy: 0.1567 - val_loss: 66.2650 - val_accuracy: 0.2222\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.2636 - accuracy: 0.1766 - val_loss: 66.1880 - val_accuracy: 0.2444\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.1894 - accuracy: 0.1642 - val_loss: 66.1174 - val_accuracy: 0.2444\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.1157 - accuracy: 0.1692 - val_loss: 66.0456 - val_accuracy: 0.2222\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.0424 - accuracy: 0.1592 - val_loss: 65.9755 - val_accuracy: 0.2222\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.9682 - accuracy: 0.1517 - val_loss: 65.9014 - val_accuracy: 0.1111\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 65.8943 - accuracy: 0.1667 - val_loss: 65.8274 - val_accuracy: 0.1778\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.8205 - accuracy: 0.1642 - val_loss: 65.7570 - val_accuracy: 0.1778\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7478 - accuracy: 0.1567 - val_loss: 65.6827 - val_accuracy: 0.2000\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6726 - accuracy: 0.1567 - val_loss: 65.6033 - val_accuracy: 0.2000\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6003 - accuracy: 0.1642 - val_loss: 65.5257 - val_accuracy: 0.2444\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.5278 - accuracy: 0.1567 - val_loss: 65.4498 - val_accuracy: 0.2222\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4548 - accuracy: 0.1592 - val_loss: 65.3803 - val_accuracy: 0.2000\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.3812 - accuracy: 0.1567 - val_loss: 65.3144 - val_accuracy: 0.2000\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3075 - accuracy: 0.1567 - val_loss: 65.2484 - val_accuracy: 0.2000\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.2341 - accuracy: 0.1567 - val_loss: 65.1813 - val_accuracy: 0.2000\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.1629 - accuracy: 0.1567 - val_loss: 65.1082 - val_accuracy: 0.2000\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.0885 - accuracy: 0.1567 - val_loss: 65.0298 - val_accuracy: 0.2000\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 65.0153 - accuracy: 0.1567 - val_loss: 64.9545 - val_accuracy: 0.2000\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.9418 - accuracy: 0.1567 - val_loss: 64.8748 - val_accuracy: 0.2000\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.8682 - accuracy: 0.1567 - val_loss: 64.7986 - val_accuracy: 0.2000\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.7963 - accuracy: 0.1567 - val_loss: 64.7240 - val_accuracy: 0.2000\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.7234 - accuracy: 0.1567 - val_loss: 64.6537 - val_accuracy: 0.2000\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.6499 - accuracy: 0.1592 - val_loss: 64.5835 - val_accuracy: 0.1111\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.5775 - accuracy: 0.1592 - val_loss: 64.5192 - val_accuracy: 0.1111\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.5051 - accuracy: 0.1592 - val_loss: 64.4512 - val_accuracy: 0.0667\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.4327 - accuracy: 0.1493 - val_loss: 64.3809 - val_accuracy: 0.0667\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.3603 - accuracy: 0.1667 - val_loss: 64.3059 - val_accuracy: 0.1111\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.2878 - accuracy: 0.1592 - val_loss: 64.2282 - val_accuracy: 0.1778\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.2152 - accuracy: 0.1567 - val_loss: 64.1533 - val_accuracy: 0.2000\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.1426 - accuracy: 0.1567 - val_loss: 64.0810 - val_accuracy: 0.2000\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.0695 - accuracy: 0.1567 - val_loss: 64.0082 - val_accuracy: 0.2000\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.9978 - accuracy: 0.1567 - val_loss: 63.9340 - val_accuracy: 0.2000\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.9256 - accuracy: 0.1567 - val_loss: 63.8644 - val_accuracy: 0.2000\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.8529 - accuracy: 0.1567 - val_loss: 63.7928 - val_accuracy: 0.2000\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7807 - accuracy: 0.1567 - val_loss: 63.7248 - val_accuracy: 0.2000\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7108 - accuracy: 0.1368 - val_loss: 63.6538 - val_accuracy: 0.1556\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.6372 - accuracy: 0.1567 - val_loss: 63.5715 - val_accuracy: 0.2000\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.5646 - accuracy: 0.1567 - val_loss: 63.4959 - val_accuracy: 0.2222\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4929 - accuracy: 0.1692 - val_loss: 63.4241 - val_accuracy: 0.2000\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.4205 - accuracy: 0.1567 - val_loss: 63.3543 - val_accuracy: 0.2000\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3492 - accuracy: 0.1592 - val_loss: 63.2835 - val_accuracy: 0.1778\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.2770 - accuracy: 0.1642 - val_loss: 63.2127 - val_accuracy: 0.2000\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.2055 - accuracy: 0.1567 - val_loss: 63.1409 - val_accuracy: 0.2000\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.1342 - accuracy: 0.1567 - val_loss: 63.0658 - val_accuracy: 0.2000\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.0625 - accuracy: 0.1667 - val_loss: 62.9923 - val_accuracy: 0.1778\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9913 - accuracy: 0.1393 - val_loss: 62.9193 - val_accuracy: 0.1556\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.9204 - accuracy: 0.1493 - val_loss: 62.8483 - val_accuracy: 0.1556\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.8493 - accuracy: 0.1567 - val_loss: 62.7813 - val_accuracy: 0.1111\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.7773 - accuracy: 0.1592 - val_loss: 62.7157 - val_accuracy: 0.1111\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.7063 - accuracy: 0.1915 - val_loss: 62.6498 - val_accuracy: 0.2222\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.6349 - accuracy: 0.1990 - val_loss: 62.5812 - val_accuracy: 0.0444\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.5631 - accuracy: 0.1692 - val_loss: 62.5095 - val_accuracy: 0.1111\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.4917 - accuracy: 0.1567 - val_loss: 62.4321 - val_accuracy: 0.1111\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.4190 - accuracy: 0.1592 - val_loss: 62.3484 - val_accuracy: 0.1556\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.3502 - accuracy: 0.1368 - val_loss: 62.2687 - val_accuracy: 0.1556\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.2815 - accuracy: 0.1343 - val_loss: 62.1925 - val_accuracy: 0.2222\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.2105 - accuracy: 0.1418 - val_loss: 62.1239 - val_accuracy: 0.2222\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.1378 - accuracy: 0.1418 - val_loss: 62.0606 - val_accuracy: 0.2222\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.0658 - accuracy: 0.1517 - val_loss: 61.9978 - val_accuracy: 0.2000\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9943 - accuracy: 0.1567 - val_loss: 61.9343 - val_accuracy: 0.2000\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9236 - accuracy: 0.1567 - val_loss: 61.8663 - val_accuracy: 0.2000\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.8534 - accuracy: 0.1592 - val_loss: 61.7984 - val_accuracy: 0.1778\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.7828 - accuracy: 0.1741 - val_loss: 61.7291 - val_accuracy: 0.1778\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7115 - accuracy: 0.1667 - val_loss: 61.6551 - val_accuracy: 0.2000\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.6414 - accuracy: 0.1592 - val_loss: 61.5779 - val_accuracy: 0.2000\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.5707 - accuracy: 0.1567 - val_loss: 61.5000 - val_accuracy: 0.2444\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.5003 - accuracy: 0.1443 - val_loss: 61.4266 - val_accuracy: 0.1556\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4300 - accuracy: 0.1493 - val_loss: 61.3555 - val_accuracy: 0.1778\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3601 - accuracy: 0.1667 - val_loss: 61.2870 - val_accuracy: 0.2222\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2891 - accuracy: 0.1692 - val_loss: 61.2188 - val_accuracy: 0.1778\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2187 - accuracy: 0.1667 - val_loss: 61.1501 - val_accuracy: 0.1778\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.1481 - accuracy: 0.1692 - val_loss: 61.0832 - val_accuracy: 0.1778\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0781 - accuracy: 0.1517 - val_loss: 61.0154 - val_accuracy: 0.1778\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.0082 - accuracy: 0.1567 - val_loss: 60.9454 - val_accuracy: 0.2000\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.9380 - accuracy: 0.1567 - val_loss: 60.8756 - val_accuracy: 0.2000\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.8680 - accuracy: 0.1567 - val_loss: 60.8082 - val_accuracy: 0.2000\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.7973 - accuracy: 0.1567 - val_loss: 60.7364 - val_accuracy: 0.2000\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.7274 - accuracy: 0.1567 - val_loss: 60.6643 - val_accuracy: 0.2000\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.6577 - accuracy: 0.1642 - val_loss: 60.5899 - val_accuracy: 0.2222\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5885 - accuracy: 0.1368 - val_loss: 60.5174 - val_accuracy: 0.1556\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5194 - accuracy: 0.1368 - val_loss: 60.4460 - val_accuracy: 0.1556\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4492 - accuracy: 0.1468 - val_loss: 60.3805 - val_accuracy: 0.1111\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.3793 - accuracy: 0.1592 - val_loss: 60.3098 - val_accuracy: 0.1111\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.3103 - accuracy: 0.1592 - val_loss: 60.2443 - val_accuracy: 0.1111\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.2405 - accuracy: 0.1592 - val_loss: 60.1783 - val_accuracy: 0.1111\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.1713 - accuracy: 0.1592 - val_loss: 60.1136 - val_accuracy: 0.1111\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.1018 - accuracy: 0.1592 - val_loss: 60.0446 - val_accuracy: 0.1111\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.0321 - accuracy: 0.1592 - val_loss: 59.9712 - val_accuracy: 0.1111\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.9622 - accuracy: 0.1592 - val_loss: 59.9017 - val_accuracy: 0.1111\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8925 - accuracy: 0.1592 - val_loss: 59.8305 - val_accuracy: 0.1111\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.8237 - accuracy: 0.1592 - val_loss: 59.7581 - val_accuracy: 0.1111\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7547 - accuracy: 0.1592 - val_loss: 59.6870 - val_accuracy: 0.1111\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6856 - accuracy: 0.1592 - val_loss: 59.6195 - val_accuracy: 0.1111\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.6175 - accuracy: 0.1567 - val_loss: 59.5554 - val_accuracy: 0.1778\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.5482 - accuracy: 0.1642 - val_loss: 59.4874 - val_accuracy: 0.1778\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.4791 - accuracy: 0.1642 - val_loss: 59.4142 - val_accuracy: 0.2444\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.4100 - accuracy: 0.1517 - val_loss: 59.3414 - val_accuracy: 0.2222\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.3406 - accuracy: 0.1418 - val_loss: 59.2730 - val_accuracy: 0.2444\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.2715 - accuracy: 0.1667 - val_loss: 59.2052 - val_accuracy: 0.1556\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2030 - accuracy: 0.1642 - val_loss: 59.1326 - val_accuracy: 0.1556\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1346 - accuracy: 0.1418 - val_loss: 59.0605 - val_accuracy: 0.2222\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.0664 - accuracy: 0.1418 - val_loss: 58.9911 - val_accuracy: 0.2444\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.9973 - accuracy: 0.1667 - val_loss: 58.9250 - val_accuracy: 0.2000\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.9292 - accuracy: 0.1567 - val_loss: 58.8657 - val_accuracy: 0.2000\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.8599 - accuracy: 0.1617 - val_loss: 58.8071 - val_accuracy: 0.1333\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.7916 - accuracy: 0.1418 - val_loss: 58.7427 - val_accuracy: 0.0667\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.7244 - accuracy: 0.1368 - val_loss: 58.6777 - val_accuracy: 0.0667\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.6556 - accuracy: 0.1393 - val_loss: 58.6044 - val_accuracy: 0.1111\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.5865 - accuracy: 0.1617 - val_loss: 58.5252 - val_accuracy: 0.1778\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.5182 - accuracy: 0.1443 - val_loss: 58.4532 - val_accuracy: 0.2222\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.4497 - accuracy: 0.1692 - val_loss: 58.3821 - val_accuracy: 0.2444\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.3817 - accuracy: 0.1766 - val_loss: 58.3098 - val_accuracy: 0.2222\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.3134 - accuracy: 0.1642 - val_loss: 58.2418 - val_accuracy: 0.2000\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2447 - accuracy: 0.1567 - val_loss: 58.1776 - val_accuracy: 0.1778\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1767 - accuracy: 0.1567 - val_loss: 58.1119 - val_accuracy: 0.1778\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1086 - accuracy: 0.1642 - val_loss: 58.0444 - val_accuracy: 0.1778\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.0412 - accuracy: 0.1642 - val_loss: 57.9772 - val_accuracy: 0.1778\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.9736 - accuracy: 0.1667 - val_loss: 57.9119 - val_accuracy: 0.1778\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.9056 - accuracy: 0.1692 - val_loss: 57.8405 - val_accuracy: 0.1778\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.8390 - accuracy: 0.1517 - val_loss: 57.7666 - val_accuracy: 0.2444\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.7709 - accuracy: 0.1493 - val_loss: 57.6948 - val_accuracy: 0.2222\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7024 - accuracy: 0.1418 - val_loss: 57.6290 - val_accuracy: 0.2222\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6353 - accuracy: 0.1468 - val_loss: 57.5677 - val_accuracy: 0.1111\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5669 - accuracy: 0.1567 - val_loss: 57.5013 - val_accuracy: 0.1778\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.4994 - accuracy: 0.1642 - val_loss: 57.4331 - val_accuracy: 0.1778\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.4319 - accuracy: 0.1642 - val_loss: 57.3652 - val_accuracy: 0.1778\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3648 - accuracy: 0.1617 - val_loss: 57.2968 - val_accuracy: 0.1111\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.2972 - accuracy: 0.1592 - val_loss: 57.2313 - val_accuracy: 0.1778\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57.2297 - accuracy: 0.1642 - val_loss: 57.1652 - val_accuracy: 0.1778\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1629 - accuracy: 0.1567 - val_loss: 57.0958 - val_accuracy: 0.2000\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.0952 - accuracy: 0.1567 - val_loss: 57.0304 - val_accuracy: 0.2000\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.0277 - accuracy: 0.1567 - val_loss: 56.9667 - val_accuracy: 0.1778\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.9605 - accuracy: 0.1692 - val_loss: 56.9024 - val_accuracy: 0.1778\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8934 - accuracy: 0.1542 - val_loss: 56.8381 - val_accuracy: 0.1111\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8271 - accuracy: 0.1592 - val_loss: 56.7707 - val_accuracy: 0.1111\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7605 - accuracy: 0.1592 - val_loss: 56.6991 - val_accuracy: 0.1111\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.6937 - accuracy: 0.1592 - val_loss: 56.6279 - val_accuracy: 0.1111\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.6272 - accuracy: 0.1592 - val_loss: 56.5605 - val_accuracy: 0.1111\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5592 - accuracy: 0.1592 - val_loss: 56.4940 - val_accuracy: 0.1111\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.4920 - accuracy: 0.1716 - val_loss: 56.4264 - val_accuracy: 0.1778\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.4255 - accuracy: 0.1617 - val_loss: 56.3589 - val_accuracy: 0.1778\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56.3593 - accuracy: 0.1617 - val_loss: 56.2941 - val_accuracy: 0.1778\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.2925 - accuracy: 0.1493 - val_loss: 56.2312 - val_accuracy: 0.1111\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.2255 - accuracy: 0.1567 - val_loss: 56.1647 - val_accuracy: 0.1778\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.1588 - accuracy: 0.1617 - val_loss: 56.1002 - val_accuracy: 0.1778\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0926 - accuracy: 0.1642 - val_loss: 56.0352 - val_accuracy: 0.1778\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0263 - accuracy: 0.1642 - val_loss: 55.9679 - val_accuracy: 0.1778\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.9602 - accuracy: 0.1493 - val_loss: 55.8972 - val_accuracy: 0.2000\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.8941 - accuracy: 0.1567 - val_loss: 55.8257 - val_accuracy: 0.2000\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.8277 - accuracy: 0.1592 - val_loss: 55.7563 - val_accuracy: 0.2444\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.7621 - accuracy: 0.1493 - val_loss: 55.6864 - val_accuracy: 0.2222\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 55.6962 - accuracy: 0.1418 - val_loss: 55.6211 - val_accuracy: 0.2222\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6297 - accuracy: 0.1418 - val_loss: 55.5568 - val_accuracy: 0.2222\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5638 - accuracy: 0.1567 - val_loss: 55.4922 - val_accuracy: 0.2444\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4979 - accuracy: 0.1542 - val_loss: 55.4258 - val_accuracy: 0.2444\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4314 - accuracy: 0.1667 - val_loss: 55.3667 - val_accuracy: 0.1778\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.3649 - accuracy: 0.1667 - val_loss: 55.3064 - val_accuracy: 0.1111\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2990 - accuracy: 0.1667 - val_loss: 55.2386 - val_accuracy: 0.2222\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.2339 - accuracy: 0.2090 - val_loss: 55.1723 - val_accuracy: 0.1778\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1686 - accuracy: 0.1766 - val_loss: 55.1053 - val_accuracy: 0.2444\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.1032 - accuracy: 0.1766 - val_loss: 55.0403 - val_accuracy: 0.2222\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0366 - accuracy: 0.1617 - val_loss: 54.9728 - val_accuracy: 0.1778\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.9707 - accuracy: 0.1642 - val_loss: 54.9062 - val_accuracy: 0.1778\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.9055 - accuracy: 0.1642 - val_loss: 54.8394 - val_accuracy: 0.1778\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8398 - accuracy: 0.1642 - val_loss: 54.7729 - val_accuracy: 0.1778\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.7748 - accuracy: 0.1617 - val_loss: 54.7072 - val_accuracy: 0.1778\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.7088 - accuracy: 0.1642 - val_loss: 54.6458 - val_accuracy: 0.1778\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.6428 - accuracy: 0.1642 - val_loss: 54.5851 - val_accuracy: 0.1778\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.5780 - accuracy: 0.1741 - val_loss: 54.5219 - val_accuracy: 0.2000\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5126 - accuracy: 0.1567 - val_loss: 54.4553 - val_accuracy: 0.2000\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.4479 - accuracy: 0.1567 - val_loss: 54.3879 - val_accuracy: 0.2000\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3824 - accuracy: 0.1567 - val_loss: 54.3145 - val_accuracy: 0.2000\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3171 - accuracy: 0.1567 - val_loss: 54.2472 - val_accuracy: 0.2000\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.2517 - accuracy: 0.1642 - val_loss: 54.1843 - val_accuracy: 0.2222\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1866 - accuracy: 0.1642 - val_loss: 54.1194 - val_accuracy: 0.2000\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1211 - accuracy: 0.1642 - val_loss: 54.0556 - val_accuracy: 0.2444\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0555 - accuracy: 0.1667 - val_loss: 53.9944 - val_accuracy: 0.1778\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.9918 - accuracy: 0.1642 - val_loss: 53.9346 - val_accuracy: 0.1778\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.9260 - accuracy: 0.1542 - val_loss: 53.8682 - val_accuracy: 0.1111\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53.8619 - accuracy: 0.1617 - val_loss: 53.7972 - val_accuracy: 0.1778\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.7978 - accuracy: 0.1592 - val_loss: 53.7268 - val_accuracy: 0.2444\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.7335 - accuracy: 0.1617 - val_loss: 53.6597 - val_accuracy: 0.2000\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6685 - accuracy: 0.1567 - val_loss: 53.5982 - val_accuracy: 0.1778\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6031 - accuracy: 0.1716 - val_loss: 53.5359 - val_accuracy: 0.1778\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.5386 - accuracy: 0.1692 - val_loss: 53.4759 - val_accuracy: 0.1778\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4757 - accuracy: 0.1692 - val_loss: 53.4149 - val_accuracy: 0.1778\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4099 - accuracy: 0.1667 - val_loss: 53.3515 - val_accuracy: 0.1778\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53.3462 - accuracy: 0.1642 - val_loss: 53.2858 - val_accuracy: 0.1778\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2815 - accuracy: 0.1766 - val_loss: 53.2178 - val_accuracy: 0.2000\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2173 - accuracy: 0.1542 - val_loss: 53.1482 - val_accuracy: 0.2222\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1519 - accuracy: 0.1418 - val_loss: 53.0852 - val_accuracy: 0.2222\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.0877 - accuracy: 0.1517 - val_loss: 53.0242 - val_accuracy: 0.2444\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0235 - accuracy: 0.1667 - val_loss: 52.9631 - val_accuracy: 0.2000\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.9610 - accuracy: 0.1567 - val_loss: 52.9001 - val_accuracy: 0.2000\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.8967 - accuracy: 0.1567 - val_loss: 52.8367 - val_accuracy: 0.2000\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.8315 - accuracy: 0.1592 - val_loss: 52.7726 - val_accuracy: 0.1778\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7670 - accuracy: 0.1468 - val_loss: 52.7076 - val_accuracy: 0.1111\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7039 - accuracy: 0.1592 - val_loss: 52.6433 - val_accuracy: 0.1111\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.6402 - accuracy: 0.1592 - val_loss: 52.5779 - val_accuracy: 0.1111\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.5757 - accuracy: 0.1567 - val_loss: 52.5130 - val_accuracy: 0.1778\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.5118 - accuracy: 0.1443 - val_loss: 52.4504 - val_accuracy: 0.2000\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.4484 - accuracy: 0.1567 - val_loss: 52.3854 - val_accuracy: 0.2000\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3846 - accuracy: 0.1567 - val_loss: 52.3219 - val_accuracy: 0.2000\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.3203 - accuracy: 0.1592 - val_loss: 52.2600 - val_accuracy: 0.1778\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.2570 - accuracy: 0.1617 - val_loss: 52.1941 - val_accuracy: 0.1778\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1936 - accuracy: 0.1393 - val_loss: 52.1275 - val_accuracy: 0.1556\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.1308 - accuracy: 0.1368 - val_loss: 52.0594 - val_accuracy: 0.2222\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.0670 - accuracy: 0.1418 - val_loss: 51.9953 - val_accuracy: 0.2222\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.0036 - accuracy: 0.1542 - val_loss: 51.9334 - val_accuracy: 0.2222\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9396 - accuracy: 0.1642 - val_loss: 51.8700 - val_accuracy: 0.2000\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8766 - accuracy: 0.1567 - val_loss: 51.8078 - val_accuracy: 0.2000\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51.8144 - accuracy: 0.1567 - val_loss: 51.7483 - val_accuracy: 0.2000\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7499 - accuracy: 0.1567 - val_loss: 51.6828 - val_accuracy: 0.1778\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6871 - accuracy: 0.1667 - val_loss: 51.6177 - val_accuracy: 0.1778\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.6233 - accuracy: 0.1642 - val_loss: 51.5593 - val_accuracy: 0.1111\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.5607 - accuracy: 0.1592 - val_loss: 51.5009 - val_accuracy: 0.1111\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.4980 - accuracy: 0.1592 - val_loss: 51.4428 - val_accuracy: 0.1111\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.4346 - accuracy: 0.1592 - val_loss: 51.3762 - val_accuracy: 0.1111\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3713 - accuracy: 0.1592 - val_loss: 51.3061 - val_accuracy: 0.1111\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3085 - accuracy: 0.1592 - val_loss: 51.2432 - val_accuracy: 0.2222\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.2453 - accuracy: 0.1642 - val_loss: 51.1829 - val_accuracy: 0.1778\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.1824 - accuracy: 0.1567 - val_loss: 51.1178 - val_accuracy: 0.1778\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1197 - accuracy: 0.1617 - val_loss: 51.0566 - val_accuracy: 0.1778\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0574 - accuracy: 0.1592 - val_loss: 50.9931 - val_accuracy: 0.2000\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9955 - accuracy: 0.1567 - val_loss: 50.9325 - val_accuracy: 0.2000\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9325 - accuracy: 0.1567 - val_loss: 50.8684 - val_accuracy: 0.2000\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.8696 - accuracy: 0.1567 - val_loss: 50.8037 - val_accuracy: 0.2000\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.8075 - accuracy: 0.1418 - val_loss: 50.7386 - val_accuracy: 0.2222\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.7449 - accuracy: 0.1443 - val_loss: 50.6774 - val_accuracy: 0.2222\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6820 - accuracy: 0.1418 - val_loss: 50.6129 - val_accuracy: 0.2222\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.6198 - accuracy: 0.1418 - val_loss: 50.5490 - val_accuracy: 0.1556\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.5577 - accuracy: 0.1368 - val_loss: 50.4905 - val_accuracy: 0.1778\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4958 - accuracy: 0.1617 - val_loss: 50.4338 - val_accuracy: 0.1111\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4350 - accuracy: 0.1592 - val_loss: 50.3810 - val_accuracy: 0.1111\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.3718 - accuracy: 0.1592 - val_loss: 50.3202 - val_accuracy: 0.1111\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.3094 - accuracy: 0.1592 - val_loss: 50.2571 - val_accuracy: 0.1111\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2472 - accuracy: 0.1592 - val_loss: 50.1905 - val_accuracy: 0.1111\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50.1847 - accuracy: 0.1592 - val_loss: 50.1230 - val_accuracy: 0.1778\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.1233 - accuracy: 0.1517 - val_loss: 50.0576 - val_accuracy: 0.1778\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.0610 - accuracy: 0.1567 - val_loss: 50.0002 - val_accuracy: 0.1111\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.9995 - accuracy: 0.1592 - val_loss: 49.9410 - val_accuracy: 0.1111\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.9379 - accuracy: 0.1667 - val_loss: 49.8837 - val_accuracy: 0.1778\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.8760 - accuracy: 0.1692 - val_loss: 49.8238 - val_accuracy: 0.1778\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.8136 - accuracy: 0.1841 - val_loss: 49.7614 - val_accuracy: 0.1778\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7521 - accuracy: 0.1692 - val_loss: 49.6938 - val_accuracy: 0.1778\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6893 - accuracy: 0.1692 - val_loss: 49.6279 - val_accuracy: 0.1778\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6282 - accuracy: 0.1567 - val_loss: 49.5638 - val_accuracy: 0.2444\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.5673 - accuracy: 0.1766 - val_loss: 49.5011 - val_accuracy: 0.1556\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.5057 - accuracy: 0.1393 - val_loss: 49.4359 - val_accuracy: 0.2222\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.4447 - accuracy: 0.1418 - val_loss: 49.3756 - val_accuracy: 0.2222\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.3827 - accuracy: 0.1418 - val_loss: 49.3174 - val_accuracy: 0.2444\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3217 - accuracy: 0.1692 - val_loss: 49.2646 - val_accuracy: 0.2000\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2605 - accuracy: 0.1567 - val_loss: 49.2054 - val_accuracy: 0.2000\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.1987 - accuracy: 0.1567 - val_loss: 49.1434 - val_accuracy: 0.1778\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1377 - accuracy: 0.1642 - val_loss: 49.0866 - val_accuracy: 0.1111\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0762 - accuracy: 0.1592 - val_loss: 49.0253 - val_accuracy: 0.1111\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0147 - accuracy: 0.1617 - val_loss: 48.9569 - val_accuracy: 0.1778\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9532 - accuracy: 0.1692 - val_loss: 48.8882 - val_accuracy: 0.2444\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8938 - accuracy: 0.1468 - val_loss: 48.8206 - val_accuracy: 0.2222\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.8344 - accuracy: 0.1418 - val_loss: 48.7560 - val_accuracy: 0.2222\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7732 - accuracy: 0.1418 - val_loss: 48.6969 - val_accuracy: 0.2222\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.7117 - accuracy: 0.1418 - val_loss: 48.6405 - val_accuracy: 0.2222\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6496 - accuracy: 0.1468 - val_loss: 48.5815 - val_accuracy: 0.2444\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5885 - accuracy: 0.1791 - val_loss: 48.5255 - val_accuracy: 0.2000\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.5279 - accuracy: 0.1468 - val_loss: 48.4734 - val_accuracy: 0.1778\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.4669 - accuracy: 0.1642 - val_loss: 48.4174 - val_accuracy: 0.1778\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.4071 - accuracy: 0.1617 - val_loss: 48.3624 - val_accuracy: 0.1778\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.3471 - accuracy: 0.1716 - val_loss: 48.3011 - val_accuracy: 0.1778\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.2863 - accuracy: 0.1667 - val_loss: 48.2367 - val_accuracy: 0.1111\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.2252 - accuracy: 0.1592 - val_loss: 48.1747 - val_accuracy: 0.1111\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1645 - accuracy: 0.1592 - val_loss: 48.1168 - val_accuracy: 0.1111\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1046 - accuracy: 0.1716 - val_loss: 48.0577 - val_accuracy: 0.1111\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.0444 - accuracy: 0.2040 - val_loss: 47.9962 - val_accuracy: 0.1556\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.9844 - accuracy: 0.1741 - val_loss: 47.9353 - val_accuracy: 0.1111\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.9235 - accuracy: 0.1990 - val_loss: 47.8719 - val_accuracy: 0.1111\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.8627 - accuracy: 0.1592 - val_loss: 47.8085 - val_accuracy: 0.1111\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8018 - accuracy: 0.1617 - val_loss: 47.7485 - val_accuracy: 0.1778\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.7422 - accuracy: 0.1692 - val_loss: 47.6909 - val_accuracy: 0.1778\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.6832 - accuracy: 0.1741 - val_loss: 47.6332 - val_accuracy: 0.2000\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.6229 - accuracy: 0.1567 - val_loss: 47.5691 - val_accuracy: 0.2000\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5619 - accuracy: 0.1567 - val_loss: 47.5033 - val_accuracy: 0.2000\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5014 - accuracy: 0.1567 - val_loss: 47.4327 - val_accuracy: 0.2444\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.4415 - accuracy: 0.1493 - val_loss: 47.3673 - val_accuracy: 0.2222\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3828 - accuracy: 0.1418 - val_loss: 47.3061 - val_accuracy: 0.2222\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.3232 - accuracy: 0.1418 - val_loss: 47.2461 - val_accuracy: 0.2444\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2633 - accuracy: 0.1567 - val_loss: 47.1888 - val_accuracy: 0.2222\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2030 - accuracy: 0.1592 - val_loss: 47.1343 - val_accuracy: 0.2000\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.1434 - accuracy: 0.1567 - val_loss: 47.0767 - val_accuracy: 0.2000\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.0837 - accuracy: 0.1567 - val_loss: 47.0212 - val_accuracy: 0.1778\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.0233 - accuracy: 0.1542 - val_loss: 46.9657 - val_accuracy: 0.1778\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9646 - accuracy: 0.1915 - val_loss: 46.9131 - val_accuracy: 0.2222\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9057 - accuracy: 0.2090 - val_loss: 46.8574 - val_accuracy: 0.1778\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.8462 - accuracy: 0.1716 - val_loss: 46.7957 - val_accuracy: 0.1778\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.7858 - accuracy: 0.1642 - val_loss: 46.7331 - val_accuracy: 0.1778\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.7273 - accuracy: 0.1667 - val_loss: 46.6705 - val_accuracy: 0.1778\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6679 - accuracy: 0.1642 - val_loss: 46.6107 - val_accuracy: 0.1778\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6081 - accuracy: 0.1642 - val_loss: 46.5532 - val_accuracy: 0.1778\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.5487 - accuracy: 0.1642 - val_loss: 46.4971 - val_accuracy: 0.1778\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.4897 - accuracy: 0.1642 - val_loss: 46.4365 - val_accuracy: 0.1778\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.4305 - accuracy: 0.1642 - val_loss: 46.3767 - val_accuracy: 0.1778\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3723 - accuracy: 0.1642 - val_loss: 46.3159 - val_accuracy: 0.1778\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.3130 - accuracy: 0.1642 - val_loss: 46.2543 - val_accuracy: 0.1778\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2537 - accuracy: 0.1642 - val_loss: 46.1918 - val_accuracy: 0.1778\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.1948 - accuracy: 0.1642 - val_loss: 46.1359 - val_accuracy: 0.1778\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.1356 - accuracy: 0.1642 - val_loss: 46.0814 - val_accuracy: 0.1778\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0765 - accuracy: 0.1642 - val_loss: 46.0246 - val_accuracy: 0.1778\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0175 - accuracy: 0.1667 - val_loss: 45.9661 - val_accuracy: 0.1778\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.9585 - accuracy: 0.1567 - val_loss: 45.9053 - val_accuracy: 0.1778\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.9001 - accuracy: 0.1542 - val_loss: 45.8425 - val_accuracy: 0.1778\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.8429 - accuracy: 0.1642 - val_loss: 45.7786 - val_accuracy: 0.1778\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7837 - accuracy: 0.1642 - val_loss: 45.7203 - val_accuracy: 0.1778\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.7256 - accuracy: 0.1716 - val_loss: 45.6612 - val_accuracy: 0.2000\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.6659 - accuracy: 0.1567 - val_loss: 45.6036 - val_accuracy: 0.2000\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6080 - accuracy: 0.1567 - val_loss: 45.5459 - val_accuracy: 0.2000\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5488 - accuracy: 0.1567 - val_loss: 45.4847 - val_accuracy: 0.2000\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.4903 - accuracy: 0.1567 - val_loss: 45.4292 - val_accuracy: 0.2000\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.4323 - accuracy: 0.1567 - val_loss: 45.3737 - val_accuracy: 0.2000\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.3749 - accuracy: 0.1617 - val_loss: 45.3194 - val_accuracy: 0.2000\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3170 - accuracy: 0.1567 - val_loss: 45.2637 - val_accuracy: 0.1778\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.2589 - accuracy: 0.1493 - val_loss: 45.2022 - val_accuracy: 0.1778\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.2003 - accuracy: 0.1617 - val_loss: 45.1415 - val_accuracy: 0.1778\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.1412 - accuracy: 0.1617 - val_loss: 45.0810 - val_accuracy: 0.1778\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.0827 - accuracy: 0.1692 - val_loss: 45.0191 - val_accuracy: 0.2222\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.0259 - accuracy: 0.1418 - val_loss: 44.9578 - val_accuracy: 0.2222\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9675 - accuracy: 0.1418 - val_loss: 44.8988 - val_accuracy: 0.2222\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.9096 - accuracy: 0.1542 - val_loss: 44.8400 - val_accuracy: 0.2000\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.8523 - accuracy: 0.1567 - val_loss: 44.7840 - val_accuracy: 0.2000\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7947 - accuracy: 0.1567 - val_loss: 44.7315 - val_accuracy: 0.2000\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7360 - accuracy: 0.1567 - val_loss: 44.6762 - val_accuracy: 0.2000\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.6780 - accuracy: 0.1692 - val_loss: 44.6207 - val_accuracy: 0.1778\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6208 - accuracy: 0.1617 - val_loss: 44.5635 - val_accuracy: 0.1111\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.5633 - accuracy: 0.1592 - val_loss: 44.5096 - val_accuracy: 0.1111\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.5057 - accuracy: 0.1592 - val_loss: 44.4550 - val_accuracy: 0.1111\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.4491 - accuracy: 0.1592 - val_loss: 44.3959 - val_accuracy: 0.1111\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44.3909 - accuracy: 0.1592 - val_loss: 44.3376 - val_accuracy: 0.1778\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3327 - accuracy: 0.1642 - val_loss: 44.2793 - val_accuracy: 0.1778\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.2756 - accuracy: 0.1667 - val_loss: 44.2178 - val_accuracy: 0.1778\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2181 - accuracy: 0.1915 - val_loss: 44.1647 - val_accuracy: 0.1778\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1609 - accuracy: 0.1915 - val_loss: 44.1070 - val_accuracy: 0.1778\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.1032 - accuracy: 0.1592 - val_loss: 44.0468 - val_accuracy: 0.1778\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0459 - accuracy: 0.1542 - val_loss: 43.9877 - val_accuracy: 0.2000\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.9885 - accuracy: 0.1567 - val_loss: 43.9274 - val_accuracy: 0.2000\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43.9311 - accuracy: 0.1567 - val_loss: 43.8734 - val_accuracy: 0.2000\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.8744 - accuracy: 0.1567 - val_loss: 43.8142 - val_accuracy: 0.2000\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.8171 - accuracy: 0.1567 - val_loss: 43.7567 - val_accuracy: 0.2000\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7598 - accuracy: 0.1567 - val_loss: 43.7010 - val_accuracy: 0.2000\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43.7031 - accuracy: 0.1567 - val_loss: 43.6515 - val_accuracy: 0.1778\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6463 - accuracy: 0.1642 - val_loss: 43.5960 - val_accuracy: 0.1778\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5900 - accuracy: 0.1642 - val_loss: 43.5378 - val_accuracy: 0.1778\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.5331 - accuracy: 0.1592 - val_loss: 43.4783 - val_accuracy: 0.1111\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4765 - accuracy: 0.1592 - val_loss: 43.4253 - val_accuracy: 0.1111\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4194 - accuracy: 0.1567 - val_loss: 43.3693 - val_accuracy: 0.1778\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3625 - accuracy: 0.1642 - val_loss: 43.3109 - val_accuracy: 0.1778\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.3060 - accuracy: 0.1493 - val_loss: 43.2551 - val_accuracy: 0.2000\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43.2499 - accuracy: 0.1567 - val_loss: 43.1973 - val_accuracy: 0.2000\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.1932 - accuracy: 0.1567 - val_loss: 43.1360 - val_accuracy: 0.2000\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.1363 - accuracy: 0.1567 - val_loss: 43.0768 - val_accuracy: 0.2000\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0796 - accuracy: 0.1592 - val_loss: 43.0148 - val_accuracy: 0.2444\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0243 - accuracy: 0.1617 - val_loss: 42.9577 - val_accuracy: 0.2444\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.9678 - accuracy: 0.1642 - val_loss: 42.9020 - val_accuracy: 0.2222\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9113 - accuracy: 0.1642 - val_loss: 42.8458 - val_accuracy: 0.2000\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.8542 - accuracy: 0.1567 - val_loss: 42.7916 - val_accuracy: 0.2000\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.7983 - accuracy: 0.1567 - val_loss: 42.7422 - val_accuracy: 0.2000\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.7426 - accuracy: 0.1567 - val_loss: 42.6938 - val_accuracy: 0.2000\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.6870 - accuracy: 0.1567 - val_loss: 42.6370 - val_accuracy: 0.2000\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.6314 - accuracy: 0.1567 - val_loss: 42.5778 - val_accuracy: 0.2000\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5744 - accuracy: 0.1567 - val_loss: 42.5204 - val_accuracy: 0.2000\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.5179 - accuracy: 0.1542 - val_loss: 42.4628 - val_accuracy: 0.1778\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4616 - accuracy: 0.1642 - val_loss: 42.4044 - val_accuracy: 0.1778\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.4055 - accuracy: 0.1642 - val_loss: 42.3494 - val_accuracy: 0.1111\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3496 - accuracy: 0.1592 - val_loss: 42.2985 - val_accuracy: 0.1111\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.2933 - accuracy: 0.1592 - val_loss: 42.2411 - val_accuracy: 0.1111\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2376 - accuracy: 0.1692 - val_loss: 42.1829 - val_accuracy: 0.1778\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.1828 - accuracy: 0.1617 - val_loss: 42.1228 - val_accuracy: 0.2000\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.1282 - accuracy: 0.1592 - val_loss: 42.0628 - val_accuracy: 0.2000\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.0729 - accuracy: 0.1567 - val_loss: 42.0064 - val_accuracy: 0.2000\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.0180 - accuracy: 0.1567 - val_loss: 41.9507 - val_accuracy: 0.2000\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.9610 - accuracy: 0.1567 - val_loss: 41.8967 - val_accuracy: 0.2000\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.9049 - accuracy: 0.1567 - val_loss: 41.8428 - val_accuracy: 0.2222\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.8488 - accuracy: 0.1592 - val_loss: 41.7886 - val_accuracy: 0.2444\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.7934 - accuracy: 0.1592 - val_loss: 41.7357 - val_accuracy: 0.2444\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7380 - accuracy: 0.1642 - val_loss: 41.6826 - val_accuracy: 0.2444\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.6838 - accuracy: 0.2114 - val_loss: 41.6334 - val_accuracy: 0.2667\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6287 - accuracy: 0.2139 - val_loss: 41.5784 - val_accuracy: 0.1111\n",
      "========== Fold 2 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 208.2018 - accuracy: 0.0920 - val_loss: 198.1417 - val_accuracy: 0.1111\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 192.4618 - accuracy: 0.1517 - val_loss: 180.5735 - val_accuracy: 0.1111\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 175.2377 - accuracy: 0.1542 - val_loss: 164.7307 - val_accuracy: 0.1556\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 160.3134 - accuracy: 0.1318 - val_loss: 151.7777 - val_accuracy: 0.1556\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 148.2735 - accuracy: 0.1592 - val_loss: 141.5528 - val_accuracy: 0.1111\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 138.8005 - accuracy: 0.1318 - val_loss: 133.5449 - val_accuracy: 0.0889\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 131.3646 - accuracy: 0.1542 - val_loss: 127.2312 - val_accuracy: 0.1778\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 125.4954 - accuracy: 0.1468 - val_loss: 122.2066 - val_accuracy: 0.2222\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 120.8120 - accuracy: 0.1567 - val_loss: 118.1532 - val_accuracy: 0.2222\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 117.0204 - accuracy: 0.1468 - val_loss: 114.8515 - val_accuracy: 0.1556\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 113.9193 - accuracy: 0.1567 - val_loss: 112.1301 - val_accuracy: 0.0889\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 111.3402 - accuracy: 0.1567 - val_loss: 109.8368 - val_accuracy: 0.0889\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 109.1672 - accuracy: 0.1617 - val_loss: 107.8872 - val_accuracy: 0.0889\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 107.3172 - accuracy: 0.1716 - val_loss: 106.2161 - val_accuracy: 0.2000\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 105.7286 - accuracy: 0.1592 - val_loss: 104.7734 - val_accuracy: 0.2667\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104.3436 - accuracy: 0.1493 - val_loss: 103.5201 - val_accuracy: 0.1556\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103.1297 - accuracy: 0.1368 - val_loss: 102.4122 - val_accuracy: 0.1556\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 102.0567 - accuracy: 0.1343 - val_loss: 101.4241 - val_accuracy: 0.2222\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.0990 - accuracy: 0.1468 - val_loss: 100.5384 - val_accuracy: 0.1778\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 100.2378 - accuracy: 0.1443 - val_loss: 99.7271 - val_accuracy: 0.0889\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.4575 - accuracy: 0.1667 - val_loss: 98.9930 - val_accuracy: 0.1556\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.7489 - accuracy: 0.1368 - val_loss: 98.3216 - val_accuracy: 0.1556\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.1039 - accuracy: 0.1368 - val_loss: 97.7021 - val_accuracy: 0.1556\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 97.5047 - accuracy: 0.1667 - val_loss: 97.1388 - val_accuracy: 0.1778\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96.9494 - accuracy: 0.1766 - val_loss: 96.6200 - val_accuracy: 0.1111\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 96.4406 - accuracy: 0.1493 - val_loss: 96.1351 - val_accuracy: 0.2000\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.9618 - accuracy: 0.1940 - val_loss: 95.6736 - val_accuracy: 0.0889\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.5118 - accuracy: 0.1468 - val_loss: 95.2382 - val_accuracy: 0.1556\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.0900 - accuracy: 0.1393 - val_loss: 94.8331 - val_accuracy: 0.1778\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94.6929 - accuracy: 0.1468 - val_loss: 94.4563 - val_accuracy: 0.1556\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.3167 - accuracy: 0.1368 - val_loss: 94.0942 - val_accuracy: 0.1556\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9592 - accuracy: 0.1393 - val_loss: 93.7486 - val_accuracy: 0.1556\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.6189 - accuracy: 0.1542 - val_loss: 93.4214 - val_accuracy: 0.1778\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.2928 - accuracy: 0.1642 - val_loss: 93.1054 - val_accuracy: 0.1778\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.9822 - accuracy: 0.1443 - val_loss: 92.8041 - val_accuracy: 0.1778\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.6820 - accuracy: 0.1517 - val_loss: 92.5124 - val_accuracy: 0.1333\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.3974 - accuracy: 0.1642 - val_loss: 92.2333 - val_accuracy: 0.0889\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.1184 - accuracy: 0.1517 - val_loss: 91.9596 - val_accuracy: 0.1556\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.8502 - accuracy: 0.1368 - val_loss: 91.6991 - val_accuracy: 0.1556\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.5896 - accuracy: 0.1517 - val_loss: 91.4471 - val_accuracy: 0.1778\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91.3380 - accuracy: 0.1542 - val_loss: 91.2033 - val_accuracy: 0.2444\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.0939 - accuracy: 0.1468 - val_loss: 90.9690 - val_accuracy: 0.1111\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.8563 - accuracy: 0.1617 - val_loss: 90.7312 - val_accuracy: 0.1556\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.6250 - accuracy: 0.1393 - val_loss: 90.4993 - val_accuracy: 0.1556\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.3987 - accuracy: 0.1617 - val_loss: 90.2755 - val_accuracy: 0.1333\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.1768 - accuracy: 0.1617 - val_loss: 90.0598 - val_accuracy: 0.0889\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.9605 - accuracy: 0.1667 - val_loss: 89.8439 - val_accuracy: 0.2444\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.7509 - accuracy: 0.1642 - val_loss: 89.6310 - val_accuracy: 0.2222\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 89.5438 - accuracy: 0.1493 - val_loss: 89.4296 - val_accuracy: 0.1778\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.3407 - accuracy: 0.1617 - val_loss: 89.2356 - val_accuracy: 0.2444\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.1424 - accuracy: 0.1617 - val_loss: 89.0461 - val_accuracy: 0.1111\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.9471 - accuracy: 0.1741 - val_loss: 88.8563 - val_accuracy: 0.1556\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.7548 - accuracy: 0.1368 - val_loss: 88.6646 - val_accuracy: 0.1556\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.5648 - accuracy: 0.1368 - val_loss: 88.4740 - val_accuracy: 0.1556\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.3785 - accuracy: 0.1368 - val_loss: 88.2842 - val_accuracy: 0.1556\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.1969 - accuracy: 0.1493 - val_loss: 88.0969 - val_accuracy: 0.2222\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 88.0134 - accuracy: 0.1642 - val_loss: 87.9156 - val_accuracy: 0.2444\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.8346 - accuracy: 0.1443 - val_loss: 87.7414 - val_accuracy: 0.1556\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.6597 - accuracy: 0.1368 - val_loss: 87.5696 - val_accuracy: 0.1556\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.4870 - accuracy: 0.1368 - val_loss: 87.3973 - val_accuracy: 0.1556\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 87.3149 - accuracy: 0.1368 - val_loss: 87.2258 - val_accuracy: 0.1556\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.1463 - accuracy: 0.1269 - val_loss: 87.0590 - val_accuracy: 0.1778\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.9762 - accuracy: 0.1542 - val_loss: 86.8917 - val_accuracy: 0.1556\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.8099 - accuracy: 0.1368 - val_loss: 86.7269 - val_accuracy: 0.1556\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.6468 - accuracy: 0.1368 - val_loss: 86.5647 - val_accuracy: 0.1556\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.4872 - accuracy: 0.1368 - val_loss: 86.4044 - val_accuracy: 0.1556\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.3239 - accuracy: 0.1667 - val_loss: 86.2402 - val_accuracy: 0.0889\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.1653 - accuracy: 0.1617 - val_loss: 86.0773 - val_accuracy: 0.0889\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0074 - accuracy: 0.1517 - val_loss: 85.9201 - val_accuracy: 0.2222\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.8508 - accuracy: 0.1418 - val_loss: 85.7639 - val_accuracy: 0.2222\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.6965 - accuracy: 0.1642 - val_loss: 85.6104 - val_accuracy: 0.2000\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.5432 - accuracy: 0.1567 - val_loss: 85.4605 - val_accuracy: 0.1778\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.3895 - accuracy: 0.1716 - val_loss: 85.3092 - val_accuracy: 0.2222\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.2407 - accuracy: 0.1418 - val_loss: 85.1621 - val_accuracy: 0.2222\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.0938 - accuracy: 0.1418 - val_loss: 85.0152 - val_accuracy: 0.2222\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.9445 - accuracy: 0.1592 - val_loss: 84.8719 - val_accuracy: 0.1556\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.7959 - accuracy: 0.1393 - val_loss: 84.7244 - val_accuracy: 0.1556\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.6476 - accuracy: 0.1766 - val_loss: 84.5745 - val_accuracy: 0.1556\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.5044 - accuracy: 0.1517 - val_loss: 84.4279 - val_accuracy: 0.1556\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.3611 - accuracy: 0.1667 - val_loss: 84.2857 - val_accuracy: 0.0889\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84.2166 - accuracy: 0.1468 - val_loss: 84.1465 - val_accuracy: 0.1111\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.0735 - accuracy: 0.1393 - val_loss: 84.0094 - val_accuracy: 0.1778\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83.9331 - accuracy: 0.1418 - val_loss: 83.8709 - val_accuracy: 0.1778\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.7930 - accuracy: 0.1517 - val_loss: 83.7282 - val_accuracy: 0.1111\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.6540 - accuracy: 0.1617 - val_loss: 83.5896 - val_accuracy: 0.1778\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.5139 - accuracy: 0.1592 - val_loss: 83.4505 - val_accuracy: 0.1778\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3768 - accuracy: 0.1592 - val_loss: 83.3114 - val_accuracy: 0.1778\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.2402 - accuracy: 0.1667 - val_loss: 83.1727 - val_accuracy: 0.2444\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 83.1039 - accuracy: 0.1741 - val_loss: 83.0397 - val_accuracy: 0.1556\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.9694 - accuracy: 0.1542 - val_loss: 82.9089 - val_accuracy: 0.1556\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82.8350 - accuracy: 0.1368 - val_loss: 82.7776 - val_accuracy: 0.1556\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.7018 - accuracy: 0.1318 - val_loss: 82.6463 - val_accuracy: 0.2222\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.5679 - accuracy: 0.1418 - val_loss: 82.5157 - val_accuracy: 0.2444\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.4377 - accuracy: 0.1592 - val_loss: 82.3852 - val_accuracy: 0.1111\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.3061 - accuracy: 0.1617 - val_loss: 82.2533 - val_accuracy: 0.1778\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.1744 - accuracy: 0.1592 - val_loss: 82.1217 - val_accuracy: 0.1556\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.0441 - accuracy: 0.1418 - val_loss: 81.9894 - val_accuracy: 0.1556\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81.9158 - accuracy: 0.1368 - val_loss: 81.8566 - val_accuracy: 0.1556\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.7862 - accuracy: 0.1418 - val_loss: 81.7243 - val_accuracy: 0.2222\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.6581 - accuracy: 0.1542 - val_loss: 81.5940 - val_accuracy: 0.1778\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.5311 - accuracy: 0.1592 - val_loss: 81.4669 - val_accuracy: 0.1778\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.4039 - accuracy: 0.1592 - val_loss: 81.3444 - val_accuracy: 0.1778\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.2768 - accuracy: 0.1592 - val_loss: 81.2200 - val_accuracy: 0.1778\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.1513 - accuracy: 0.1592 - val_loss: 81.0962 - val_accuracy: 0.1778\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81.0262 - accuracy: 0.1741 - val_loss: 80.9749 - val_accuracy: 0.1556\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.9014 - accuracy: 0.1667 - val_loss: 80.8538 - val_accuracy: 0.0889\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.7778 - accuracy: 0.1617 - val_loss: 80.7303 - val_accuracy: 0.0889\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.6546 - accuracy: 0.1716 - val_loss: 80.6067 - val_accuracy: 0.1556\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.5320 - accuracy: 0.1592 - val_loss: 80.4811 - val_accuracy: 0.1778\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.4112 - accuracy: 0.1493 - val_loss: 80.3566 - val_accuracy: 0.2222\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.2882 - accuracy: 0.1418 - val_loss: 80.2354 - val_accuracy: 0.2222\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1662 - accuracy: 0.1418 - val_loss: 80.1147 - val_accuracy: 0.2444\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.0453 - accuracy: 0.1692 - val_loss: 79.9989 - val_accuracy: 0.0889\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.9269 - accuracy: 0.1617 - val_loss: 79.8821 - val_accuracy: 0.0889\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8069 - accuracy: 0.1617 - val_loss: 79.7600 - val_accuracy: 0.0889\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6867 - accuracy: 0.1468 - val_loss: 79.6390 - val_accuracy: 0.2222\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.5673 - accuracy: 0.1418 - val_loss: 79.5207 - val_accuracy: 0.2444\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.4490 - accuracy: 0.1692 - val_loss: 79.4042 - val_accuracy: 0.1778\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.3321 - accuracy: 0.1517 - val_loss: 79.2902 - val_accuracy: 0.1556\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 79.2148 - accuracy: 0.1766 - val_loss: 79.1712 - val_accuracy: 0.2222\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0981 - accuracy: 0.1318 - val_loss: 79.0546 - val_accuracy: 0.1556\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.9804 - accuracy: 0.1368 - val_loss: 78.9388 - val_accuracy: 0.1556\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.8645 - accuracy: 0.1393 - val_loss: 78.8226 - val_accuracy: 0.1556\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.7491 - accuracy: 0.1468 - val_loss: 78.7090 - val_accuracy: 0.1556\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.6335 - accuracy: 0.1443 - val_loss: 78.5966 - val_accuracy: 0.1556\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5186 - accuracy: 0.2065 - val_loss: 78.4814 - val_accuracy: 0.1556\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.4053 - accuracy: 0.1667 - val_loss: 78.3640 - val_accuracy: 0.1778\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.2911 - accuracy: 0.1667 - val_loss: 78.2479 - val_accuracy: 0.1778\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 78.1778 - accuracy: 0.1592 - val_loss: 78.1360 - val_accuracy: 0.1333\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.0647 - accuracy: 0.1468 - val_loss: 78.0238 - val_accuracy: 0.1556\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.9500 - accuracy: 0.1368 - val_loss: 77.9091 - val_accuracy: 0.2000\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.8390 - accuracy: 0.1493 - val_loss: 77.7979 - val_accuracy: 0.2000\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.7274 - accuracy: 0.1343 - val_loss: 77.6883 - val_accuracy: 0.1556\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.6159 - accuracy: 0.1617 - val_loss: 77.5774 - val_accuracy: 0.0889\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.5051 - accuracy: 0.1617 - val_loss: 77.4659 - val_accuracy: 0.0889\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.3940 - accuracy: 0.1617 - val_loss: 77.3530 - val_accuracy: 0.1556\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.2829 - accuracy: 0.1368 - val_loss: 77.2403 - val_accuracy: 0.1556\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1716 - accuracy: 0.1368 - val_loss: 77.1308 - val_accuracy: 0.1556\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.0622 - accuracy: 0.1443 - val_loss: 77.0208 - val_accuracy: 0.0889\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.9543 - accuracy: 0.1617 - val_loss: 76.9068 - val_accuracy: 0.0889\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.8434 - accuracy: 0.1542 - val_loss: 76.7966 - val_accuracy: 0.1111\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.7351 - accuracy: 0.1517 - val_loss: 76.6870 - val_accuracy: 0.0889\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76.6267 - accuracy: 0.1567 - val_loss: 76.5754 - val_accuracy: 0.1778\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.5182 - accuracy: 0.1542 - val_loss: 76.4667 - val_accuracy: 0.2444\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.4096 - accuracy: 0.1617 - val_loss: 76.3616 - val_accuracy: 0.2222\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.3023 - accuracy: 0.1418 - val_loss: 76.2594 - val_accuracy: 0.1556\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.1957 - accuracy: 0.1368 - val_loss: 76.1552 - val_accuracy: 0.1556\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.0891 - accuracy: 0.1368 - val_loss: 76.0476 - val_accuracy: 0.1556\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.9811 - accuracy: 0.1368 - val_loss: 75.9392 - val_accuracy: 0.1556\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75.8754 - accuracy: 0.1343 - val_loss: 75.8332 - val_accuracy: 0.2000\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7713 - accuracy: 0.1493 - val_loss: 75.7269 - val_accuracy: 0.2222\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.6656 - accuracy: 0.1617 - val_loss: 75.6229 - val_accuracy: 0.2222\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.5592 - accuracy: 0.1269 - val_loss: 75.5214 - val_accuracy: 0.1556\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.4531 - accuracy: 0.1716 - val_loss: 75.4178 - val_accuracy: 0.0889\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.3491 - accuracy: 0.1617 - val_loss: 75.3136 - val_accuracy: 0.1111\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.2450 - accuracy: 0.1940 - val_loss: 75.2108 - val_accuracy: 0.0889\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.1412 - accuracy: 0.1493 - val_loss: 75.1049 - val_accuracy: 0.2000\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.0369 - accuracy: 0.1766 - val_loss: 75.0008 - val_accuracy: 0.2000\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.9329 - accuracy: 0.1891 - val_loss: 74.8988 - val_accuracy: 0.2000\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8299 - accuracy: 0.1766 - val_loss: 74.7976 - val_accuracy: 0.1556\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.7285 - accuracy: 0.1791 - val_loss: 74.6961 - val_accuracy: 0.1778\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.6262 - accuracy: 0.1716 - val_loss: 74.5909 - val_accuracy: 0.1778\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.5222 - accuracy: 0.1642 - val_loss: 74.4842 - val_accuracy: 0.2222\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.4188 - accuracy: 0.1418 - val_loss: 74.3828 - val_accuracy: 0.2222\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.3174 - accuracy: 0.1418 - val_loss: 74.2822 - val_accuracy: 0.2222\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.2164 - accuracy: 0.1418 - val_loss: 74.1814 - val_accuracy: 0.2222\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.1143 - accuracy: 0.1418 - val_loss: 74.0797 - val_accuracy: 0.2222\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.0131 - accuracy: 0.1443 - val_loss: 73.9781 - val_accuracy: 0.1556\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.9144 - accuracy: 0.1368 - val_loss: 73.8773 - val_accuracy: 0.1556\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.8134 - accuracy: 0.1393 - val_loss: 73.7731 - val_accuracy: 0.1556\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.7130 - accuracy: 0.1592 - val_loss: 73.6735 - val_accuracy: 0.0889\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.6127 - accuracy: 0.1617 - val_loss: 73.5756 - val_accuracy: 0.0889\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.5134 - accuracy: 0.1617 - val_loss: 73.4765 - val_accuracy: 0.0889\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4129 - accuracy: 0.1617 - val_loss: 73.3746 - val_accuracy: 0.0889\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3137 - accuracy: 0.1617 - val_loss: 73.2771 - val_accuracy: 0.0889\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.2162 - accuracy: 0.1692 - val_loss: 73.1797 - val_accuracy: 0.1333\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.1161 - accuracy: 0.1692 - val_loss: 73.0788 - val_accuracy: 0.1556\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 73.0162 - accuracy: 0.1368 - val_loss: 72.9820 - val_accuracy: 0.1556\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.9170 - accuracy: 0.1368 - val_loss: 72.8864 - val_accuracy: 0.1556\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.8194 - accuracy: 0.1368 - val_loss: 72.7881 - val_accuracy: 0.1556\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.7209 - accuracy: 0.1368 - val_loss: 72.6898 - val_accuracy: 0.1556\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.6234 - accuracy: 0.1343 - val_loss: 72.5941 - val_accuracy: 0.2222\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5253 - accuracy: 0.1642 - val_loss: 72.4958 - val_accuracy: 0.2444\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.4280 - accuracy: 0.1692 - val_loss: 72.3989 - val_accuracy: 0.2444\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.3309 - accuracy: 0.1567 - val_loss: 72.3024 - val_accuracy: 0.2000\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72.2356 - accuracy: 0.1493 - val_loss: 72.2087 - val_accuracy: 0.2000\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.1385 - accuracy: 0.1493 - val_loss: 72.1122 - val_accuracy: 0.2000\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.0420 - accuracy: 0.1393 - val_loss: 72.0152 - val_accuracy: 0.2444\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9456 - accuracy: 0.1617 - val_loss: 71.9212 - val_accuracy: 0.2444\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8497 - accuracy: 0.1567 - val_loss: 71.8270 - val_accuracy: 0.1778\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.7541 - accuracy: 0.1368 - val_loss: 71.7306 - val_accuracy: 0.1556\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.6577 - accuracy: 0.1368 - val_loss: 71.6350 - val_accuracy: 0.1556\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.5624 - accuracy: 0.1617 - val_loss: 71.5376 - val_accuracy: 0.0889\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4677 - accuracy: 0.1617 - val_loss: 71.4443 - val_accuracy: 0.0889\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.3741 - accuracy: 0.1617 - val_loss: 71.3515 - val_accuracy: 0.0889\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.2799 - accuracy: 0.1891 - val_loss: 71.2585 - val_accuracy: 0.1333\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1852 - accuracy: 0.1766 - val_loss: 71.1632 - val_accuracy: 0.0889\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.0900 - accuracy: 0.1617 - val_loss: 71.0684 - val_accuracy: 0.0889\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.9957 - accuracy: 0.1468 - val_loss: 70.9706 - val_accuracy: 0.1778\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.9020 - accuracy: 0.1592 - val_loss: 70.8687 - val_accuracy: 0.1778\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.8084 - accuracy: 0.1592 - val_loss: 70.7729 - val_accuracy: 0.1778\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7146 - accuracy: 0.1617 - val_loss: 70.6806 - val_accuracy: 0.2444\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.6221 - accuracy: 0.1418 - val_loss: 70.5889 - val_accuracy: 0.2222\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.5275 - accuracy: 0.1418 - val_loss: 70.4997 - val_accuracy: 0.1556\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.4346 - accuracy: 0.1617 - val_loss: 70.4140 - val_accuracy: 0.0889\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.3429 - accuracy: 0.1617 - val_loss: 70.3213 - val_accuracy: 0.0889\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.2511 - accuracy: 0.1741 - val_loss: 70.2292 - val_accuracy: 0.1111\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.1590 - accuracy: 0.1841 - val_loss: 70.1385 - val_accuracy: 0.1778\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0665 - accuracy: 0.1642 - val_loss: 70.0449 - val_accuracy: 0.1778\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.9741 - accuracy: 0.1592 - val_loss: 69.9525 - val_accuracy: 0.1778\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69.8817 - accuracy: 0.1592 - val_loss: 69.8593 - val_accuracy: 0.1778\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.7903 - accuracy: 0.1592 - val_loss: 69.7683 - val_accuracy: 0.1778\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.6984 - accuracy: 0.1592 - val_loss: 69.6759 - val_accuracy: 0.1778\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.6070 - accuracy: 0.1592 - val_loss: 69.5843 - val_accuracy: 0.1778\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.5157 - accuracy: 0.1642 - val_loss: 69.4946 - val_accuracy: 0.1111\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.4263 - accuracy: 0.1542 - val_loss: 69.4021 - val_accuracy: 0.0889\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.3349 - accuracy: 0.1617 - val_loss: 69.3121 - val_accuracy: 0.0889\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.2440 - accuracy: 0.1592 - val_loss: 69.2204 - val_accuracy: 0.1778\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.1538 - accuracy: 0.1592 - val_loss: 69.1309 - val_accuracy: 0.1778\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.0636 - accuracy: 0.1617 - val_loss: 69.0390 - val_accuracy: 0.1778\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.9736 - accuracy: 0.1592 - val_loss: 68.9484 - val_accuracy: 0.1778\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.8827 - accuracy: 0.1617 - val_loss: 68.8609 - val_accuracy: 0.2444\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.7936 - accuracy: 0.1642 - val_loss: 68.7726 - val_accuracy: 0.2444\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.7048 - accuracy: 0.1517 - val_loss: 68.6816 - val_accuracy: 0.2444\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.6148 - accuracy: 0.1692 - val_loss: 68.5920 - val_accuracy: 0.1778\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.5260 - accuracy: 0.1542 - val_loss: 68.5045 - val_accuracy: 0.1111\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.4368 - accuracy: 0.1617 - val_loss: 68.4149 - val_accuracy: 0.1778\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.3482 - accuracy: 0.1592 - val_loss: 68.3259 - val_accuracy: 0.1778\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2602 - accuracy: 0.1592 - val_loss: 68.2362 - val_accuracy: 0.1778\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.1718 - accuracy: 0.1592 - val_loss: 68.1482 - val_accuracy: 0.1778\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.0835 - accuracy: 0.1592 - val_loss: 68.0618 - val_accuracy: 0.2222\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9949 - accuracy: 0.1716 - val_loss: 67.9759 - val_accuracy: 0.2444\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.9063 - accuracy: 0.1592 - val_loss: 67.8916 - val_accuracy: 0.2222\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.8185 - accuracy: 0.1493 - val_loss: 67.8049 - val_accuracy: 0.1556\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.7311 - accuracy: 0.1592 - val_loss: 67.7166 - val_accuracy: 0.0889\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6439 - accuracy: 0.1617 - val_loss: 67.6283 - val_accuracy: 0.0889\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.5568 - accuracy: 0.1542 - val_loss: 67.5394 - val_accuracy: 0.1556\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.4696 - accuracy: 0.1368 - val_loss: 67.4529 - val_accuracy: 0.1556\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3813 - accuracy: 0.1493 - val_loss: 67.3632 - val_accuracy: 0.2444\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.2941 - accuracy: 0.1592 - val_loss: 67.2756 - val_accuracy: 0.2000\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67.2078 - accuracy: 0.1915 - val_loss: 67.1873 - val_accuracy: 0.2000\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.1211 - accuracy: 0.1716 - val_loss: 67.0983 - val_accuracy: 0.2222\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67.0346 - accuracy: 0.1716 - val_loss: 67.0138 - val_accuracy: 0.2444\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.9479 - accuracy: 0.1418 - val_loss: 66.9294 - val_accuracy: 0.2222\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8623 - accuracy: 0.1269 - val_loss: 66.8452 - val_accuracy: 0.1556\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.7764 - accuracy: 0.1368 - val_loss: 66.7584 - val_accuracy: 0.1556\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6904 - accuracy: 0.1368 - val_loss: 66.6728 - val_accuracy: 0.1556\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.6050 - accuracy: 0.1368 - val_loss: 66.5855 - val_accuracy: 0.1556\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5184 - accuracy: 0.1393 - val_loss: 66.4973 - val_accuracy: 0.2444\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.4326 - accuracy: 0.1667 - val_loss: 66.4126 - val_accuracy: 0.1778\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3484 - accuracy: 0.1592 - val_loss: 66.3282 - val_accuracy: 0.1778\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.2632 - accuracy: 0.1592 - val_loss: 66.2436 - val_accuracy: 0.1778\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.1781 - accuracy: 0.1617 - val_loss: 66.1599 - val_accuracy: 0.2222\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.0927 - accuracy: 0.1393 - val_loss: 66.0764 - val_accuracy: 0.1556\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.0089 - accuracy: 0.1368 - val_loss: 65.9940 - val_accuracy: 0.1556\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.9247 - accuracy: 0.1368 - val_loss: 65.9070 - val_accuracy: 0.1556\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.8405 - accuracy: 0.1368 - val_loss: 65.8197 - val_accuracy: 0.2000\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7559 - accuracy: 0.1493 - val_loss: 65.7349 - val_accuracy: 0.2000\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6714 - accuracy: 0.1692 - val_loss: 65.6512 - val_accuracy: 0.1556\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.5875 - accuracy: 0.1592 - val_loss: 65.5700 - val_accuracy: 0.1778\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.5026 - accuracy: 0.1642 - val_loss: 65.4895 - val_accuracy: 0.2444\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.4191 - accuracy: 0.1443 - val_loss: 65.4084 - val_accuracy: 0.2222\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3361 - accuracy: 0.1493 - val_loss: 65.3260 - val_accuracy: 0.1556\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.2550 - accuracy: 0.1418 - val_loss: 65.2415 - val_accuracy: 0.2222\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.1727 - accuracy: 0.1418 - val_loss: 65.1547 - val_accuracy: 0.2222\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.0888 - accuracy: 0.1368 - val_loss: 65.0712 - val_accuracy: 0.1556\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.0040 - accuracy: 0.1443 - val_loss: 64.9872 - val_accuracy: 0.2222\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.9197 - accuracy: 0.1393 - val_loss: 64.9025 - val_accuracy: 0.2222\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.8366 - accuracy: 0.1318 - val_loss: 64.8186 - val_accuracy: 0.2444\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.7544 - accuracy: 0.1443 - val_loss: 64.7340 - val_accuracy: 0.2444\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.6727 - accuracy: 0.1567 - val_loss: 64.6494 - val_accuracy: 0.1778\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.5904 - accuracy: 0.1592 - val_loss: 64.5660 - val_accuracy: 0.1778\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.5076 - accuracy: 0.1592 - val_loss: 64.4836 - val_accuracy: 0.1778\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.4241 - accuracy: 0.1667 - val_loss: 64.4046 - val_accuracy: 0.2222\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.3433 - accuracy: 0.1418 - val_loss: 64.3257 - val_accuracy: 0.2222\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.2614 - accuracy: 0.1418 - val_loss: 64.2418 - val_accuracy: 0.2222\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.1795 - accuracy: 0.1318 - val_loss: 64.1618 - val_accuracy: 0.1556\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.0977 - accuracy: 0.1393 - val_loss: 64.0803 - val_accuracy: 0.0889\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.0159 - accuracy: 0.1617 - val_loss: 63.9977 - val_accuracy: 0.0889\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.9341 - accuracy: 0.1667 - val_loss: 63.9170 - val_accuracy: 0.0889\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.8528 - accuracy: 0.1443 - val_loss: 63.8356 - val_accuracy: 0.1778\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.7721 - accuracy: 0.1468 - val_loss: 63.7566 - val_accuracy: 0.0889\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.6913 - accuracy: 0.1617 - val_loss: 63.6780 - val_accuracy: 0.0889\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.6101 - accuracy: 0.1617 - val_loss: 63.5977 - val_accuracy: 0.0889\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.5293 - accuracy: 0.1617 - val_loss: 63.5164 - val_accuracy: 0.0889\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4485 - accuracy: 0.1592 - val_loss: 63.4351 - val_accuracy: 0.1556\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.3685 - accuracy: 0.1542 - val_loss: 63.3588 - val_accuracy: 0.1556\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.2884 - accuracy: 0.1368 - val_loss: 63.2761 - val_accuracy: 0.1556\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.2077 - accuracy: 0.1418 - val_loss: 63.1951 - val_accuracy: 0.2222\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.1276 - accuracy: 0.1443 - val_loss: 63.1170 - val_accuracy: 0.2444\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.0470 - accuracy: 0.1716 - val_loss: 63.0347 - val_accuracy: 0.1778\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.9663 - accuracy: 0.1692 - val_loss: 62.9521 - val_accuracy: 0.2000\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.8864 - accuracy: 0.1791 - val_loss: 62.8725 - val_accuracy: 0.2000\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.8063 - accuracy: 0.1791 - val_loss: 62.7917 - val_accuracy: 0.2444\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.7268 - accuracy: 0.1741 - val_loss: 62.7136 - val_accuracy: 0.2222\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.6468 - accuracy: 0.1642 - val_loss: 62.6346 - val_accuracy: 0.2222\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62.5675 - accuracy: 0.1567 - val_loss: 62.5548 - val_accuracy: 0.2000\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.4879 - accuracy: 0.1468 - val_loss: 62.4777 - val_accuracy: 0.1556\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.4087 - accuracy: 0.1368 - val_loss: 62.4006 - val_accuracy: 0.1556\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.3298 - accuracy: 0.1294 - val_loss: 62.3216 - val_accuracy: 0.2444\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.2525 - accuracy: 0.1642 - val_loss: 62.2417 - val_accuracy: 0.1778\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1745 - accuracy: 0.1592 - val_loss: 62.1629 - val_accuracy: 0.1778\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.0942 - accuracy: 0.1791 - val_loss: 62.0864 - val_accuracy: 0.1778\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.0155 - accuracy: 0.1766 - val_loss: 62.0087 - val_accuracy: 0.1556\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9371 - accuracy: 0.1915 - val_loss: 61.9292 - val_accuracy: 0.1778\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8580 - accuracy: 0.1692 - val_loss: 61.8512 - val_accuracy: 0.2444\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7804 - accuracy: 0.1617 - val_loss: 61.7726 - val_accuracy: 0.1778\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.7014 - accuracy: 0.1592 - val_loss: 61.6929 - val_accuracy: 0.1778\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.6235 - accuracy: 0.1592 - val_loss: 61.6145 - val_accuracy: 0.1778\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.5457 - accuracy: 0.1517 - val_loss: 61.5365 - val_accuracy: 0.1556\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.4676 - accuracy: 0.1592 - val_loss: 61.4573 - val_accuracy: 0.1556\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3899 - accuracy: 0.1667 - val_loss: 61.3808 - val_accuracy: 0.1556\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3120 - accuracy: 0.1592 - val_loss: 61.3001 - val_accuracy: 0.2000\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2359 - accuracy: 0.1493 - val_loss: 61.2189 - val_accuracy: 0.2444\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.1573 - accuracy: 0.1567 - val_loss: 61.1384 - val_accuracy: 0.2444\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0797 - accuracy: 0.1716 - val_loss: 61.0621 - val_accuracy: 0.1778\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.0025 - accuracy: 0.1592 - val_loss: 60.9877 - val_accuracy: 0.1778\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.9254 - accuracy: 0.1592 - val_loss: 60.9132 - val_accuracy: 0.1778\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.8481 - accuracy: 0.1592 - val_loss: 60.8398 - val_accuracy: 0.1778\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.7724 - accuracy: 0.1940 - val_loss: 60.7665 - val_accuracy: 0.2000\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.6959 - accuracy: 0.1741 - val_loss: 60.6892 - val_accuracy: 0.2222\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6185 - accuracy: 0.1517 - val_loss: 60.6138 - val_accuracy: 0.2000\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5419 - accuracy: 0.1493 - val_loss: 60.5377 - val_accuracy: 0.2000\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60.4653 - accuracy: 0.1493 - val_loss: 60.4587 - val_accuracy: 0.2000\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3893 - accuracy: 0.1493 - val_loss: 60.3804 - val_accuracy: 0.2000\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3123 - accuracy: 0.1493 - val_loss: 60.3022 - val_accuracy: 0.2000\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.2356 - accuracy: 0.1443 - val_loss: 60.2259 - val_accuracy: 0.2222\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.1583 - accuracy: 0.1418 - val_loss: 60.1501 - val_accuracy: 0.2444\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.0840 - accuracy: 0.1716 - val_loss: 60.0764 - val_accuracy: 0.1333\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.0081 - accuracy: 0.2065 - val_loss: 59.9999 - val_accuracy: 0.0889\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.9310 - accuracy: 0.1592 - val_loss: 59.9216 - val_accuracy: 0.1556\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8554 - accuracy: 0.1368 - val_loss: 59.8423 - val_accuracy: 0.1556\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.7802 - accuracy: 0.1368 - val_loss: 59.7656 - val_accuracy: 0.1556\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7046 - accuracy: 0.1368 - val_loss: 59.6913 - val_accuracy: 0.1556\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6289 - accuracy: 0.1368 - val_loss: 59.6178 - val_accuracy: 0.1556\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.5535 - accuracy: 0.1393 - val_loss: 59.5470 - val_accuracy: 0.1556\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.4791 - accuracy: 0.2065 - val_loss: 59.4757 - val_accuracy: 0.1111\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.4050 - accuracy: 0.1915 - val_loss: 59.4014 - val_accuracy: 0.1333\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.3289 - accuracy: 0.2040 - val_loss: 59.3247 - val_accuracy: 0.1778\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2536 - accuracy: 0.1542 - val_loss: 59.2494 - val_accuracy: 0.2444\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1785 - accuracy: 0.1716 - val_loss: 59.1712 - val_accuracy: 0.2444\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1035 - accuracy: 0.1468 - val_loss: 59.0958 - val_accuracy: 0.2222\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.0292 - accuracy: 0.1368 - val_loss: 59.0206 - val_accuracy: 0.1556\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.9548 - accuracy: 0.1368 - val_loss: 58.9422 - val_accuracy: 0.1556\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.8800 - accuracy: 0.1318 - val_loss: 58.8647 - val_accuracy: 0.2222\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.8053 - accuracy: 0.1517 - val_loss: 58.7916 - val_accuracy: 0.2222\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.7313 - accuracy: 0.1716 - val_loss: 58.7188 - val_accuracy: 0.1556\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.6588 - accuracy: 0.1667 - val_loss: 58.6458 - val_accuracy: 0.1556\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5842 - accuracy: 0.1692 - val_loss: 58.5697 - val_accuracy: 0.2444\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.5100 - accuracy: 0.1692 - val_loss: 58.4985 - val_accuracy: 0.2444\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.4347 - accuracy: 0.1692 - val_loss: 58.4266 - val_accuracy: 0.2444\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.3623 - accuracy: 0.1542 - val_loss: 58.3583 - val_accuracy: 0.2222\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2878 - accuracy: 0.1393 - val_loss: 58.2875 - val_accuracy: 0.1556\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2145 - accuracy: 0.1368 - val_loss: 58.2150 - val_accuracy: 0.1556\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1414 - accuracy: 0.1393 - val_loss: 58.1394 - val_accuracy: 0.1556\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.0682 - accuracy: 0.1517 - val_loss: 58.0657 - val_accuracy: 0.1111\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.9942 - accuracy: 0.1617 - val_loss: 57.9882 - val_accuracy: 0.1778\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.9212 - accuracy: 0.1592 - val_loss: 57.9112 - val_accuracy: 0.2444\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.8486 - accuracy: 0.1418 - val_loss: 57.8364 - val_accuracy: 0.1556\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.7751 - accuracy: 0.1368 - val_loss: 57.7636 - val_accuracy: 0.1556\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7022 - accuracy: 0.1443 - val_loss: 57.6907 - val_accuracy: 0.2222\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6281 - accuracy: 0.1493 - val_loss: 57.6167 - val_accuracy: 0.2222\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5552 - accuracy: 0.1667 - val_loss: 57.5442 - val_accuracy: 0.1778\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 57.4825 - accuracy: 0.1592 - val_loss: 57.4731 - val_accuracy: 0.1778\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.4100 - accuracy: 0.1592 - val_loss: 57.4049 - val_accuracy: 0.1778\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3372 - accuracy: 0.1592 - val_loss: 57.3340 - val_accuracy: 0.0889\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.2653 - accuracy: 0.1542 - val_loss: 57.2608 - val_accuracy: 0.1778\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1919 - accuracy: 0.1468 - val_loss: 57.1853 - val_accuracy: 0.2444\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1196 - accuracy: 0.1617 - val_loss: 57.1108 - val_accuracy: 0.2444\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.0479 - accuracy: 0.1468 - val_loss: 57.0383 - val_accuracy: 0.2222\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9759 - accuracy: 0.1418 - val_loss: 56.9651 - val_accuracy: 0.2444\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.9039 - accuracy: 0.1617 - val_loss: 56.8910 - val_accuracy: 0.2222\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.8322 - accuracy: 0.1592 - val_loss: 56.8195 - val_accuracy: 0.2444\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7599 - accuracy: 0.1517 - val_loss: 56.7503 - val_accuracy: 0.1778\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.6878 - accuracy: 0.1592 - val_loss: 56.6795 - val_accuracy: 0.1778\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.6158 - accuracy: 0.1592 - val_loss: 56.6102 - val_accuracy: 0.1778\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.5453 - accuracy: 0.1642 - val_loss: 56.5420 - val_accuracy: 0.1778\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.4743 - accuracy: 0.1866 - val_loss: 56.4724 - val_accuracy: 0.1556\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.4025 - accuracy: 0.1990 - val_loss: 56.3993 - val_accuracy: 0.2222\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.3309 - accuracy: 0.1567 - val_loss: 56.3269 - val_accuracy: 0.1778\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2595 - accuracy: 0.1592 - val_loss: 56.2534 - val_accuracy: 0.1778\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.1881 - accuracy: 0.1592 - val_loss: 56.1799 - val_accuracy: 0.1778\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.1167 - accuracy: 0.1592 - val_loss: 56.1050 - val_accuracy: 0.1778\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.0461 - accuracy: 0.1393 - val_loss: 56.0332 - val_accuracy: 0.2222\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.9744 - accuracy: 0.1493 - val_loss: 55.9634 - val_accuracy: 0.1556\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.9047 - accuracy: 0.1567 - val_loss: 55.8928 - val_accuracy: 0.2000\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.8355 - accuracy: 0.1493 - val_loss: 55.8234 - val_accuracy: 0.2000\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.7644 - accuracy: 0.1667 - val_loss: 55.7539 - val_accuracy: 0.2444\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6932 - accuracy: 0.1692 - val_loss: 55.6829 - val_accuracy: 0.2222\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6216 - accuracy: 0.1692 - val_loss: 55.6118 - val_accuracy: 0.2222\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5506 - accuracy: 0.1766 - val_loss: 55.5437 - val_accuracy: 0.1778\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.4803 - accuracy: 0.1592 - val_loss: 55.4775 - val_accuracy: 0.1778\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4110 - accuracy: 0.1592 - val_loss: 55.4092 - val_accuracy: 0.1778\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.3397 - accuracy: 0.1592 - val_loss: 55.3356 - val_accuracy: 0.2222\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2699 - accuracy: 0.1741 - val_loss: 55.2623 - val_accuracy: 0.2444\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.2003 - accuracy: 0.1443 - val_loss: 55.1891 - val_accuracy: 0.2222\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1300 - accuracy: 0.1368 - val_loss: 55.1187 - val_accuracy: 0.2000\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.0598 - accuracy: 0.1493 - val_loss: 55.0510 - val_accuracy: 0.2222\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.9905 - accuracy: 0.1716 - val_loss: 54.9853 - val_accuracy: 0.2000\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.9204 - accuracy: 0.1791 - val_loss: 54.9171 - val_accuracy: 0.1556\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8511 - accuracy: 0.1841 - val_loss: 54.8491 - val_accuracy: 0.2000\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.7812 - accuracy: 0.1493 - val_loss: 54.7788 - val_accuracy: 0.2000\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.7111 - accuracy: 0.1468 - val_loss: 54.7095 - val_accuracy: 0.2444\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.6419 - accuracy: 0.1567 - val_loss: 54.6402 - val_accuracy: 0.1778\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.5725 - accuracy: 0.1592 - val_loss: 54.5707 - val_accuracy: 0.1778\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5031 - accuracy: 0.1592 - val_loss: 54.5014 - val_accuracy: 0.1778\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.4339 - accuracy: 0.1592 - val_loss: 54.4336 - val_accuracy: 0.1778\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.3651 - accuracy: 0.1592 - val_loss: 54.3664 - val_accuracy: 0.2222\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.2954 - accuracy: 0.1716 - val_loss: 54.2985 - val_accuracy: 0.1556\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.2283 - accuracy: 0.1368 - val_loss: 54.2302 - val_accuracy: 0.1556\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1596 - accuracy: 0.1368 - val_loss: 54.1574 - val_accuracy: 0.1556\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.0903 - accuracy: 0.1368 - val_loss: 54.0851 - val_accuracy: 0.1556\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0207 - accuracy: 0.1443 - val_loss: 54.0142 - val_accuracy: 0.1111\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.9523 - accuracy: 0.1617 - val_loss: 53.9451 - val_accuracy: 0.1778\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.8836 - accuracy: 0.1592 - val_loss: 53.8756 - val_accuracy: 0.1778\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.8153 - accuracy: 0.1592 - val_loss: 53.8069 - val_accuracy: 0.1778\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.7465 - accuracy: 0.1592 - val_loss: 53.7411 - val_accuracy: 0.1778\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6775 - accuracy: 0.1692 - val_loss: 53.6750 - val_accuracy: 0.2444\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.6099 - accuracy: 0.1592 - val_loss: 53.6089 - val_accuracy: 0.2222\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.5428 - accuracy: 0.1418 - val_loss: 53.5424 - val_accuracy: 0.2222\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4757 - accuracy: 0.1418 - val_loss: 53.4733 - val_accuracy: 0.2222\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.4060 - accuracy: 0.1418 - val_loss: 53.4020 - val_accuracy: 0.2222\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.3370 - accuracy: 0.1418 - val_loss: 53.3316 - val_accuracy: 0.2222\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2689 - accuracy: 0.1517 - val_loss: 53.2648 - val_accuracy: 0.2222\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2019 - accuracy: 0.1617 - val_loss: 53.1991 - val_accuracy: 0.1556\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1358 - accuracy: 0.1617 - val_loss: 53.1338 - val_accuracy: 0.1556\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.0694 - accuracy: 0.1667 - val_loss: 53.0682 - val_accuracy: 0.1556\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.9999 - accuracy: 0.1741 - val_loss: 52.9995 - val_accuracy: 0.2222\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.9318 - accuracy: 0.1493 - val_loss: 52.9303 - val_accuracy: 0.2222\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.8634 - accuracy: 0.1393 - val_loss: 52.8656 - val_accuracy: 0.1556\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7976 - accuracy: 0.1368 - val_loss: 52.7985 - val_accuracy: 0.2222\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7302 - accuracy: 0.1418 - val_loss: 52.7282 - val_accuracy: 0.2222\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6622 - accuracy: 0.1443 - val_loss: 52.6613 - val_accuracy: 0.2444\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.5943 - accuracy: 0.1443 - val_loss: 52.5982 - val_accuracy: 0.0889\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.5279 - accuracy: 0.1617 - val_loss: 52.5354 - val_accuracy: 0.0889\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.4611 - accuracy: 0.1617 - val_loss: 52.4688 - val_accuracy: 0.0889\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.3936 - accuracy: 0.1617 - val_loss: 52.4003 - val_accuracy: 0.0889\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3265 - accuracy: 0.1617 - val_loss: 52.3315 - val_accuracy: 0.0889\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.2602 - accuracy: 0.1642 - val_loss: 52.2604 - val_accuracy: 0.1778\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1935 - accuracy: 0.1617 - val_loss: 52.1888 - val_accuracy: 0.1778\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.1263 - accuracy: 0.1592 - val_loss: 52.1202 - val_accuracy: 0.1778\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.0593 - accuracy: 0.1592 - val_loss: 52.0516 - val_accuracy: 0.1778\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9926 - accuracy: 0.1592 - val_loss: 51.9832 - val_accuracy: 0.1778\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9257 - accuracy: 0.1567 - val_loss: 51.9150 - val_accuracy: 0.2444\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8600 - accuracy: 0.1418 - val_loss: 51.8507 - val_accuracy: 0.1556\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.7941 - accuracy: 0.1368 - val_loss: 51.7884 - val_accuracy: 0.1556\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7269 - accuracy: 0.1368 - val_loss: 51.7235 - val_accuracy: 0.1556\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51.6617 - accuracy: 0.1592 - val_loss: 51.6573 - val_accuracy: 0.1111\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5944 - accuracy: 0.1642 - val_loss: 51.5904 - val_accuracy: 0.1556\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5287 - accuracy: 0.1493 - val_loss: 51.5241 - val_accuracy: 0.2222\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.4630 - accuracy: 0.1741 - val_loss: 51.4554 - val_accuracy: 0.1778\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3967 - accuracy: 0.1418 - val_loss: 51.3867 - val_accuracy: 0.0889\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3319 - accuracy: 0.1592 - val_loss: 51.3189 - val_accuracy: 0.1333\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51.2657 - accuracy: 0.1766 - val_loss: 51.2533 - val_accuracy: 0.0889\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1996 - accuracy: 0.1617 - val_loss: 51.1890 - val_accuracy: 0.1556\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1332 - accuracy: 0.1418 - val_loss: 51.1249 - val_accuracy: 0.1556\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0686 - accuracy: 0.1368 - val_loss: 51.0600 - val_accuracy: 0.1556\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0031 - accuracy: 0.1468 - val_loss: 50.9938 - val_accuracy: 0.2222\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9374 - accuracy: 0.1418 - val_loss: 50.9287 - val_accuracy: 0.2222\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8716 - accuracy: 0.1418 - val_loss: 50.8632 - val_accuracy: 0.2222\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.8056 - accuracy: 0.1567 - val_loss: 50.7961 - val_accuracy: 0.2222\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50.7418 - accuracy: 0.1617 - val_loss: 50.7290 - val_accuracy: 0.1778\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6768 - accuracy: 0.1667 - val_loss: 50.6646 - val_accuracy: 0.2444\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6119 - accuracy: 0.1667 - val_loss: 50.6032 - val_accuracy: 0.2444\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.5470 - accuracy: 0.1542 - val_loss: 50.5431 - val_accuracy: 0.1111\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4807 - accuracy: 0.1617 - val_loss: 50.4828 - val_accuracy: 0.1778\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.4155 - accuracy: 0.1393 - val_loss: 50.4203 - val_accuracy: 0.1556\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.3516 - accuracy: 0.1368 - val_loss: 50.3541 - val_accuracy: 0.1556\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.2867 - accuracy: 0.1368 - val_loss: 50.2862 - val_accuracy: 0.1556\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2215 - accuracy: 0.1368 - val_loss: 50.2184 - val_accuracy: 0.1556\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.1566 - accuracy: 0.1368 - val_loss: 50.1510 - val_accuracy: 0.1556\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.0917 - accuracy: 0.1368 - val_loss: 50.0839 - val_accuracy: 0.2222\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.0290 - accuracy: 0.1592 - val_loss: 50.0170 - val_accuracy: 0.1778\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.9649 - accuracy: 0.1592 - val_loss: 49.9517 - val_accuracy: 0.1778\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.9001 - accuracy: 0.1592 - val_loss: 49.8890 - val_accuracy: 0.1778\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8360 - accuracy: 0.1642 - val_loss: 49.8276 - val_accuracy: 0.2444\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7706 - accuracy: 0.1443 - val_loss: 49.7657 - val_accuracy: 0.2222\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.7076 - accuracy: 0.1468 - val_loss: 49.7029 - val_accuracy: 0.1556\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49.6423 - accuracy: 0.1418 - val_loss: 49.6396 - val_accuracy: 0.0889\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5790 - accuracy: 0.1617 - val_loss: 49.5759 - val_accuracy: 0.0889\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5155 - accuracy: 0.1617 - val_loss: 49.5140 - val_accuracy: 0.1111\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4511 - accuracy: 0.1866 - val_loss: 49.4504 - val_accuracy: 0.1778\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3873 - accuracy: 0.1915 - val_loss: 49.3861 - val_accuracy: 0.2000\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3229 - accuracy: 0.2040 - val_loss: 49.3240 - val_accuracy: 0.1778\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.2598 - accuracy: 0.1592 - val_loss: 49.2610 - val_accuracy: 0.1778\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.1952 - accuracy: 0.1592 - val_loss: 49.1962 - val_accuracy: 0.1778\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49.1316 - accuracy: 0.1667 - val_loss: 49.1334 - val_accuracy: 0.2000\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0678 - accuracy: 0.1493 - val_loss: 49.0705 - val_accuracy: 0.2000\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0049 - accuracy: 0.1493 - val_loss: 49.0093 - val_accuracy: 0.2000\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9419 - accuracy: 0.1493 - val_loss: 48.9469 - val_accuracy: 0.2000\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8786 - accuracy: 0.1493 - val_loss: 48.8823 - val_accuracy: 0.2000\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.8148 - accuracy: 0.1493 - val_loss: 48.8163 - val_accuracy: 0.1556\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7516 - accuracy: 0.1418 - val_loss: 48.7499 - val_accuracy: 0.1778\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6887 - accuracy: 0.1368 - val_loss: 48.6838 - val_accuracy: 0.1556\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.6254 - accuracy: 0.1318 - val_loss: 48.6214 - val_accuracy: 0.1556\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5622 - accuracy: 0.1393 - val_loss: 48.5596 - val_accuracy: 0.1778\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4984 - accuracy: 0.1617 - val_loss: 48.4977 - val_accuracy: 0.1556\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.4357 - accuracy: 0.1766 - val_loss: 48.4360 - val_accuracy: 0.2000\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.3735 - accuracy: 0.1692 - val_loss: 48.3744 - val_accuracy: 0.2000\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.3106 - accuracy: 0.1493 - val_loss: 48.3121 - val_accuracy: 0.2000\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.2487 - accuracy: 0.1443 - val_loss: 48.2497 - val_accuracy: 0.2222\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.1868 - accuracy: 0.1493 - val_loss: 48.1895 - val_accuracy: 0.2000\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.1251 - accuracy: 0.1493 - val_loss: 48.1270 - val_accuracy: 0.2000\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0631 - accuracy: 0.1493 - val_loss: 48.0629 - val_accuracy: 0.2000\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.0003 - accuracy: 0.1443 - val_loss: 47.9961 - val_accuracy: 0.2222\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.9361 - accuracy: 0.1443 - val_loss: 47.9300 - val_accuracy: 0.2222\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.8728 - accuracy: 0.1642 - val_loss: 47.8659 - val_accuracy: 0.1778\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.8119 - accuracy: 0.1716 - val_loss: 47.8057 - val_accuracy: 0.2000\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.7499 - accuracy: 0.1816 - val_loss: 47.7448 - val_accuracy: 0.1778\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.6876 - accuracy: 0.1692 - val_loss: 47.6844 - val_accuracy: 0.0889\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.6240 - accuracy: 0.1617 - val_loss: 47.6229 - val_accuracy: 0.1556\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.5628 - accuracy: 0.1443 - val_loss: 47.5616 - val_accuracy: 0.1556\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5017 - accuracy: 0.1393 - val_loss: 47.4995 - val_accuracy: 0.2222\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.4391 - accuracy: 0.1418 - val_loss: 47.4359 - val_accuracy: 0.2222\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3767 - accuracy: 0.1393 - val_loss: 47.3715 - val_accuracy: 0.2222\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.3152 - accuracy: 0.1418 - val_loss: 47.3083 - val_accuracy: 0.1778\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.2527 - accuracy: 0.1592 - val_loss: 47.2482 - val_accuracy: 0.1778\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.1911 - accuracy: 0.1617 - val_loss: 47.1855 - val_accuracy: 0.2444\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1296 - accuracy: 0.1517 - val_loss: 47.1226 - val_accuracy: 0.2222\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0687 - accuracy: 0.1343 - val_loss: 47.0615 - val_accuracy: 0.1556\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.0068 - accuracy: 0.1493 - val_loss: 47.0016 - val_accuracy: 0.1778\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9458 - accuracy: 0.1592 - val_loss: 46.9416 - val_accuracy: 0.1778\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.8854 - accuracy: 0.1642 - val_loss: 46.8798 - val_accuracy: 0.1778\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.8226 - accuracy: 0.1567 - val_loss: 46.8189 - val_accuracy: 0.2444\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7613 - accuracy: 0.1617 - val_loss: 46.7601 - val_accuracy: 0.2222\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7006 - accuracy: 0.1418 - val_loss: 46.7006 - val_accuracy: 0.2222\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6390 - accuracy: 0.1418 - val_loss: 46.6400 - val_accuracy: 0.2222\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5768 - accuracy: 0.1418 - val_loss: 46.5818 - val_accuracy: 0.2222\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.5159 - accuracy: 0.1766 - val_loss: 46.5275 - val_accuracy: 0.0889\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.4568 - accuracy: 0.2164 - val_loss: 46.4690 - val_accuracy: 0.1333\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3963 - accuracy: 0.2065 - val_loss: 46.4051 - val_accuracy: 0.0889\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3351 - accuracy: 0.1617 - val_loss: 46.3393 - val_accuracy: 0.0889\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.2745 - accuracy: 0.1716 - val_loss: 46.2724 - val_accuracy: 0.2222\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2136 - accuracy: 0.1592 - val_loss: 46.2089 - val_accuracy: 0.2222\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.1514 - accuracy: 0.1567 - val_loss: 46.1468 - val_accuracy: 0.2222\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0913 - accuracy: 0.1418 - val_loss: 46.0868 - val_accuracy: 0.2222\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0314 - accuracy: 0.1443 - val_loss: 46.0285 - val_accuracy: 0.2000\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.9707 - accuracy: 0.1567 - val_loss: 45.9694 - val_accuracy: 0.2000\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.9098 - accuracy: 0.1443 - val_loss: 45.9085 - val_accuracy: 0.2222\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8496 - accuracy: 0.1493 - val_loss: 45.8487 - val_accuracy: 0.2444\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.7886 - accuracy: 0.1493 - val_loss: 45.7868 - val_accuracy: 0.2222\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7288 - accuracy: 0.1418 - val_loss: 45.7254 - val_accuracy: 0.2222\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6682 - accuracy: 0.1418 - val_loss: 45.6647 - val_accuracy: 0.2222\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6087 - accuracy: 0.1418 - val_loss: 45.6051 - val_accuracy: 0.2222\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5485 - accuracy: 0.1418 - val_loss: 45.5416 - val_accuracy: 0.2222\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.4883 - accuracy: 0.1443 - val_loss: 45.4814 - val_accuracy: 0.2444\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.4282 - accuracy: 0.1716 - val_loss: 45.4229 - val_accuracy: 0.1778\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3678 - accuracy: 0.1592 - val_loss: 45.3652 - val_accuracy: 0.1778\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3085 - accuracy: 0.1592 - val_loss: 45.3072 - val_accuracy: 0.2222\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.2503 - accuracy: 0.2090 - val_loss: 45.2512 - val_accuracy: 0.2000\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1917 - accuracy: 0.1766 - val_loss: 45.1917 - val_accuracy: 0.2000\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1305 - accuracy: 0.1841 - val_loss: 45.1309 - val_accuracy: 0.1556\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.0694 - accuracy: 0.1692 - val_loss: 45.0711 - val_accuracy: 0.2222\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.0114 - accuracy: 0.1418 - val_loss: 45.0104 - val_accuracy: 0.2222\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.9516 - accuracy: 0.1418 - val_loss: 44.9513 - val_accuracy: 0.2222\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8914 - accuracy: 0.1418 - val_loss: 44.8924 - val_accuracy: 0.2222\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8323 - accuracy: 0.2040 - val_loss: 44.8340 - val_accuracy: 0.2889\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44.7733 - accuracy: 0.2189 - val_loss: 44.7731 - val_accuracy: 0.2000\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.7134 - accuracy: 0.1542 - val_loss: 44.7119 - val_accuracy: 0.2222\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6540 - accuracy: 0.1418 - val_loss: 44.6518 - val_accuracy: 0.2222\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.5949 - accuracy: 0.1418 - val_loss: 44.5930 - val_accuracy: 0.2222\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.5362 - accuracy: 0.1418 - val_loss: 44.5359 - val_accuracy: 0.2222\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.4766 - accuracy: 0.1468 - val_loss: 44.4794 - val_accuracy: 0.2444\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.4182 - accuracy: 0.1517 - val_loss: 44.4228 - val_accuracy: 0.1778\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.3606 - accuracy: 0.1592 - val_loss: 44.3670 - val_accuracy: 0.1778\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.3020 - accuracy: 0.1592 - val_loss: 44.3087 - val_accuracy: 0.1778\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.2439 - accuracy: 0.1592 - val_loss: 44.2490 - val_accuracy: 0.1778\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1835 - accuracy: 0.1667 - val_loss: 44.1888 - val_accuracy: 0.2222\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1239 - accuracy: 0.1716 - val_loss: 44.1288 - val_accuracy: 0.1556\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0653 - accuracy: 0.1841 - val_loss: 44.0683 - val_accuracy: 0.2222\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0060 - accuracy: 0.1567 - val_loss: 44.0072 - val_accuracy: 0.1778\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.9480 - accuracy: 0.1592 - val_loss: 43.9481 - val_accuracy: 0.1778\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.8903 - accuracy: 0.1592 - val_loss: 43.8890 - val_accuracy: 0.1778\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.8313 - accuracy: 0.1592 - val_loss: 43.8303 - val_accuracy: 0.1778\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.7730 - accuracy: 0.1592 - val_loss: 43.7718 - val_accuracy: 0.1778\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7152 - accuracy: 0.1592 - val_loss: 43.7141 - val_accuracy: 0.2444\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6573 - accuracy: 0.1418 - val_loss: 43.6568 - val_accuracy: 0.1556\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5983 - accuracy: 0.1493 - val_loss: 43.6005 - val_accuracy: 0.2444\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.5399 - accuracy: 0.1667 - val_loss: 43.5433 - val_accuracy: 0.1778\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.4815 - accuracy: 0.1592 - val_loss: 43.4853 - val_accuracy: 0.1778\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4240 - accuracy: 0.1592 - val_loss: 43.4278 - val_accuracy: 0.1778\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.3663 - accuracy: 0.1642 - val_loss: 43.3726 - val_accuracy: 0.1556\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3093 - accuracy: 0.1667 - val_loss: 43.3144 - val_accuracy: 0.1556\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2519 - accuracy: 0.1667 - val_loss: 43.2560 - val_accuracy: 0.2000\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.1932 - accuracy: 0.1592 - val_loss: 43.1961 - val_accuracy: 0.1778\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43.1348 - accuracy: 0.1592 - val_loss: 43.1362 - val_accuracy: 0.1778\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0760 - accuracy: 0.1592 - val_loss: 43.0772 - val_accuracy: 0.2222\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.0194 - accuracy: 0.1418 - val_loss: 43.0213 - val_accuracy: 0.2000\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9617 - accuracy: 0.1493 - val_loss: 42.9661 - val_accuracy: 0.2000\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.9033 - accuracy: 0.1443 - val_loss: 42.9072 - val_accuracy: 0.2222\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42.8467 - accuracy: 0.1418 - val_loss: 42.8491 - val_accuracy: 0.2222\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.7892 - accuracy: 0.1418 - val_loss: 42.7895 - val_accuracy: 0.2222\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.7323 - accuracy: 0.1418 - val_loss: 42.7289 - val_accuracy: 0.2222\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6739 - accuracy: 0.1418 - val_loss: 42.6692 - val_accuracy: 0.2444\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6159 - accuracy: 0.1617 - val_loss: 42.6127 - val_accuracy: 0.2444\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5589 - accuracy: 0.1493 - val_loss: 42.5565 - val_accuracy: 0.2000\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.5013 - accuracy: 0.1493 - val_loss: 42.5007 - val_accuracy: 0.2000\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4450 - accuracy: 0.1343 - val_loss: 42.4449 - val_accuracy: 0.2444\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.3874 - accuracy: 0.1517 - val_loss: 42.3908 - val_accuracy: 0.2444\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3310 - accuracy: 0.1517 - val_loss: 42.3355 - val_accuracy: 0.1778\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.2740 - accuracy: 0.1592 - val_loss: 42.2790 - val_accuracy: 0.1778\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2170 - accuracy: 0.1592 - val_loss: 42.2217 - val_accuracy: 0.1778\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.1601 - accuracy: 0.1592 - val_loss: 42.1653 - val_accuracy: 0.1778\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1034 - accuracy: 0.1592 - val_loss: 42.1079 - val_accuracy: 0.1111\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.0460 - accuracy: 0.1542 - val_loss: 42.0495 - val_accuracy: 0.2222\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.9894 - accuracy: 0.1418 - val_loss: 41.9919 - val_accuracy: 0.2222\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.9324 - accuracy: 0.1517 - val_loss: 41.9341 - val_accuracy: 0.2000\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.8764 - accuracy: 0.1493 - val_loss: 41.8786 - val_accuracy: 0.2000\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.8205 - accuracy: 0.1493 - val_loss: 41.8230 - val_accuracy: 0.2000\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.7647 - accuracy: 0.1493 - val_loss: 41.7679 - val_accuracy: 0.2000\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.7080 - accuracy: 0.1468 - val_loss: 41.7111 - val_accuracy: 0.1556\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6509 - accuracy: 0.1393 - val_loss: 41.6532 - val_accuracy: 0.1556\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.5947 - accuracy: 0.1542 - val_loss: 41.5964 - val_accuracy: 0.1556\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.5377 - accuracy: 0.1368 - val_loss: 41.5418 - val_accuracy: 0.1556\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41.4822 - accuracy: 0.1393 - val_loss: 41.4873 - val_accuracy: 0.2222\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4267 - accuracy: 0.1418 - val_loss: 41.4295 - val_accuracy: 0.2222\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3704 - accuracy: 0.1468 - val_loss: 41.3731 - val_accuracy: 0.2222\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.3141 - accuracy: 0.1418 - val_loss: 41.3160 - val_accuracy: 0.2444\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.2574 - accuracy: 0.1692 - val_loss: 41.2579 - val_accuracy: 0.2222\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2019 - accuracy: 0.1741 - val_loss: 41.2007 - val_accuracy: 0.2444\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.1463 - accuracy: 0.1468 - val_loss: 41.1436 - val_accuracy: 0.2222\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.0902 - accuracy: 0.1418 - val_loss: 41.0888 - val_accuracy: 0.2222\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0336 - accuracy: 0.1418 - val_loss: 41.0359 - val_accuracy: 0.1556\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.9781 - accuracy: 0.1368 - val_loss: 40.9831 - val_accuracy: 0.1556\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.9231 - accuracy: 0.1592 - val_loss: 40.9283 - val_accuracy: 0.1778\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8678 - accuracy: 0.1791 - val_loss: 40.8745 - val_accuracy: 0.1778\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8118 - accuracy: 0.1517 - val_loss: 40.8166 - val_accuracy: 0.1556\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.7569 - accuracy: 0.1368 - val_loss: 40.7578 - val_accuracy: 0.1556\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.7008 - accuracy: 0.1443 - val_loss: 40.6994 - val_accuracy: 0.2000\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.6459 - accuracy: 0.1517 - val_loss: 40.6421 - val_accuracy: 0.2444\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5908 - accuracy: 0.1716 - val_loss: 40.5867 - val_accuracy: 0.1778\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5349 - accuracy: 0.1592 - val_loss: 40.5323 - val_accuracy: 0.1778\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.4800 - accuracy: 0.1617 - val_loss: 40.4773 - val_accuracy: 0.2222\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.4242 - accuracy: 0.1418 - val_loss: 40.4252 - val_accuracy: 0.2222\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3679 - accuracy: 0.1493 - val_loss: 40.3728 - val_accuracy: 0.1778\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3140 - accuracy: 0.2065 - val_loss: 40.3195 - val_accuracy: 0.1111\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2600 - accuracy: 0.2040 - val_loss: 40.2644 - val_accuracy: 0.1333\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2053 - accuracy: 0.1642 - val_loss: 40.2069 - val_accuracy: 0.0889\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.1500 - accuracy: 0.1617 - val_loss: 40.1499 - val_accuracy: 0.0889\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.0954 - accuracy: 0.1617 - val_loss: 40.0908 - val_accuracy: 0.0889\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0413 - accuracy: 0.1592 - val_loss: 40.0330 - val_accuracy: 0.1556\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9850 - accuracy: 0.1368 - val_loss: 39.9785 - val_accuracy: 0.2222\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9291 - accuracy: 0.1418 - val_loss: 39.9257 - val_accuracy: 0.2222\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.8745 - accuracy: 0.1816 - val_loss: 39.8733 - val_accuracy: 0.3111\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.8200 - accuracy: 0.2438 - val_loss: 39.8204 - val_accuracy: 0.2889\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7652 - accuracy: 0.2413 - val_loss: 39.7681 - val_accuracy: 0.2222\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7107 - accuracy: 0.1866 - val_loss: 39.7148 - val_accuracy: 0.1778\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.6560 - accuracy: 0.1592 - val_loss: 39.6598 - val_accuracy: 0.1778\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.6012 - accuracy: 0.1642 - val_loss: 39.6058 - val_accuracy: 0.2444\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.5468 - accuracy: 0.1468 - val_loss: 39.5507 - val_accuracy: 0.2222\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4919 - accuracy: 0.1517 - val_loss: 39.4947 - val_accuracy: 0.2444\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.4392 - accuracy: 0.1667 - val_loss: 39.4390 - val_accuracy: 0.1778\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3850 - accuracy: 0.1592 - val_loss: 39.3848 - val_accuracy: 0.1778\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3300 - accuracy: 0.1592 - val_loss: 39.3327 - val_accuracy: 0.1778\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.2761 - accuracy: 0.1592 - val_loss: 39.2822 - val_accuracy: 0.1778\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.2225 - accuracy: 0.1592 - val_loss: 39.2305 - val_accuracy: 0.1778\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.1681 - accuracy: 0.1592 - val_loss: 39.1756 - val_accuracy: 0.1778\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.1144 - accuracy: 0.1692 - val_loss: 39.1209 - val_accuracy: 0.2444\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.0594 - accuracy: 0.1841 - val_loss: 39.0653 - val_accuracy: 0.2444\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.0050 - accuracy: 0.1692 - val_loss: 39.0092 - val_accuracy: 0.2222\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9527 - accuracy: 0.1418 - val_loss: 38.9560 - val_accuracy: 0.2222\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.8988 - accuracy: 0.1393 - val_loss: 38.9034 - val_accuracy: 0.2000\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.8451 - accuracy: 0.1493 - val_loss: 38.8491 - val_accuracy: 0.2000\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7918 - accuracy: 0.1493 - val_loss: 38.7937 - val_accuracy: 0.2000\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.7385 - accuracy: 0.1244 - val_loss: 38.7351 - val_accuracy: 0.2000\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6847 - accuracy: 0.1493 - val_loss: 38.6812 - val_accuracy: 0.2000\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6295 - accuracy: 0.1517 - val_loss: 38.6286 - val_accuracy: 0.2222\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5766 - accuracy: 0.1766 - val_loss: 38.5760 - val_accuracy: 0.2000\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.5249 - accuracy: 0.1766 - val_loss: 38.5242 - val_accuracy: 0.2000\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.4709 - accuracy: 0.1766 - val_loss: 38.4723 - val_accuracy: 0.2444\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4166 - accuracy: 0.1692 - val_loss: 38.4207 - val_accuracy: 0.2222\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.3627 - accuracy: 0.1692 - val_loss: 38.3684 - val_accuracy: 0.1778\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.3093 - accuracy: 0.1592 - val_loss: 38.3160 - val_accuracy: 0.1778\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.2562 - accuracy: 0.1592 - val_loss: 38.2620 - val_accuracy: 0.1778\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.2033 - accuracy: 0.1592 - val_loss: 38.2101 - val_accuracy: 0.1556\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.1500 - accuracy: 0.1667 - val_loss: 38.1575 - val_accuracy: 0.1556\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.0965 - accuracy: 0.1741 - val_loss: 38.1025 - val_accuracy: 0.2222\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0435 - accuracy: 0.1766 - val_loss: 38.0516 - val_accuracy: 0.2222\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.9902 - accuracy: 0.1517 - val_loss: 38.0008 - val_accuracy: 0.1556\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.9394 - accuracy: 0.1368 - val_loss: 37.9511 - val_accuracy: 0.1556\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.8859 - accuracy: 0.1368 - val_loss: 37.8966 - val_accuracy: 0.1556\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.8325 - accuracy: 0.1368 - val_loss: 37.8392 - val_accuracy: 0.1556\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7794 - accuracy: 0.1517 - val_loss: 37.7830 - val_accuracy: 0.2000\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.7273 - accuracy: 0.1493 - val_loss: 37.7302 - val_accuracy: 0.2000\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.6748 - accuracy: 0.1493 - val_loss: 37.6778 - val_accuracy: 0.2222\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.6213 - accuracy: 0.1741 - val_loss: 37.6250 - val_accuracy: 0.2222\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.5689 - accuracy: 0.1642 - val_loss: 37.5730 - val_accuracy: 0.1778\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37.5170 - accuracy: 0.1592 - val_loss: 37.5220 - val_accuracy: 0.1778\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4635 - accuracy: 0.1592 - val_loss: 37.4694 - val_accuracy: 0.1778\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.4115 - accuracy: 0.1791 - val_loss: 37.4192 - val_accuracy: 0.2667\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3592 - accuracy: 0.1716 - val_loss: 37.3638 - val_accuracy: 0.2444\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.3062 - accuracy: 0.1418 - val_loss: 37.3107 - val_accuracy: 0.2000\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37.2540 - accuracy: 0.1493 - val_loss: 37.2569 - val_accuracy: 0.2000\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2023 - accuracy: 0.1343 - val_loss: 37.2038 - val_accuracy: 0.2444\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1500 - accuracy: 0.1592 - val_loss: 37.1523 - val_accuracy: 0.1778\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.0985 - accuracy: 0.1493 - val_loss: 37.1030 - val_accuracy: 0.2000\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.0459 - accuracy: 0.1816 - val_loss: 37.0530 - val_accuracy: 0.2222\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.9944 - accuracy: 0.1692 - val_loss: 37.0040 - val_accuracy: 0.2000\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9421 - accuracy: 0.1642 - val_loss: 36.9538 - val_accuracy: 0.2222\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8908 - accuracy: 0.1716 - val_loss: 36.9018 - val_accuracy: 0.2000\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8386 - accuracy: 0.1567 - val_loss: 36.8484 - val_accuracy: 0.1778\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.7866 - accuracy: 0.1592 - val_loss: 36.7947 - val_accuracy: 0.1778\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.7346 - accuracy: 0.1716 - val_loss: 36.7434 - val_accuracy: 0.2000\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6826 - accuracy: 0.2015 - val_loss: 36.6927 - val_accuracy: 0.2000\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6318 - accuracy: 0.2114 - val_loss: 36.6418 - val_accuracy: 0.1778\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.5803 - accuracy: 0.1667 - val_loss: 36.5867 - val_accuracy: 0.2222\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.5283 - accuracy: 0.1766 - val_loss: 36.5331 - val_accuracy: 0.2444\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4762 - accuracy: 0.1443 - val_loss: 36.4812 - val_accuracy: 0.2222\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.4249 - accuracy: 0.1443 - val_loss: 36.4307 - val_accuracy: 0.2000\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.3747 - accuracy: 0.1269 - val_loss: 36.3817 - val_accuracy: 0.1556\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3223 - accuracy: 0.1368 - val_loss: 36.3287 - val_accuracy: 0.2222\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2706 - accuracy: 0.1418 - val_loss: 36.2759 - val_accuracy: 0.2222\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2196 - accuracy: 0.1617 - val_loss: 36.2247 - val_accuracy: 0.1556\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.1680 - accuracy: 0.1642 - val_loss: 36.1718 - val_accuracy: 0.2222\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.1177 - accuracy: 0.1692 - val_loss: 36.1203 - val_accuracy: 0.1556\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0670 - accuracy: 0.2214 - val_loss: 36.0690 - val_accuracy: 0.2000\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0154 - accuracy: 0.2139 - val_loss: 36.0183 - val_accuracy: 0.1778\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.9643 - accuracy: 0.1542 - val_loss: 35.9670 - val_accuracy: 0.1778\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.9129 - accuracy: 0.1592 - val_loss: 35.9163 - val_accuracy: 0.1778\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.8613 - accuracy: 0.1592 - val_loss: 35.8654 - val_accuracy: 0.2222\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8099 - accuracy: 0.1692 - val_loss: 35.8135 - val_accuracy: 0.2222\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.7588 - accuracy: 0.1642 - val_loss: 35.7618 - val_accuracy: 0.2667\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7086 - accuracy: 0.1915 - val_loss: 35.7123 - val_accuracy: 0.2667\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.6586 - accuracy: 0.2239 - val_loss: 35.6643 - val_accuracy: 0.2667\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6080 - accuracy: 0.2313 - val_loss: 35.6137 - val_accuracy: 0.2444\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.5569 - accuracy: 0.2114 - val_loss: 35.5620 - val_accuracy: 0.2000\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.5060 - accuracy: 0.1493 - val_loss: 35.5101 - val_accuracy: 0.2000\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.4557 - accuracy: 0.1493 - val_loss: 35.4609 - val_accuracy: 0.2000\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4056 - accuracy: 0.1343 - val_loss: 35.4114 - val_accuracy: 0.2444\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.3537 - accuracy: 0.1567 - val_loss: 35.3635 - val_accuracy: 0.2444\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.3045 - accuracy: 0.2338 - val_loss: 35.3158 - val_accuracy: 0.2667\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2552 - accuracy: 0.2562 - val_loss: 35.2653 - val_accuracy: 0.2667\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2045 - accuracy: 0.2512 - val_loss: 35.2129 - val_accuracy: 0.2444\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1523 - accuracy: 0.1816 - val_loss: 35.1604 - val_accuracy: 0.2222\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1027 - accuracy: 0.1418 - val_loss: 35.1096 - val_accuracy: 0.2222\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0528 - accuracy: 0.1418 - val_loss: 35.0596 - val_accuracy: 0.2222\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.0029 - accuracy: 0.1443 - val_loss: 35.0089 - val_accuracy: 0.2000\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9527 - accuracy: 0.1791 - val_loss: 34.9597 - val_accuracy: 0.2222\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.9013 - accuracy: 0.1592 - val_loss: 34.9073 - val_accuracy: 0.2444\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8520 - accuracy: 0.1592 - val_loss: 34.8573 - val_accuracy: 0.1778\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.8022 - accuracy: 0.1965 - val_loss: 34.8099 - val_accuracy: 0.2444\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7521 - accuracy: 0.2313 - val_loss: 34.7591 - val_accuracy: 0.2667\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.7022 - accuracy: 0.1866 - val_loss: 34.7081 - val_accuracy: 0.2222\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6518 - accuracy: 0.1617 - val_loss: 34.6573 - val_accuracy: 0.2444\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.6028 - accuracy: 0.1567 - val_loss: 34.6063 - val_accuracy: 0.2222\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5527 - accuracy: 0.1418 - val_loss: 34.5575 - val_accuracy: 0.2222\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.5028 - accuracy: 0.1418 - val_loss: 34.5095 - val_accuracy: 0.2222\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.4534 - accuracy: 0.1517 - val_loss: 34.4595 - val_accuracy: 0.2000\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.4040 - accuracy: 0.1493 - val_loss: 34.4078 - val_accuracy: 0.2000\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.3548 - accuracy: 0.1418 - val_loss: 34.3564 - val_accuracy: 0.2222\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.3047 - accuracy: 0.1443 - val_loss: 34.3040 - val_accuracy: 0.2444\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.2560 - accuracy: 0.1667 - val_loss: 34.2544 - val_accuracy: 0.1778\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.2067 - accuracy: 0.1592 - val_loss: 34.2065 - val_accuracy: 0.1778\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.1573 - accuracy: 0.1592 - val_loss: 34.1622 - val_accuracy: 0.1778\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1073 - accuracy: 0.2015 - val_loss: 34.1205 - val_accuracy: 0.2889\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0593 - accuracy: 0.2338 - val_loss: 34.0745 - val_accuracy: 0.2889\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0095 - accuracy: 0.2413 - val_loss: 34.0242 - val_accuracy: 0.1778\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.9592 - accuracy: 0.1716 - val_loss: 33.9709 - val_accuracy: 0.1556\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.9107 - accuracy: 0.1667 - val_loss: 33.9198 - val_accuracy: 0.1111\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.8610 - accuracy: 0.1716 - val_loss: 33.8704 - val_accuracy: 0.2444\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.8122 - accuracy: 0.1791 - val_loss: 33.8201 - val_accuracy: 0.2222\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.7634 - accuracy: 0.1692 - val_loss: 33.7708 - val_accuracy: 0.2222\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.7138 - accuracy: 0.1418 - val_loss: 33.7219 - val_accuracy: 0.2222\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6655 - accuracy: 0.1418 - val_loss: 33.6737 - val_accuracy: 0.2222\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.6165 - accuracy: 0.1393 - val_loss: 33.6232 - val_accuracy: 0.1556\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5675 - accuracy: 0.1368 - val_loss: 33.5737 - val_accuracy: 0.1556\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5190 - accuracy: 0.1343 - val_loss: 33.5247 - val_accuracy: 0.2222\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4702 - accuracy: 0.1443 - val_loss: 33.4756 - val_accuracy: 0.2222\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4215 - accuracy: 0.1567 - val_loss: 33.4264 - val_accuracy: 0.1778\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.3731 - accuracy: 0.1592 - val_loss: 33.3775 - val_accuracy: 0.1778\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3245 - accuracy: 0.1592 - val_loss: 33.3316 - val_accuracy: 0.2000\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2768 - accuracy: 0.2512 - val_loss: 33.2838 - val_accuracy: 0.2000\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2283 - accuracy: 0.2488 - val_loss: 33.2336 - val_accuracy: 0.1556\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1781 - accuracy: 0.1716 - val_loss: 33.1846 - val_accuracy: 0.1778\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1309 - accuracy: 0.1592 - val_loss: 33.1362 - val_accuracy: 0.1778\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.0828 - accuracy: 0.1592 - val_loss: 33.0884 - val_accuracy: 0.1778\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.0331 - accuracy: 0.1617 - val_loss: 33.0429 - val_accuracy: 0.2000\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.9855 - accuracy: 0.2289 - val_loss: 32.9963 - val_accuracy: 0.2889\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.9378 - accuracy: 0.2214 - val_loss: 32.9463 - val_accuracy: 0.2444\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8888 - accuracy: 0.1493 - val_loss: 32.8946 - val_accuracy: 0.2222\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.8415 - accuracy: 0.1443 - val_loss: 32.8449 - val_accuracy: 0.2444\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.7925 - accuracy: 0.1617 - val_loss: 32.7972 - val_accuracy: 0.2444\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7445 - accuracy: 0.2065 - val_loss: 32.7537 - val_accuracy: 0.2889\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.6979 - accuracy: 0.2363 - val_loss: 32.7063 - val_accuracy: 0.2889\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.6493 - accuracy: 0.2289 - val_loss: 32.6579 - val_accuracy: 0.2000\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.6012 - accuracy: 0.1692 - val_loss: 32.6086 - val_accuracy: 0.1556\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5539 - accuracy: 0.1692 - val_loss: 32.5597 - val_accuracy: 0.1556\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.5055 - accuracy: 0.1443 - val_loss: 32.5124 - val_accuracy: 0.2222\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4575 - accuracy: 0.1741 - val_loss: 32.4640 - val_accuracy: 0.2000\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4105 - accuracy: 0.1567 - val_loss: 32.4137 - val_accuracy: 0.2000\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3629 - accuracy: 0.1468 - val_loss: 32.3665 - val_accuracy: 0.2222\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3145 - accuracy: 0.1567 - val_loss: 32.3203 - val_accuracy: 0.2222\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.2669 - accuracy: 0.1617 - val_loss: 32.2739 - val_accuracy: 0.1778\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.2189 - accuracy: 0.1642 - val_loss: 32.2283 - val_accuracy: 0.2000\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.1721 - accuracy: 0.2264 - val_loss: 32.1840 - val_accuracy: 0.3111\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.1249 - accuracy: 0.2512 - val_loss: 32.1387 - val_accuracy: 0.3111\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.0770 - accuracy: 0.2537 - val_loss: 32.0900 - val_accuracy: 0.2667\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0297 - accuracy: 0.2090 - val_loss: 32.0425 - val_accuracy: 0.0889\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9818 - accuracy: 0.1816 - val_loss: 31.9940 - val_accuracy: 0.0889\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9353 - accuracy: 0.1940 - val_loss: 31.9465 - val_accuracy: 0.1778\n",
      "========== Fold 3 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 207.7753 - accuracy: 0.1144 - val_loss: 196.7464 - val_accuracy: 0.2222\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 190.6986 - accuracy: 0.1169 - val_loss: 178.1727 - val_accuracy: 0.1111\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 172.6951 - accuracy: 0.1368 - val_loss: 161.9593 - val_accuracy: 0.0889\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 157.5437 - accuracy: 0.1443 - val_loss: 149.0285 - val_accuracy: 0.0889\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 145.6035 - accuracy: 0.1343 - val_loss: 139.0049 - val_accuracy: 0.1333\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 136.3686 - accuracy: 0.1443 - val_loss: 131.2713 - val_accuracy: 0.1333\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 129.2193 - accuracy: 0.1567 - val_loss: 125.2472 - val_accuracy: 0.1333\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 123.6303 - accuracy: 0.1294 - val_loss: 120.4983 - val_accuracy: 0.0889\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 119.1947 - accuracy: 0.1443 - val_loss: 116.6835 - val_accuracy: 0.0889\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 115.6211 - accuracy: 0.1517 - val_loss: 113.5823 - val_accuracy: 0.1333\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 112.7055 - accuracy: 0.1642 - val_loss: 111.0225 - val_accuracy: 0.1333\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 110.2870 - accuracy: 0.1667 - val_loss: 108.8710 - val_accuracy: 0.0889\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 108.2584 - accuracy: 0.1443 - val_loss: 107.0523 - val_accuracy: 0.0889\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 106.5304 - accuracy: 0.1194 - val_loss: 105.4828 - val_accuracy: 0.1333\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 105.0450 - accuracy: 0.1269 - val_loss: 104.1279 - val_accuracy: 0.1333\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103.7507 - accuracy: 0.1269 - val_loss: 102.9442 - val_accuracy: 0.1333\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102.6146 - accuracy: 0.1368 - val_loss: 101.9092 - val_accuracy: 0.0889\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101.6088 - accuracy: 0.1443 - val_loss: 100.9876 - val_accuracy: 0.1333\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100.7099 - accuracy: 0.1567 - val_loss: 100.1556 - val_accuracy: 0.0889\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 99.8991 - accuracy: 0.1692 - val_loss: 99.3923 - val_accuracy: 0.1333\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.1656 - accuracy: 0.1692 - val_loss: 98.6989 - val_accuracy: 0.1111\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 98.4979 - accuracy: 0.1567 - val_loss: 98.0651 - val_accuracy: 0.1333\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.8878 - accuracy: 0.1567 - val_loss: 97.4832 - val_accuracy: 0.1333\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.3239 - accuracy: 0.1567 - val_loss: 96.9505 - val_accuracy: 0.1333\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.8010 - accuracy: 0.1592 - val_loss: 96.4629 - val_accuracy: 0.1111\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.3110 - accuracy: 0.1542 - val_loss: 96.0023 - val_accuracy: 0.1111\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.8533 - accuracy: 0.1741 - val_loss: 95.5657 - val_accuracy: 0.1333\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 95.4245 - accuracy: 0.1642 - val_loss: 95.1489 - val_accuracy: 0.1333\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.0210 - accuracy: 0.1642 - val_loss: 94.7604 - val_accuracy: 0.1333\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94.6401 - accuracy: 0.1642 - val_loss: 94.3919 - val_accuracy: 0.1333\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.2802 - accuracy: 0.1766 - val_loss: 94.0454 - val_accuracy: 0.1111\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9342 - accuracy: 0.1542 - val_loss: 93.7066 - val_accuracy: 0.1111\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.6045 - accuracy: 0.1542 - val_loss: 93.3830 - val_accuracy: 0.1111\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.2888 - accuracy: 0.1716 - val_loss: 93.0816 - val_accuracy: 0.1333\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.9859 - accuracy: 0.1642 - val_loss: 92.7918 - val_accuracy: 0.1333\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.6952 - accuracy: 0.1592 - val_loss: 92.5086 - val_accuracy: 0.1333\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.4154 - accuracy: 0.1642 - val_loss: 92.2356 - val_accuracy: 0.1333\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92.1456 - accuracy: 0.1816 - val_loss: 91.9681 - val_accuracy: 0.1333\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.8837 - accuracy: 0.1567 - val_loss: 91.7206 - val_accuracy: 0.1333\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.6291 - accuracy: 0.1716 - val_loss: 91.4754 - val_accuracy: 0.1333\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.3799 - accuracy: 0.1642 - val_loss: 91.2244 - val_accuracy: 0.1333\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.1398 - accuracy: 0.1642 - val_loss: 90.9737 - val_accuracy: 0.1333\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.9058 - accuracy: 0.1642 - val_loss: 90.7308 - val_accuracy: 0.1333\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90.6792 - accuracy: 0.1716 - val_loss: 90.5036 - val_accuracy: 0.1111\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.4564 - accuracy: 0.1542 - val_loss: 90.2877 - val_accuracy: 0.1333\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.2375 - accuracy: 0.1343 - val_loss: 90.0783 - val_accuracy: 0.1111\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.0248 - accuracy: 0.1617 - val_loss: 89.8803 - val_accuracy: 0.1111\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.8146 - accuracy: 0.1667 - val_loss: 89.6751 - val_accuracy: 0.1111\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.6113 - accuracy: 0.1542 - val_loss: 89.4727 - val_accuracy: 0.1111\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 89.4097 - accuracy: 0.1542 - val_loss: 89.2764 - val_accuracy: 0.1111\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.2103 - accuracy: 0.1766 - val_loss: 89.0839 - val_accuracy: 0.1333\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.0162 - accuracy: 0.1567 - val_loss: 88.8971 - val_accuracy: 0.0889\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.8255 - accuracy: 0.1468 - val_loss: 88.7050 - val_accuracy: 0.0889\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.6360 - accuracy: 0.1567 - val_loss: 88.5142 - val_accuracy: 0.1333\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.4498 - accuracy: 0.1642 - val_loss: 88.3223 - val_accuracy: 0.1333\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88.2678 - accuracy: 0.1567 - val_loss: 88.1387 - val_accuracy: 0.1111\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.0855 - accuracy: 0.1692 - val_loss: 87.9639 - val_accuracy: 0.1333\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.9072 - accuracy: 0.1642 - val_loss: 87.7935 - val_accuracy: 0.1333\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.7315 - accuracy: 0.1567 - val_loss: 87.6200 - val_accuracy: 0.0889\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.5583 - accuracy: 0.1443 - val_loss: 87.4446 - val_accuracy: 0.1556\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.3865 - accuracy: 0.1716 - val_loss: 87.2735 - val_accuracy: 0.1333\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.2173 - accuracy: 0.1642 - val_loss: 87.1133 - val_accuracy: 0.1333\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.0493 - accuracy: 0.1642 - val_loss: 86.9464 - val_accuracy: 0.1333\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.8822 - accuracy: 0.1642 - val_loss: 86.7802 - val_accuracy: 0.1333\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.7171 - accuracy: 0.1642 - val_loss: 86.6059 - val_accuracy: 0.1111\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.5545 - accuracy: 0.1716 - val_loss: 86.4333 - val_accuracy: 0.1111\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.3940 - accuracy: 0.1542 - val_loss: 86.2717 - val_accuracy: 0.1111\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.2335 - accuracy: 0.1667 - val_loss: 86.1186 - val_accuracy: 0.1333\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0761 - accuracy: 0.1642 - val_loss: 85.9700 - val_accuracy: 0.1333\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.9201 - accuracy: 0.1642 - val_loss: 85.8179 - val_accuracy: 0.1333\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.7646 - accuracy: 0.1642 - val_loss: 85.6636 - val_accuracy: 0.1333\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.6098 - accuracy: 0.1642 - val_loss: 85.5104 - val_accuracy: 0.1333\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.4559 - accuracy: 0.1667 - val_loss: 85.3617 - val_accuracy: 0.1111\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.3041 - accuracy: 0.1716 - val_loss: 85.2085 - val_accuracy: 0.1111\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.1549 - accuracy: 0.1617 - val_loss: 85.0514 - val_accuracy: 0.1111\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.0055 - accuracy: 0.1592 - val_loss: 84.9043 - val_accuracy: 0.1333\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.8571 - accuracy: 0.1642 - val_loss: 84.7546 - val_accuracy: 0.1333\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.7092 - accuracy: 0.1642 - val_loss: 84.6067 - val_accuracy: 0.1333\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 84.5635 - accuracy: 0.1642 - val_loss: 84.4599 - val_accuracy: 0.1333\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.4174 - accuracy: 0.1716 - val_loss: 84.3175 - val_accuracy: 0.1111\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.2743 - accuracy: 0.1741 - val_loss: 84.1787 - val_accuracy: 0.1111\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.1322 - accuracy: 0.1542 - val_loss: 84.0362 - val_accuracy: 0.1111\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.9902 - accuracy: 0.1617 - val_loss: 83.8955 - val_accuracy: 0.1111\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.8475 - accuracy: 0.1741 - val_loss: 83.7549 - val_accuracy: 0.1111\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83.7062 - accuracy: 0.1816 - val_loss: 83.6168 - val_accuracy: 0.1111\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.5669 - accuracy: 0.1642 - val_loss: 83.4807 - val_accuracy: 0.1333\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.4286 - accuracy: 0.1642 - val_loss: 83.3458 - val_accuracy: 0.1333\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.2900 - accuracy: 0.1642 - val_loss: 83.2080 - val_accuracy: 0.1333\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.1530 - accuracy: 0.1667 - val_loss: 83.0687 - val_accuracy: 0.1111\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83.0177 - accuracy: 0.1891 - val_loss: 82.9316 - val_accuracy: 0.1111\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.8815 - accuracy: 0.1692 - val_loss: 82.7957 - val_accuracy: 0.1111\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.7466 - accuracy: 0.1766 - val_loss: 82.6586 - val_accuracy: 0.1111\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.6133 - accuracy: 0.1667 - val_loss: 82.5303 - val_accuracy: 0.1333\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.4801 - accuracy: 0.1642 - val_loss: 82.3950 - val_accuracy: 0.1333\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.3478 - accuracy: 0.1642 - val_loss: 82.2578 - val_accuracy: 0.1333\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2158 - accuracy: 0.1667 - val_loss: 82.1238 - val_accuracy: 0.1111\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.0848 - accuracy: 0.1667 - val_loss: 81.9938 - val_accuracy: 0.1111\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.9537 - accuracy: 0.1592 - val_loss: 81.8684 - val_accuracy: 0.1111\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.8239 - accuracy: 0.1766 - val_loss: 81.7391 - val_accuracy: 0.1333\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.6943 - accuracy: 0.1741 - val_loss: 81.6076 - val_accuracy: 0.1111\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.5661 - accuracy: 0.1741 - val_loss: 81.4800 - val_accuracy: 0.1111\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.4384 - accuracy: 0.1567 - val_loss: 81.3584 - val_accuracy: 0.1111\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.3120 - accuracy: 0.1741 - val_loss: 81.2413 - val_accuracy: 0.1111\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.1839 - accuracy: 0.1841 - val_loss: 81.1108 - val_accuracy: 0.1111\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.0574 - accuracy: 0.1816 - val_loss: 80.9809 - val_accuracy: 0.1111\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.9317 - accuracy: 0.1866 - val_loss: 80.8504 - val_accuracy: 0.1111\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.8080 - accuracy: 0.1642 - val_loss: 80.7242 - val_accuracy: 0.2222\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.6834 - accuracy: 0.1642 - val_loss: 80.6032 - val_accuracy: 0.1111\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80.5591 - accuracy: 0.1841 - val_loss: 80.4828 - val_accuracy: 0.1111\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.4354 - accuracy: 0.1716 - val_loss: 80.3653 - val_accuracy: 0.1111\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.3129 - accuracy: 0.1891 - val_loss: 80.2455 - val_accuracy: 0.1333\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.1898 - accuracy: 0.1642 - val_loss: 80.1247 - val_accuracy: 0.1333\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.0680 - accuracy: 0.1642 - val_loss: 80.0019 - val_accuracy: 0.1333\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.9463 - accuracy: 0.1642 - val_loss: 79.8725 - val_accuracy: 0.1333\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8259 - accuracy: 0.1692 - val_loss: 79.7426 - val_accuracy: 0.1111\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.7055 - accuracy: 0.1692 - val_loss: 79.6223 - val_accuracy: 0.1333\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 79.5862 - accuracy: 0.1642 - val_loss: 79.4999 - val_accuracy: 0.1333\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.4674 - accuracy: 0.1642 - val_loss: 79.3771 - val_accuracy: 0.1333\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.3505 - accuracy: 0.1567 - val_loss: 79.2592 - val_accuracy: 0.1556\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.2320 - accuracy: 0.1667 - val_loss: 79.1491 - val_accuracy: 0.1333\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.1133 - accuracy: 0.1642 - val_loss: 79.0391 - val_accuracy: 0.1333\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 78.9951 - accuracy: 0.1791 - val_loss: 78.9296 - val_accuracy: 0.1333\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.8779 - accuracy: 0.1642 - val_loss: 78.8104 - val_accuracy: 0.1333\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.7596 - accuracy: 0.1642 - val_loss: 78.6919 - val_accuracy: 0.1333\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.6430 - accuracy: 0.1642 - val_loss: 78.5743 - val_accuracy: 0.1333\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5272 - accuracy: 0.1642 - val_loss: 78.4541 - val_accuracy: 0.1333\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.4111 - accuracy: 0.1642 - val_loss: 78.3383 - val_accuracy: 0.1333\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.2969 - accuracy: 0.1642 - val_loss: 78.2265 - val_accuracy: 0.1333\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.1817 - accuracy: 0.1642 - val_loss: 78.1158 - val_accuracy: 0.1333\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.0670 - accuracy: 0.1642 - val_loss: 78.0041 - val_accuracy: 0.1333\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.9533 - accuracy: 0.1642 - val_loss: 77.8887 - val_accuracy: 0.1333\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.8402 - accuracy: 0.1642 - val_loss: 77.7753 - val_accuracy: 0.1111\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.7269 - accuracy: 0.1841 - val_loss: 77.6558 - val_accuracy: 0.1111\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6150 - accuracy: 0.1667 - val_loss: 77.5385 - val_accuracy: 0.1111\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5031 - accuracy: 0.1542 - val_loss: 77.4247 - val_accuracy: 0.1111\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.3908 - accuracy: 0.1592 - val_loss: 77.3208 - val_accuracy: 0.1111\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.2794 - accuracy: 0.1642 - val_loss: 77.2133 - val_accuracy: 0.1333\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1677 - accuracy: 0.1642 - val_loss: 77.0994 - val_accuracy: 0.1333\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.0585 - accuracy: 0.1642 - val_loss: 76.9869 - val_accuracy: 0.1333\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.9480 - accuracy: 0.1642 - val_loss: 76.8741 - val_accuracy: 0.1333\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.8368 - accuracy: 0.1642 - val_loss: 76.7594 - val_accuracy: 0.1333\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.7266 - accuracy: 0.1642 - val_loss: 76.6482 - val_accuracy: 0.1333\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.6175 - accuracy: 0.1642 - val_loss: 76.5440 - val_accuracy: 0.1333\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76.5076 - accuracy: 0.1642 - val_loss: 76.4425 - val_accuracy: 0.1111\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.3993 - accuracy: 0.1692 - val_loss: 76.3364 - val_accuracy: 0.0889\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.2920 - accuracy: 0.1567 - val_loss: 76.2315 - val_accuracy: 0.0889\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.1839 - accuracy: 0.1667 - val_loss: 76.1212 - val_accuracy: 0.1333\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.0763 - accuracy: 0.1642 - val_loss: 76.0073 - val_accuracy: 0.1333\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.9688 - accuracy: 0.1642 - val_loss: 75.9043 - val_accuracy: 0.1333\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.8601 - accuracy: 0.1642 - val_loss: 75.7939 - val_accuracy: 0.1333\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7532 - accuracy: 0.1642 - val_loss: 75.6856 - val_accuracy: 0.1333\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.6462 - accuracy: 0.1642 - val_loss: 75.5785 - val_accuracy: 0.1333\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.5408 - accuracy: 0.1766 - val_loss: 75.4714 - val_accuracy: 0.1111\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.4347 - accuracy: 0.1741 - val_loss: 75.3703 - val_accuracy: 0.1333\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.3298 - accuracy: 0.1642 - val_loss: 75.2710 - val_accuracy: 0.1333\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.2240 - accuracy: 0.1642 - val_loss: 75.1687 - val_accuracy: 0.1333\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.1190 - accuracy: 0.1642 - val_loss: 75.0644 - val_accuracy: 0.1333\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.0139 - accuracy: 0.1642 - val_loss: 74.9579 - val_accuracy: 0.1333\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.9098 - accuracy: 0.1816 - val_loss: 74.8518 - val_accuracy: 0.0889\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.8057 - accuracy: 0.1517 - val_loss: 74.7478 - val_accuracy: 0.0889\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7036 - accuracy: 0.1567 - val_loss: 74.6449 - val_accuracy: 0.1111\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.6004 - accuracy: 0.1741 - val_loss: 74.5347 - val_accuracy: 0.1333\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.4965 - accuracy: 0.1642 - val_loss: 74.4236 - val_accuracy: 0.1333\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.3931 - accuracy: 0.1642 - val_loss: 74.3163 - val_accuracy: 0.1333\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74.2900 - accuracy: 0.1642 - val_loss: 74.2144 - val_accuracy: 0.1333\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 74.1868 - accuracy: 0.1642 - val_loss: 74.1157 - val_accuracy: 0.1333\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.0841 - accuracy: 0.1642 - val_loss: 74.0191 - val_accuracy: 0.1333\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.9821 - accuracy: 0.1642 - val_loss: 73.9194 - val_accuracy: 0.1333\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.8798 - accuracy: 0.1642 - val_loss: 73.8233 - val_accuracy: 0.1333\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.7784 - accuracy: 0.1642 - val_loss: 73.7196 - val_accuracy: 0.1333\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.6777 - accuracy: 0.1642 - val_loss: 73.6131 - val_accuracy: 0.1333\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.5770 - accuracy: 0.1716 - val_loss: 73.5077 - val_accuracy: 0.1333\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4762 - accuracy: 0.1642 - val_loss: 73.4007 - val_accuracy: 0.1333\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.3754 - accuracy: 0.1816 - val_loss: 73.2931 - val_accuracy: 0.1111\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 73.2775 - accuracy: 0.1617 - val_loss: 73.1901 - val_accuracy: 0.1111\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.1770 - accuracy: 0.1816 - val_loss: 73.0981 - val_accuracy: 0.1333\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.0776 - accuracy: 0.1642 - val_loss: 73.0062 - val_accuracy: 0.1333\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.9777 - accuracy: 0.1642 - val_loss: 72.9105 - val_accuracy: 0.1333\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.8782 - accuracy: 0.1642 - val_loss: 72.8113 - val_accuracy: 0.1333\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.7780 - accuracy: 0.1642 - val_loss: 72.7111 - val_accuracy: 0.1333\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.6798 - accuracy: 0.1766 - val_loss: 72.6137 - val_accuracy: 0.1111\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5811 - accuracy: 0.1741 - val_loss: 72.5147 - val_accuracy: 0.1111\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.4834 - accuracy: 0.1692 - val_loss: 72.4187 - val_accuracy: 0.1111\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.3858 - accuracy: 0.1841 - val_loss: 72.3255 - val_accuracy: 0.1111\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.2878 - accuracy: 0.1791 - val_loss: 72.2336 - val_accuracy: 0.1333\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.1911 - accuracy: 0.1642 - val_loss: 72.1463 - val_accuracy: 0.1333\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.0941 - accuracy: 0.1741 - val_loss: 72.0520 - val_accuracy: 0.0889\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9968 - accuracy: 0.1791 - val_loss: 71.9450 - val_accuracy: 0.1333\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 71.8994 - accuracy: 0.1642 - val_loss: 71.8383 - val_accuracy: 0.1111\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.8026 - accuracy: 0.1741 - val_loss: 71.7389 - val_accuracy: 0.1111\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.7063 - accuracy: 0.1766 - val_loss: 71.6453 - val_accuracy: 0.1111\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.6088 - accuracy: 0.1816 - val_loss: 71.5511 - val_accuracy: 0.1111\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.5132 - accuracy: 0.1667 - val_loss: 71.4604 - val_accuracy: 0.1333\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4184 - accuracy: 0.1642 - val_loss: 71.3688 - val_accuracy: 0.1333\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.3223 - accuracy: 0.1642 - val_loss: 71.2698 - val_accuracy: 0.1333\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.2267 - accuracy: 0.1642 - val_loss: 71.1690 - val_accuracy: 0.1333\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.1320 - accuracy: 0.1841 - val_loss: 71.0706 - val_accuracy: 0.1111\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.0370 - accuracy: 0.1866 - val_loss: 70.9755 - val_accuracy: 0.1111\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.9420 - accuracy: 0.1642 - val_loss: 70.8865 - val_accuracy: 0.1333\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.8475 - accuracy: 0.1642 - val_loss: 70.7970 - val_accuracy: 0.1333\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.7534 - accuracy: 0.1642 - val_loss: 70.7065 - val_accuracy: 0.1333\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.6592 - accuracy: 0.1642 - val_loss: 70.6142 - val_accuracy: 0.1333\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.5659 - accuracy: 0.1642 - val_loss: 70.5170 - val_accuracy: 0.1333\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70.4721 - accuracy: 0.1642 - val_loss: 70.4197 - val_accuracy: 0.1333\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.3781 - accuracy: 0.1642 - val_loss: 70.3221 - val_accuracy: 0.1333\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.2844 - accuracy: 0.1642 - val_loss: 70.2261 - val_accuracy: 0.1333\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.1914 - accuracy: 0.1642 - val_loss: 70.1300 - val_accuracy: 0.1111\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0991 - accuracy: 0.1816 - val_loss: 70.0311 - val_accuracy: 0.1111\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.0061 - accuracy: 0.1741 - val_loss: 69.9380 - val_accuracy: 0.1333\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.9133 - accuracy: 0.1816 - val_loss: 69.8494 - val_accuracy: 0.1111\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8213 - accuracy: 0.1716 - val_loss: 69.7667 - val_accuracy: 0.1333\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.7284 - accuracy: 0.1642 - val_loss: 69.6769 - val_accuracy: 0.1333\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69.6364 - accuracy: 0.1642 - val_loss: 69.5814 - val_accuracy: 0.1333\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.5451 - accuracy: 0.1642 - val_loss: 69.4890 - val_accuracy: 0.1333\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4537 - accuracy: 0.1642 - val_loss: 69.3981 - val_accuracy: 0.1333\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.3623 - accuracy: 0.1617 - val_loss: 69.3044 - val_accuracy: 0.1111\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69.2726 - accuracy: 0.1841 - val_loss: 69.2173 - val_accuracy: 0.1111\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.1801 - accuracy: 0.1866 - val_loss: 69.1252 - val_accuracy: 0.1111\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.0891 - accuracy: 0.1841 - val_loss: 69.0326 - val_accuracy: 0.1111\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.9985 - accuracy: 0.1841 - val_loss: 68.9459 - val_accuracy: 0.1111\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.9078 - accuracy: 0.1716 - val_loss: 68.8544 - val_accuracy: 0.1111\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.8174 - accuracy: 0.1592 - val_loss: 68.7631 - val_accuracy: 0.1111\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.7264 - accuracy: 0.1567 - val_loss: 68.6728 - val_accuracy: 0.1111\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.6361 - accuracy: 0.1542 - val_loss: 68.5841 - val_accuracy: 0.1111\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.5475 - accuracy: 0.1567 - val_loss: 68.4982 - val_accuracy: 0.1111\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.4575 - accuracy: 0.1692 - val_loss: 68.4073 - val_accuracy: 0.1111\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.3683 - accuracy: 0.1841 - val_loss: 68.3157 - val_accuracy: 0.1111\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.2790 - accuracy: 0.1692 - val_loss: 68.2204 - val_accuracy: 0.1111\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.1902 - accuracy: 0.1642 - val_loss: 68.1313 - val_accuracy: 0.1333\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.1009 - accuracy: 0.1667 - val_loss: 68.0407 - val_accuracy: 0.1111\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.0122 - accuracy: 0.1866 - val_loss: 67.9548 - val_accuracy: 0.1111\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.9234 - accuracy: 0.1592 - val_loss: 67.8633 - val_accuracy: 0.1111\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.8347 - accuracy: 0.1542 - val_loss: 67.7725 - val_accuracy: 0.1111\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.7456 - accuracy: 0.1766 - val_loss: 67.6868 - val_accuracy: 0.1333\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6578 - accuracy: 0.1642 - val_loss: 67.6070 - val_accuracy: 0.1333\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.5705 - accuracy: 0.1642 - val_loss: 67.5206 - val_accuracy: 0.1333\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.4822 - accuracy: 0.1642 - val_loss: 67.4290 - val_accuracy: 0.1333\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.3945 - accuracy: 0.1667 - val_loss: 67.3359 - val_accuracy: 0.1111\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3064 - accuracy: 0.1741 - val_loss: 67.2533 - val_accuracy: 0.1111\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.2196 - accuracy: 0.1716 - val_loss: 67.1751 - val_accuracy: 0.1111\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.1320 - accuracy: 0.1891 - val_loss: 67.0881 - val_accuracy: 0.1111\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67.0446 - accuracy: 0.1816 - val_loss: 66.9979 - val_accuracy: 0.1111\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9576 - accuracy: 0.1766 - val_loss: 66.9049 - val_accuracy: 0.1333\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.8708 - accuracy: 0.1642 - val_loss: 66.8168 - val_accuracy: 0.1333\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.7838 - accuracy: 0.1642 - val_loss: 66.7313 - val_accuracy: 0.1333\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6986 - accuracy: 0.1642 - val_loss: 66.6516 - val_accuracy: 0.1333\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.6120 - accuracy: 0.1642 - val_loss: 66.5648 - val_accuracy: 0.1333\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.5260 - accuracy: 0.1642 - val_loss: 66.4840 - val_accuracy: 0.1333\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.4398 - accuracy: 0.1642 - val_loss: 66.4053 - val_accuracy: 0.1333\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3549 - accuracy: 0.1766 - val_loss: 66.3250 - val_accuracy: 0.1333\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.2698 - accuracy: 0.1741 - val_loss: 66.2382 - val_accuracy: 0.1333\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.1835 - accuracy: 0.1692 - val_loss: 66.1448 - val_accuracy: 0.1333\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.0966 - accuracy: 0.1642 - val_loss: 66.0498 - val_accuracy: 0.1333\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.0118 - accuracy: 0.1642 - val_loss: 65.9552 - val_accuracy: 0.1333\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.9266 - accuracy: 0.1642 - val_loss: 65.8677 - val_accuracy: 0.1111\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 65.8422 - accuracy: 0.1716 - val_loss: 65.7791 - val_accuracy: 0.1111\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7568 - accuracy: 0.1542 - val_loss: 65.6961 - val_accuracy: 0.1111\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.6721 - accuracy: 0.1542 - val_loss: 65.6184 - val_accuracy: 0.1111\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.5876 - accuracy: 0.1542 - val_loss: 65.5388 - val_accuracy: 0.1111\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.5023 - accuracy: 0.1592 - val_loss: 65.4568 - val_accuracy: 0.1111\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4183 - accuracy: 0.1791 - val_loss: 65.3681 - val_accuracy: 0.1111\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3344 - accuracy: 0.1841 - val_loss: 65.2793 - val_accuracy: 0.1111\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.2509 - accuracy: 0.1617 - val_loss: 65.1885 - val_accuracy: 0.1111\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.1677 - accuracy: 0.1542 - val_loss: 65.1021 - val_accuracy: 0.1111\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0836 - accuracy: 0.1692 - val_loss: 65.0251 - val_accuracy: 0.1111\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0005 - accuracy: 0.1667 - val_loss: 64.9541 - val_accuracy: 0.1333\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.9159 - accuracy: 0.1642 - val_loss: 64.8728 - val_accuracy: 0.1333\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.8330 - accuracy: 0.1642 - val_loss: 64.7894 - val_accuracy: 0.1333\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.7490 - accuracy: 0.1642 - val_loss: 64.7062 - val_accuracy: 0.1333\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.6668 - accuracy: 0.1642 - val_loss: 64.6247 - val_accuracy: 0.1333\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.5840 - accuracy: 0.1642 - val_loss: 64.5436 - val_accuracy: 0.1333\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.5011 - accuracy: 0.1642 - val_loss: 64.4614 - val_accuracy: 0.1333\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64.4177 - accuracy: 0.1642 - val_loss: 64.3808 - val_accuracy: 0.1333\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.3354 - accuracy: 0.1642 - val_loss: 64.2990 - val_accuracy: 0.1333\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.2527 - accuracy: 0.1642 - val_loss: 64.2057 - val_accuracy: 0.1111\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.1705 - accuracy: 0.1816 - val_loss: 64.1189 - val_accuracy: 0.1111\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.0889 - accuracy: 0.1766 - val_loss: 64.0344 - val_accuracy: 0.1111\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.0081 - accuracy: 0.1791 - val_loss: 63.9477 - val_accuracy: 0.1111\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.9259 - accuracy: 0.1642 - val_loss: 63.8617 - val_accuracy: 0.1111\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.8435 - accuracy: 0.1592 - val_loss: 63.7873 - val_accuracy: 0.1111\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7608 - accuracy: 0.1692 - val_loss: 63.7154 - val_accuracy: 0.1333\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.6791 - accuracy: 0.1642 - val_loss: 63.6405 - val_accuracy: 0.1333\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.5975 - accuracy: 0.1642 - val_loss: 63.5612 - val_accuracy: 0.1333\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.5166 - accuracy: 0.1642 - val_loss: 63.4821 - val_accuracy: 0.1333\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4351 - accuracy: 0.1642 - val_loss: 63.3964 - val_accuracy: 0.1333\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3541 - accuracy: 0.1642 - val_loss: 63.3101 - val_accuracy: 0.1333\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.2728 - accuracy: 0.1642 - val_loss: 63.2284 - val_accuracy: 0.1333\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.1922 - accuracy: 0.1642 - val_loss: 63.1506 - val_accuracy: 0.1333\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.1119 - accuracy: 0.1642 - val_loss: 63.0734 - val_accuracy: 0.1333\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.0308 - accuracy: 0.1642 - val_loss: 62.9906 - val_accuracy: 0.1111\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9508 - accuracy: 0.1716 - val_loss: 62.9082 - val_accuracy: 0.1111\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.8706 - accuracy: 0.1542 - val_loss: 62.8298 - val_accuracy: 0.1111\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62.7917 - accuracy: 0.1667 - val_loss: 62.7508 - val_accuracy: 0.1111\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.7116 - accuracy: 0.1791 - val_loss: 62.6716 - val_accuracy: 0.1333\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.6316 - accuracy: 0.1642 - val_loss: 62.5904 - val_accuracy: 0.1333\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62.5515 - accuracy: 0.1642 - val_loss: 62.5045 - val_accuracy: 0.1333\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.4710 - accuracy: 0.1642 - val_loss: 62.4241 - val_accuracy: 0.1333\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.3913 - accuracy: 0.1642 - val_loss: 62.3474 - val_accuracy: 0.1333\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.3117 - accuracy: 0.1642 - val_loss: 62.2679 - val_accuracy: 0.1333\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.2316 - accuracy: 0.1642 - val_loss: 62.1960 - val_accuracy: 0.1111\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.1528 - accuracy: 0.1791 - val_loss: 62.1169 - val_accuracy: 0.1111\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.0745 - accuracy: 0.1592 - val_loss: 62.0368 - val_accuracy: 0.1111\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9965 - accuracy: 0.1542 - val_loss: 61.9519 - val_accuracy: 0.1111\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.9163 - accuracy: 0.1667 - val_loss: 61.8695 - val_accuracy: 0.1111\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.8372 - accuracy: 0.1791 - val_loss: 61.7907 - val_accuracy: 0.1333\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7587 - accuracy: 0.1642 - val_loss: 61.7091 - val_accuracy: 0.1333\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.6802 - accuracy: 0.1642 - val_loss: 61.6278 - val_accuracy: 0.1333\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.6027 - accuracy: 0.1642 - val_loss: 61.5473 - val_accuracy: 0.1333\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.5234 - accuracy: 0.1642 - val_loss: 61.4749 - val_accuracy: 0.1333\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.4448 - accuracy: 0.1642 - val_loss: 61.4021 - val_accuracy: 0.1333\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3671 - accuracy: 0.1642 - val_loss: 61.3282 - val_accuracy: 0.1333\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.2885 - accuracy: 0.1642 - val_loss: 61.2455 - val_accuracy: 0.1333\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.2106 - accuracy: 0.1642 - val_loss: 61.1652 - val_accuracy: 0.1111\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.1343 - accuracy: 0.1542 - val_loss: 61.0903 - val_accuracy: 0.1111\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0565 - accuracy: 0.1716 - val_loss: 61.0183 - val_accuracy: 0.1111\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.9780 - accuracy: 0.1766 - val_loss: 60.9408 - val_accuracy: 0.1333\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.9008 - accuracy: 0.1642 - val_loss: 60.8603 - val_accuracy: 0.1333\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.8223 - accuracy: 0.1642 - val_loss: 60.7810 - val_accuracy: 0.1333\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.7455 - accuracy: 0.1642 - val_loss: 60.7034 - val_accuracy: 0.1333\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6686 - accuracy: 0.1642 - val_loss: 60.6219 - val_accuracy: 0.1333\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60.5912 - accuracy: 0.1642 - val_loss: 60.5385 - val_accuracy: 0.1111\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.5145 - accuracy: 0.1841 - val_loss: 60.4592 - val_accuracy: 0.1111\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4377 - accuracy: 0.1692 - val_loss: 60.3794 - val_accuracy: 0.1111\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.3610 - accuracy: 0.1592 - val_loss: 60.3005 - val_accuracy: 0.1111\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.2851 - accuracy: 0.1692 - val_loss: 60.2239 - val_accuracy: 0.1111\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.2084 - accuracy: 0.1841 - val_loss: 60.1473 - val_accuracy: 0.1111\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.1320 - accuracy: 0.1791 - val_loss: 60.0777 - val_accuracy: 0.1333\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.0563 - accuracy: 0.1642 - val_loss: 60.0103 - val_accuracy: 0.1333\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.9788 - accuracy: 0.1642 - val_loss: 59.9396 - val_accuracy: 0.1333\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.9024 - accuracy: 0.1642 - val_loss: 59.8667 - val_accuracy: 0.1333\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8260 - accuracy: 0.1642 - val_loss: 59.7872 - val_accuracy: 0.1111\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7509 - accuracy: 0.1741 - val_loss: 59.7069 - val_accuracy: 0.1111\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6752 - accuracy: 0.1542 - val_loss: 59.6289 - val_accuracy: 0.1111\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.5998 - accuracy: 0.1542 - val_loss: 59.5486 - val_accuracy: 0.1111\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.5232 - accuracy: 0.1542 - val_loss: 59.4713 - val_accuracy: 0.1111\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.4485 - accuracy: 0.1542 - val_loss: 59.4001 - val_accuracy: 0.1111\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.3729 - accuracy: 0.1841 - val_loss: 59.3362 - val_accuracy: 0.1333\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.2973 - accuracy: 0.1642 - val_loss: 59.2685 - val_accuracy: 0.1333\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2231 - accuracy: 0.1642 - val_loss: 59.1996 - val_accuracy: 0.1333\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59.1477 - accuracy: 0.1642 - val_loss: 59.1260 - val_accuracy: 0.1333\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0725 - accuracy: 0.1642 - val_loss: 59.0470 - val_accuracy: 0.1333\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.9969 - accuracy: 0.1642 - val_loss: 58.9695 - val_accuracy: 0.1111\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.9228 - accuracy: 0.1791 - val_loss: 58.8893 - val_accuracy: 0.1111\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.8476 - accuracy: 0.1542 - val_loss: 58.8114 - val_accuracy: 0.1111\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.7728 - accuracy: 0.1542 - val_loss: 58.7342 - val_accuracy: 0.1111\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.6978 - accuracy: 0.1816 - val_loss: 58.6579 - val_accuracy: 0.1111\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.6234 - accuracy: 0.1816 - val_loss: 58.5798 - val_accuracy: 0.1111\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5488 - accuracy: 0.1741 - val_loss: 58.5086 - val_accuracy: 0.1333\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.4742 - accuracy: 0.1642 - val_loss: 58.4383 - val_accuracy: 0.1333\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.4002 - accuracy: 0.1642 - val_loss: 58.3699 - val_accuracy: 0.1333\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.3263 - accuracy: 0.1642 - val_loss: 58.2997 - val_accuracy: 0.1333\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.2523 - accuracy: 0.1642 - val_loss: 58.2251 - val_accuracy: 0.1333\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.1787 - accuracy: 0.1642 - val_loss: 58.1497 - val_accuracy: 0.1333\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1047 - accuracy: 0.1642 - val_loss: 58.0724 - val_accuracy: 0.1333\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.0305 - accuracy: 0.1642 - val_loss: 57.9963 - val_accuracy: 0.1333\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.9565 - accuracy: 0.1667 - val_loss: 57.9210 - val_accuracy: 0.1111\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.8833 - accuracy: 0.1816 - val_loss: 57.8442 - val_accuracy: 0.1111\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.8099 - accuracy: 0.1841 - val_loss: 57.7711 - val_accuracy: 0.1111\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.7364 - accuracy: 0.1841 - val_loss: 57.6999 - val_accuracy: 0.1111\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6637 - accuracy: 0.1592 - val_loss: 57.6355 - val_accuracy: 0.1333\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5906 - accuracy: 0.1642 - val_loss: 57.5634 - val_accuracy: 0.1333\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5176 - accuracy: 0.1642 - val_loss: 57.4919 - val_accuracy: 0.1333\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.4443 - accuracy: 0.1642 - val_loss: 57.4178 - val_accuracy: 0.1333\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.3718 - accuracy: 0.1642 - val_loss: 57.3373 - val_accuracy: 0.1333\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.2995 - accuracy: 0.1642 - val_loss: 57.2567 - val_accuracy: 0.1333\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.2270 - accuracy: 0.1642 - val_loss: 57.1813 - val_accuracy: 0.1111\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1556 - accuracy: 0.1716 - val_loss: 57.1058 - val_accuracy: 0.1111\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0826 - accuracy: 0.1542 - val_loss: 57.0330 - val_accuracy: 0.1111\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.0095 - accuracy: 0.1542 - val_loss: 56.9642 - val_accuracy: 0.1111\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9372 - accuracy: 0.1642 - val_loss: 56.8929 - val_accuracy: 0.1111\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.8645 - accuracy: 0.1667 - val_loss: 56.8141 - val_accuracy: 0.1111\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56.7928 - accuracy: 0.1542 - val_loss: 56.7396 - val_accuracy: 0.1111\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7206 - accuracy: 0.1542 - val_loss: 56.6690 - val_accuracy: 0.1111\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.6468 - accuracy: 0.1567 - val_loss: 56.6048 - val_accuracy: 0.1111\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5748 - accuracy: 0.1816 - val_loss: 56.5408 - val_accuracy: 0.1333\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.5036 - accuracy: 0.1642 - val_loss: 56.4724 - val_accuracy: 0.1333\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.4324 - accuracy: 0.1642 - val_loss: 56.4018 - val_accuracy: 0.1333\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.3610 - accuracy: 0.1642 - val_loss: 56.3311 - val_accuracy: 0.1333\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2888 - accuracy: 0.1642 - val_loss: 56.2578 - val_accuracy: 0.1333\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2166 - accuracy: 0.1642 - val_loss: 56.1841 - val_accuracy: 0.1333\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.1450 - accuracy: 0.1741 - val_loss: 56.1081 - val_accuracy: 0.1111\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56.0742 - accuracy: 0.1816 - val_loss: 56.0296 - val_accuracy: 0.1111\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.0028 - accuracy: 0.1766 - val_loss: 55.9568 - val_accuracy: 0.1111\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.9318 - accuracy: 0.1692 - val_loss: 55.8832 - val_accuracy: 0.1111\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.8610 - accuracy: 0.1542 - val_loss: 55.8098 - val_accuracy: 0.1111\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.7908 - accuracy: 0.1542 - val_loss: 55.7382 - val_accuracy: 0.1111\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.7198 - accuracy: 0.1542 - val_loss: 55.6711 - val_accuracy: 0.1111\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6489 - accuracy: 0.1542 - val_loss: 55.6051 - val_accuracy: 0.1111\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5776 - accuracy: 0.1567 - val_loss: 55.5417 - val_accuracy: 0.1111\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5064 - accuracy: 0.1841 - val_loss: 55.4749 - val_accuracy: 0.1111\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4359 - accuracy: 0.1667 - val_loss: 55.4068 - val_accuracy: 0.1333\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.3652 - accuracy: 0.1667 - val_loss: 55.3282 - val_accuracy: 0.1111\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.2942 - accuracy: 0.1816 - val_loss: 55.2573 - val_accuracy: 0.1111\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 55.2246 - accuracy: 0.1642 - val_loss: 55.1892 - val_accuracy: 0.1333\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1550 - accuracy: 0.1642 - val_loss: 55.1238 - val_accuracy: 0.1333\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0841 - accuracy: 0.1642 - val_loss: 55.0526 - val_accuracy: 0.1333\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0138 - accuracy: 0.1642 - val_loss: 54.9772 - val_accuracy: 0.1333\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.9438 - accuracy: 0.1642 - val_loss: 54.9055 - val_accuracy: 0.1333\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54.8740 - accuracy: 0.1766 - val_loss: 54.8306 - val_accuracy: 0.1111\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.8040 - accuracy: 0.1692 - val_loss: 54.7612 - val_accuracy: 0.1111\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.7335 - accuracy: 0.1542 - val_loss: 54.6921 - val_accuracy: 0.1333\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.6648 - accuracy: 0.1567 - val_loss: 54.6212 - val_accuracy: 0.1333\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.5950 - accuracy: 0.1791 - val_loss: 54.5568 - val_accuracy: 0.1556\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.5260 - accuracy: 0.1642 - val_loss: 54.4921 - val_accuracy: 0.1333\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.4571 - accuracy: 0.1542 - val_loss: 54.4248 - val_accuracy: 0.1333\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.3877 - accuracy: 0.1642 - val_loss: 54.3521 - val_accuracy: 0.1111\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3179 - accuracy: 0.1692 - val_loss: 54.2816 - val_accuracy: 0.1111\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.2499 - accuracy: 0.1542 - val_loss: 54.2117 - val_accuracy: 0.1111\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1802 - accuracy: 0.1542 - val_loss: 54.1473 - val_accuracy: 0.1111\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1111 - accuracy: 0.1642 - val_loss: 54.0857 - val_accuracy: 0.1111\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0418 - accuracy: 0.1692 - val_loss: 54.0157 - val_accuracy: 0.1111\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.9735 - accuracy: 0.1692 - val_loss: 53.9428 - val_accuracy: 0.1111\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.9043 - accuracy: 0.1542 - val_loss: 53.8707 - val_accuracy: 0.1111\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.8350 - accuracy: 0.1542 - val_loss: 53.7967 - val_accuracy: 0.1111\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.7667 - accuracy: 0.1542 - val_loss: 53.7286 - val_accuracy: 0.1111\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.6975 - accuracy: 0.1542 - val_loss: 53.6644 - val_accuracy: 0.1111\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6290 - accuracy: 0.1542 - val_loss: 53.5995 - val_accuracy: 0.1111\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.5605 - accuracy: 0.1716 - val_loss: 53.5374 - val_accuracy: 0.1333\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.4926 - accuracy: 0.1642 - val_loss: 53.4694 - val_accuracy: 0.1333\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4235 - accuracy: 0.1642 - val_loss: 53.3933 - val_accuracy: 0.1333\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.3557 - accuracy: 0.1642 - val_loss: 53.3193 - val_accuracy: 0.1333\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.2870 - accuracy: 0.1642 - val_loss: 53.2562 - val_accuracy: 0.1333\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2193 - accuracy: 0.1716 - val_loss: 53.1921 - val_accuracy: 0.1111\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1512 - accuracy: 0.1816 - val_loss: 53.1274 - val_accuracy: 0.1333\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0841 - accuracy: 0.1642 - val_loss: 53.0599 - val_accuracy: 0.1333\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.0165 - accuracy: 0.1642 - val_loss: 52.9860 - val_accuracy: 0.1333\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52.9481 - accuracy: 0.1642 - val_loss: 52.9167 - val_accuracy: 0.1333\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.8804 - accuracy: 0.1642 - val_loss: 52.8516 - val_accuracy: 0.1333\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.8127 - accuracy: 0.1642 - val_loss: 52.7823 - val_accuracy: 0.1333\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.7448 - accuracy: 0.1667 - val_loss: 52.7146 - val_accuracy: 0.1333\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.6766 - accuracy: 0.1642 - val_loss: 52.6532 - val_accuracy: 0.1333\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.6099 - accuracy: 0.1642 - val_loss: 52.5929 - val_accuracy: 0.1333\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.5443 - accuracy: 0.1741 - val_loss: 52.5309 - val_accuracy: 0.1333\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.4763 - accuracy: 0.1667 - val_loss: 52.4571 - val_accuracy: 0.1333\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.4089 - accuracy: 0.1642 - val_loss: 52.3789 - val_accuracy: 0.1333\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.3408 - accuracy: 0.1642 - val_loss: 52.3031 - val_accuracy: 0.1111\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.2748 - accuracy: 0.1692 - val_loss: 52.2276 - val_accuracy: 0.1111\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.2083 - accuracy: 0.1542 - val_loss: 52.1587 - val_accuracy: 0.1111\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.1417 - accuracy: 0.1542 - val_loss: 52.0963 - val_accuracy: 0.1111\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.0739 - accuracy: 0.1542 - val_loss: 52.0296 - val_accuracy: 0.1111\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.0069 - accuracy: 0.1542 - val_loss: 51.9596 - val_accuracy: 0.1111\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9405 - accuracy: 0.1542 - val_loss: 51.8973 - val_accuracy: 0.1111\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8730 - accuracy: 0.1542 - val_loss: 51.8376 - val_accuracy: 0.1111\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.8067 - accuracy: 0.1542 - val_loss: 51.7746 - val_accuracy: 0.1111\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.7405 - accuracy: 0.1542 - val_loss: 51.7108 - val_accuracy: 0.1111\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6740 - accuracy: 0.1542 - val_loss: 51.6477 - val_accuracy: 0.1111\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.6074 - accuracy: 0.1542 - val_loss: 51.5791 - val_accuracy: 0.1111\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5406 - accuracy: 0.1592 - val_loss: 51.5106 - val_accuracy: 0.1111\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.4751 - accuracy: 0.1692 - val_loss: 51.4417 - val_accuracy: 0.1111\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.4079 - accuracy: 0.1741 - val_loss: 51.3748 - val_accuracy: 0.1111\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3419 - accuracy: 0.1791 - val_loss: 51.3082 - val_accuracy: 0.1111\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.2760 - accuracy: 0.1841 - val_loss: 51.2393 - val_accuracy: 0.1111\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.2104 - accuracy: 0.1891 - val_loss: 51.1713 - val_accuracy: 0.1111\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.1447 - accuracy: 0.1791 - val_loss: 51.1058 - val_accuracy: 0.1111\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.0788 - accuracy: 0.1642 - val_loss: 51.0406 - val_accuracy: 0.1111\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.0130 - accuracy: 0.1542 - val_loss: 50.9733 - val_accuracy: 0.1111\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9472 - accuracy: 0.1542 - val_loss: 50.9092 - val_accuracy: 0.1111\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.8818 - accuracy: 0.1542 - val_loss: 50.8439 - val_accuracy: 0.1111\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8170 - accuracy: 0.1542 - val_loss: 50.7845 - val_accuracy: 0.1111\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.7523 - accuracy: 0.1542 - val_loss: 50.7216 - val_accuracy: 0.1111\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6867 - accuracy: 0.1741 - val_loss: 50.6576 - val_accuracy: 0.1111\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.6207 - accuracy: 0.1866 - val_loss: 50.5850 - val_accuracy: 0.1111\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.5551 - accuracy: 0.1642 - val_loss: 50.5142 - val_accuracy: 0.1111\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.4899 - accuracy: 0.1542 - val_loss: 50.4468 - val_accuracy: 0.1111\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.4247 - accuracy: 0.1542 - val_loss: 50.3810 - val_accuracy: 0.1111\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.3603 - accuracy: 0.1542 - val_loss: 50.3170 - val_accuracy: 0.1111\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.2959 - accuracy: 0.1642 - val_loss: 50.2592 - val_accuracy: 0.1333\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2302 - accuracy: 0.1766 - val_loss: 50.1928 - val_accuracy: 0.1111\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.1651 - accuracy: 0.1542 - val_loss: 50.1262 - val_accuracy: 0.1111\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.1004 - accuracy: 0.1542 - val_loss: 50.0630 - val_accuracy: 0.1111\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.0362 - accuracy: 0.1542 - val_loss: 50.0021 - val_accuracy: 0.1111\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.9714 - accuracy: 0.1542 - val_loss: 49.9364 - val_accuracy: 0.1111\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.9064 - accuracy: 0.1542 - val_loss: 49.8670 - val_accuracy: 0.1111\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.8422 - accuracy: 0.1542 - val_loss: 49.8021 - val_accuracy: 0.1111\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7777 - accuracy: 0.1542 - val_loss: 49.7400 - val_accuracy: 0.1111\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.7128 - accuracy: 0.1642 - val_loss: 49.6780 - val_accuracy: 0.1111\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6491 - accuracy: 0.1791 - val_loss: 49.6159 - val_accuracy: 0.1111\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.5848 - accuracy: 0.1766 - val_loss: 49.5545 - val_accuracy: 0.1333\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5213 - accuracy: 0.1642 - val_loss: 49.4933 - val_accuracy: 0.1333\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49.4572 - accuracy: 0.1692 - val_loss: 49.4250 - val_accuracy: 0.1111\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3934 - accuracy: 0.1692 - val_loss: 49.3593 - val_accuracy: 0.1111\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.3296 - accuracy: 0.1692 - val_loss: 49.2920 - val_accuracy: 0.1111\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2657 - accuracy: 0.1542 - val_loss: 49.2248 - val_accuracy: 0.1111\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2025 - accuracy: 0.1542 - val_loss: 49.1596 - val_accuracy: 0.1111\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.1377 - accuracy: 0.1542 - val_loss: 49.1011 - val_accuracy: 0.1111\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0744 - accuracy: 0.1692 - val_loss: 49.0469 - val_accuracy: 0.1111\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0104 - accuracy: 0.1816 - val_loss: 48.9846 - val_accuracy: 0.1111\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.9465 - accuracy: 0.1766 - val_loss: 48.9216 - val_accuracy: 0.1333\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.8836 - accuracy: 0.1642 - val_loss: 48.8567 - val_accuracy: 0.1333\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8206 - accuracy: 0.1642 - val_loss: 48.7945 - val_accuracy: 0.1333\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.7565 - accuracy: 0.1642 - val_loss: 48.7294 - val_accuracy: 0.1333\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.6929 - accuracy: 0.1791 - val_loss: 48.6610 - val_accuracy: 0.1111\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6299 - accuracy: 0.1866 - val_loss: 48.5963 - val_accuracy: 0.1111\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.5664 - accuracy: 0.1766 - val_loss: 48.5331 - val_accuracy: 0.1111\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5028 - accuracy: 0.1667 - val_loss: 48.4696 - val_accuracy: 0.1111\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.4407 - accuracy: 0.1542 - val_loss: 48.4047 - val_accuracy: 0.1111\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.3786 - accuracy: 0.1542 - val_loss: 48.3381 - val_accuracy: 0.1111\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.3158 - accuracy: 0.1542 - val_loss: 48.2724 - val_accuracy: 0.1111\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.2524 - accuracy: 0.1542 - val_loss: 48.2101 - val_accuracy: 0.1111\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1886 - accuracy: 0.1567 - val_loss: 48.1502 - val_accuracy: 0.1111\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1257 - accuracy: 0.1816 - val_loss: 48.0918 - val_accuracy: 0.1111\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.0636 - accuracy: 0.1766 - val_loss: 48.0333 - val_accuracy: 0.1111\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0010 - accuracy: 0.1766 - val_loss: 47.9782 - val_accuracy: 0.1333\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.9388 - accuracy: 0.1692 - val_loss: 47.9126 - val_accuracy: 0.1111\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.8755 - accuracy: 0.1667 - val_loss: 47.8523 - val_accuracy: 0.1333\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.8133 - accuracy: 0.1642 - val_loss: 47.7907 - val_accuracy: 0.1333\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.7504 - accuracy: 0.1642 - val_loss: 47.7274 - val_accuracy: 0.1333\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.6887 - accuracy: 0.1642 - val_loss: 47.6585 - val_accuracy: 0.1333\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.6265 - accuracy: 0.1642 - val_loss: 47.5925 - val_accuracy: 0.1333\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.5645 - accuracy: 0.1642 - val_loss: 47.5361 - val_accuracy: 0.1333\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5025 - accuracy: 0.1642 - val_loss: 47.4762 - val_accuracy: 0.1333\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.4402 - accuracy: 0.1642 - val_loss: 47.4198 - val_accuracy: 0.1333\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.3792 - accuracy: 0.1642 - val_loss: 47.3652 - val_accuracy: 0.1333\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3171 - accuracy: 0.1642 - val_loss: 47.3009 - val_accuracy: 0.1333\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2544 - accuracy: 0.1642 - val_loss: 47.2354 - val_accuracy: 0.1333\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47.1927 - accuracy: 0.1642 - val_loss: 47.1725 - val_accuracy: 0.1333\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1299 - accuracy: 0.1642 - val_loss: 47.1050 - val_accuracy: 0.1111\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.0682 - accuracy: 0.1915 - val_loss: 47.0363 - val_accuracy: 0.1111\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.0078 - accuracy: 0.1542 - val_loss: 46.9681 - val_accuracy: 0.1111\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.9460 - accuracy: 0.1542 - val_loss: 46.9074 - val_accuracy: 0.1111\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.8847 - accuracy: 0.1542 - val_loss: 46.8456 - val_accuracy: 0.1111\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.8229 - accuracy: 0.1592 - val_loss: 46.7878 - val_accuracy: 0.1111\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7615 - accuracy: 0.1816 - val_loss: 46.7282 - val_accuracy: 0.1111\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7002 - accuracy: 0.1841 - val_loss: 46.6667 - val_accuracy: 0.1111\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.6383 - accuracy: 0.1816 - val_loss: 46.6081 - val_accuracy: 0.1111\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.5772 - accuracy: 0.1741 - val_loss: 46.5499 - val_accuracy: 0.1333\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.5167 - accuracy: 0.1642 - val_loss: 46.4906 - val_accuracy: 0.1333\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4552 - accuracy: 0.1716 - val_loss: 46.4257 - val_accuracy: 0.1111\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3941 - accuracy: 0.1816 - val_loss: 46.3646 - val_accuracy: 0.1111\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3336 - accuracy: 0.1716 - val_loss: 46.3079 - val_accuracy: 0.1333\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.2733 - accuracy: 0.1642 - val_loss: 46.2488 - val_accuracy: 0.1333\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46.2124 - accuracy: 0.1642 - val_loss: 46.1905 - val_accuracy: 0.1333\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1518 - accuracy: 0.1642 - val_loss: 46.1328 - val_accuracy: 0.1333\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0906 - accuracy: 0.1642 - val_loss: 46.0663 - val_accuracy: 0.1333\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.0299 - accuracy: 0.1766 - val_loss: 45.9953 - val_accuracy: 0.1111\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.9691 - accuracy: 0.1542 - val_loss: 45.9318 - val_accuracy: 0.1111\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.9087 - accuracy: 0.1542 - val_loss: 45.8727 - val_accuracy: 0.1111\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8483 - accuracy: 0.1542 - val_loss: 45.8166 - val_accuracy: 0.1111\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.7876 - accuracy: 0.1542 - val_loss: 45.7558 - val_accuracy: 0.1111\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7272 - accuracy: 0.1542 - val_loss: 45.6990 - val_accuracy: 0.1111\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.6672 - accuracy: 0.1667 - val_loss: 45.6418 - val_accuracy: 0.1111\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.6059 - accuracy: 0.1791 - val_loss: 45.5824 - val_accuracy: 0.1333\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5460 - accuracy: 0.1642 - val_loss: 45.5222 - val_accuracy: 0.1333\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.4862 - accuracy: 0.1642 - val_loss: 45.4626 - val_accuracy: 0.1333\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.4264 - accuracy: 0.1642 - val_loss: 45.4079 - val_accuracy: 0.1333\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3666 - accuracy: 0.1642 - val_loss: 45.3465 - val_accuracy: 0.1333\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.3062 - accuracy: 0.1642 - val_loss: 45.2809 - val_accuracy: 0.1333\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.2459 - accuracy: 0.1642 - val_loss: 45.2212 - val_accuracy: 0.1333\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1863 - accuracy: 0.1617 - val_loss: 45.1560 - val_accuracy: 0.1111\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.1275 - accuracy: 0.1766 - val_loss: 45.0901 - val_accuracy: 0.1111\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.0678 - accuracy: 0.1542 - val_loss: 45.0275 - val_accuracy: 0.1111\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.0078 - accuracy: 0.1567 - val_loss: 44.9697 - val_accuracy: 0.1111\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9474 - accuracy: 0.1866 - val_loss: 44.9138 - val_accuracy: 0.1111\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8873 - accuracy: 0.1791 - val_loss: 44.8527 - val_accuracy: 0.1111\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.8290 - accuracy: 0.1766 - val_loss: 44.7906 - val_accuracy: 0.1111\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.7698 - accuracy: 0.1542 - val_loss: 44.7291 - val_accuracy: 0.1111\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.7097 - accuracy: 0.1741 - val_loss: 44.6735 - val_accuracy: 0.1111\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.6510 - accuracy: 0.1716 - val_loss: 44.6173 - val_accuracy: 0.1333\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.5910 - accuracy: 0.1642 - val_loss: 44.5592 - val_accuracy: 0.1333\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.5319 - accuracy: 0.1642 - val_loss: 44.5017 - val_accuracy: 0.1333\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.4730 - accuracy: 0.1642 - val_loss: 44.4466 - val_accuracy: 0.1333\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.4141 - accuracy: 0.1642 - val_loss: 44.3933 - val_accuracy: 0.1333\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.3555 - accuracy: 0.1642 - val_loss: 44.3414 - val_accuracy: 0.1333\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.2971 - accuracy: 0.1642 - val_loss: 44.2870 - val_accuracy: 0.1333\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2387 - accuracy: 0.1741 - val_loss: 44.2245 - val_accuracy: 0.1333\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.1793 - accuracy: 0.1766 - val_loss: 44.1660 - val_accuracy: 0.1333\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.1207 - accuracy: 0.1642 - val_loss: 44.1034 - val_accuracy: 0.1333\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0604 - accuracy: 0.1642 - val_loss: 44.0384 - val_accuracy: 0.1333\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0010 - accuracy: 0.1667 - val_loss: 43.9746 - val_accuracy: 0.1111\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.9425 - accuracy: 0.1891 - val_loss: 43.9143 - val_accuracy: 0.1111\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.8844 - accuracy: 0.1816 - val_loss: 43.8622 - val_accuracy: 0.1111\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.8262 - accuracy: 0.1617 - val_loss: 43.8068 - val_accuracy: 0.1333\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.7681 - accuracy: 0.1642 - val_loss: 43.7498 - val_accuracy: 0.1333\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7093 - accuracy: 0.1642 - val_loss: 43.6901 - val_accuracy: 0.1111\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43.6511 - accuracy: 0.1816 - val_loss: 43.6314 - val_accuracy: 0.1111\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.5929 - accuracy: 0.1915 - val_loss: 43.5714 - val_accuracy: 0.1111\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5339 - accuracy: 0.1841 - val_loss: 43.5124 - val_accuracy: 0.1111\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4766 - accuracy: 0.1816 - val_loss: 43.4527 - val_accuracy: 0.1111\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.4179 - accuracy: 0.1816 - val_loss: 43.3882 - val_accuracy: 0.1111\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.3606 - accuracy: 0.1741 - val_loss: 43.3249 - val_accuracy: 0.1111\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3019 - accuracy: 0.1791 - val_loss: 43.2673 - val_accuracy: 0.1111\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.2439 - accuracy: 0.1816 - val_loss: 43.2093 - val_accuracy: 0.1111\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.1858 - accuracy: 0.1816 - val_loss: 43.1495 - val_accuracy: 0.1111\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.1285 - accuracy: 0.1791 - val_loss: 43.0966 - val_accuracy: 0.1333\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.0712 - accuracy: 0.1642 - val_loss: 43.0421 - val_accuracy: 0.1333\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0130 - accuracy: 0.1642 - val_loss: 42.9849 - val_accuracy: 0.1333\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.9557 - accuracy: 0.1642 - val_loss: 42.9320 - val_accuracy: 0.1333\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.8978 - accuracy: 0.1642 - val_loss: 42.8751 - val_accuracy: 0.1333\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.8405 - accuracy: 0.1642 - val_loss: 42.8189 - val_accuracy: 0.1333\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7820 - accuracy: 0.1642 - val_loss: 42.7582 - val_accuracy: 0.1333\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.7242 - accuracy: 0.1741 - val_loss: 42.6949 - val_accuracy: 0.1111\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6673 - accuracy: 0.1816 - val_loss: 42.6342 - val_accuracy: 0.1111\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6104 - accuracy: 0.1741 - val_loss: 42.5728 - val_accuracy: 0.1111\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.5529 - accuracy: 0.1816 - val_loss: 42.5104 - val_accuracy: 0.1111\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4962 - accuracy: 0.1741 - val_loss: 42.4529 - val_accuracy: 0.1111\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.4385 - accuracy: 0.1741 - val_loss: 42.4014 - val_accuracy: 0.1333\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.3803 - accuracy: 0.1642 - val_loss: 42.3489 - val_accuracy: 0.1333\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3234 - accuracy: 0.1642 - val_loss: 42.2929 - val_accuracy: 0.1333\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.2663 - accuracy: 0.1766 - val_loss: 42.2324 - val_accuracy: 0.1111\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.2092 - accuracy: 0.1766 - val_loss: 42.1726 - val_accuracy: 0.1111\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1526 - accuracy: 0.1592 - val_loss: 42.1168 - val_accuracy: 0.1111\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0952 - accuracy: 0.1791 - val_loss: 42.0611 - val_accuracy: 0.1111\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.0389 - accuracy: 0.1816 - val_loss: 42.0045 - val_accuracy: 0.1111\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.9820 - accuracy: 0.1716 - val_loss: 41.9492 - val_accuracy: 0.1111\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.9249 - accuracy: 0.1816 - val_loss: 41.8963 - val_accuracy: 0.1111\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.8691 - accuracy: 0.1692 - val_loss: 41.8474 - val_accuracy: 0.1333\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.8123 - accuracy: 0.1891 - val_loss: 41.7912 - val_accuracy: 0.1111\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.7579 - accuracy: 0.1592 - val_loss: 41.7307 - val_accuracy: 0.1111\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6998 - accuracy: 0.1542 - val_loss: 41.6762 - val_accuracy: 0.1111\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6428 - accuracy: 0.1567 - val_loss: 41.6206 - val_accuracy: 0.1111\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.5866 - accuracy: 0.1692 - val_loss: 41.5652 - val_accuracy: 0.1333\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.5298 - accuracy: 0.1642 - val_loss: 41.5051 - val_accuracy: 0.1333\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4733 - accuracy: 0.1642 - val_loss: 41.4465 - val_accuracy: 0.1111\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4172 - accuracy: 0.1816 - val_loss: 41.3890 - val_accuracy: 0.1111\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3617 - accuracy: 0.1617 - val_loss: 41.3313 - val_accuracy: 0.1111\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3055 - accuracy: 0.1542 - val_loss: 41.2768 - val_accuracy: 0.1111\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.2491 - accuracy: 0.1542 - val_loss: 41.2171 - val_accuracy: 0.1111\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1932 - accuracy: 0.1542 - val_loss: 41.1560 - val_accuracy: 0.1111\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1372 - accuracy: 0.1542 - val_loss: 41.0959 - val_accuracy: 0.1111\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.0815 - accuracy: 0.1542 - val_loss: 41.0407 - val_accuracy: 0.1111\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.0253 - accuracy: 0.1542 - val_loss: 40.9869 - val_accuracy: 0.1111\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.9692 - accuracy: 0.1567 - val_loss: 40.9342 - val_accuracy: 0.1111\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.9129 - accuracy: 0.1816 - val_loss: 40.8805 - val_accuracy: 0.1111\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8581 - accuracy: 0.1642 - val_loss: 40.8292 - val_accuracy: 0.1333\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.8026 - accuracy: 0.1642 - val_loss: 40.7811 - val_accuracy: 0.1333\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.7469 - accuracy: 0.1642 - val_loss: 40.7296 - val_accuracy: 0.1333\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.6917 - accuracy: 0.1642 - val_loss: 40.6701 - val_accuracy: 0.1333\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.6354 - accuracy: 0.1642 - val_loss: 40.6143 - val_accuracy: 0.1333\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.5801 - accuracy: 0.1741 - val_loss: 40.5557 - val_accuracy: 0.1111\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.5247 - accuracy: 0.1791 - val_loss: 40.4997 - val_accuracy: 0.1111\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.4686 - accuracy: 0.1841 - val_loss: 40.4486 - val_accuracy: 0.1111\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.4136 - accuracy: 0.1642 - val_loss: 40.4030 - val_accuracy: 0.1333\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3600 - accuracy: 0.1642 - val_loss: 40.3509 - val_accuracy: 0.1333\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.3038 - accuracy: 0.1642 - val_loss: 40.2903 - val_accuracy: 0.1333\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2486 - accuracy: 0.1642 - val_loss: 40.2300 - val_accuracy: 0.1333\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.1940 - accuracy: 0.1716 - val_loss: 40.1719 - val_accuracy: 0.1111\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.1394 - accuracy: 0.1692 - val_loss: 40.1100 - val_accuracy: 0.1111\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0844 - accuracy: 0.1642 - val_loss: 40.0530 - val_accuracy: 0.1111\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.0283 - accuracy: 0.1692 - val_loss: 39.9981 - val_accuracy: 0.1111\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.9736 - accuracy: 0.1642 - val_loss: 39.9452 - val_accuracy: 0.1111\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.9187 - accuracy: 0.1667 - val_loss: 39.8942 - val_accuracy: 0.1111\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.8640 - accuracy: 0.1716 - val_loss: 39.8430 - val_accuracy: 0.1111\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.8097 - accuracy: 0.1741 - val_loss: 39.7928 - val_accuracy: 0.1333\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7556 - accuracy: 0.1692 - val_loss: 39.7350 - val_accuracy: 0.1111\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7004 - accuracy: 0.1816 - val_loss: 39.6818 - val_accuracy: 0.1111\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.6459 - accuracy: 0.1766 - val_loss: 39.6288 - val_accuracy: 0.1333\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5912 - accuracy: 0.1841 - val_loss: 39.5703 - val_accuracy: 0.1111\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5369 - accuracy: 0.1542 - val_loss: 39.5116 - val_accuracy: 0.1111\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4815 - accuracy: 0.1542 - val_loss: 39.4584 - val_accuracy: 0.1111\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4272 - accuracy: 0.1567 - val_loss: 39.4069 - val_accuracy: 0.1111\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3728 - accuracy: 0.1692 - val_loss: 39.3538 - val_accuracy: 0.1111\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3190 - accuracy: 0.1791 - val_loss: 39.2997 - val_accuracy: 0.1111\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.2648 - accuracy: 0.1816 - val_loss: 39.2455 - val_accuracy: 0.1111\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.2101 - accuracy: 0.1716 - val_loss: 39.1891 - val_accuracy: 0.1333\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.1559 - accuracy: 0.1642 - val_loss: 39.1305 - val_accuracy: 0.1333\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1022 - accuracy: 0.1642 - val_loss: 39.0723 - val_accuracy: 0.1333\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.0487 - accuracy: 0.1642 - val_loss: 39.0145 - val_accuracy: 0.1333\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.9951 - accuracy: 0.1642 - val_loss: 38.9632 - val_accuracy: 0.1333\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.9406 - accuracy: 0.1642 - val_loss: 38.9124 - val_accuracy: 0.1333\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.8874 - accuracy: 0.1642 - val_loss: 38.8652 - val_accuracy: 0.1333\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.8334 - accuracy: 0.1642 - val_loss: 38.8157 - val_accuracy: 0.1333\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.7796 - accuracy: 0.1642 - val_loss: 38.7635 - val_accuracy: 0.1333\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.7258 - accuracy: 0.1642 - val_loss: 38.7132 - val_accuracy: 0.1333\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6714 - accuracy: 0.1642 - val_loss: 38.6566 - val_accuracy: 0.1333\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6180 - accuracy: 0.1642 - val_loss: 38.6012 - val_accuracy: 0.1333\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5645 - accuracy: 0.1642 - val_loss: 38.5420 - val_accuracy: 0.1333\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.5117 - accuracy: 0.1642 - val_loss: 38.4814 - val_accuracy: 0.1333\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.4579 - accuracy: 0.1741 - val_loss: 38.4267 - val_accuracy: 0.1111\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.4050 - accuracy: 0.1816 - val_loss: 38.3771 - val_accuracy: 0.1111\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.3512 - accuracy: 0.1716 - val_loss: 38.3265 - val_accuracy: 0.1333\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2977 - accuracy: 0.1642 - val_loss: 38.2748 - val_accuracy: 0.1333\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.2443 - accuracy: 0.1642 - val_loss: 38.2229 - val_accuracy: 0.1333\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.1908 - accuracy: 0.1642 - val_loss: 38.1709 - val_accuracy: 0.1333\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.1379 - accuracy: 0.1642 - val_loss: 38.1174 - val_accuracy: 0.1333\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0847 - accuracy: 0.1667 - val_loss: 38.0589 - val_accuracy: 0.1111\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0314 - accuracy: 0.1791 - val_loss: 37.9999 - val_accuracy: 0.1111\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.9783 - accuracy: 0.1692 - val_loss: 37.9421 - val_accuracy: 0.1111\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.9256 - accuracy: 0.1542 - val_loss: 37.8890 - val_accuracy: 0.1111\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.8734 - accuracy: 0.1542 - val_loss: 37.8370 - val_accuracy: 0.1111\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.8201 - accuracy: 0.1542 - val_loss: 37.7862 - val_accuracy: 0.1111\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7674 - accuracy: 0.1617 - val_loss: 37.7393 - val_accuracy: 0.1111\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7144 - accuracy: 0.1891 - val_loss: 37.6891 - val_accuracy: 0.1333\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.6612 - accuracy: 0.1642 - val_loss: 37.6347 - val_accuracy: 0.1333\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.6094 - accuracy: 0.1642 - val_loss: 37.5845 - val_accuracy: 0.1333\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5586 - accuracy: 0.1716 - val_loss: 37.5363 - val_accuracy: 0.1333\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5054 - accuracy: 0.1667 - val_loss: 37.4819 - val_accuracy: 0.1333\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4521 - accuracy: 0.1642 - val_loss: 37.4272 - val_accuracy: 0.1333\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.3988 - accuracy: 0.1642 - val_loss: 37.3735 - val_accuracy: 0.1333\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3466 - accuracy: 0.1642 - val_loss: 37.3235 - val_accuracy: 0.1333\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.2943 - accuracy: 0.1642 - val_loss: 37.2729 - val_accuracy: 0.1333\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2421 - accuracy: 0.1642 - val_loss: 37.2215 - val_accuracy: 0.1333\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1898 - accuracy: 0.1642 - val_loss: 37.1698 - val_accuracy: 0.1333\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37.1369 - accuracy: 0.1642 - val_loss: 37.1200 - val_accuracy: 0.1333\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.0851 - accuracy: 0.1642 - val_loss: 37.0635 - val_accuracy: 0.1111\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.0334 - accuracy: 0.1866 - val_loss: 37.0068 - val_accuracy: 0.1111\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.9807 - accuracy: 0.1542 - val_loss: 36.9500 - val_accuracy: 0.1111\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.9303 - accuracy: 0.1542 - val_loss: 36.8955 - val_accuracy: 0.1111\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36.8787 - accuracy: 0.1542 - val_loss: 36.8456 - val_accuracy: 0.1111\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.8259 - accuracy: 0.1542 - val_loss: 36.8005 - val_accuracy: 0.1111\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7733 - accuracy: 0.1542 - val_loss: 36.7540 - val_accuracy: 0.1111\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.7217 - accuracy: 0.1542 - val_loss: 36.7021 - val_accuracy: 0.1111\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.6698 - accuracy: 0.1542 - val_loss: 36.6494 - val_accuracy: 0.1111\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6175 - accuracy: 0.1542 - val_loss: 36.5966 - val_accuracy: 0.1111\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5667 - accuracy: 0.1542 - val_loss: 36.5404 - val_accuracy: 0.1111\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5144 - accuracy: 0.1542 - val_loss: 36.4859 - val_accuracy: 0.1111\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.4627 - accuracy: 0.1542 - val_loss: 36.4332 - val_accuracy: 0.1111\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.4113 - accuracy: 0.1766 - val_loss: 36.3852 - val_accuracy: 0.1111\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3603 - accuracy: 0.1667 - val_loss: 36.3382 - val_accuracy: 0.1333\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3087 - accuracy: 0.1642 - val_loss: 36.2890 - val_accuracy: 0.1333\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.2572 - accuracy: 0.1642 - val_loss: 36.2343 - val_accuracy: 0.1333\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2051 - accuracy: 0.1642 - val_loss: 36.1808 - val_accuracy: 0.1333\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.1542 - accuracy: 0.1766 - val_loss: 36.1280 - val_accuracy: 0.1111\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.1028 - accuracy: 0.1816 - val_loss: 36.0728 - val_accuracy: 0.1111\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.0516 - accuracy: 0.1866 - val_loss: 36.0246 - val_accuracy: 0.1111\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.0004 - accuracy: 0.1741 - val_loss: 35.9730 - val_accuracy: 0.1333\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.9495 - accuracy: 0.1642 - val_loss: 35.9222 - val_accuracy: 0.1333\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.8987 - accuracy: 0.1642 - val_loss: 35.8750 - val_accuracy: 0.1333\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8476 - accuracy: 0.1642 - val_loss: 35.8282 - val_accuracy: 0.1333\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7966 - accuracy: 0.1642 - val_loss: 35.7810 - val_accuracy: 0.1333\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7455 - accuracy: 0.1642 - val_loss: 35.7326 - val_accuracy: 0.1333\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6945 - accuracy: 0.1667 - val_loss: 35.6803 - val_accuracy: 0.1111\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.6434 - accuracy: 0.1816 - val_loss: 35.6298 - val_accuracy: 0.1111\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35.5927 - accuracy: 0.1891 - val_loss: 35.5753 - val_accuracy: 0.1111\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.5425 - accuracy: 0.1791 - val_loss: 35.5187 - val_accuracy: 0.1111\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.4918 - accuracy: 0.1692 - val_loss: 35.4642 - val_accuracy: 0.1111\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.4411 - accuracy: 0.1692 - val_loss: 35.4132 - val_accuracy: 0.1111\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.3907 - accuracy: 0.1542 - val_loss: 35.3604 - val_accuracy: 0.1111\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.3400 - accuracy: 0.1542 - val_loss: 35.3136 - val_accuracy: 0.1111\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.2891 - accuracy: 0.1692 - val_loss: 35.2633 - val_accuracy: 0.1333\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.2388 - accuracy: 0.1990 - val_loss: 35.2157 - val_accuracy: 0.1333\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1887 - accuracy: 0.2114 - val_loss: 35.1625 - val_accuracy: 0.1111\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1381 - accuracy: 0.1841 - val_loss: 35.1130 - val_accuracy: 0.1333\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0894 - accuracy: 0.1642 - val_loss: 35.0655 - val_accuracy: 0.1333\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0386 - accuracy: 0.1642 - val_loss: 35.0171 - val_accuracy: 0.1333\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9878 - accuracy: 0.1642 - val_loss: 34.9651 - val_accuracy: 0.1333\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.9372 - accuracy: 0.1642 - val_loss: 34.9127 - val_accuracy: 0.1333\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8872 - accuracy: 0.1642 - val_loss: 34.8623 - val_accuracy: 0.1333\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.8369 - accuracy: 0.1642 - val_loss: 34.8154 - val_accuracy: 0.1333\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7871 - accuracy: 0.1642 - val_loss: 34.7679 - val_accuracy: 0.1333\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.7369 - accuracy: 0.1642 - val_loss: 34.7221 - val_accuracy: 0.1333\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6875 - accuracy: 0.1642 - val_loss: 34.6740 - val_accuracy: 0.1333\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.6374 - accuracy: 0.1791 - val_loss: 34.6207 - val_accuracy: 0.1111\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5882 - accuracy: 0.1642 - val_loss: 34.5686 - val_accuracy: 0.1111\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5385 - accuracy: 0.1542 - val_loss: 34.5192 - val_accuracy: 0.1111\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.4883 - accuracy: 0.1542 - val_loss: 34.4685 - val_accuracy: 0.1111\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.4386 - accuracy: 0.1542 - val_loss: 34.4167 - val_accuracy: 0.1111\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3885 - accuracy: 0.1667 - val_loss: 34.3700 - val_accuracy: 0.1111\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3391 - accuracy: 0.1816 - val_loss: 34.3234 - val_accuracy: 0.1111\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.2897 - accuracy: 0.1816 - val_loss: 34.2738 - val_accuracy: 0.1111\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.2399 - accuracy: 0.1816 - val_loss: 34.2225 - val_accuracy: 0.1111\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.1903 - accuracy: 0.1841 - val_loss: 34.1695 - val_accuracy: 0.1111\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.1412 - accuracy: 0.1816 - val_loss: 34.1236 - val_accuracy: 0.1111\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.0919 - accuracy: 0.1816 - val_loss: 34.0733 - val_accuracy: 0.1111\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.0425 - accuracy: 0.1816 - val_loss: 34.0263 - val_accuracy: 0.1111\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9937 - accuracy: 0.1741 - val_loss: 33.9766 - val_accuracy: 0.1556\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.9448 - accuracy: 0.1667 - val_loss: 33.9250 - val_accuracy: 0.1333\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.8952 - accuracy: 0.1642 - val_loss: 33.8779 - val_accuracy: 0.1333\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.8461 - accuracy: 0.1642 - val_loss: 33.8244 - val_accuracy: 0.1333\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7965 - accuracy: 0.1642 - val_loss: 33.7713 - val_accuracy: 0.1333\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.7472 - accuracy: 0.1741 - val_loss: 33.7218 - val_accuracy: 0.1111\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.6990 - accuracy: 0.1816 - val_loss: 33.6732 - val_accuracy: 0.1111\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.6494 - accuracy: 0.1841 - val_loss: 33.6233 - val_accuracy: 0.1111\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.6005 - accuracy: 0.1841 - val_loss: 33.5744 - val_accuracy: 0.1111\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5520 - accuracy: 0.1816 - val_loss: 33.5288 - val_accuracy: 0.1111\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5029 - accuracy: 0.1841 - val_loss: 33.4851 - val_accuracy: 0.1111\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4546 - accuracy: 0.1766 - val_loss: 33.4378 - val_accuracy: 0.1111\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4060 - accuracy: 0.1542 - val_loss: 33.3905 - val_accuracy: 0.1111\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.3570 - accuracy: 0.1716 - val_loss: 33.3412 - val_accuracy: 0.1111\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3083 - accuracy: 0.1841 - val_loss: 33.2915 - val_accuracy: 0.1111\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2596 - accuracy: 0.1816 - val_loss: 33.2442 - val_accuracy: 0.1333\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2115 - accuracy: 0.1642 - val_loss: 33.1941 - val_accuracy: 0.1333\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1633 - accuracy: 0.1766 - val_loss: 33.1402 - val_accuracy: 0.1333\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1147 - accuracy: 0.1940 - val_loss: 33.0893 - val_accuracy: 0.1333\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.0661 - accuracy: 0.1891 - val_loss: 33.0406 - val_accuracy: 0.1111\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.0173 - accuracy: 0.1915 - val_loss: 32.9926 - val_accuracy: 0.1111\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.9692 - accuracy: 0.1816 - val_loss: 32.9446 - val_accuracy: 0.1111\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9217 - accuracy: 0.1716 - val_loss: 32.8951 - val_accuracy: 0.1111\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8729 - accuracy: 0.1741 - val_loss: 32.8501 - val_accuracy: 0.1111\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8250 - accuracy: 0.1741 - val_loss: 32.8026 - val_accuracy: 0.1111\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.7764 - accuracy: 0.1791 - val_loss: 32.7576 - val_accuracy: 0.1111\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.7286 - accuracy: 0.1741 - val_loss: 32.7150 - val_accuracy: 0.1333\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.6807 - accuracy: 0.1642 - val_loss: 32.6734 - val_accuracy: 0.1333\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.6334 - accuracy: 0.1642 - val_loss: 32.6297 - val_accuracy: 0.1333\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.5852 - accuracy: 0.1642 - val_loss: 32.5792 - val_accuracy: 0.1333\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5362 - accuracy: 0.1692 - val_loss: 32.5241 - val_accuracy: 0.1111\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.4897 - accuracy: 0.1642 - val_loss: 32.4658 - val_accuracy: 0.1111\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.4425 - accuracy: 0.1542 - val_loss: 32.4170 - val_accuracy: 0.1111\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3943 - accuracy: 0.1542 - val_loss: 32.3684 - val_accuracy: 0.1111\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3464 - accuracy: 0.1542 - val_loss: 32.3205 - val_accuracy: 0.1111\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2990 - accuracy: 0.1542 - val_loss: 32.2712 - val_accuracy: 0.1111\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2509 - accuracy: 0.1642 - val_loss: 32.2239 - val_accuracy: 0.1111\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.2033 - accuracy: 0.1692 - val_loss: 32.1797 - val_accuracy: 0.1111\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.1552 - accuracy: 0.1841 - val_loss: 32.1317 - val_accuracy: 0.1111\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.1075 - accuracy: 0.1766 - val_loss: 32.0835 - val_accuracy: 0.1333\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0605 - accuracy: 0.1642 - val_loss: 32.0377 - val_accuracy: 0.1333\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.0130 - accuracy: 0.1642 - val_loss: 31.9905 - val_accuracy: 0.1333\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9665 - accuracy: 0.1642 - val_loss: 31.9397 - val_accuracy: 0.1333\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31.9196 - accuracy: 0.1642 - val_loss: 31.8879 - val_accuracy: 0.1333\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.8722 - accuracy: 0.1642 - val_loss: 31.8385 - val_accuracy: 0.1333\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.8245 - accuracy: 0.1667 - val_loss: 31.7907 - val_accuracy: 0.1111\n",
      "========== Fold 4 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 207.7126 - accuracy: 0.0871 - val_loss: 196.4753 - val_accuracy: 0.1778\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 190.3493 - accuracy: 0.1269 - val_loss: 177.7314 - val_accuracy: 0.2222\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 172.2297 - accuracy: 0.1318 - val_loss: 161.4737 - val_accuracy: 0.2444\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 157.0588 - accuracy: 0.1418 - val_loss: 148.5641 - val_accuracy: 0.1778\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 145.1392 - accuracy: 0.1418 - val_loss: 138.5797 - val_accuracy: 0.1556\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 135.9351 - accuracy: 0.1393 - val_loss: 130.8567 - val_accuracy: 0.2222\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 128.8099 - accuracy: 0.1294 - val_loss: 124.8629 - val_accuracy: 0.0667\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 123.2409 - accuracy: 0.1517 - val_loss: 120.1158 - val_accuracy: 0.0889\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 118.8298 - accuracy: 0.1567 - val_loss: 116.3134 - val_accuracy: 0.1778\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115.2752 - accuracy: 0.1667 - val_loss: 113.2267 - val_accuracy: 0.2222\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 112.3700 - accuracy: 0.1493 - val_loss: 110.6712 - val_accuracy: 0.2222\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 109.9635 - accuracy: 0.1617 - val_loss: 108.5307 - val_accuracy: 0.2222\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 107.9398 - accuracy: 0.1542 - val_loss: 106.7331 - val_accuracy: 0.2222\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 106.2191 - accuracy: 0.1542 - val_loss: 105.1902 - val_accuracy: 0.2444\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 104.7356 - accuracy: 0.1692 - val_loss: 103.8493 - val_accuracy: 0.1111\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 103.4462 - accuracy: 0.1741 - val_loss: 102.6684 - val_accuracy: 0.2222\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102.3153 - accuracy: 0.1468 - val_loss: 101.6110 - val_accuracy: 0.2222\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 101.3091 - accuracy: 0.1343 - val_loss: 100.6776 - val_accuracy: 0.2222\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 100.4107 - accuracy: 0.1517 - val_loss: 99.8425 - val_accuracy: 0.2222\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 99.6008 - accuracy: 0.1542 - val_loss: 99.0870 - val_accuracy: 0.2222\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.8669 - accuracy: 0.1542 - val_loss: 98.4018 - val_accuracy: 0.2444\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.1972 - accuracy: 0.1716 - val_loss: 97.7716 - val_accuracy: 0.2444\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 97.5839 - accuracy: 0.1418 - val_loss: 97.1853 - val_accuracy: 0.2222\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 97.0151 - accuracy: 0.1716 - val_loss: 96.6534 - val_accuracy: 0.2222\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 96.4914 - accuracy: 0.1567 - val_loss: 96.1533 - val_accuracy: 0.2444\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96.0024 - accuracy: 0.1617 - val_loss: 95.6819 - val_accuracy: 0.1111\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.5436 - accuracy: 0.1517 - val_loss: 95.2373 - val_accuracy: 0.2000\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.1134 - accuracy: 0.1816 - val_loss: 94.8270 - val_accuracy: 0.1778\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94.7077 - accuracy: 0.1443 - val_loss: 94.4350 - val_accuracy: 0.2222\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94.3248 - accuracy: 0.1741 - val_loss: 94.0647 - val_accuracy: 0.2222\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9622 - accuracy: 0.1393 - val_loss: 93.7145 - val_accuracy: 0.1778\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 93.6138 - accuracy: 0.1393 - val_loss: 93.3752 - val_accuracy: 0.2222\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.2819 - accuracy: 0.1418 - val_loss: 93.0523 - val_accuracy: 0.2222\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.9637 - accuracy: 0.1493 - val_loss: 92.7482 - val_accuracy: 0.1778\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.6611 - accuracy: 0.1592 - val_loss: 92.4544 - val_accuracy: 0.1778\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92.3675 - accuracy: 0.1692 - val_loss: 92.1640 - val_accuracy: 0.2000\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.0828 - accuracy: 0.1692 - val_loss: 91.8851 - val_accuracy: 0.2222\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 91.8103 - accuracy: 0.1542 - val_loss: 91.6145 - val_accuracy: 0.2222\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.5444 - accuracy: 0.1542 - val_loss: 91.3659 - val_accuracy: 0.2222\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.2889 - accuracy: 0.1542 - val_loss: 91.1256 - val_accuracy: 0.2222\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.0409 - accuracy: 0.1542 - val_loss: 90.8870 - val_accuracy: 0.2222\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90.7992 - accuracy: 0.1592 - val_loss: 90.6482 - val_accuracy: 0.2444\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.5618 - accuracy: 0.1692 - val_loss: 90.4060 - val_accuracy: 0.2222\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.3302 - accuracy: 0.1542 - val_loss: 90.1784 - val_accuracy: 0.2000\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.1055 - accuracy: 0.1567 - val_loss: 89.9580 - val_accuracy: 0.2444\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.8865 - accuracy: 0.1592 - val_loss: 89.7434 - val_accuracy: 0.0667\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.6728 - accuracy: 0.1642 - val_loss: 89.5200 - val_accuracy: 0.0667\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.4600 - accuracy: 0.1866 - val_loss: 89.3036 - val_accuracy: 0.1778\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.2522 - accuracy: 0.1766 - val_loss: 89.1018 - val_accuracy: 0.2444\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.0479 - accuracy: 0.1468 - val_loss: 88.9008 - val_accuracy: 0.2222\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.8496 - accuracy: 0.1418 - val_loss: 88.7017 - val_accuracy: 0.2222\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 88.6535 - accuracy: 0.1418 - val_loss: 88.5044 - val_accuracy: 0.2222\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.4611 - accuracy: 0.1542 - val_loss: 88.3218 - val_accuracy: 0.2222\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.2700 - accuracy: 0.1542 - val_loss: 88.1454 - val_accuracy: 0.2444\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0814 - accuracy: 0.1692 - val_loss: 87.9603 - val_accuracy: 0.1111\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.8977 - accuracy: 0.1517 - val_loss: 87.7709 - val_accuracy: 0.2444\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.7151 - accuracy: 0.1791 - val_loss: 87.5802 - val_accuracy: 0.2222\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.5360 - accuracy: 0.1468 - val_loss: 87.4028 - val_accuracy: 0.2222\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.3584 - accuracy: 0.1617 - val_loss: 87.2347 - val_accuracy: 0.2444\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.1820 - accuracy: 0.1816 - val_loss: 87.0623 - val_accuracy: 0.2222\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.0087 - accuracy: 0.1766 - val_loss: 86.8984 - val_accuracy: 0.1333\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.8373 - accuracy: 0.1841 - val_loss: 86.7227 - val_accuracy: 0.2222\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.6675 - accuracy: 0.1443 - val_loss: 86.5426 - val_accuracy: 0.2000\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.5031 - accuracy: 0.1716 - val_loss: 86.3630 - val_accuracy: 0.1778\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.3384 - accuracy: 0.1692 - val_loss: 86.1971 - val_accuracy: 0.2222\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.1715 - accuracy: 0.1493 - val_loss: 86.0392 - val_accuracy: 0.2222\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.0085 - accuracy: 0.1642 - val_loss: 85.8881 - val_accuracy: 0.2222\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.8476 - accuracy: 0.1418 - val_loss: 85.7343 - val_accuracy: 0.2222\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.6890 - accuracy: 0.1393 - val_loss: 85.5722 - val_accuracy: 0.2222\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.5316 - accuracy: 0.1418 - val_loss: 85.4158 - val_accuracy: 0.2222\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.3739 - accuracy: 0.1667 - val_loss: 85.2577 - val_accuracy: 0.2222\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.2166 - accuracy: 0.1542 - val_loss: 85.1072 - val_accuracy: 0.2222\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.0633 - accuracy: 0.1642 - val_loss: 84.9570 - val_accuracy: 0.2000\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.9117 - accuracy: 0.1542 - val_loss: 84.8088 - val_accuracy: 0.1556\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.7600 - accuracy: 0.1891 - val_loss: 84.6540 - val_accuracy: 0.2222\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.6101 - accuracy: 0.1567 - val_loss: 84.4963 - val_accuracy: 0.2222\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.4603 - accuracy: 0.1194 - val_loss: 84.3451 - val_accuracy: 0.2222\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.3140 - accuracy: 0.1368 - val_loss: 84.1942 - val_accuracy: 0.2222\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.1670 - accuracy: 0.1418 - val_loss: 84.0467 - val_accuracy: 0.2222\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.0192 - accuracy: 0.1443 - val_loss: 83.9042 - val_accuracy: 0.2444\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.8734 - accuracy: 0.1517 - val_loss: 83.7639 - val_accuracy: 0.1778\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.7292 - accuracy: 0.1642 - val_loss: 83.6212 - val_accuracy: 0.2000\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.5851 - accuracy: 0.2015 - val_loss: 83.4822 - val_accuracy: 0.1333\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.4418 - accuracy: 0.1741 - val_loss: 83.3447 - val_accuracy: 0.1111\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3010 - accuracy: 0.1517 - val_loss: 83.2101 - val_accuracy: 0.1111\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.1611 - accuracy: 0.1517 - val_loss: 83.0707 - val_accuracy: 0.1111\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.0215 - accuracy: 0.1567 - val_loss: 82.9202 - val_accuracy: 0.2222\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.8829 - accuracy: 0.1542 - val_loss: 82.7685 - val_accuracy: 0.2222\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.7455 - accuracy: 0.1418 - val_loss: 82.6222 - val_accuracy: 0.2222\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.6108 - accuracy: 0.1418 - val_loss: 82.4873 - val_accuracy: 0.2222\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.4733 - accuracy: 0.1418 - val_loss: 82.3564 - val_accuracy: 0.2222\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.3363 - accuracy: 0.1418 - val_loss: 82.2285 - val_accuracy: 0.1778\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.2014 - accuracy: 0.1517 - val_loss: 82.0956 - val_accuracy: 0.1778\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 82.0667 - accuracy: 0.1517 - val_loss: 81.9689 - val_accuracy: 0.2000\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.9325 - accuracy: 0.1642 - val_loss: 81.8410 - val_accuracy: 0.2222\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.8010 - accuracy: 0.1542 - val_loss: 81.7079 - val_accuracy: 0.2222\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.6690 - accuracy: 0.1542 - val_loss: 81.5720 - val_accuracy: 0.2222\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.5373 - accuracy: 0.1542 - val_loss: 81.4389 - val_accuracy: 0.2222\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 81.4060 - accuracy: 0.1542 - val_loss: 81.3113 - val_accuracy: 0.2222\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.2767 - accuracy: 0.1542 - val_loss: 81.1853 - val_accuracy: 0.2222\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.1468 - accuracy: 0.1542 - val_loss: 81.0566 - val_accuracy: 0.2222\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.0194 - accuracy: 0.1567 - val_loss: 80.9288 - val_accuracy: 0.2444\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.8915 - accuracy: 0.1517 - val_loss: 80.8013 - val_accuracy: 0.2222\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 80.7630 - accuracy: 0.1567 - val_loss: 80.6747 - val_accuracy: 0.2222\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.6370 - accuracy: 0.1542 - val_loss: 80.5506 - val_accuracy: 0.2222\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.5107 - accuracy: 0.1542 - val_loss: 80.4278 - val_accuracy: 0.2222\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.3849 - accuracy: 0.1517 - val_loss: 80.3061 - val_accuracy: 0.1778\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.2599 - accuracy: 0.1418 - val_loss: 80.1791 - val_accuracy: 0.2000\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1345 - accuracy: 0.1592 - val_loss: 80.0408 - val_accuracy: 0.2444\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.0104 - accuracy: 0.1592 - val_loss: 79.9151 - val_accuracy: 0.1778\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79.8880 - accuracy: 0.1517 - val_loss: 79.7903 - val_accuracy: 0.1778\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.7663 - accuracy: 0.1517 - val_loss: 79.6701 - val_accuracy: 0.1778\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6433 - accuracy: 0.1517 - val_loss: 79.5481 - val_accuracy: 0.1778\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.5218 - accuracy: 0.1517 - val_loss: 79.4184 - val_accuracy: 0.1778\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.4006 - accuracy: 0.1318 - val_loss: 79.2998 - val_accuracy: 0.2222\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79.2778 - accuracy: 0.1418 - val_loss: 79.1892 - val_accuracy: 0.2222\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.1576 - accuracy: 0.1667 - val_loss: 79.0775 - val_accuracy: 0.1111\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0394 - accuracy: 0.1468 - val_loss: 78.9585 - val_accuracy: 0.0667\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.9194 - accuracy: 0.1617 - val_loss: 78.8317 - val_accuracy: 0.0667\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.8000 - accuracy: 0.2015 - val_loss: 78.7107 - val_accuracy: 0.1778\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.6816 - accuracy: 0.1692 - val_loss: 78.5935 - val_accuracy: 0.1778\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.5638 - accuracy: 0.1741 - val_loss: 78.4726 - val_accuracy: 0.1778\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.4461 - accuracy: 0.1517 - val_loss: 78.3513 - val_accuracy: 0.2222\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 78.3279 - accuracy: 0.1642 - val_loss: 78.2352 - val_accuracy: 0.2222\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.2123 - accuracy: 0.1542 - val_loss: 78.1214 - val_accuracy: 0.2222\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.0976 - accuracy: 0.1642 - val_loss: 78.0133 - val_accuracy: 0.1778\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.9814 - accuracy: 0.1542 - val_loss: 77.9015 - val_accuracy: 0.2222\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.8660 - accuracy: 0.1542 - val_loss: 77.7836 - val_accuracy: 0.2222\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.7495 - accuracy: 0.1542 - val_loss: 77.6675 - val_accuracy: 0.2444\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.6348 - accuracy: 0.1493 - val_loss: 77.5507 - val_accuracy: 0.2222\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5201 - accuracy: 0.1468 - val_loss: 77.4392 - val_accuracy: 0.2667\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 77.4064 - accuracy: 0.1642 - val_loss: 77.3245 - val_accuracy: 0.1111\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.2931 - accuracy: 0.1443 - val_loss: 77.2057 - val_accuracy: 0.1111\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1815 - accuracy: 0.1716 - val_loss: 77.0842 - val_accuracy: 0.2222\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.0681 - accuracy: 0.1542 - val_loss: 76.9768 - val_accuracy: 0.2222\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.9542 - accuracy: 0.1741 - val_loss: 76.8727 - val_accuracy: 0.2000\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.8424 - accuracy: 0.1915 - val_loss: 76.7616 - val_accuracy: 0.2000\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.7307 - accuracy: 0.1940 - val_loss: 76.6460 - val_accuracy: 0.2222\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.6195 - accuracy: 0.1542 - val_loss: 76.5315 - val_accuracy: 0.2222\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.5095 - accuracy: 0.1567 - val_loss: 76.4225 - val_accuracy: 0.2444\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.3990 - accuracy: 0.1493 - val_loss: 76.3167 - val_accuracy: 0.2222\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.2882 - accuracy: 0.1418 - val_loss: 76.2013 - val_accuracy: 0.2222\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.1789 - accuracy: 0.1418 - val_loss: 76.0915 - val_accuracy: 0.2222\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.0698 - accuracy: 0.1418 - val_loss: 75.9841 - val_accuracy: 0.2222\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.9605 - accuracy: 0.1716 - val_loss: 75.8781 - val_accuracy: 0.1778\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8526 - accuracy: 0.1642 - val_loss: 75.7744 - val_accuracy: 0.1111\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7449 - accuracy: 0.1517 - val_loss: 75.6716 - val_accuracy: 0.1111\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.6364 - accuracy: 0.1517 - val_loss: 75.5647 - val_accuracy: 0.1111\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.5276 - accuracy: 0.1592 - val_loss: 75.4534 - val_accuracy: 0.2444\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.4204 - accuracy: 0.1642 - val_loss: 75.3446 - val_accuracy: 0.2222\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.3144 - accuracy: 0.1542 - val_loss: 75.2405 - val_accuracy: 0.2222\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.2072 - accuracy: 0.1542 - val_loss: 75.1303 - val_accuracy: 0.2222\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.1003 - accuracy: 0.1542 - val_loss: 75.0226 - val_accuracy: 0.2222\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.9946 - accuracy: 0.1542 - val_loss: 74.9136 - val_accuracy: 0.2222\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8891 - accuracy: 0.1517 - val_loss: 74.8115 - val_accuracy: 0.1778\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7846 - accuracy: 0.1517 - val_loss: 74.7070 - val_accuracy: 0.2222\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.6778 - accuracy: 0.1617 - val_loss: 74.6047 - val_accuracy: 0.2444\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.5724 - accuracy: 0.1517 - val_loss: 74.5014 - val_accuracy: 0.2444\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.4676 - accuracy: 0.1965 - val_loss: 74.3952 - val_accuracy: 0.1333\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.3628 - accuracy: 0.1741 - val_loss: 74.2874 - val_accuracy: 0.1111\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.2586 - accuracy: 0.1816 - val_loss: 74.1810 - val_accuracy: 0.2444\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74.1553 - accuracy: 0.1891 - val_loss: 74.0790 - val_accuracy: 0.2222\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.0527 - accuracy: 0.1642 - val_loss: 73.9755 - val_accuracy: 0.2222\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.9484 - accuracy: 0.1741 - val_loss: 73.8780 - val_accuracy: 0.2222\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.8455 - accuracy: 0.1542 - val_loss: 73.7735 - val_accuracy: 0.2222\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.7432 - accuracy: 0.1542 - val_loss: 73.6703 - val_accuracy: 0.2222\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73.6404 - accuracy: 0.1542 - val_loss: 73.5688 - val_accuracy: 0.2222\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.5385 - accuracy: 0.1542 - val_loss: 73.4688 - val_accuracy: 0.2222\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4373 - accuracy: 0.1716 - val_loss: 73.3662 - val_accuracy: 0.2444\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3351 - accuracy: 0.1965 - val_loss: 73.2623 - val_accuracy: 0.1556\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.2337 - accuracy: 0.2065 - val_loss: 73.1583 - val_accuracy: 0.1778\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.1333 - accuracy: 0.1642 - val_loss: 73.0596 - val_accuracy: 0.1111\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.0320 - accuracy: 0.1468 - val_loss: 72.9614 - val_accuracy: 0.1111\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.9322 - accuracy: 0.1517 - val_loss: 72.8606 - val_accuracy: 0.1111\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.8326 - accuracy: 0.1517 - val_loss: 72.7638 - val_accuracy: 0.1111\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.7316 - accuracy: 0.1766 - val_loss: 72.6571 - val_accuracy: 0.2222\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.6313 - accuracy: 0.1542 - val_loss: 72.5518 - val_accuracy: 0.2222\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5331 - accuracy: 0.1517 - val_loss: 72.4447 - val_accuracy: 0.2444\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.4329 - accuracy: 0.1667 - val_loss: 72.3471 - val_accuracy: 0.2222\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.3339 - accuracy: 0.1542 - val_loss: 72.2514 - val_accuracy: 0.2222\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.2353 - accuracy: 0.1542 - val_loss: 72.1584 - val_accuracy: 0.2222\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 72.1370 - accuracy: 0.1542 - val_loss: 72.0616 - val_accuracy: 0.2222\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.0377 - accuracy: 0.1542 - val_loss: 71.9635 - val_accuracy: 0.2222\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.9394 - accuracy: 0.1542 - val_loss: 71.8690 - val_accuracy: 0.2222\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 71.8422 - accuracy: 0.1318 - val_loss: 71.7753 - val_accuracy: 0.2222\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.7461 - accuracy: 0.1517 - val_loss: 71.6824 - val_accuracy: 0.2222\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.6509 - accuracy: 0.1542 - val_loss: 71.5850 - val_accuracy: 0.2222\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.5529 - accuracy: 0.1542 - val_loss: 71.4832 - val_accuracy: 0.2222\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.4531 - accuracy: 0.1542 - val_loss: 71.3825 - val_accuracy: 0.2222\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.3571 - accuracy: 0.1443 - val_loss: 71.2829 - val_accuracy: 0.2222\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.2602 - accuracy: 0.1418 - val_loss: 71.1831 - val_accuracy: 0.2444\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1646 - accuracy: 0.1617 - val_loss: 71.0846 - val_accuracy: 0.2222\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.0688 - accuracy: 0.1542 - val_loss: 70.9895 - val_accuracy: 0.1778\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.9727 - accuracy: 0.1493 - val_loss: 70.9056 - val_accuracy: 0.0667\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.8766 - accuracy: 0.1642 - val_loss: 70.8132 - val_accuracy: 0.1333\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70.7813 - accuracy: 0.1990 - val_loss: 70.7176 - val_accuracy: 0.2000\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.6863 - accuracy: 0.1642 - val_loss: 70.6193 - val_accuracy: 0.1778\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.5903 - accuracy: 0.1667 - val_loss: 70.5204 - val_accuracy: 0.2444\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.4948 - accuracy: 0.2065 - val_loss: 70.4227 - val_accuracy: 0.2000\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.4014 - accuracy: 0.1741 - val_loss: 70.3256 - val_accuracy: 0.1778\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.3068 - accuracy: 0.1692 - val_loss: 70.2335 - val_accuracy: 0.1778\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.2129 - accuracy: 0.1716 - val_loss: 70.1399 - val_accuracy: 0.2000\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.1192 - accuracy: 0.1766 - val_loss: 70.0465 - val_accuracy: 0.1778\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0248 - accuracy: 0.1816 - val_loss: 69.9561 - val_accuracy: 0.1556\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.9310 - accuracy: 0.1816 - val_loss: 69.8665 - val_accuracy: 0.0667\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.8375 - accuracy: 0.1766 - val_loss: 69.7757 - val_accuracy: 0.1111\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.7457 - accuracy: 0.1517 - val_loss: 69.6846 - val_accuracy: 0.1556\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.6517 - accuracy: 0.1891 - val_loss: 69.5872 - val_accuracy: 0.2222\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.5590 - accuracy: 0.1642 - val_loss: 69.4928 - val_accuracy: 0.2444\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4674 - accuracy: 0.1642 - val_loss: 69.4020 - val_accuracy: 0.1111\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.3738 - accuracy: 0.1517 - val_loss: 69.3110 - val_accuracy: 0.1111\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.2820 - accuracy: 0.1517 - val_loss: 69.2210 - val_accuracy: 0.1111\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69.1903 - accuracy: 0.1517 - val_loss: 69.1255 - val_accuracy: 0.1111\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.0982 - accuracy: 0.1692 - val_loss: 69.0325 - val_accuracy: 0.1333\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.0066 - accuracy: 0.1766 - val_loss: 68.9438 - val_accuracy: 0.1111\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.9151 - accuracy: 0.1766 - val_loss: 68.8501 - val_accuracy: 0.2444\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.8235 - accuracy: 0.1990 - val_loss: 68.7580 - val_accuracy: 0.2444\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.7322 - accuracy: 0.1915 - val_loss: 68.6666 - val_accuracy: 0.2222\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.6414 - accuracy: 0.1592 - val_loss: 68.5749 - val_accuracy: 0.2222\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.5502 - accuracy: 0.1542 - val_loss: 68.4822 - val_accuracy: 0.2222\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.4606 - accuracy: 0.1542 - val_loss: 68.3919 - val_accuracy: 0.2222\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.3693 - accuracy: 0.1542 - val_loss: 68.3045 - val_accuracy: 0.2222\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.2790 - accuracy: 0.1567 - val_loss: 68.2147 - val_accuracy: 0.2222\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.1899 - accuracy: 0.1567 - val_loss: 68.1275 - val_accuracy: 0.2222\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.1002 - accuracy: 0.1866 - val_loss: 68.0415 - val_accuracy: 0.2222\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.0109 - accuracy: 0.1692 - val_loss: 67.9496 - val_accuracy: 0.2222\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9210 - accuracy: 0.1542 - val_loss: 67.8583 - val_accuracy: 0.2222\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.8315 - accuracy: 0.1617 - val_loss: 67.7670 - val_accuracy: 0.1778\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.7423 - accuracy: 0.1642 - val_loss: 67.6733 - val_accuracy: 0.1778\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6536 - accuracy: 0.1517 - val_loss: 67.5803 - val_accuracy: 0.2222\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.5653 - accuracy: 0.1542 - val_loss: 67.4905 - val_accuracy: 0.2222\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.4773 - accuracy: 0.1542 - val_loss: 67.4026 - val_accuracy: 0.2222\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.3895 - accuracy: 0.1542 - val_loss: 67.3233 - val_accuracy: 0.2222\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.3005 - accuracy: 0.1816 - val_loss: 67.2359 - val_accuracy: 0.2000\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.2123 - accuracy: 0.1642 - val_loss: 67.1454 - val_accuracy: 0.1111\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.1238 - accuracy: 0.1741 - val_loss: 67.0529 - val_accuracy: 0.2444\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.0354 - accuracy: 0.2015 - val_loss: 66.9648 - val_accuracy: 0.2222\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.9475 - accuracy: 0.1716 - val_loss: 66.8766 - val_accuracy: 0.2444\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8600 - accuracy: 0.1692 - val_loss: 66.7905 - val_accuracy: 0.2444\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.7731 - accuracy: 0.1617 - val_loss: 66.7075 - val_accuracy: 0.2222\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.6862 - accuracy: 0.1542 - val_loss: 66.6208 - val_accuracy: 0.2222\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5992 - accuracy: 0.1542 - val_loss: 66.5326 - val_accuracy: 0.2222\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.5117 - accuracy: 0.1542 - val_loss: 66.4475 - val_accuracy: 0.2222\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.4251 - accuracy: 0.1542 - val_loss: 66.3588 - val_accuracy: 0.2222\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3384 - accuracy: 0.1542 - val_loss: 66.2725 - val_accuracy: 0.2222\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.2521 - accuracy: 0.1542 - val_loss: 66.1901 - val_accuracy: 0.2444\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.1658 - accuracy: 0.1915 - val_loss: 66.1029 - val_accuracy: 0.1111\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.0792 - accuracy: 0.1517 - val_loss: 66.0161 - val_accuracy: 0.1111\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.9939 - accuracy: 0.1517 - val_loss: 65.9294 - val_accuracy: 0.1111\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.9081 - accuracy: 0.1493 - val_loss: 65.8451 - val_accuracy: 0.1111\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.8228 - accuracy: 0.1567 - val_loss: 65.7629 - val_accuracy: 0.1111\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7374 - accuracy: 0.1642 - val_loss: 65.6731 - val_accuracy: 0.2222\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.6518 - accuracy: 0.1567 - val_loss: 65.5850 - val_accuracy: 0.2444\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.5663 - accuracy: 0.1493 - val_loss: 65.5005 - val_accuracy: 0.2222\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.4820 - accuracy: 0.1468 - val_loss: 65.4164 - val_accuracy: 0.2444\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.3969 - accuracy: 0.1741 - val_loss: 65.3290 - val_accuracy: 0.2444\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.3117 - accuracy: 0.1667 - val_loss: 65.2414 - val_accuracy: 0.2444\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.2278 - accuracy: 0.1667 - val_loss: 65.1603 - val_accuracy: 0.1778\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.1433 - accuracy: 0.1642 - val_loss: 65.0756 - val_accuracy: 0.1778\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0584 - accuracy: 0.1667 - val_loss: 64.9888 - val_accuracy: 0.2222\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.9739 - accuracy: 0.1418 - val_loss: 64.9062 - val_accuracy: 0.2222\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.8900 - accuracy: 0.1542 - val_loss: 64.8214 - val_accuracy: 0.2444\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.8058 - accuracy: 0.1716 - val_loss: 64.7363 - val_accuracy: 0.2444\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.7219 - accuracy: 0.1791 - val_loss: 64.6529 - val_accuracy: 0.2000\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.6382 - accuracy: 0.1841 - val_loss: 64.5734 - val_accuracy: 0.2000\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.5551 - accuracy: 0.1692 - val_loss: 64.4946 - val_accuracy: 0.1778\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.4713 - accuracy: 0.1642 - val_loss: 64.4105 - val_accuracy: 0.1778\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.3882 - accuracy: 0.1642 - val_loss: 64.3307 - val_accuracy: 0.2222\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.3051 - accuracy: 0.1667 - val_loss: 64.2521 - val_accuracy: 0.2444\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.2227 - accuracy: 0.1741 - val_loss: 64.1668 - val_accuracy: 0.2222\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.1399 - accuracy: 0.1542 - val_loss: 64.0801 - val_accuracy: 0.2222\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.0570 - accuracy: 0.1542 - val_loss: 63.9880 - val_accuracy: 0.2222\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.9745 - accuracy: 0.1542 - val_loss: 63.9033 - val_accuracy: 0.2222\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.8918 - accuracy: 0.1542 - val_loss: 63.8185 - val_accuracy: 0.2222\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63.8100 - accuracy: 0.1542 - val_loss: 63.7384 - val_accuracy: 0.2222\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.7274 - accuracy: 0.1617 - val_loss: 63.6659 - val_accuracy: 0.1778\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.6456 - accuracy: 0.1741 - val_loss: 63.5964 - val_accuracy: 0.0667\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.5650 - accuracy: 0.1617 - val_loss: 63.5177 - val_accuracy: 0.0667\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4827 - accuracy: 0.1617 - val_loss: 63.4331 - val_accuracy: 0.0667\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.4009 - accuracy: 0.1617 - val_loss: 63.3462 - val_accuracy: 0.1778\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3178 - accuracy: 0.1766 - val_loss: 63.2598 - val_accuracy: 0.2222\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63.2371 - accuracy: 0.1642 - val_loss: 63.1760 - val_accuracy: 0.2222\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.1563 - accuracy: 0.1592 - val_loss: 63.0929 - val_accuracy: 0.2222\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.0740 - accuracy: 0.1542 - val_loss: 63.0145 - val_accuracy: 0.1778\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.9930 - accuracy: 0.1493 - val_loss: 62.9344 - val_accuracy: 0.1778\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9123 - accuracy: 0.1642 - val_loss: 62.8577 - val_accuracy: 0.1778\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.8320 - accuracy: 0.1517 - val_loss: 62.7771 - val_accuracy: 0.2222\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.7520 - accuracy: 0.1542 - val_loss: 62.6915 - val_accuracy: 0.2222\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.6733 - accuracy: 0.1343 - val_loss: 62.6010 - val_accuracy: 0.2222\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.5923 - accuracy: 0.1418 - val_loss: 62.5186 - val_accuracy: 0.2222\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.5101 - accuracy: 0.1418 - val_loss: 62.4433 - val_accuracy: 0.2444\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62.4293 - accuracy: 0.1667 - val_loss: 62.3673 - val_accuracy: 0.1778\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.3503 - accuracy: 0.1642 - val_loss: 62.2861 - val_accuracy: 0.1778\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.2705 - accuracy: 0.1642 - val_loss: 62.2086 - val_accuracy: 0.1778\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1907 - accuracy: 0.1642 - val_loss: 62.1274 - val_accuracy: 0.1778\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.1106 - accuracy: 0.1493 - val_loss: 62.0491 - val_accuracy: 0.2222\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62.0301 - accuracy: 0.1841 - val_loss: 61.9744 - val_accuracy: 0.2222\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9508 - accuracy: 0.1940 - val_loss: 61.9001 - val_accuracy: 0.2000\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8717 - accuracy: 0.1891 - val_loss: 61.8192 - val_accuracy: 0.2222\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7927 - accuracy: 0.1542 - val_loss: 61.7375 - val_accuracy: 0.2222\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.7140 - accuracy: 0.1542 - val_loss: 61.6541 - val_accuracy: 0.2222\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.6338 - accuracy: 0.1542 - val_loss: 61.5780 - val_accuracy: 0.2444\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.5551 - accuracy: 0.1766 - val_loss: 61.5008 - val_accuracy: 0.1111\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.4760 - accuracy: 0.1642 - val_loss: 61.4204 - val_accuracy: 0.1111\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.3986 - accuracy: 0.1940 - val_loss: 61.3429 - val_accuracy: 0.2000\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.3206 - accuracy: 0.2139 - val_loss: 61.2695 - val_accuracy: 0.1556\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2428 - accuracy: 0.1766 - val_loss: 61.1944 - val_accuracy: 0.0667\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.1641 - accuracy: 0.1617 - val_loss: 61.1152 - val_accuracy: 0.0667\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0858 - accuracy: 0.1418 - val_loss: 61.0332 - val_accuracy: 0.1111\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0059 - accuracy: 0.1692 - val_loss: 60.9485 - val_accuracy: 0.2444\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.9280 - accuracy: 0.1592 - val_loss: 60.8644 - val_accuracy: 0.2444\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.8502 - accuracy: 0.1667 - val_loss: 60.7813 - val_accuracy: 0.2444\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.7727 - accuracy: 0.1692 - val_loss: 60.7058 - val_accuracy: 0.2444\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.6950 - accuracy: 0.1592 - val_loss: 60.6336 - val_accuracy: 0.2222\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.6174 - accuracy: 0.1542 - val_loss: 60.5617 - val_accuracy: 0.2444\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5400 - accuracy: 0.1692 - val_loss: 60.4890 - val_accuracy: 0.1111\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.4626 - accuracy: 0.1517 - val_loss: 60.4096 - val_accuracy: 0.1778\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.3853 - accuracy: 0.1791 - val_loss: 60.3281 - val_accuracy: 0.2222\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3082 - accuracy: 0.1542 - val_loss: 60.2524 - val_accuracy: 0.2444\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.2316 - accuracy: 0.1915 - val_loss: 60.1793 - val_accuracy: 0.2000\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.1544 - accuracy: 0.2065 - val_loss: 60.1045 - val_accuracy: 0.2000\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.0780 - accuracy: 0.2065 - val_loss: 60.0314 - val_accuracy: 0.1333\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.0007 - accuracy: 0.2090 - val_loss: 59.9496 - val_accuracy: 0.2000\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.9242 - accuracy: 0.2139 - val_loss: 59.8729 - val_accuracy: 0.2000\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8478 - accuracy: 0.2114 - val_loss: 59.7977 - val_accuracy: 0.1778\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.7715 - accuracy: 0.1915 - val_loss: 59.7234 - val_accuracy: 0.0667\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.6954 - accuracy: 0.1816 - val_loss: 59.6457 - val_accuracy: 0.1778\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.6194 - accuracy: 0.1965 - val_loss: 59.5650 - val_accuracy: 0.2222\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.5430 - accuracy: 0.1592 - val_loss: 59.4837 - val_accuracy: 0.2222\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59.4680 - accuracy: 0.1592 - val_loss: 59.4016 - val_accuracy: 0.2222\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.3913 - accuracy: 0.1642 - val_loss: 59.3237 - val_accuracy: 0.2222\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.3164 - accuracy: 0.1393 - val_loss: 59.2507 - val_accuracy: 0.2222\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2405 - accuracy: 0.1418 - val_loss: 59.1788 - val_accuracy: 0.2444\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1651 - accuracy: 0.1592 - val_loss: 59.1150 - val_accuracy: 0.2444\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0889 - accuracy: 0.1866 - val_loss: 59.0457 - val_accuracy: 0.1111\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0136 - accuracy: 0.1667 - val_loss: 58.9685 - val_accuracy: 0.0667\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.9395 - accuracy: 0.1841 - val_loss: 58.8867 - val_accuracy: 0.1556\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.8637 - accuracy: 0.2164 - val_loss: 58.8042 - val_accuracy: 0.1778\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.7889 - accuracy: 0.1592 - val_loss: 58.7244 - val_accuracy: 0.2222\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.7140 - accuracy: 0.1542 - val_loss: 58.6475 - val_accuracy: 0.2222\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.6382 - accuracy: 0.1542 - val_loss: 58.5738 - val_accuracy: 0.2222\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5644 - accuracy: 0.1542 - val_loss: 58.4994 - val_accuracy: 0.2222\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.4884 - accuracy: 0.1542 - val_loss: 58.4221 - val_accuracy: 0.2222\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.4142 - accuracy: 0.1741 - val_loss: 58.3429 - val_accuracy: 0.1778\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.3395 - accuracy: 0.1517 - val_loss: 58.2693 - val_accuracy: 0.1778\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2662 - accuracy: 0.1517 - val_loss: 58.2016 - val_accuracy: 0.1778\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1921 - accuracy: 0.1692 - val_loss: 58.1322 - val_accuracy: 0.2667\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.1173 - accuracy: 0.2065 - val_loss: 58.0547 - val_accuracy: 0.2222\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.0433 - accuracy: 0.1418 - val_loss: 57.9811 - val_accuracy: 0.2222\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.9692 - accuracy: 0.1418 - val_loss: 57.9079 - val_accuracy: 0.2444\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.8951 - accuracy: 0.1667 - val_loss: 57.8319 - val_accuracy: 0.2444\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.8220 - accuracy: 0.1542 - val_loss: 57.7627 - val_accuracy: 0.2444\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7478 - accuracy: 0.1766 - val_loss: 57.6917 - val_accuracy: 0.1333\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.6740 - accuracy: 0.1891 - val_loss: 57.6140 - val_accuracy: 0.2222\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6004 - accuracy: 0.1542 - val_loss: 57.5413 - val_accuracy: 0.2222\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.5260 - accuracy: 0.1542 - val_loss: 57.4670 - val_accuracy: 0.2222\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.4533 - accuracy: 0.1542 - val_loss: 57.3949 - val_accuracy: 0.2222\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3802 - accuracy: 0.1542 - val_loss: 57.3175 - val_accuracy: 0.2222\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3075 - accuracy: 0.1542 - val_loss: 57.2441 - val_accuracy: 0.2222\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.2341 - accuracy: 0.1542 - val_loss: 57.1772 - val_accuracy: 0.2000\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.1609 - accuracy: 0.1965 - val_loss: 57.1054 - val_accuracy: 0.2444\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0883 - accuracy: 0.2363 - val_loss: 57.0293 - val_accuracy: 0.2000\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0160 - accuracy: 0.1791 - val_loss: 56.9544 - val_accuracy: 0.1778\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9434 - accuracy: 0.1667 - val_loss: 56.8841 - val_accuracy: 0.2000\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.8710 - accuracy: 0.1841 - val_loss: 56.8113 - val_accuracy: 0.1778\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7987 - accuracy: 0.1667 - val_loss: 56.7356 - val_accuracy: 0.1778\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.7258 - accuracy: 0.1617 - val_loss: 56.6651 - val_accuracy: 0.1778\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.6528 - accuracy: 0.1915 - val_loss: 56.5954 - val_accuracy: 0.2000\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5801 - accuracy: 0.2164 - val_loss: 56.5262 - val_accuracy: 0.1778\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5080 - accuracy: 0.1915 - val_loss: 56.4537 - val_accuracy: 0.2444\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.4362 - accuracy: 0.1567 - val_loss: 56.3809 - val_accuracy: 0.2222\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.3648 - accuracy: 0.1542 - val_loss: 56.3051 - val_accuracy: 0.2222\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.2926 - accuracy: 0.1542 - val_loss: 56.2329 - val_accuracy: 0.2222\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.2205 - accuracy: 0.1542 - val_loss: 56.1616 - val_accuracy: 0.2222\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.1487 - accuracy: 0.1617 - val_loss: 56.0938 - val_accuracy: 0.2000\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0771 - accuracy: 0.1716 - val_loss: 56.0190 - val_accuracy: 0.2000\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.0049 - accuracy: 0.1741 - val_loss: 55.9458 - val_accuracy: 0.2444\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.9339 - accuracy: 0.1617 - val_loss: 55.8731 - val_accuracy: 0.2222\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.8628 - accuracy: 0.1542 - val_loss: 55.8004 - val_accuracy: 0.2222\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.7924 - accuracy: 0.1542 - val_loss: 55.7322 - val_accuracy: 0.2222\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.7211 - accuracy: 0.1542 - val_loss: 55.6669 - val_accuracy: 0.2222\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6490 - accuracy: 0.1567 - val_loss: 55.6001 - val_accuracy: 0.2444\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5773 - accuracy: 0.2040 - val_loss: 55.5294 - val_accuracy: 0.2222\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5068 - accuracy: 0.1741 - val_loss: 55.4623 - val_accuracy: 0.0667\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4361 - accuracy: 0.1642 - val_loss: 55.3888 - val_accuracy: 0.1333\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.3649 - accuracy: 0.1940 - val_loss: 55.3100 - val_accuracy: 0.2000\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2945 - accuracy: 0.1617 - val_loss: 55.2325 - val_accuracy: 0.2222\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2238 - accuracy: 0.1667 - val_loss: 55.1665 - val_accuracy: 0.2000\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.1526 - accuracy: 0.1866 - val_loss: 55.1024 - val_accuracy: 0.2000\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0832 - accuracy: 0.2189 - val_loss: 55.0359 - val_accuracy: 0.1778\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.0127 - accuracy: 0.2114 - val_loss: 54.9650 - val_accuracy: 0.1333\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 54.9418 - accuracy: 0.1841 - val_loss: 54.8922 - val_accuracy: 0.1111\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8719 - accuracy: 0.1517 - val_loss: 54.8223 - val_accuracy: 0.1111\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8022 - accuracy: 0.1741 - val_loss: 54.7486 - val_accuracy: 0.2444\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.7326 - accuracy: 0.1965 - val_loss: 54.6762 - val_accuracy: 0.2222\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.6615 - accuracy: 0.2015 - val_loss: 54.6059 - val_accuracy: 0.2444\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.5915 - accuracy: 0.1965 - val_loss: 54.5386 - val_accuracy: 0.1556\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5219 - accuracy: 0.1940 - val_loss: 54.4696 - val_accuracy: 0.2444\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.4522 - accuracy: 0.1990 - val_loss: 54.4036 - val_accuracy: 0.1556\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.3824 - accuracy: 0.1667 - val_loss: 54.3330 - val_accuracy: 0.1111\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3130 - accuracy: 0.1592 - val_loss: 54.2637 - val_accuracy: 0.1333\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.2439 - accuracy: 0.1766 - val_loss: 54.1939 - val_accuracy: 0.1111\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1748 - accuracy: 0.1617 - val_loss: 54.1190 - val_accuracy: 0.1111\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1059 - accuracy: 0.1667 - val_loss: 54.0476 - val_accuracy: 0.2222\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0359 - accuracy: 0.2090 - val_loss: 53.9779 - val_accuracy: 0.2667\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.9668 - accuracy: 0.1667 - val_loss: 53.9037 - val_accuracy: 0.2222\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.8979 - accuracy: 0.1418 - val_loss: 53.8337 - val_accuracy: 0.2222\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.8294 - accuracy: 0.1343 - val_loss: 53.7724 - val_accuracy: 0.1778\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.7603 - accuracy: 0.1517 - val_loss: 53.7081 - val_accuracy: 0.2000\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.6916 - accuracy: 0.2114 - val_loss: 53.6409 - val_accuracy: 0.1778\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.6215 - accuracy: 0.2015 - val_loss: 53.5707 - val_accuracy: 0.2222\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.5528 - accuracy: 0.2015 - val_loss: 53.5003 - val_accuracy: 0.2444\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.4847 - accuracy: 0.1866 - val_loss: 53.4307 - val_accuracy: 0.2222\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.4164 - accuracy: 0.1542 - val_loss: 53.3584 - val_accuracy: 0.2444\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.3478 - accuracy: 0.1667 - val_loss: 53.2875 - val_accuracy: 0.2222\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2796 - accuracy: 0.1418 - val_loss: 53.2155 - val_accuracy: 0.2222\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2110 - accuracy: 0.1418 - val_loss: 53.1463 - val_accuracy: 0.2222\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1428 - accuracy: 0.1418 - val_loss: 53.0793 - val_accuracy: 0.1778\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0744 - accuracy: 0.1443 - val_loss: 53.0168 - val_accuracy: 0.2222\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53.0063 - accuracy: 0.1667 - val_loss: 52.9557 - val_accuracy: 0.1111\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.9390 - accuracy: 0.1517 - val_loss: 52.8917 - val_accuracy: 0.1111\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.8705 - accuracy: 0.1517 - val_loss: 52.8253 - val_accuracy: 0.1111\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.8027 - accuracy: 0.1592 - val_loss: 52.7525 - val_accuracy: 0.1333\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7343 - accuracy: 0.1667 - val_loss: 52.6865 - val_accuracy: 0.0889\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6675 - accuracy: 0.2015 - val_loss: 52.6160 - val_accuracy: 0.2000\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.6008 - accuracy: 0.1766 - val_loss: 52.5444 - val_accuracy: 0.1778\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.5328 - accuracy: 0.1692 - val_loss: 52.4812 - val_accuracy: 0.1778\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52.4648 - accuracy: 0.1741 - val_loss: 52.4152 - val_accuracy: 0.1778\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.3974 - accuracy: 0.1891 - val_loss: 52.3511 - val_accuracy: 0.2222\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3303 - accuracy: 0.2065 - val_loss: 52.2823 - val_accuracy: 0.1778\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.2633 - accuracy: 0.1766 - val_loss: 52.2134 - val_accuracy: 0.2000\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.1964 - accuracy: 0.1866 - val_loss: 52.1447 - val_accuracy: 0.2000\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.1291 - accuracy: 0.1493 - val_loss: 52.0787 - val_accuracy: 0.2222\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.0617 - accuracy: 0.1542 - val_loss: 52.0103 - val_accuracy: 0.2222\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.9945 - accuracy: 0.1542 - val_loss: 51.9375 - val_accuracy: 0.2444\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.9269 - accuracy: 0.1716 - val_loss: 51.8665 - val_accuracy: 0.2444\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.8602 - accuracy: 0.1667 - val_loss: 51.8029 - val_accuracy: 0.1778\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.7943 - accuracy: 0.1965 - val_loss: 51.7440 - val_accuracy: 0.0889\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7287 - accuracy: 0.1990 - val_loss: 51.6880 - val_accuracy: 0.0667\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.6619 - accuracy: 0.1418 - val_loss: 51.6238 - val_accuracy: 0.1111\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51.5949 - accuracy: 0.1443 - val_loss: 51.5560 - val_accuracy: 0.1333\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.5278 - accuracy: 0.1816 - val_loss: 51.4839 - val_accuracy: 0.1556\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.4620 - accuracy: 0.1816 - val_loss: 51.4145 - val_accuracy: 0.2222\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.3953 - accuracy: 0.1542 - val_loss: 51.3509 - val_accuracy: 0.2222\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51.3296 - accuracy: 0.1741 - val_loss: 51.2879 - val_accuracy: 0.2444\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.2631 - accuracy: 0.2040 - val_loss: 51.2203 - val_accuracy: 0.2444\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1972 - accuracy: 0.2040 - val_loss: 51.1506 - val_accuracy: 0.2444\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51.1312 - accuracy: 0.2040 - val_loss: 51.0834 - val_accuracy: 0.2444\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.0651 - accuracy: 0.1667 - val_loss: 51.0143 - val_accuracy: 0.2222\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.9982 - accuracy: 0.1741 - val_loss: 50.9524 - val_accuracy: 0.2444\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9321 - accuracy: 0.1766 - val_loss: 50.8832 - val_accuracy: 0.2222\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.8669 - accuracy: 0.1542 - val_loss: 50.8151 - val_accuracy: 0.2222\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8017 - accuracy: 0.1592 - val_loss: 50.7483 - val_accuracy: 0.2444\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.7364 - accuracy: 0.1542 - val_loss: 50.6827 - val_accuracy: 0.2222\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6703 - accuracy: 0.1418 - val_loss: 50.6153 - val_accuracy: 0.2222\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50.6052 - accuracy: 0.1493 - val_loss: 50.5513 - val_accuracy: 0.2444\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.5394 - accuracy: 0.2065 - val_loss: 50.4910 - val_accuracy: 0.1556\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.4734 - accuracy: 0.1716 - val_loss: 50.4290 - val_accuracy: 0.0667\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4088 - accuracy: 0.1716 - val_loss: 50.3621 - val_accuracy: 0.0889\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.3434 - accuracy: 0.2015 - val_loss: 50.2925 - val_accuracy: 0.2000\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.2784 - accuracy: 0.1791 - val_loss: 50.2263 - val_accuracy: 0.2000\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.2133 - accuracy: 0.1791 - val_loss: 50.1602 - val_accuracy: 0.2000\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.1488 - accuracy: 0.1642 - val_loss: 50.0971 - val_accuracy: 0.1778\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.0839 - accuracy: 0.1493 - val_loss: 50.0327 - val_accuracy: 0.2222\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.0187 - accuracy: 0.1567 - val_loss: 49.9669 - val_accuracy: 0.1778\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.9549 - accuracy: 0.1866 - val_loss: 49.9058 - val_accuracy: 0.0667\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8899 - accuracy: 0.1567 - val_loss: 49.8453 - val_accuracy: 0.0889\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.8246 - accuracy: 0.1716 - val_loss: 49.7822 - val_accuracy: 0.1333\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49.7605 - accuracy: 0.1841 - val_loss: 49.7242 - val_accuracy: 0.1333\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6968 - accuracy: 0.1940 - val_loss: 49.6665 - val_accuracy: 0.0889\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.6328 - accuracy: 0.2040 - val_loss: 49.5997 - val_accuracy: 0.0889\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.5678 - accuracy: 0.2040 - val_loss: 49.5308 - val_accuracy: 0.1111\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.5035 - accuracy: 0.2040 - val_loss: 49.4614 - val_accuracy: 0.2222\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.4383 - accuracy: 0.1542 - val_loss: 49.3945 - val_accuracy: 0.2222\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3742 - accuracy: 0.1667 - val_loss: 49.3311 - val_accuracy: 0.1778\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3096 - accuracy: 0.1642 - val_loss: 49.2671 - val_accuracy: 0.1778\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.2462 - accuracy: 0.1443 - val_loss: 49.2014 - val_accuracy: 0.1778\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.1822 - accuracy: 0.1642 - val_loss: 49.1374 - val_accuracy: 0.1778\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.1184 - accuracy: 0.1841 - val_loss: 49.0744 - val_accuracy: 0.2000\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0547 - accuracy: 0.1866 - val_loss: 49.0087 - val_accuracy: 0.2222\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9898 - accuracy: 0.1642 - val_loss: 48.9449 - val_accuracy: 0.2222\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9260 - accuracy: 0.1542 - val_loss: 48.8762 - val_accuracy: 0.2222\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.8624 - accuracy: 0.1592 - val_loss: 48.8067 - val_accuracy: 0.2000\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.7990 - accuracy: 0.1791 - val_loss: 48.7479 - val_accuracy: 0.2000\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.7358 - accuracy: 0.1617 - val_loss: 48.6896 - val_accuracy: 0.1778\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6734 - accuracy: 0.1542 - val_loss: 48.6290 - val_accuracy: 0.2444\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6099 - accuracy: 0.2189 - val_loss: 48.5654 - val_accuracy: 0.2000\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5469 - accuracy: 0.2189 - val_loss: 48.4970 - val_accuracy: 0.2000\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4842 - accuracy: 0.1716 - val_loss: 48.4253 - val_accuracy: 0.1778\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4211 - accuracy: 0.1766 - val_loss: 48.3640 - val_accuracy: 0.1778\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.3579 - accuracy: 0.1965 - val_loss: 48.3100 - val_accuracy: 0.1111\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.2946 - accuracy: 0.1741 - val_loss: 48.2551 - val_accuracy: 0.0667\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.2322 - accuracy: 0.1791 - val_loss: 48.1959 - val_accuracy: 0.0889\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1685 - accuracy: 0.1816 - val_loss: 48.1259 - val_accuracy: 0.0667\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1043 - accuracy: 0.1915 - val_loss: 48.0553 - val_accuracy: 0.1778\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0411 - accuracy: 0.1766 - val_loss: 47.9903 - val_accuracy: 0.2222\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.9784 - accuracy: 0.1542 - val_loss: 47.9267 - val_accuracy: 0.2222\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.9155 - accuracy: 0.1816 - val_loss: 47.8709 - val_accuracy: 0.1111\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8531 - accuracy: 0.1592 - val_loss: 47.8142 - val_accuracy: 0.1333\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.7915 - accuracy: 0.1841 - val_loss: 47.7528 - val_accuracy: 0.1111\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.7292 - accuracy: 0.1965 - val_loss: 47.6855 - val_accuracy: 0.0889\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.6665 - accuracy: 0.1766 - val_loss: 47.6179 - val_accuracy: 0.0667\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.6040 - accuracy: 0.1816 - val_loss: 47.5513 - val_accuracy: 0.2222\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.5415 - accuracy: 0.1542 - val_loss: 47.4866 - val_accuracy: 0.2222\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.4798 - accuracy: 0.1542 - val_loss: 47.4274 - val_accuracy: 0.2222\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.4168 - accuracy: 0.1542 - val_loss: 47.3728 - val_accuracy: 0.2222\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.3550 - accuracy: 0.1567 - val_loss: 47.3141 - val_accuracy: 0.2222\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2930 - accuracy: 0.1542 - val_loss: 47.2508 - val_accuracy: 0.2222\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.2311 - accuracy: 0.1542 - val_loss: 47.1824 - val_accuracy: 0.2222\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.1693 - accuracy: 0.1542 - val_loss: 47.1127 - val_accuracy: 0.2222\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1073 - accuracy: 0.1542 - val_loss: 47.0514 - val_accuracy: 0.2222\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0450 - accuracy: 0.1542 - val_loss: 46.9891 - val_accuracy: 0.2444\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.9832 - accuracy: 0.1766 - val_loss: 46.9263 - val_accuracy: 0.2000\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9218 - accuracy: 0.1517 - val_loss: 46.8670 - val_accuracy: 0.2222\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.8603 - accuracy: 0.1542 - val_loss: 46.8096 - val_accuracy: 0.2444\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.7977 - accuracy: 0.1716 - val_loss: 46.7447 - val_accuracy: 0.2444\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.7370 - accuracy: 0.1642 - val_loss: 46.6783 - val_accuracy: 0.2000\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6760 - accuracy: 0.1567 - val_loss: 46.6181 - val_accuracy: 0.1778\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6149 - accuracy: 0.1567 - val_loss: 46.5649 - val_accuracy: 0.2000\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5531 - accuracy: 0.1692 - val_loss: 46.5044 - val_accuracy: 0.2222\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4922 - accuracy: 0.1617 - val_loss: 46.4382 - val_accuracy: 0.2444\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4313 - accuracy: 0.1741 - val_loss: 46.3757 - val_accuracy: 0.2444\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.3695 - accuracy: 0.1766 - val_loss: 46.3177 - val_accuracy: 0.2000\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.3083 - accuracy: 0.1692 - val_loss: 46.2671 - val_accuracy: 0.1778\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2484 - accuracy: 0.1642 - val_loss: 46.2036 - val_accuracy: 0.1778\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.1871 - accuracy: 0.1642 - val_loss: 46.1458 - val_accuracy: 0.1778\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.1265 - accuracy: 0.1692 - val_loss: 46.0864 - val_accuracy: 0.2222\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0649 - accuracy: 0.2313 - val_loss: 46.0266 - val_accuracy: 0.2222\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0041 - accuracy: 0.2363 - val_loss: 45.9631 - val_accuracy: 0.2222\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.9433 - accuracy: 0.1990 - val_loss: 45.9015 - val_accuracy: 0.2667\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8826 - accuracy: 0.1816 - val_loss: 45.8416 - val_accuracy: 0.2444\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8218 - accuracy: 0.1866 - val_loss: 45.7787 - val_accuracy: 0.2222\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.7618 - accuracy: 0.1692 - val_loss: 45.7181 - val_accuracy: 0.2222\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7021 - accuracy: 0.1667 - val_loss: 45.6587 - val_accuracy: 0.2000\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.6428 - accuracy: 0.1368 - val_loss: 45.6030 - val_accuracy: 0.1333\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5826 - accuracy: 0.1766 - val_loss: 45.5473 - val_accuracy: 0.1111\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5214 - accuracy: 0.1667 - val_loss: 45.4853 - val_accuracy: 0.1111\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.4598 - accuracy: 0.1592 - val_loss: 45.4227 - val_accuracy: 0.1333\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.3994 - accuracy: 0.1667 - val_loss: 45.3599 - val_accuracy: 0.2222\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3394 - accuracy: 0.2015 - val_loss: 45.2945 - val_accuracy: 0.2222\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.2791 - accuracy: 0.1542 - val_loss: 45.2306 - val_accuracy: 0.2222\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.2194 - accuracy: 0.1542 - val_loss: 45.1710 - val_accuracy: 0.2222\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1598 - accuracy: 0.1542 - val_loss: 45.1101 - val_accuracy: 0.1778\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.0994 - accuracy: 0.1642 - val_loss: 45.0576 - val_accuracy: 0.2000\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.0398 - accuracy: 0.2015 - val_loss: 45.0030 - val_accuracy: 0.0889\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44.9797 - accuracy: 0.1965 - val_loss: 44.9421 - val_accuracy: 0.1556\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9205 - accuracy: 0.1891 - val_loss: 44.8823 - val_accuracy: 0.1556\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.8610 - accuracy: 0.1915 - val_loss: 44.8180 - val_accuracy: 0.2444\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8013 - accuracy: 0.1642 - val_loss: 44.7529 - val_accuracy: 0.2222\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.7418 - accuracy: 0.1617 - val_loss: 44.6923 - val_accuracy: 0.2000\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44.6816 - accuracy: 0.1716 - val_loss: 44.6297 - val_accuracy: 0.1778\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6226 - accuracy: 0.1766 - val_loss: 44.5725 - val_accuracy: 0.2444\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.5630 - accuracy: 0.1940 - val_loss: 44.5188 - val_accuracy: 0.2444\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.5044 - accuracy: 0.2015 - val_loss: 44.4626 - val_accuracy: 0.2444\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.4450 - accuracy: 0.2015 - val_loss: 44.4034 - val_accuracy: 0.2444\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.3857 - accuracy: 0.1965 - val_loss: 44.3464 - val_accuracy: 0.1333\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.3265 - accuracy: 0.1816 - val_loss: 44.2864 - val_accuracy: 0.2222\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.2673 - accuracy: 0.2015 - val_loss: 44.2245 - val_accuracy: 0.2444\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.2080 - accuracy: 0.2164 - val_loss: 44.1685 - val_accuracy: 0.1556\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.1493 - accuracy: 0.1915 - val_loss: 44.1114 - val_accuracy: 0.1556\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.0906 - accuracy: 0.1915 - val_loss: 44.0559 - val_accuracy: 0.0889\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.0315 - accuracy: 0.1667 - val_loss: 43.9976 - val_accuracy: 0.0667\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.9737 - accuracy: 0.1642 - val_loss: 43.9385 - val_accuracy: 0.1333\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.9143 - accuracy: 0.1965 - val_loss: 43.8768 - val_accuracy: 0.2444\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.8556 - accuracy: 0.1915 - val_loss: 43.8150 - val_accuracy: 0.2222\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.7971 - accuracy: 0.1542 - val_loss: 43.7556 - val_accuracy: 0.2222\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7379 - accuracy: 0.1542 - val_loss: 43.6953 - val_accuracy: 0.2222\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.6796 - accuracy: 0.1667 - val_loss: 43.6388 - val_accuracy: 0.2444\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.6214 - accuracy: 0.2065 - val_loss: 43.5813 - val_accuracy: 0.2222\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.5631 - accuracy: 0.2114 - val_loss: 43.5228 - val_accuracy: 0.1556\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.5044 - accuracy: 0.1990 - val_loss: 43.4612 - val_accuracy: 0.1556\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.4467 - accuracy: 0.1940 - val_loss: 43.3995 - val_accuracy: 0.2444\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.3887 - accuracy: 0.2040 - val_loss: 43.3408 - val_accuracy: 0.2444\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3305 - accuracy: 0.2040 - val_loss: 43.2839 - val_accuracy: 0.2444\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2724 - accuracy: 0.2065 - val_loss: 43.2334 - val_accuracy: 0.1333\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.2142 - accuracy: 0.1940 - val_loss: 43.1728 - val_accuracy: 0.2222\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.1556 - accuracy: 0.2065 - val_loss: 43.1144 - val_accuracy: 0.2444\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0983 - accuracy: 0.2114 - val_loss: 43.0625 - val_accuracy: 0.2444\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.0405 - accuracy: 0.1990 - val_loss: 43.0083 - val_accuracy: 0.1111\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9831 - accuracy: 0.2189 - val_loss: 42.9520 - val_accuracy: 0.1111\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.9246 - accuracy: 0.2189 - val_loss: 42.8904 - val_accuracy: 0.2000\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.8669 - accuracy: 0.2114 - val_loss: 42.8312 - val_accuracy: 0.2000\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.8099 - accuracy: 0.2189 - val_loss: 42.7752 - val_accuracy: 0.2000\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.7530 - accuracy: 0.1891 - val_loss: 42.7159 - val_accuracy: 0.1556\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6945 - accuracy: 0.1592 - val_loss: 42.6509 - val_accuracy: 0.2222\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42.6367 - accuracy: 0.1542 - val_loss: 42.5909 - val_accuracy: 0.2222\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42.5798 - accuracy: 0.1542 - val_loss: 42.5344 - val_accuracy: 0.2222\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5219 - accuracy: 0.1741 - val_loss: 42.4848 - val_accuracy: 0.1778\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4641 - accuracy: 0.1891 - val_loss: 42.4326 - val_accuracy: 0.0889\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42.4074 - accuracy: 0.1791 - val_loss: 42.3778 - val_accuracy: 0.1111\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.3504 - accuracy: 0.1667 - val_loss: 42.3192 - val_accuracy: 0.1333\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.2934 - accuracy: 0.1791 - val_loss: 42.2565 - val_accuracy: 0.1111\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.2358 - accuracy: 0.1567 - val_loss: 42.1956 - val_accuracy: 0.1333\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1790 - accuracy: 0.1940 - val_loss: 42.1333 - val_accuracy: 0.2444\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.1223 - accuracy: 0.1741 - val_loss: 42.0745 - val_accuracy: 0.2222\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0649 - accuracy: 0.1542 - val_loss: 42.0134 - val_accuracy: 0.2222\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.0081 - accuracy: 0.1542 - val_loss: 41.9562 - val_accuracy: 0.2444\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.9509 - accuracy: 0.1766 - val_loss: 41.8983 - val_accuracy: 0.2444\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.8943 - accuracy: 0.2065 - val_loss: 41.8442 - val_accuracy: 0.2444\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.8379 - accuracy: 0.2040 - val_loss: 41.7893 - val_accuracy: 0.2444\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.7804 - accuracy: 0.2040 - val_loss: 41.7377 - val_accuracy: 0.1333\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.7246 - accuracy: 0.1667 - val_loss: 41.6865 - val_accuracy: 0.1333\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.6681 - accuracy: 0.1791 - val_loss: 41.6295 - val_accuracy: 0.1111\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6111 - accuracy: 0.1692 - val_loss: 41.5690 - val_accuracy: 0.2444\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.5546 - accuracy: 0.1940 - val_loss: 41.5090 - val_accuracy: 0.2222\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.4983 - accuracy: 0.1592 - val_loss: 41.4533 - val_accuracy: 0.2444\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.4417 - accuracy: 0.1891 - val_loss: 41.4031 - val_accuracy: 0.2444\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.3854 - accuracy: 0.2065 - val_loss: 41.3466 - val_accuracy: 0.2444\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.3291 - accuracy: 0.1915 - val_loss: 41.2850 - val_accuracy: 0.2222\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.2728 - accuracy: 0.1542 - val_loss: 41.2235 - val_accuracy: 0.2444\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2177 - accuracy: 0.1667 - val_loss: 41.1631 - val_accuracy: 0.2444\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1617 - accuracy: 0.1567 - val_loss: 41.1042 - val_accuracy: 0.2222\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.1060 - accuracy: 0.1468 - val_loss: 41.0448 - val_accuracy: 0.2444\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0494 - accuracy: 0.1667 - val_loss: 40.9915 - val_accuracy: 0.2444\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.9942 - accuracy: 0.1891 - val_loss: 40.9477 - val_accuracy: 0.1556\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.9377 - accuracy: 0.1940 - val_loss: 40.8945 - val_accuracy: 0.1333\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.8816 - accuracy: 0.1791 - val_loss: 40.8454 - val_accuracy: 0.1333\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.8259 - accuracy: 0.1542 - val_loss: 40.7899 - val_accuracy: 0.1333\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.7700 - accuracy: 0.1766 - val_loss: 40.7350 - val_accuracy: 0.2444\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.7140 - accuracy: 0.1816 - val_loss: 40.6705 - val_accuracy: 0.2222\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6579 - accuracy: 0.1542 - val_loss: 40.6055 - val_accuracy: 0.2222\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.6026 - accuracy: 0.1592 - val_loss: 40.5442 - val_accuracy: 0.2222\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.5486 - accuracy: 0.1418 - val_loss: 40.4888 - val_accuracy: 0.2222\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.4931 - accuracy: 0.1542 - val_loss: 40.4395 - val_accuracy: 0.1778\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.4378 - accuracy: 0.1542 - val_loss: 40.3888 - val_accuracy: 0.2222\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.3827 - accuracy: 0.2114 - val_loss: 40.3356 - val_accuracy: 0.2222\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3266 - accuracy: 0.1940 - val_loss: 40.2787 - val_accuracy: 0.1778\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40.2711 - accuracy: 0.1517 - val_loss: 40.2181 - val_accuracy: 0.1778\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2159 - accuracy: 0.1517 - val_loss: 40.1624 - val_accuracy: 0.1778\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.1608 - accuracy: 0.1468 - val_loss: 40.1070 - val_accuracy: 0.1778\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.1058 - accuracy: 0.1592 - val_loss: 40.0617 - val_accuracy: 0.2000\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.0503 - accuracy: 0.1741 - val_loss: 40.0060 - val_accuracy: 0.1778\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9953 - accuracy: 0.1642 - val_loss: 39.9487 - val_accuracy: 0.1778\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.9400 - accuracy: 0.1716 - val_loss: 39.8941 - val_accuracy: 0.2444\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.8852 - accuracy: 0.2015 - val_loss: 39.8416 - val_accuracy: 0.1333\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.8308 - accuracy: 0.1667 - val_loss: 39.7894 - val_accuracy: 0.1333\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.7756 - accuracy: 0.1766 - val_loss: 39.7303 - val_accuracy: 0.2444\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7207 - accuracy: 0.1965 - val_loss: 39.6699 - val_accuracy: 0.2222\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.6667 - accuracy: 0.1791 - val_loss: 39.6174 - val_accuracy: 0.2444\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.6123 - accuracy: 0.2040 - val_loss: 39.5678 - val_accuracy: 0.2444\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5576 - accuracy: 0.1915 - val_loss: 39.5155 - val_accuracy: 0.1556\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.5033 - accuracy: 0.1965 - val_loss: 39.4587 - val_accuracy: 0.2444\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.4488 - accuracy: 0.1791 - val_loss: 39.3985 - val_accuracy: 0.2222\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.3948 - accuracy: 0.1766 - val_loss: 39.3515 - val_accuracy: 0.2444\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3394 - accuracy: 0.2040 - val_loss: 39.2973 - val_accuracy: 0.2444\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.2857 - accuracy: 0.2040 - val_loss: 39.2422 - val_accuracy: 0.2444\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.2312 - accuracy: 0.2040 - val_loss: 39.1847 - val_accuracy: 0.2444\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1772 - accuracy: 0.2363 - val_loss: 39.1333 - val_accuracy: 0.2667\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.1227 - accuracy: 0.2189 - val_loss: 39.0819 - val_accuracy: 0.2444\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.0688 - accuracy: 0.2040 - val_loss: 39.0273 - val_accuracy: 0.2444\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.0148 - accuracy: 0.2040 - val_loss: 38.9715 - val_accuracy: 0.2444\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9609 - accuracy: 0.1692 - val_loss: 38.9134 - val_accuracy: 0.2222\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.9065 - accuracy: 0.1542 - val_loss: 38.8637 - val_accuracy: 0.2222\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.8525 - accuracy: 0.1841 - val_loss: 38.8158 - val_accuracy: 0.2444\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7989 - accuracy: 0.2040 - val_loss: 38.7609 - val_accuracy: 0.2444\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.7455 - accuracy: 0.2040 - val_loss: 38.7084 - val_accuracy: 0.2444\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.6918 - accuracy: 0.2040 - val_loss: 38.6527 - val_accuracy: 0.2444\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.6384 - accuracy: 0.2040 - val_loss: 38.5998 - val_accuracy: 0.2444\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5838 - accuracy: 0.1866 - val_loss: 38.5448 - val_accuracy: 0.2444\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5309 - accuracy: 0.1592 - val_loss: 38.4881 - val_accuracy: 0.2222\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.4775 - accuracy: 0.1542 - val_loss: 38.4382 - val_accuracy: 0.2000\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4235 - accuracy: 0.1716 - val_loss: 38.3831 - val_accuracy: 0.1778\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.3699 - accuracy: 0.1592 - val_loss: 38.3297 - val_accuracy: 0.2444\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.3162 - accuracy: 0.2040 - val_loss: 38.2775 - val_accuracy: 0.2444\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2625 - accuracy: 0.2040 - val_loss: 38.2244 - val_accuracy: 0.2444\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.2097 - accuracy: 0.1990 - val_loss: 38.1710 - val_accuracy: 0.2444\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.1570 - accuracy: 0.1891 - val_loss: 38.1198 - val_accuracy: 0.2444\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.1033 - accuracy: 0.2040 - val_loss: 38.0695 - val_accuracy: 0.2444\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.0499 - accuracy: 0.1940 - val_loss: 38.0177 - val_accuracy: 0.1333\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9969 - accuracy: 0.1692 - val_loss: 37.9645 - val_accuracy: 0.1333\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.9443 - accuracy: 0.1891 - val_loss: 37.9184 - val_accuracy: 0.0889\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.8925 - accuracy: 0.2040 - val_loss: 37.8670 - val_accuracy: 0.0889\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.8391 - accuracy: 0.2015 - val_loss: 37.8018 - val_accuracy: 0.1556\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.7856 - accuracy: 0.2015 - val_loss: 37.7425 - val_accuracy: 0.2444\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.7323 - accuracy: 0.1791 - val_loss: 37.6897 - val_accuracy: 0.2444\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.6795 - accuracy: 0.2040 - val_loss: 37.6414 - val_accuracy: 0.2444\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.6267 - accuracy: 0.2040 - val_loss: 37.5904 - val_accuracy: 0.1556\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5743 - accuracy: 0.1692 - val_loss: 37.5425 - val_accuracy: 0.1111\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5220 - accuracy: 0.1642 - val_loss: 37.4884 - val_accuracy: 0.1333\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4698 - accuracy: 0.1915 - val_loss: 37.4323 - val_accuracy: 0.2444\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4166 - accuracy: 0.2040 - val_loss: 37.3812 - val_accuracy: 0.2444\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3642 - accuracy: 0.2338 - val_loss: 37.3263 - val_accuracy: 0.2222\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3118 - accuracy: 0.2065 - val_loss: 37.2668 - val_accuracy: 0.2444\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.2592 - accuracy: 0.1617 - val_loss: 37.2149 - val_accuracy: 0.2222\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2068 - accuracy: 0.1667 - val_loss: 37.1663 - val_accuracy: 0.2444\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1540 - accuracy: 0.2164 - val_loss: 37.1178 - val_accuracy: 0.2667\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.1021 - accuracy: 0.2338 - val_loss: 37.0666 - val_accuracy: 0.2889\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.0500 - accuracy: 0.2488 - val_loss: 37.0088 - val_accuracy: 0.2889\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9983 - accuracy: 0.1990 - val_loss: 36.9512 - val_accuracy: 0.2667\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.9466 - accuracy: 0.2015 - val_loss: 36.9025 - val_accuracy: 0.2889\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8945 - accuracy: 0.2637 - val_loss: 36.8538 - val_accuracy: 0.1778\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.8422 - accuracy: 0.2139 - val_loss: 36.8039 - val_accuracy: 0.2444\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.7897 - accuracy: 0.2189 - val_loss: 36.7551 - val_accuracy: 0.2222\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7373 - accuracy: 0.2040 - val_loss: 36.7005 - val_accuracy: 0.2444\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6859 - accuracy: 0.2040 - val_loss: 36.6488 - val_accuracy: 0.2444\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6342 - accuracy: 0.1891 - val_loss: 36.5925 - val_accuracy: 0.2222\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5825 - accuracy: 0.1617 - val_loss: 36.5401 - val_accuracy: 0.2222\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5302 - accuracy: 0.1542 - val_loss: 36.4885 - val_accuracy: 0.2222\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.4786 - accuracy: 0.1866 - val_loss: 36.4431 - val_accuracy: 0.2000\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4276 - accuracy: 0.2363 - val_loss: 36.3930 - val_accuracy: 0.2444\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.3766 - accuracy: 0.2662 - val_loss: 36.3364 - val_accuracy: 0.2222\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3250 - accuracy: 0.1940 - val_loss: 36.2799 - val_accuracy: 0.1778\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2738 - accuracy: 0.1517 - val_loss: 36.2237 - val_accuracy: 0.1778\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2225 - accuracy: 0.1343 - val_loss: 36.1730 - val_accuracy: 0.2222\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1708 - accuracy: 0.1692 - val_loss: 36.1316 - val_accuracy: 0.2222\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1189 - accuracy: 0.2512 - val_loss: 36.0838 - val_accuracy: 0.2444\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.0669 - accuracy: 0.2662 - val_loss: 36.0352 - val_accuracy: 0.2222\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.0158 - accuracy: 0.2264 - val_loss: 35.9794 - val_accuracy: 0.2444\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.9659 - accuracy: 0.1915 - val_loss: 35.9263 - val_accuracy: 0.2444\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.9150 - accuracy: 0.1990 - val_loss: 35.8770 - val_accuracy: 0.2444\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8641 - accuracy: 0.1891 - val_loss: 35.8317 - val_accuracy: 0.1333\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.8128 - accuracy: 0.1990 - val_loss: 35.7793 - val_accuracy: 0.2444\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.7610 - accuracy: 0.2040 - val_loss: 35.7251 - val_accuracy: 0.2000\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.7100 - accuracy: 0.2139 - val_loss: 35.6738 - val_accuracy: 0.2000\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.6596 - accuracy: 0.2040 - val_loss: 35.6241 - val_accuracy: 0.2000\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6087 - accuracy: 0.1791 - val_loss: 35.5737 - val_accuracy: 0.1778\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.5574 - accuracy: 0.1841 - val_loss: 35.5232 - val_accuracy: 0.2000\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5070 - accuracy: 0.2214 - val_loss: 35.4724 - val_accuracy: 0.2222\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.4562 - accuracy: 0.2164 - val_loss: 35.4186 - val_accuracy: 0.2000\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.4056 - accuracy: 0.1791 - val_loss: 35.3631 - val_accuracy: 0.2000\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.3551 - accuracy: 0.2338 - val_loss: 35.3160 - val_accuracy: 0.2444\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.3048 - accuracy: 0.2488 - val_loss: 35.2731 - val_accuracy: 0.0889\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2549 - accuracy: 0.1915 - val_loss: 35.2314 - val_accuracy: 0.0667\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.2045 - accuracy: 0.1692 - val_loss: 35.1752 - val_accuracy: 0.1333\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1535 - accuracy: 0.2388 - val_loss: 35.1179 - val_accuracy: 0.2889\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.1029 - accuracy: 0.2537 - val_loss: 35.0636 - val_accuracy: 0.2889\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0527 - accuracy: 0.2289 - val_loss: 35.0138 - val_accuracy: 0.2889\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.0020 - accuracy: 0.1915 - val_loss: 34.9648 - val_accuracy: 0.2444\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9517 - accuracy: 0.2264 - val_loss: 34.9214 - val_accuracy: 0.1556\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9013 - accuracy: 0.1990 - val_loss: 34.8732 - val_accuracy: 0.1333\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.8519 - accuracy: 0.1642 - val_loss: 34.8225 - val_accuracy: 0.1111\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.8018 - accuracy: 0.1517 - val_loss: 34.7694 - val_accuracy: 0.1111\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.7526 - accuracy: 0.1542 - val_loss: 34.7174 - val_accuracy: 0.1111\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.7020 - accuracy: 0.1592 - val_loss: 34.6667 - val_accuracy: 0.1333\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6516 - accuracy: 0.1841 - val_loss: 34.6139 - val_accuracy: 0.2667\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6019 - accuracy: 0.2239 - val_loss: 34.5570 - val_accuracy: 0.2889\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5523 - accuracy: 0.1866 - val_loss: 34.5076 - val_accuracy: 0.2444\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5020 - accuracy: 0.2338 - val_loss: 34.4661 - val_accuracy: 0.2222\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.4528 - accuracy: 0.2413 - val_loss: 34.4205 - val_accuracy: 0.2222\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.4027 - accuracy: 0.2413 - val_loss: 34.3736 - val_accuracy: 0.2222\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3527 - accuracy: 0.2338 - val_loss: 34.3207 - val_accuracy: 0.2000\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.3033 - accuracy: 0.2338 - val_loss: 34.2674 - val_accuracy: 0.2000\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.2534 - accuracy: 0.1891 - val_loss: 34.2127 - val_accuracy: 0.2222\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.2047 - accuracy: 0.1542 - val_loss: 34.1642 - val_accuracy: 0.2444\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1547 - accuracy: 0.1990 - val_loss: 34.1227 - val_accuracy: 0.2000\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.1054 - accuracy: 0.2015 - val_loss: 34.0801 - val_accuracy: 0.1556\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.0571 - accuracy: 0.1866 - val_loss: 34.0342 - val_accuracy: 0.1333\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.0074 - accuracy: 0.1940 - val_loss: 33.9804 - val_accuracy: 0.1556\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9581 - accuracy: 0.2239 - val_loss: 33.9207 - val_accuracy: 0.2444\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9085 - accuracy: 0.2015 - val_loss: 33.8693 - val_accuracy: 0.2444\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.8592 - accuracy: 0.2114 - val_loss: 33.8226 - val_accuracy: 0.2667\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.8097 - accuracy: 0.2313 - val_loss: 33.7714 - val_accuracy: 0.2444\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7609 - accuracy: 0.2214 - val_loss: 33.7228 - val_accuracy: 0.2667\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.7117 - accuracy: 0.2438 - val_loss: 33.6811 - val_accuracy: 0.2000\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6636 - accuracy: 0.2139 - val_loss: 33.6408 - val_accuracy: 0.0889\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.6143 - accuracy: 0.2139 - val_loss: 33.5873 - val_accuracy: 0.2000\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5646 - accuracy: 0.2214 - val_loss: 33.5313 - val_accuracy: 0.2444\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.5163 - accuracy: 0.1791 - val_loss: 33.4809 - val_accuracy: 0.2222\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4671 - accuracy: 0.1542 - val_loss: 33.4326 - val_accuracy: 0.2222\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4185 - accuracy: 0.1965 - val_loss: 33.3921 - val_accuracy: 0.2222\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.3709 - accuracy: 0.2363 - val_loss: 33.3465 - val_accuracy: 0.1556\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3221 - accuracy: 0.2338 - val_loss: 33.2877 - val_accuracy: 0.2667\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.2724 - accuracy: 0.2289 - val_loss: 33.2385 - val_accuracy: 0.2444\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.2235 - accuracy: 0.2040 - val_loss: 33.1909 - val_accuracy: 0.2444\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.1753 - accuracy: 0.2040 - val_loss: 33.1450 - val_accuracy: 0.2444\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1269 - accuracy: 0.2040 - val_loss: 33.0947 - val_accuracy: 0.2444\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.0786 - accuracy: 0.2040 - val_loss: 33.0460 - val_accuracy: 0.2444\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.0297 - accuracy: 0.2040 - val_loss: 32.9993 - val_accuracy: 0.2444\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9822 - accuracy: 0.2040 - val_loss: 32.9440 - val_accuracy: 0.2444\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9331 - accuracy: 0.2114 - val_loss: 32.8994 - val_accuracy: 0.2667\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.8846 - accuracy: 0.2289 - val_loss: 32.8501 - val_accuracy: 0.2889\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.8366 - accuracy: 0.2338 - val_loss: 32.8044 - val_accuracy: 0.2667\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.7886 - accuracy: 0.2289 - val_loss: 32.7571 - val_accuracy: 0.2667\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.7402 - accuracy: 0.2313 - val_loss: 32.7014 - val_accuracy: 0.2444\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.6931 - accuracy: 0.1791 - val_loss: 32.6499 - val_accuracy: 0.2444\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.6447 - accuracy: 0.1592 - val_loss: 32.6040 - val_accuracy: 0.2667\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5970 - accuracy: 0.2363 - val_loss: 32.5644 - val_accuracy: 0.2889\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.5487 - accuracy: 0.2612 - val_loss: 32.5110 - val_accuracy: 0.2889\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.5019 - accuracy: 0.1766 - val_loss: 32.4539 - val_accuracy: 0.2222\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4541 - accuracy: 0.1542 - val_loss: 32.4132 - val_accuracy: 0.2222\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.4055 - accuracy: 0.1741 - val_loss: 32.3728 - val_accuracy: 0.2444\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3573 - accuracy: 0.2289 - val_loss: 32.3349 - val_accuracy: 0.2000\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3103 - accuracy: 0.2189 - val_loss: 32.2887 - val_accuracy: 0.1556\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.2624 - accuracy: 0.2488 - val_loss: 32.2332 - val_accuracy: 0.2222\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2140 - accuracy: 0.2338 - val_loss: 32.1803 - val_accuracy: 0.2444\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.1671 - accuracy: 0.1891 - val_loss: 32.1291 - val_accuracy: 0.2444\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.1200 - accuracy: 0.2015 - val_loss: 32.0846 - val_accuracy: 0.2667\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.0720 - accuracy: 0.2363 - val_loss: 32.0371 - val_accuracy: 0.2889\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.0250 - accuracy: 0.2313 - val_loss: 31.9872 - val_accuracy: 0.2667\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9769 - accuracy: 0.2338 - val_loss: 31.9418 - val_accuracy: 0.2889\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9296 - accuracy: 0.2562 - val_loss: 31.9002 - val_accuracy: 0.1778\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8824 - accuracy: 0.2139 - val_loss: 31.8555 - val_accuracy: 0.1556\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.8351 - accuracy: 0.2164 - val_loss: 31.8031 - val_accuracy: 0.2222\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.7878 - accuracy: 0.2264 - val_loss: 31.7531 - val_accuracy: 0.2222\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.7405 - accuracy: 0.2313 - val_loss: 31.7072 - val_accuracy: 0.2222\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.6936 - accuracy: 0.2413 - val_loss: 31.6645 - val_accuracy: 0.1778\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.6472 - accuracy: 0.2239 - val_loss: 31.6120 - val_accuracy: 0.2667\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.5999 - accuracy: 0.2264 - val_loss: 31.5611 - val_accuracy: 0.2444\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.5523 - accuracy: 0.2114 - val_loss: 31.5154 - val_accuracy: 0.2444\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.5058 - accuracy: 0.2114 - val_loss: 31.4699 - val_accuracy: 0.2444\n",
      "========== Fold 5 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 207.6951 - accuracy: 0.1194 - val_loss: 196.5166 - val_accuracy: 0.1778\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 190.3905 - accuracy: 0.1493 - val_loss: 177.8105 - val_accuracy: 0.2222\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 172.3082 - accuracy: 0.1567 - val_loss: 161.5725 - val_accuracy: 0.1333\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 157.1403 - accuracy: 0.1692 - val_loss: 148.6591 - val_accuracy: 0.1333\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 145.2166 - accuracy: 0.1443 - val_loss: 138.6630 - val_accuracy: 0.1111\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 136.0023 - accuracy: 0.1368 - val_loss: 130.9438 - val_accuracy: 0.1778\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 128.8651 - accuracy: 0.1443 - val_loss: 124.9195 - val_accuracy: 0.2000\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 123.2838 - accuracy: 0.1642 - val_loss: 120.1661 - val_accuracy: 0.1778\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 118.8560 - accuracy: 0.1468 - val_loss: 116.3621 - val_accuracy: 0.1778\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 115.2934 - accuracy: 0.1542 - val_loss: 113.2700 - val_accuracy: 0.1333\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 112.3842 - accuracy: 0.1443 - val_loss: 110.7109 - val_accuracy: 0.1333\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109.9702 - accuracy: 0.1468 - val_loss: 108.5685 - val_accuracy: 0.1333\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 107.9435 - accuracy: 0.1393 - val_loss: 106.7539 - val_accuracy: 0.2000\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 106.2173 - accuracy: 0.1542 - val_loss: 105.1999 - val_accuracy: 0.1778\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 104.7293 - accuracy: 0.1468 - val_loss: 103.8493 - val_accuracy: 0.1778\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 103.4369 - accuracy: 0.1542 - val_loss: 102.6669 - val_accuracy: 0.1778\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102.3009 - accuracy: 0.1468 - val_loss: 101.6219 - val_accuracy: 0.1333\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.2953 - accuracy: 0.1393 - val_loss: 100.6850 - val_accuracy: 0.1333\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 100.3938 - accuracy: 0.1493 - val_loss: 99.8450 - val_accuracy: 0.1778\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.5820 - accuracy: 0.1542 - val_loss: 99.0894 - val_accuracy: 0.1333\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.8480 - accuracy: 0.1418 - val_loss: 98.4027 - val_accuracy: 0.1333\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.1801 - accuracy: 0.1418 - val_loss: 97.7716 - val_accuracy: 0.1333\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.5577 - accuracy: 0.1443 - val_loss: 97.1874 - val_accuracy: 0.2000\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.9906 - accuracy: 0.1493 - val_loss: 96.6504 - val_accuracy: 0.1333\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 96.4644 - accuracy: 0.1393 - val_loss: 96.1470 - val_accuracy: 0.1333\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.9725 - accuracy: 0.1393 - val_loss: 95.6729 - val_accuracy: 0.1111\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.5133 - accuracy: 0.1642 - val_loss: 95.2353 - val_accuracy: 0.2000\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.0829 - accuracy: 0.1567 - val_loss: 94.8230 - val_accuracy: 0.2000\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.6776 - accuracy: 0.1642 - val_loss: 94.4409 - val_accuracy: 0.1778\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.2926 - accuracy: 0.1393 - val_loss: 94.0694 - val_accuracy: 0.1111\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9268 - accuracy: 0.1468 - val_loss: 93.7048 - val_accuracy: 0.1778\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.5770 - accuracy: 0.1468 - val_loss: 93.3618 - val_accuracy: 0.2000\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.2478 - accuracy: 0.1567 - val_loss: 93.0378 - val_accuracy: 0.2000\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.9322 - accuracy: 0.1468 - val_loss: 92.7282 - val_accuracy: 0.2000\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.6228 - accuracy: 0.1567 - val_loss: 92.4342 - val_accuracy: 0.1778\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92.3278 - accuracy: 0.1468 - val_loss: 92.1510 - val_accuracy: 0.1778\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.0455 - accuracy: 0.1468 - val_loss: 91.8765 - val_accuracy: 0.2000\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.7708 - accuracy: 0.1592 - val_loss: 91.6051 - val_accuracy: 0.2000\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91.5076 - accuracy: 0.1567 - val_loss: 91.3454 - val_accuracy: 0.2000\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.2502 - accuracy: 0.1517 - val_loss: 91.0984 - val_accuracy: 0.1778\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.0005 - accuracy: 0.1517 - val_loss: 90.8530 - val_accuracy: 0.1333\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.7584 - accuracy: 0.1443 - val_loss: 90.6084 - val_accuracy: 0.1778\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90.5205 - accuracy: 0.1592 - val_loss: 90.3695 - val_accuracy: 0.1778\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.2878 - accuracy: 0.1443 - val_loss: 90.1386 - val_accuracy: 0.2000\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.0623 - accuracy: 0.1716 - val_loss: 89.9149 - val_accuracy: 0.2000\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89.8425 - accuracy: 0.1592 - val_loss: 89.7007 - val_accuracy: 0.2000\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.6249 - accuracy: 0.1692 - val_loss: 89.4952 - val_accuracy: 0.1778\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.4135 - accuracy: 0.1468 - val_loss: 89.2953 - val_accuracy: 0.1778\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.2076 - accuracy: 0.1468 - val_loss: 89.0885 - val_accuracy: 0.1778\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.0027 - accuracy: 0.1468 - val_loss: 88.8784 - val_accuracy: 0.1778\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.8025 - accuracy: 0.1542 - val_loss: 88.6745 - val_accuracy: 0.2000\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.6074 - accuracy: 0.1592 - val_loss: 88.4828 - val_accuracy: 0.2000\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.4142 - accuracy: 0.1567 - val_loss: 88.2947 - val_accuracy: 0.2000\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88.2215 - accuracy: 0.1592 - val_loss: 88.1131 - val_accuracy: 0.2000\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0348 - accuracy: 0.1517 - val_loss: 87.9298 - val_accuracy: 0.1778\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.8497 - accuracy: 0.1468 - val_loss: 87.7458 - val_accuracy: 0.2000\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.6689 - accuracy: 0.1692 - val_loss: 87.5588 - val_accuracy: 0.2000\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.4885 - accuracy: 0.1567 - val_loss: 87.3812 - val_accuracy: 0.2000\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.3109 - accuracy: 0.1592 - val_loss: 87.2038 - val_accuracy: 0.2222\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.1328 - accuracy: 0.1617 - val_loss: 87.0287 - val_accuracy: 0.2000\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 86.9572 - accuracy: 0.1716 - val_loss: 86.8570 - val_accuracy: 0.1778\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.7859 - accuracy: 0.1468 - val_loss: 86.6871 - val_accuracy: 0.1778\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.6162 - accuracy: 0.1468 - val_loss: 86.5233 - val_accuracy: 0.1778\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.4492 - accuracy: 0.1418 - val_loss: 86.3617 - val_accuracy: 0.1333\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 86.2837 - accuracy: 0.1368 - val_loss: 86.1964 - val_accuracy: 0.2000\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 86.1192 - accuracy: 0.1716 - val_loss: 86.0262 - val_accuracy: 0.2000\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.9537 - accuracy: 0.1692 - val_loss: 85.8650 - val_accuracy: 0.2000\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.7932 - accuracy: 0.1617 - val_loss: 85.7102 - val_accuracy: 0.1778\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.6351 - accuracy: 0.1468 - val_loss: 85.5541 - val_accuracy: 0.1778\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.4784 - accuracy: 0.1517 - val_loss: 85.3963 - val_accuracy: 0.1111\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 85.3207 - accuracy: 0.1443 - val_loss: 85.2394 - val_accuracy: 0.1778\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.1632 - accuracy: 0.1468 - val_loss: 85.0789 - val_accuracy: 0.1778\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.0079 - accuracy: 0.1318 - val_loss: 84.9198 - val_accuracy: 0.1333\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.8534 - accuracy: 0.1393 - val_loss: 84.7706 - val_accuracy: 0.1333\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.7029 - accuracy: 0.1393 - val_loss: 84.6238 - val_accuracy: 0.1333\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.5516 - accuracy: 0.1393 - val_loss: 84.4720 - val_accuracy: 0.1778\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.4045 - accuracy: 0.1940 - val_loss: 84.3153 - val_accuracy: 0.2222\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.2564 - accuracy: 0.1468 - val_loss: 84.1644 - val_accuracy: 0.1333\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.1059 - accuracy: 0.1542 - val_loss: 84.0174 - val_accuracy: 0.2000\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.9599 - accuracy: 0.1766 - val_loss: 83.8746 - val_accuracy: 0.1778\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.8135 - accuracy: 0.1592 - val_loss: 83.7349 - val_accuracy: 0.1556\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.6690 - accuracy: 0.1542 - val_loss: 83.5922 - val_accuracy: 0.1556\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83.5258 - accuracy: 0.1542 - val_loss: 83.4512 - val_accuracy: 0.1556\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3837 - accuracy: 0.1592 - val_loss: 83.3094 - val_accuracy: 0.1778\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.2424 - accuracy: 0.1468 - val_loss: 83.1612 - val_accuracy: 0.1778\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83.1002 - accuracy: 0.1468 - val_loss: 83.0186 - val_accuracy: 0.1778\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.9606 - accuracy: 0.1368 - val_loss: 82.8763 - val_accuracy: 0.1556\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.8223 - accuracy: 0.1542 - val_loss: 82.7395 - val_accuracy: 0.1556\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.6848 - accuracy: 0.1542 - val_loss: 82.6060 - val_accuracy: 0.1556\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.5471 - accuracy: 0.1468 - val_loss: 82.4688 - val_accuracy: 0.1778\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.4096 - accuracy: 0.1393 - val_loss: 82.3344 - val_accuracy: 0.1778\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.2725 - accuracy: 0.1468 - val_loss: 82.2052 - val_accuracy: 0.1778\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82.1385 - accuracy: 0.1468 - val_loss: 82.0732 - val_accuracy: 0.1778\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.0048 - accuracy: 0.1468 - val_loss: 81.9391 - val_accuracy: 0.1778\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.8703 - accuracy: 0.1468 - val_loss: 81.8011 - val_accuracy: 0.1778\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.7375 - accuracy: 0.1567 - val_loss: 81.6621 - val_accuracy: 0.2000\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.6060 - accuracy: 0.1816 - val_loss: 81.5287 - val_accuracy: 0.2000\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.4746 - accuracy: 0.1617 - val_loss: 81.3937 - val_accuracy: 0.1778\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81.3436 - accuracy: 0.1468 - val_loss: 81.2640 - val_accuracy: 0.1778\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81.2155 - accuracy: 0.1468 - val_loss: 81.1368 - val_accuracy: 0.1778\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.0856 - accuracy: 0.1468 - val_loss: 81.0095 - val_accuracy: 0.1778\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.9548 - accuracy: 0.1567 - val_loss: 80.8826 - val_accuracy: 0.2000\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.8267 - accuracy: 0.1940 - val_loss: 80.7602 - val_accuracy: 0.1333\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.7001 - accuracy: 0.1816 - val_loss: 80.6373 - val_accuracy: 0.0889\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.5737 - accuracy: 0.1716 - val_loss: 80.5108 - val_accuracy: 0.1778\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.4459 - accuracy: 0.1468 - val_loss: 80.3843 - val_accuracy: 0.1778\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.3192 - accuracy: 0.1443 - val_loss: 80.2567 - val_accuracy: 0.1333\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.1948 - accuracy: 0.1393 - val_loss: 80.1263 - val_accuracy: 0.1333\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.0699 - accuracy: 0.1393 - val_loss: 79.9973 - val_accuracy: 0.1333\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.9462 - accuracy: 0.1393 - val_loss: 79.8718 - val_accuracy: 0.1778\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8230 - accuracy: 0.1468 - val_loss: 79.7475 - val_accuracy: 0.1778\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79.6997 - accuracy: 0.1567 - val_loss: 79.6244 - val_accuracy: 0.1556\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.5769 - accuracy: 0.1517 - val_loss: 79.5038 - val_accuracy: 0.1778\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.4549 - accuracy: 0.1493 - val_loss: 79.3825 - val_accuracy: 0.2000\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.3316 - accuracy: 0.1692 - val_loss: 79.2665 - val_accuracy: 0.1778\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.2104 - accuracy: 0.1468 - val_loss: 79.1494 - val_accuracy: 0.1778\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0921 - accuracy: 0.1443 - val_loss: 79.0298 - val_accuracy: 0.1333\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 78.9730 - accuracy: 0.1368 - val_loss: 78.9085 - val_accuracy: 0.2000\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.8521 - accuracy: 0.1741 - val_loss: 78.7874 - val_accuracy: 0.2000\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.7317 - accuracy: 0.1741 - val_loss: 78.6683 - val_accuracy: 0.2000\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.6128 - accuracy: 0.1567 - val_loss: 78.5470 - val_accuracy: 0.2000\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.4945 - accuracy: 0.1642 - val_loss: 78.4288 - val_accuracy: 0.2000\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.3779 - accuracy: 0.1517 - val_loss: 78.3153 - val_accuracy: 0.1778\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.2601 - accuracy: 0.1468 - val_loss: 78.2000 - val_accuracy: 0.1778\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.1434 - accuracy: 0.1468 - val_loss: 78.0839 - val_accuracy: 0.1333\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.0270 - accuracy: 0.1393 - val_loss: 77.9698 - val_accuracy: 0.1333\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.9128 - accuracy: 0.1393 - val_loss: 77.8553 - val_accuracy: 0.1333\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.7971 - accuracy: 0.1393 - val_loss: 77.7359 - val_accuracy: 0.1333\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6811 - accuracy: 0.1542 - val_loss: 77.6189 - val_accuracy: 0.2000\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.5653 - accuracy: 0.1567 - val_loss: 77.5010 - val_accuracy: 0.2000\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.4503 - accuracy: 0.1567 - val_loss: 77.3833 - val_accuracy: 0.2000\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.3361 - accuracy: 0.1567 - val_loss: 77.2681 - val_accuracy: 0.2000\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 77.2232 - accuracy: 0.1542 - val_loss: 77.1531 - val_accuracy: 0.2000\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1121 - accuracy: 0.1493 - val_loss: 77.0431 - val_accuracy: 0.1778\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.9982 - accuracy: 0.1294 - val_loss: 76.9348 - val_accuracy: 0.1778\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.8863 - accuracy: 0.1468 - val_loss: 76.8215 - val_accuracy: 0.1778\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76.7734 - accuracy: 0.1468 - val_loss: 76.7119 - val_accuracy: 0.1778\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.6612 - accuracy: 0.1468 - val_loss: 76.5988 - val_accuracy: 0.2000\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.5501 - accuracy: 0.1567 - val_loss: 76.4867 - val_accuracy: 0.2000\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.4402 - accuracy: 0.1592 - val_loss: 76.3805 - val_accuracy: 0.1111\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.3296 - accuracy: 0.1542 - val_loss: 76.2714 - val_accuracy: 0.2000\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.2187 - accuracy: 0.1692 - val_loss: 76.1627 - val_accuracy: 0.1778\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.1081 - accuracy: 0.1468 - val_loss: 76.0518 - val_accuracy: 0.1778\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.9993 - accuracy: 0.1468 - val_loss: 75.9413 - val_accuracy: 0.1778\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8907 - accuracy: 0.1468 - val_loss: 75.8314 - val_accuracy: 0.1778\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75.7808 - accuracy: 0.1468 - val_loss: 75.7187 - val_accuracy: 0.1778\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.6718 - accuracy: 0.1468 - val_loss: 75.6097 - val_accuracy: 0.1778\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.5644 - accuracy: 0.1617 - val_loss: 75.5077 - val_accuracy: 0.2000\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.4570 - accuracy: 0.1692 - val_loss: 75.4044 - val_accuracy: 0.1778\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75.3487 - accuracy: 0.1617 - val_loss: 75.2948 - val_accuracy: 0.2000\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.2421 - accuracy: 0.1567 - val_loss: 75.1871 - val_accuracy: 0.2000\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.1357 - accuracy: 0.1716 - val_loss: 75.0822 - val_accuracy: 0.2000\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.0299 - accuracy: 0.1816 - val_loss: 74.9738 - val_accuracy: 0.2000\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.9223 - accuracy: 0.1567 - val_loss: 74.8660 - val_accuracy: 0.2000\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8161 - accuracy: 0.1493 - val_loss: 74.7598 - val_accuracy: 0.1333\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.7108 - accuracy: 0.1368 - val_loss: 74.6506 - val_accuracy: 0.1778\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.6049 - accuracy: 0.1468 - val_loss: 74.5440 - val_accuracy: 0.1778\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.5003 - accuracy: 0.1468 - val_loss: 74.4380 - val_accuracy: 0.1556\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.3948 - accuracy: 0.1542 - val_loss: 74.3349 - val_accuracy: 0.1556\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.2909 - accuracy: 0.1542 - val_loss: 74.2322 - val_accuracy: 0.1778\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.1874 - accuracy: 0.1468 - val_loss: 74.1272 - val_accuracy: 0.1778\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.0845 - accuracy: 0.1468 - val_loss: 74.0256 - val_accuracy: 0.1778\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.9808 - accuracy: 0.1468 - val_loss: 73.9235 - val_accuracy: 0.1778\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.8772 - accuracy: 0.1468 - val_loss: 73.8191 - val_accuracy: 0.1778\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.7735 - accuracy: 0.1468 - val_loss: 73.7171 - val_accuracy: 0.1778\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.6714 - accuracy: 0.1468 - val_loss: 73.6135 - val_accuracy: 0.1778\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.5689 - accuracy: 0.1468 - val_loss: 73.5153 - val_accuracy: 0.1778\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4665 - accuracy: 0.1468 - val_loss: 73.4119 - val_accuracy: 0.1778\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3633 - accuracy: 0.1468 - val_loss: 73.3128 - val_accuracy: 0.1778\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.2631 - accuracy: 0.1468 - val_loss: 73.2153 - val_accuracy: 0.1778\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.1618 - accuracy: 0.1468 - val_loss: 73.1117 - val_accuracy: 0.1778\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.0586 - accuracy: 0.1468 - val_loss: 73.0079 - val_accuracy: 0.1778\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.9582 - accuracy: 0.1468 - val_loss: 72.9024 - val_accuracy: 0.1778\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.8575 - accuracy: 0.1468 - val_loss: 72.8000 - val_accuracy: 0.2000\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.7575 - accuracy: 0.1617 - val_loss: 72.6993 - val_accuracy: 0.2000\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.6579 - accuracy: 0.1567 - val_loss: 72.5988 - val_accuracy: 0.2000\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.5578 - accuracy: 0.1567 - val_loss: 72.5006 - val_accuracy: 0.2000\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.4586 - accuracy: 0.1567 - val_loss: 72.4056 - val_accuracy: 0.1778\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.3590 - accuracy: 0.1468 - val_loss: 72.3104 - val_accuracy: 0.1778\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.2604 - accuracy: 0.1468 - val_loss: 72.2123 - val_accuracy: 0.1778\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.1616 - accuracy: 0.1468 - val_loss: 72.1134 - val_accuracy: 0.1778\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.0628 - accuracy: 0.1468 - val_loss: 72.0157 - val_accuracy: 0.1778\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9642 - accuracy: 0.1468 - val_loss: 71.9126 - val_accuracy: 0.2000\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8648 - accuracy: 0.1592 - val_loss: 71.8085 - val_accuracy: 0.1778\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.7674 - accuracy: 0.1468 - val_loss: 71.7081 - val_accuracy: 0.1778\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.6709 - accuracy: 0.1468 - val_loss: 71.6092 - val_accuracy: 0.1778\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.5731 - accuracy: 0.1493 - val_loss: 71.5122 - val_accuracy: 0.1556\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.4765 - accuracy: 0.1517 - val_loss: 71.4159 - val_accuracy: 0.1778\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 71.3786 - accuracy: 0.1318 - val_loss: 71.3246 - val_accuracy: 0.1333\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.2810 - accuracy: 0.1468 - val_loss: 71.2319 - val_accuracy: 0.1778\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.1848 - accuracy: 0.1468 - val_loss: 71.1357 - val_accuracy: 0.1778\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.0879 - accuracy: 0.1567 - val_loss: 71.0395 - val_accuracy: 0.2000\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.9923 - accuracy: 0.1592 - val_loss: 70.9448 - val_accuracy: 0.1778\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70.8962 - accuracy: 0.1468 - val_loss: 70.8478 - val_accuracy: 0.1778\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.7998 - accuracy: 0.1468 - val_loss: 70.7529 - val_accuracy: 0.1778\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7048 - accuracy: 0.1468 - val_loss: 70.6551 - val_accuracy: 0.1778\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.6097 - accuracy: 0.1567 - val_loss: 70.5592 - val_accuracy: 0.2000\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.5144 - accuracy: 0.1741 - val_loss: 70.4620 - val_accuracy: 0.2000\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.4196 - accuracy: 0.1741 - val_loss: 70.3688 - val_accuracy: 0.2000\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.3251 - accuracy: 0.1716 - val_loss: 70.2744 - val_accuracy: 0.2000\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.2316 - accuracy: 0.1642 - val_loss: 70.1802 - val_accuracy: 0.2000\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.1374 - accuracy: 0.1692 - val_loss: 70.0887 - val_accuracy: 0.1778\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.0433 - accuracy: 0.1468 - val_loss: 69.9940 - val_accuracy: 0.2000\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.9489 - accuracy: 0.1716 - val_loss: 69.9010 - val_accuracy: 0.2000\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.8554 - accuracy: 0.1716 - val_loss: 69.8103 - val_accuracy: 0.2000\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.7625 - accuracy: 0.1567 - val_loss: 69.7162 - val_accuracy: 0.2000\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.6689 - accuracy: 0.1567 - val_loss: 69.6247 - val_accuracy: 0.2000\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.5752 - accuracy: 0.1692 - val_loss: 69.5327 - val_accuracy: 0.2000\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4833 - accuracy: 0.1642 - val_loss: 69.4407 - val_accuracy: 0.2000\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.3917 - accuracy: 0.1667 - val_loss: 69.3473 - val_accuracy: 0.2000\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.2990 - accuracy: 0.1741 - val_loss: 69.2546 - val_accuracy: 0.2000\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.2071 - accuracy: 0.1692 - val_loss: 69.1620 - val_accuracy: 0.2000\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.1138 - accuracy: 0.1592 - val_loss: 69.0662 - val_accuracy: 0.2000\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.0217 - accuracy: 0.1791 - val_loss: 68.9744 - val_accuracy: 0.2000\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.9294 - accuracy: 0.1567 - val_loss: 68.8845 - val_accuracy: 0.2000\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 68.8387 - accuracy: 0.1567 - val_loss: 68.7951 - val_accuracy: 0.2000\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.7484 - accuracy: 0.1567 - val_loss: 68.7026 - val_accuracy: 0.2000\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.6567 - accuracy: 0.1617 - val_loss: 68.6101 - val_accuracy: 0.1778\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.5656 - accuracy: 0.1468 - val_loss: 68.5204 - val_accuracy: 0.1778\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.4745 - accuracy: 0.1468 - val_loss: 68.4311 - val_accuracy: 0.1333\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.3863 - accuracy: 0.1393 - val_loss: 68.3444 - val_accuracy: 0.1333\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2953 - accuracy: 0.1393 - val_loss: 68.2517 - val_accuracy: 0.1333\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.2042 - accuracy: 0.1393 - val_loss: 68.1581 - val_accuracy: 0.1778\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.1132 - accuracy: 0.1468 - val_loss: 68.0659 - val_accuracy: 0.2000\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.0235 - accuracy: 0.1567 - val_loss: 67.9776 - val_accuracy: 0.1556\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9351 - accuracy: 0.1567 - val_loss: 67.8891 - val_accuracy: 0.1556\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.8454 - accuracy: 0.1542 - val_loss: 67.7999 - val_accuracy: 0.1556\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.7554 - accuracy: 0.1493 - val_loss: 67.7112 - val_accuracy: 0.1333\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6661 - accuracy: 0.1294 - val_loss: 67.6210 - val_accuracy: 0.1333\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67.5771 - accuracy: 0.1393 - val_loss: 67.5290 - val_accuracy: 0.1778\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.4870 - accuracy: 0.1468 - val_loss: 67.4419 - val_accuracy: 0.1778\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.3991 - accuracy: 0.1493 - val_loss: 67.3546 - val_accuracy: 0.2000\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.3110 - accuracy: 0.1741 - val_loss: 67.2675 - val_accuracy: 0.2000\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.2231 - accuracy: 0.1567 - val_loss: 67.1795 - val_accuracy: 0.2000\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.1374 - accuracy: 0.1542 - val_loss: 67.0901 - val_accuracy: 0.1333\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.0488 - accuracy: 0.1418 - val_loss: 67.0025 - val_accuracy: 0.1333\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9599 - accuracy: 0.1517 - val_loss: 66.9174 - val_accuracy: 0.1111\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8717 - accuracy: 0.1493 - val_loss: 66.8320 - val_accuracy: 0.0667\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.7849 - accuracy: 0.1567 - val_loss: 66.7457 - val_accuracy: 0.1556\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6974 - accuracy: 0.1542 - val_loss: 66.6562 - val_accuracy: 0.1556\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.6117 - accuracy: 0.1542 - val_loss: 66.5649 - val_accuracy: 0.1556\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.5225 - accuracy: 0.1542 - val_loss: 66.4734 - val_accuracy: 0.1556\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.4354 - accuracy: 0.1542 - val_loss: 66.3846 - val_accuracy: 0.2000\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3484 - accuracy: 0.1567 - val_loss: 66.3002 - val_accuracy: 0.2000\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.2619 - accuracy: 0.1567 - val_loss: 66.2185 - val_accuracy: 0.2000\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.1747 - accuracy: 0.1542 - val_loss: 66.1339 - val_accuracy: 0.1778\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.0887 - accuracy: 0.1468 - val_loss: 66.0455 - val_accuracy: 0.1778\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.0039 - accuracy: 0.1468 - val_loss: 65.9580 - val_accuracy: 0.1778\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.9177 - accuracy: 0.1517 - val_loss: 65.8703 - val_accuracy: 0.1778\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.8317 - accuracy: 0.1468 - val_loss: 65.7833 - val_accuracy: 0.1778\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65.7457 - accuracy: 0.1468 - val_loss: 65.6978 - val_accuracy: 0.1778\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.6600 - accuracy: 0.1542 - val_loss: 65.6141 - val_accuracy: 0.2000\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.5743 - accuracy: 0.1493 - val_loss: 65.5315 - val_accuracy: 0.1778\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.4893 - accuracy: 0.1468 - val_loss: 65.4493 - val_accuracy: 0.1778\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4051 - accuracy: 0.1468 - val_loss: 65.3659 - val_accuracy: 0.1778\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3194 - accuracy: 0.1617 - val_loss: 65.2785 - val_accuracy: 0.2000\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.2347 - accuracy: 0.1617 - val_loss: 65.1924 - val_accuracy: 0.2000\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.1500 - accuracy: 0.1667 - val_loss: 65.1090 - val_accuracy: 0.1556\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.0658 - accuracy: 0.1990 - val_loss: 65.0236 - val_accuracy: 0.1556\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.9819 - accuracy: 0.1493 - val_loss: 64.9375 - val_accuracy: 0.1778\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.8968 - accuracy: 0.1617 - val_loss: 64.8538 - val_accuracy: 0.2000\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.8134 - accuracy: 0.1841 - val_loss: 64.7693 - val_accuracy: 0.1333\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.7293 - accuracy: 0.1841 - val_loss: 64.6832 - val_accuracy: 0.2000\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.6464 - accuracy: 0.1592 - val_loss: 64.5990 - val_accuracy: 0.2000\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.5624 - accuracy: 0.1692 - val_loss: 64.5148 - val_accuracy: 0.2000\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.4783 - accuracy: 0.1567 - val_loss: 64.4327 - val_accuracy: 0.2000\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.3951 - accuracy: 0.1567 - val_loss: 64.3513 - val_accuracy: 0.2000\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.3112 - accuracy: 0.1567 - val_loss: 64.2693 - val_accuracy: 0.2000\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.2282 - accuracy: 0.1567 - val_loss: 64.1868 - val_accuracy: 0.2000\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.1452 - accuracy: 0.1567 - val_loss: 64.1009 - val_accuracy: 0.2000\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.0618 - accuracy: 0.1567 - val_loss: 64.0168 - val_accuracy: 0.2000\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.9787 - accuracy: 0.1667 - val_loss: 63.9334 - val_accuracy: 0.2000\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.8967 - accuracy: 0.1493 - val_loss: 63.8514 - val_accuracy: 0.1556\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.8146 - accuracy: 0.1542 - val_loss: 63.7698 - val_accuracy: 0.1556\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.7331 - accuracy: 0.1542 - val_loss: 63.6895 - val_accuracy: 0.1556\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.6526 - accuracy: 0.1542 - val_loss: 63.6061 - val_accuracy: 0.1556\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.5700 - accuracy: 0.1542 - val_loss: 63.5228 - val_accuracy: 0.1778\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4870 - accuracy: 0.1468 - val_loss: 63.4377 - val_accuracy: 0.2000\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4047 - accuracy: 0.1667 - val_loss: 63.3551 - val_accuracy: 0.2000\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.3231 - accuracy: 0.1567 - val_loss: 63.2739 - val_accuracy: 0.2000\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.2416 - accuracy: 0.1567 - val_loss: 63.1951 - val_accuracy: 0.2000\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.1597 - accuracy: 0.1567 - val_loss: 63.1167 - val_accuracy: 0.2000\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.0796 - accuracy: 0.1766 - val_loss: 63.0407 - val_accuracy: 0.1556\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.9984 - accuracy: 0.1667 - val_loss: 62.9623 - val_accuracy: 0.1778\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9170 - accuracy: 0.1468 - val_loss: 62.8786 - val_accuracy: 0.1778\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.8357 - accuracy: 0.1642 - val_loss: 62.7937 - val_accuracy: 0.2000\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.7550 - accuracy: 0.1567 - val_loss: 62.7124 - val_accuracy: 0.2000\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.6733 - accuracy: 0.1567 - val_loss: 62.6333 - val_accuracy: 0.2000\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.5931 - accuracy: 0.1567 - val_loss: 62.5547 - val_accuracy: 0.2000\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.5144 - accuracy: 0.1667 - val_loss: 62.4778 - val_accuracy: 0.2000\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.4333 - accuracy: 0.1766 - val_loss: 62.3947 - val_accuracy: 0.2000\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.3521 - accuracy: 0.1617 - val_loss: 62.3120 - val_accuracy: 0.1778\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62.2718 - accuracy: 0.1468 - val_loss: 62.2327 - val_accuracy: 0.1778\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.1918 - accuracy: 0.1468 - val_loss: 62.1520 - val_accuracy: 0.1778\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1127 - accuracy: 0.1468 - val_loss: 62.0698 - val_accuracy: 0.1778\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.0327 - accuracy: 0.1468 - val_loss: 61.9925 - val_accuracy: 0.1778\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.9530 - accuracy: 0.1468 - val_loss: 61.9133 - val_accuracy: 0.1778\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 61.8738 - accuracy: 0.1468 - val_loss: 61.8375 - val_accuracy: 0.1778\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.7944 - accuracy: 0.1468 - val_loss: 61.7583 - val_accuracy: 0.1778\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.7152 - accuracy: 0.1468 - val_loss: 61.6801 - val_accuracy: 0.1778\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.6363 - accuracy: 0.1468 - val_loss: 61.6010 - val_accuracy: 0.1778\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.5567 - accuracy: 0.1468 - val_loss: 61.5181 - val_accuracy: 0.1778\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4776 - accuracy: 0.1468 - val_loss: 61.4334 - val_accuracy: 0.2000\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.3997 - accuracy: 0.1766 - val_loss: 61.3516 - val_accuracy: 0.2000\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.3217 - accuracy: 0.1567 - val_loss: 61.2739 - val_accuracy: 0.2000\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2440 - accuracy: 0.1716 - val_loss: 61.1979 - val_accuracy: 0.1333\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.1664 - accuracy: 0.1517 - val_loss: 61.1238 - val_accuracy: 0.2222\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.0862 - accuracy: 0.1791 - val_loss: 61.0459 - val_accuracy: 0.2000\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.0071 - accuracy: 0.1617 - val_loss: 60.9684 - val_accuracy: 0.2000\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.9290 - accuracy: 0.1667 - val_loss: 60.8916 - val_accuracy: 0.1556\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.8518 - accuracy: 0.1542 - val_loss: 60.8134 - val_accuracy: 0.1556\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.7742 - accuracy: 0.1542 - val_loss: 60.7347 - val_accuracy: 0.1556\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.6957 - accuracy: 0.1542 - val_loss: 60.6549 - val_accuracy: 0.1556\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6185 - accuracy: 0.1393 - val_loss: 60.5763 - val_accuracy: 0.1778\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.5410 - accuracy: 0.1468 - val_loss: 60.5002 - val_accuracy: 0.1778\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4633 - accuracy: 0.1468 - val_loss: 60.4226 - val_accuracy: 0.1778\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3862 - accuracy: 0.1468 - val_loss: 60.3444 - val_accuracy: 0.1778\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.3091 - accuracy: 0.1542 - val_loss: 60.2674 - val_accuracy: 0.1556\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.2316 - accuracy: 0.1542 - val_loss: 60.1929 - val_accuracy: 0.1556\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.1541 - accuracy: 0.1542 - val_loss: 60.1143 - val_accuracy: 0.1556\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0780 - accuracy: 0.1443 - val_loss: 60.0371 - val_accuracy: 0.1333\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0010 - accuracy: 0.1393 - val_loss: 59.9618 - val_accuracy: 0.1556\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.9244 - accuracy: 0.1443 - val_loss: 59.8854 - val_accuracy: 0.1778\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8481 - accuracy: 0.1617 - val_loss: 59.8070 - val_accuracy: 0.2000\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.7722 - accuracy: 0.1716 - val_loss: 59.7289 - val_accuracy: 0.2000\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.6957 - accuracy: 0.1567 - val_loss: 59.6501 - val_accuracy: 0.1556\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.6193 - accuracy: 0.1542 - val_loss: 59.5722 - val_accuracy: 0.1556\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.5431 - accuracy: 0.1592 - val_loss: 59.4956 - val_accuracy: 0.2000\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.4676 - accuracy: 0.1617 - val_loss: 59.4206 - val_accuracy: 0.2000\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.3905 - accuracy: 0.1567 - val_loss: 59.3481 - val_accuracy: 0.2000\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.3143 - accuracy: 0.1567 - val_loss: 59.2751 - val_accuracy: 0.2000\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.2384 - accuracy: 0.1642 - val_loss: 59.2037 - val_accuracy: 0.1778\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.1632 - accuracy: 0.1517 - val_loss: 59.1325 - val_accuracy: 0.1556\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.0893 - accuracy: 0.1542 - val_loss: 59.0622 - val_accuracy: 0.1556\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.0144 - accuracy: 0.1542 - val_loss: 58.9921 - val_accuracy: 0.1556\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.9391 - accuracy: 0.1741 - val_loss: 58.9097 - val_accuracy: 0.1556\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.8618 - accuracy: 0.1642 - val_loss: 58.8281 - val_accuracy: 0.0889\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.7872 - accuracy: 0.1841 - val_loss: 58.7486 - val_accuracy: 0.2000\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.7118 - accuracy: 0.1692 - val_loss: 58.6718 - val_accuracy: 0.2000\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.6371 - accuracy: 0.1567 - val_loss: 58.5968 - val_accuracy: 0.1556\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.5621 - accuracy: 0.1741 - val_loss: 58.5205 - val_accuracy: 0.2000\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.4867 - accuracy: 0.1642 - val_loss: 58.4476 - val_accuracy: 0.2000\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.4127 - accuracy: 0.1617 - val_loss: 58.3767 - val_accuracy: 0.1556\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.3379 - accuracy: 0.1692 - val_loss: 58.3030 - val_accuracy: 0.1556\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2639 - accuracy: 0.1542 - val_loss: 58.2264 - val_accuracy: 0.1556\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1887 - accuracy: 0.1517 - val_loss: 58.1501 - val_accuracy: 0.2000\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.1142 - accuracy: 0.1741 - val_loss: 58.0768 - val_accuracy: 0.2000\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.0405 - accuracy: 0.1692 - val_loss: 58.0039 - val_accuracy: 0.1111\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.9671 - accuracy: 0.1443 - val_loss: 57.9302 - val_accuracy: 0.1111\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.8938 - accuracy: 0.1443 - val_loss: 57.8615 - val_accuracy: 0.1111\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.8199 - accuracy: 0.1443 - val_loss: 57.7909 - val_accuracy: 0.1111\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7456 - accuracy: 0.1443 - val_loss: 57.7156 - val_accuracy: 0.1111\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6710 - accuracy: 0.1443 - val_loss: 57.6405 - val_accuracy: 0.1111\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5966 - accuracy: 0.1841 - val_loss: 57.5667 - val_accuracy: 0.1778\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.5233 - accuracy: 0.1468 - val_loss: 57.4931 - val_accuracy: 0.1778\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.4511 - accuracy: 0.1468 - val_loss: 57.4192 - val_accuracy: 0.1778\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3777 - accuracy: 0.1468 - val_loss: 57.3479 - val_accuracy: 0.1778\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.3037 - accuracy: 0.1468 - val_loss: 57.2778 - val_accuracy: 0.1778\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.2311 - accuracy: 0.1716 - val_loss: 57.2103 - val_accuracy: 0.0889\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.1595 - accuracy: 0.1418 - val_loss: 57.1380 - val_accuracy: 0.1111\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.0865 - accuracy: 0.1692 - val_loss: 57.0592 - val_accuracy: 0.1111\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0127 - accuracy: 0.1443 - val_loss: 56.9816 - val_accuracy: 0.1111\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9391 - accuracy: 0.1542 - val_loss: 56.9049 - val_accuracy: 0.2000\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.8664 - accuracy: 0.1617 - val_loss: 56.8292 - val_accuracy: 0.2000\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.7928 - accuracy: 0.1542 - val_loss: 56.7562 - val_accuracy: 0.1778\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7205 - accuracy: 0.1468 - val_loss: 56.6810 - val_accuracy: 0.1778\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.6487 - accuracy: 0.1468 - val_loss: 56.6100 - val_accuracy: 0.1778\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.5774 - accuracy: 0.1468 - val_loss: 56.5413 - val_accuracy: 0.1778\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.5036 - accuracy: 0.1468 - val_loss: 56.4717 - val_accuracy: 0.1778\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.4316 - accuracy: 0.1468 - val_loss: 56.4004 - val_accuracy: 0.1778\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.3601 - accuracy: 0.1816 - val_loss: 56.3284 - val_accuracy: 0.1111\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.2882 - accuracy: 0.1617 - val_loss: 56.2595 - val_accuracy: 0.1111\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2168 - accuracy: 0.1493 - val_loss: 56.1888 - val_accuracy: 0.1333\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.1447 - accuracy: 0.1716 - val_loss: 56.1181 - val_accuracy: 0.2000\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0727 - accuracy: 0.1592 - val_loss: 56.0442 - val_accuracy: 0.2000\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0001 - accuracy: 0.1716 - val_loss: 55.9684 - val_accuracy: 0.2000\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.9295 - accuracy: 0.1468 - val_loss: 55.8957 - val_accuracy: 0.1778\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.8587 - accuracy: 0.1567 - val_loss: 55.8237 - val_accuracy: 0.1556\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.7873 - accuracy: 0.1542 - val_loss: 55.7507 - val_accuracy: 0.1778\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.7150 - accuracy: 0.1468 - val_loss: 55.6810 - val_accuracy: 0.1778\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.6436 - accuracy: 0.1468 - val_loss: 55.6104 - val_accuracy: 0.1778\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5730 - accuracy: 0.1468 - val_loss: 55.5419 - val_accuracy: 0.1778\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55.5023 - accuracy: 0.1468 - val_loss: 55.4707 - val_accuracy: 0.1778\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.4304 - accuracy: 0.1667 - val_loss: 55.4013 - val_accuracy: 0.1778\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.3597 - accuracy: 0.1766 - val_loss: 55.3318 - val_accuracy: 0.1556\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2899 - accuracy: 0.1940 - val_loss: 55.2618 - val_accuracy: 0.1556\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2202 - accuracy: 0.1567 - val_loss: 55.1912 - val_accuracy: 0.1556\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1494 - accuracy: 0.1542 - val_loss: 55.1234 - val_accuracy: 0.1556\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.0782 - accuracy: 0.1468 - val_loss: 55.0520 - val_accuracy: 0.1778\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0073 - accuracy: 0.1468 - val_loss: 54.9787 - val_accuracy: 0.1778\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.9367 - accuracy: 0.1567 - val_loss: 54.9066 - val_accuracy: 0.1778\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8660 - accuracy: 0.1517 - val_loss: 54.8350 - val_accuracy: 0.1556\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.7969 - accuracy: 0.1542 - val_loss: 54.7661 - val_accuracy: 0.1556\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.7270 - accuracy: 0.1542 - val_loss: 54.6950 - val_accuracy: 0.1556\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.6577 - accuracy: 0.1542 - val_loss: 54.6225 - val_accuracy: 0.1556\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5879 - accuracy: 0.1592 - val_loss: 54.5498 - val_accuracy: 0.1778\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.5170 - accuracy: 0.1692 - val_loss: 54.4838 - val_accuracy: 0.2000\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.4462 - accuracy: 0.1741 - val_loss: 54.4164 - val_accuracy: 0.2000\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3766 - accuracy: 0.1592 - val_loss: 54.3492 - val_accuracy: 0.1778\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.3069 - accuracy: 0.1468 - val_loss: 54.2794 - val_accuracy: 0.1778\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.2374 - accuracy: 0.1468 - val_loss: 54.2077 - val_accuracy: 0.1778\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1682 - accuracy: 0.1468 - val_loss: 54.1357 - val_accuracy: 0.1778\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.0989 - accuracy: 0.1468 - val_loss: 54.0652 - val_accuracy: 0.1556\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0303 - accuracy: 0.1617 - val_loss: 53.9969 - val_accuracy: 0.0889\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.9610 - accuracy: 0.1642 - val_loss: 53.9293 - val_accuracy: 0.1556\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.8920 - accuracy: 0.1965 - val_loss: 53.8602 - val_accuracy: 0.1778\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.8223 - accuracy: 0.1567 - val_loss: 53.7914 - val_accuracy: 0.2000\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.7535 - accuracy: 0.1517 - val_loss: 53.7229 - val_accuracy: 0.1778\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.6854 - accuracy: 0.1468 - val_loss: 53.6545 - val_accuracy: 0.1778\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6158 - accuracy: 0.1468 - val_loss: 53.5852 - val_accuracy: 0.1778\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.5465 - accuracy: 0.1468 - val_loss: 53.5176 - val_accuracy: 0.1778\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.4779 - accuracy: 0.1468 - val_loss: 53.4495 - val_accuracy: 0.1778\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4093 - accuracy: 0.1468 - val_loss: 53.3802 - val_accuracy: 0.1778\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.3407 - accuracy: 0.1468 - val_loss: 53.3091 - val_accuracy: 0.1556\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.2734 - accuracy: 0.1542 - val_loss: 53.2375 - val_accuracy: 0.1556\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2053 - accuracy: 0.1542 - val_loss: 53.1691 - val_accuracy: 0.1556\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.1365 - accuracy: 0.1542 - val_loss: 53.1001 - val_accuracy: 0.1778\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0694 - accuracy: 0.1468 - val_loss: 53.0307 - val_accuracy: 0.2000\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0016 - accuracy: 0.1542 - val_loss: 52.9637 - val_accuracy: 0.2000\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52.9326 - accuracy: 0.1567 - val_loss: 52.8966 - val_accuracy: 0.2000\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52.8650 - accuracy: 0.1567 - val_loss: 52.8303 - val_accuracy: 0.2000\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7964 - accuracy: 0.1567 - val_loss: 52.7641 - val_accuracy: 0.2000\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.7285 - accuracy: 0.1567 - val_loss: 52.6979 - val_accuracy: 0.2000\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6611 - accuracy: 0.1567 - val_loss: 52.6288 - val_accuracy: 0.2000\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52.5927 - accuracy: 0.1567 - val_loss: 52.5626 - val_accuracy: 0.2000\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.5250 - accuracy: 0.1766 - val_loss: 52.4982 - val_accuracy: 0.2000\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.4578 - accuracy: 0.1667 - val_loss: 52.4339 - val_accuracy: 0.1778\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.3909 - accuracy: 0.1468 - val_loss: 52.3686 - val_accuracy: 0.1778\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3237 - accuracy: 0.1468 - val_loss: 52.3022 - val_accuracy: 0.1778\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.2572 - accuracy: 0.1468 - val_loss: 52.2356 - val_accuracy: 0.1778\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.1897 - accuracy: 0.1368 - val_loss: 52.1678 - val_accuracy: 0.1556\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1213 - accuracy: 0.1542 - val_loss: 52.0960 - val_accuracy: 0.1556\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.0547 - accuracy: 0.1542 - val_loss: 52.0231 - val_accuracy: 0.1556\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.9879 - accuracy: 0.1542 - val_loss: 51.9541 - val_accuracy: 0.1556\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9196 - accuracy: 0.1617 - val_loss: 51.8891 - val_accuracy: 0.1556\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8527 - accuracy: 0.1692 - val_loss: 51.8282 - val_accuracy: 0.0667\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.7871 - accuracy: 0.1443 - val_loss: 51.7655 - val_accuracy: 0.0667\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.7208 - accuracy: 0.1443 - val_loss: 51.6992 - val_accuracy: 0.0667\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6535 - accuracy: 0.1642 - val_loss: 51.6277 - val_accuracy: 0.1556\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.5859 - accuracy: 0.1517 - val_loss: 51.5573 - val_accuracy: 0.2000\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.5192 - accuracy: 0.1617 - val_loss: 51.4895 - val_accuracy: 0.2000\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.4539 - accuracy: 0.1567 - val_loss: 51.4223 - val_accuracy: 0.2000\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3871 - accuracy: 0.1567 - val_loss: 51.3566 - val_accuracy: 0.2000\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3204 - accuracy: 0.1592 - val_loss: 51.2911 - val_accuracy: 0.1778\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51.2540 - accuracy: 0.1468 - val_loss: 51.2271 - val_accuracy: 0.1778\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1877 - accuracy: 0.1468 - val_loss: 51.1598 - val_accuracy: 0.2000\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1214 - accuracy: 0.1816 - val_loss: 51.0957 - val_accuracy: 0.2000\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0564 - accuracy: 0.1965 - val_loss: 51.0296 - val_accuracy: 0.2000\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.9909 - accuracy: 0.1741 - val_loss: 50.9638 - val_accuracy: 0.2000\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.9244 - accuracy: 0.1493 - val_loss: 50.8964 - val_accuracy: 0.1778\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.8588 - accuracy: 0.1468 - val_loss: 50.8293 - val_accuracy: 0.1778\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.7927 - accuracy: 0.1493 - val_loss: 50.7612 - val_accuracy: 0.2000\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.7271 - accuracy: 0.1493 - val_loss: 50.6939 - val_accuracy: 0.1778\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6616 - accuracy: 0.1468 - val_loss: 50.6273 - val_accuracy: 0.1778\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.5961 - accuracy: 0.1468 - val_loss: 50.5621 - val_accuracy: 0.1778\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.5316 - accuracy: 0.1468 - val_loss: 50.4990 - val_accuracy: 0.1778\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4652 - accuracy: 0.1443 - val_loss: 50.4323 - val_accuracy: 0.1556\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.3997 - accuracy: 0.1542 - val_loss: 50.3679 - val_accuracy: 0.1556\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.3340 - accuracy: 0.1542 - val_loss: 50.3016 - val_accuracy: 0.1778\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.2692 - accuracy: 0.1468 - val_loss: 50.2351 - val_accuracy: 0.2000\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2051 - accuracy: 0.1493 - val_loss: 50.1688 - val_accuracy: 0.2000\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.1401 - accuracy: 0.1567 - val_loss: 50.1070 - val_accuracy: 0.2000\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.0745 - accuracy: 0.1617 - val_loss: 50.0445 - val_accuracy: 0.2000\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.0094 - accuracy: 0.1791 - val_loss: 49.9810 - val_accuracy: 0.2000\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.9449 - accuracy: 0.1642 - val_loss: 49.9154 - val_accuracy: 0.2000\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8800 - accuracy: 0.1567 - val_loss: 49.8497 - val_accuracy: 0.2000\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8152 - accuracy: 0.1617 - val_loss: 49.7865 - val_accuracy: 0.1778\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.7505 - accuracy: 0.1468 - val_loss: 49.7196 - val_accuracy: 0.1778\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.6863 - accuracy: 0.1468 - val_loss: 49.6538 - val_accuracy: 0.1778\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.6226 - accuracy: 0.1468 - val_loss: 49.5889 - val_accuracy: 0.1778\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.5580 - accuracy: 0.1617 - val_loss: 49.5269 - val_accuracy: 0.1556\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4933 - accuracy: 0.1542 - val_loss: 49.4627 - val_accuracy: 0.1556\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4296 - accuracy: 0.1542 - val_loss: 49.3995 - val_accuracy: 0.1556\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.3646 - accuracy: 0.1542 - val_loss: 49.3371 - val_accuracy: 0.1556\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3006 - accuracy: 0.1542 - val_loss: 49.2761 - val_accuracy: 0.1778\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.2368 - accuracy: 0.1542 - val_loss: 49.2114 - val_accuracy: 0.2000\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1729 - accuracy: 0.1667 - val_loss: 49.1465 - val_accuracy: 0.1778\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1086 - accuracy: 0.1468 - val_loss: 49.0829 - val_accuracy: 0.1778\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0443 - accuracy: 0.1468 - val_loss: 49.0177 - val_accuracy: 0.1778\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9812 - accuracy: 0.1468 - val_loss: 48.9521 - val_accuracy: 0.1778\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9170 - accuracy: 0.1468 - val_loss: 48.8892 - val_accuracy: 0.1778\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.8535 - accuracy: 0.1592 - val_loss: 48.8255 - val_accuracy: 0.2000\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7892 - accuracy: 0.1617 - val_loss: 48.7643 - val_accuracy: 0.1778\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.7262 - accuracy: 0.1468 - val_loss: 48.7011 - val_accuracy: 0.1778\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6633 - accuracy: 0.1468 - val_loss: 48.6372 - val_accuracy: 0.1778\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.5999 - accuracy: 0.1468 - val_loss: 48.5738 - val_accuracy: 0.1778\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.5368 - accuracy: 0.1592 - val_loss: 48.5092 - val_accuracy: 0.2000\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4728 - accuracy: 0.1567 - val_loss: 48.4472 - val_accuracy: 0.1778\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4100 - accuracy: 0.1468 - val_loss: 48.3833 - val_accuracy: 0.1778\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.3463 - accuracy: 0.1468 - val_loss: 48.3186 - val_accuracy: 0.1778\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.2838 - accuracy: 0.1468 - val_loss: 48.2571 - val_accuracy: 0.1778\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.2200 - accuracy: 0.1468 - val_loss: 48.1928 - val_accuracy: 0.2000\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1576 - accuracy: 0.1592 - val_loss: 48.1291 - val_accuracy: 0.2000\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.0942 - accuracy: 0.1567 - val_loss: 48.0661 - val_accuracy: 0.2000\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.0315 - accuracy: 0.1567 - val_loss: 48.0046 - val_accuracy: 0.2000\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.9685 - accuracy: 0.1667 - val_loss: 47.9438 - val_accuracy: 0.1778\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.9056 - accuracy: 0.1468 - val_loss: 47.8831 - val_accuracy: 0.1778\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8434 - accuracy: 0.1542 - val_loss: 47.8223 - val_accuracy: 0.1778\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.7814 - accuracy: 0.1617 - val_loss: 47.7595 - val_accuracy: 0.1778\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.7179 - accuracy: 0.1468 - val_loss: 47.6966 - val_accuracy: 0.1778\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.6557 - accuracy: 0.1468 - val_loss: 47.6329 - val_accuracy: 0.1556\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5941 - accuracy: 0.1542 - val_loss: 47.5668 - val_accuracy: 0.1778\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5322 - accuracy: 0.1567 - val_loss: 47.5043 - val_accuracy: 0.2222\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.4700 - accuracy: 0.1692 - val_loss: 47.4426 - val_accuracy: 0.2222\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.4081 - accuracy: 0.1741 - val_loss: 47.3811 - val_accuracy: 0.1333\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47.3458 - accuracy: 0.1716 - val_loss: 47.3188 - val_accuracy: 0.2000\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.2843 - accuracy: 0.1667 - val_loss: 47.2561 - val_accuracy: 0.2000\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.2204 - accuracy: 0.1791 - val_loss: 47.1921 - val_accuracy: 0.2000\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1589 - accuracy: 0.1716 - val_loss: 47.1288 - val_accuracy: 0.2000\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0971 - accuracy: 0.1517 - val_loss: 47.0692 - val_accuracy: 0.1778\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.0351 - accuracy: 0.1468 - val_loss: 47.0102 - val_accuracy: 0.1778\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.9739 - accuracy: 0.1468 - val_loss: 46.9498 - val_accuracy: 0.1778\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.9128 - accuracy: 0.1468 - val_loss: 46.8872 - val_accuracy: 0.1778\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.8510 - accuracy: 0.1468 - val_loss: 46.8226 - val_accuracy: 0.1778\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46.7896 - accuracy: 0.1592 - val_loss: 46.7603 - val_accuracy: 0.1556\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7282 - accuracy: 0.1542 - val_loss: 46.6982 - val_accuracy: 0.1556\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6665 - accuracy: 0.1542 - val_loss: 46.6370 - val_accuracy: 0.1556\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.6049 - accuracy: 0.1418 - val_loss: 46.5798 - val_accuracy: 0.1778\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.5436 - accuracy: 0.1468 - val_loss: 46.5216 - val_accuracy: 0.1778\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.4824 - accuracy: 0.1468 - val_loss: 46.4599 - val_accuracy: 0.1778\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46.4214 - accuracy: 0.1468 - val_loss: 46.3977 - val_accuracy: 0.1778\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.3603 - accuracy: 0.1468 - val_loss: 46.3351 - val_accuracy: 0.1778\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.2983 - accuracy: 0.1468 - val_loss: 46.2730 - val_accuracy: 0.1778\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2374 - accuracy: 0.1567 - val_loss: 46.2111 - val_accuracy: 0.1556\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1765 - accuracy: 0.1542 - val_loss: 46.1498 - val_accuracy: 0.1556\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1164 - accuracy: 0.1940 - val_loss: 46.0922 - val_accuracy: 0.1556\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0556 - accuracy: 0.1915 - val_loss: 46.0325 - val_accuracy: 0.1556\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.9942 - accuracy: 0.1542 - val_loss: 45.9725 - val_accuracy: 0.1556\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.9333 - accuracy: 0.1542 - val_loss: 45.9127 - val_accuracy: 0.1556\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8725 - accuracy: 0.1393 - val_loss: 45.8497 - val_accuracy: 0.1778\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8109 - accuracy: 0.1468 - val_loss: 45.7860 - val_accuracy: 0.1778\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7505 - accuracy: 0.1269 - val_loss: 45.7235 - val_accuracy: 0.1778\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.6903 - accuracy: 0.1468 - val_loss: 45.6608 - val_accuracy: 0.1778\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6305 - accuracy: 0.1542 - val_loss: 45.5993 - val_accuracy: 0.2000\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.5701 - accuracy: 0.1517 - val_loss: 45.5383 - val_accuracy: 0.2000\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.5100 - accuracy: 0.1567 - val_loss: 45.4775 - val_accuracy: 0.2000\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.4491 - accuracy: 0.1642 - val_loss: 45.4177 - val_accuracy: 0.2000\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3886 - accuracy: 0.1468 - val_loss: 45.3591 - val_accuracy: 0.1778\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3284 - accuracy: 0.1468 - val_loss: 45.3024 - val_accuracy: 0.1778\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.2686 - accuracy: 0.1642 - val_loss: 45.2454 - val_accuracy: 0.2000\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.2094 - accuracy: 0.2139 - val_loss: 45.1873 - val_accuracy: 0.2000\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.1491 - accuracy: 0.2090 - val_loss: 45.1262 - val_accuracy: 0.2000\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.0888 - accuracy: 0.1642 - val_loss: 45.0629 - val_accuracy: 0.2000\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.0292 - accuracy: 0.1592 - val_loss: 45.0006 - val_accuracy: 0.2000\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9697 - accuracy: 0.1567 - val_loss: 44.9395 - val_accuracy: 0.2000\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9098 - accuracy: 0.1567 - val_loss: 44.8789 - val_accuracy: 0.2000\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.8517 - accuracy: 0.1642 - val_loss: 44.8199 - val_accuracy: 0.2000\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7919 - accuracy: 0.1642 - val_loss: 44.7638 - val_accuracy: 0.2000\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.7307 - accuracy: 0.1567 - val_loss: 44.7080 - val_accuracy: 0.1778\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6713 - accuracy: 0.1468 - val_loss: 44.6502 - val_accuracy: 0.1778\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.6122 - accuracy: 0.1468 - val_loss: 44.5880 - val_accuracy: 0.1778\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.5533 - accuracy: 0.1468 - val_loss: 44.5305 - val_accuracy: 0.1778\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.4937 - accuracy: 0.1468 - val_loss: 44.4682 - val_accuracy: 0.1778\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.4338 - accuracy: 0.1468 - val_loss: 44.4069 - val_accuracy: 0.1778\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.3749 - accuracy: 0.1468 - val_loss: 44.3478 - val_accuracy: 0.1778\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.3150 - accuracy: 0.1468 - val_loss: 44.2865 - val_accuracy: 0.1778\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.2562 - accuracy: 0.1468 - val_loss: 44.2297 - val_accuracy: 0.1556\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.1971 - accuracy: 0.1542 - val_loss: 44.1728 - val_accuracy: 0.1556\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1386 - accuracy: 0.1542 - val_loss: 44.1120 - val_accuracy: 0.1556\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.0802 - accuracy: 0.1542 - val_loss: 44.0520 - val_accuracy: 0.1556\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0203 - accuracy: 0.1493 - val_loss: 43.9944 - val_accuracy: 0.1778\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.9623 - accuracy: 0.1468 - val_loss: 43.9373 - val_accuracy: 0.1778\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9039 - accuracy: 0.1468 - val_loss: 43.8795 - val_accuracy: 0.1778\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.8452 - accuracy: 0.1468 - val_loss: 43.8248 - val_accuracy: 0.1778\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7863 - accuracy: 0.1468 - val_loss: 43.7675 - val_accuracy: 0.1778\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.7286 - accuracy: 0.1468 - val_loss: 43.7106 - val_accuracy: 0.2000\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6701 - accuracy: 0.1617 - val_loss: 43.6528 - val_accuracy: 0.1778\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.6112 - accuracy: 0.1468 - val_loss: 43.5952 - val_accuracy: 0.1778\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.5538 - accuracy: 0.1468 - val_loss: 43.5366 - val_accuracy: 0.1778\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4943 - accuracy: 0.1468 - val_loss: 43.4757 - val_accuracy: 0.1778\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4354 - accuracy: 0.1468 - val_loss: 43.4141 - val_accuracy: 0.1778\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.3775 - accuracy: 0.1567 - val_loss: 43.3501 - val_accuracy: 0.1556\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3193 - accuracy: 0.1542 - val_loss: 43.2881 - val_accuracy: 0.1556\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2618 - accuracy: 0.1542 - val_loss: 43.2276 - val_accuracy: 0.1556\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2044 - accuracy: 0.1716 - val_loss: 43.1710 - val_accuracy: 0.1778\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.1453 - accuracy: 0.1766 - val_loss: 43.1174 - val_accuracy: 0.1778\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0869 - accuracy: 0.1766 - val_loss: 43.0633 - val_accuracy: 0.2000\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0292 - accuracy: 0.1617 - val_loss: 43.0066 - val_accuracy: 0.2000\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.9708 - accuracy: 0.1766 - val_loss: 42.9489 - val_accuracy: 0.2000\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9133 - accuracy: 0.1766 - val_loss: 42.8901 - val_accuracy: 0.2000\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.8562 - accuracy: 0.1567 - val_loss: 42.8326 - val_accuracy: 0.2000\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7987 - accuracy: 0.1567 - val_loss: 42.7742 - val_accuracy: 0.2000\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7407 - accuracy: 0.1891 - val_loss: 42.7178 - val_accuracy: 0.2000\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.6833 - accuracy: 0.1990 - val_loss: 42.6591 - val_accuracy: 0.2000\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.6256 - accuracy: 0.1667 - val_loss: 42.6030 - val_accuracy: 0.1111\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.5687 - accuracy: 0.2015 - val_loss: 42.5447 - val_accuracy: 0.2000\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5105 - accuracy: 0.1791 - val_loss: 42.4849 - val_accuracy: 0.2000\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.4539 - accuracy: 0.1667 - val_loss: 42.4281 - val_accuracy: 0.2000\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3971 - accuracy: 0.1766 - val_loss: 42.3715 - val_accuracy: 0.2000\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3397 - accuracy: 0.2065 - val_loss: 42.3146 - val_accuracy: 0.1778\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.2813 - accuracy: 0.1592 - val_loss: 42.2568 - val_accuracy: 0.1556\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.2241 - accuracy: 0.1493 - val_loss: 42.1993 - val_accuracy: 0.1778\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.1671 - accuracy: 0.1468 - val_loss: 42.1409 - val_accuracy: 0.1778\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.1107 - accuracy: 0.1393 - val_loss: 42.0837 - val_accuracy: 0.1556\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0544 - accuracy: 0.1542 - val_loss: 42.0231 - val_accuracy: 0.1556\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.9972 - accuracy: 0.1542 - val_loss: 41.9699 - val_accuracy: 0.1556\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41.9408 - accuracy: 0.1443 - val_loss: 41.9165 - val_accuracy: 0.1778\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.8845 - accuracy: 0.1443 - val_loss: 41.8584 - val_accuracy: 0.1556\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.8278 - accuracy: 0.1493 - val_loss: 41.7992 - val_accuracy: 0.1778\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.7700 - accuracy: 0.1468 - val_loss: 41.7438 - val_accuracy: 0.1778\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7129 - accuracy: 0.1468 - val_loss: 41.6888 - val_accuracy: 0.1778\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.6561 - accuracy: 0.1468 - val_loss: 41.6331 - val_accuracy: 0.1778\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.5997 - accuracy: 0.1468 - val_loss: 41.5774 - val_accuracy: 0.1778\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.5434 - accuracy: 0.1468 - val_loss: 41.5243 - val_accuracy: 0.1778\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4871 - accuracy: 0.1567 - val_loss: 41.4677 - val_accuracy: 0.1778\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.4305 - accuracy: 0.1841 - val_loss: 41.4086 - val_accuracy: 0.1778\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3745 - accuracy: 0.1418 - val_loss: 41.3510 - val_accuracy: 0.1556\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3179 - accuracy: 0.1393 - val_loss: 41.2927 - val_accuracy: 0.1778\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.2621 - accuracy: 0.1468 - val_loss: 41.2368 - val_accuracy: 0.1778\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.2059 - accuracy: 0.1468 - val_loss: 41.1834 - val_accuracy: 0.1778\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1497 - accuracy: 0.1468 - val_loss: 41.1290 - val_accuracy: 0.1778\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.0938 - accuracy: 0.1468 - val_loss: 41.0720 - val_accuracy: 0.1778\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.0371 - accuracy: 0.1468 - val_loss: 41.0165 - val_accuracy: 0.1778\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.9812 - accuracy: 0.1468 - val_loss: 40.9611 - val_accuracy: 0.2000\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.9254 - accuracy: 0.1592 - val_loss: 40.9041 - val_accuracy: 0.2444\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8703 - accuracy: 0.1741 - val_loss: 40.8469 - val_accuracy: 0.2222\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8147 - accuracy: 0.2040 - val_loss: 40.7920 - val_accuracy: 0.2222\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.7592 - accuracy: 0.2040 - val_loss: 40.7378 - val_accuracy: 0.2222\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.7035 - accuracy: 0.1990 - val_loss: 40.6842 - val_accuracy: 0.2000\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6478 - accuracy: 0.1866 - val_loss: 40.6293 - val_accuracy: 0.1556\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5922 - accuracy: 0.1542 - val_loss: 40.5748 - val_accuracy: 0.1556\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.5371 - accuracy: 0.1542 - val_loss: 40.5185 - val_accuracy: 0.1778\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.4815 - accuracy: 0.1468 - val_loss: 40.4615 - val_accuracy: 0.1778\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.4259 - accuracy: 0.1468 - val_loss: 40.4046 - val_accuracy: 0.1778\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.3697 - accuracy: 0.1468 - val_loss: 40.3476 - val_accuracy: 0.1778\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.3144 - accuracy: 0.1468 - val_loss: 40.2923 - val_accuracy: 0.1556\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.2596 - accuracy: 0.1791 - val_loss: 40.2388 - val_accuracy: 0.1111\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.2054 - accuracy: 0.1567 - val_loss: 40.1833 - val_accuracy: 0.1333\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.1497 - accuracy: 0.2015 - val_loss: 40.1260 - val_accuracy: 0.2000\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0941 - accuracy: 0.1990 - val_loss: 40.0724 - val_accuracy: 0.2000\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.0388 - accuracy: 0.1692 - val_loss: 40.0189 - val_accuracy: 0.1778\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9844 - accuracy: 0.1468 - val_loss: 39.9654 - val_accuracy: 0.1778\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9296 - accuracy: 0.1468 - val_loss: 39.9111 - val_accuracy: 0.1778\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.8738 - accuracy: 0.1468 - val_loss: 39.8568 - val_accuracy: 0.1556\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.8198 - accuracy: 0.1915 - val_loss: 39.8037 - val_accuracy: 0.1556\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7649 - accuracy: 0.1940 - val_loss: 39.7460 - val_accuracy: 0.1778\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.7094 - accuracy: 0.1791 - val_loss: 39.6892 - val_accuracy: 0.2000\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.6548 - accuracy: 0.1692 - val_loss: 39.6332 - val_accuracy: 0.2000\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.6003 - accuracy: 0.1716 - val_loss: 39.5797 - val_accuracy: 0.2000\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.5456 - accuracy: 0.1667 - val_loss: 39.5286 - val_accuracy: 0.1778\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.4912 - accuracy: 0.1468 - val_loss: 39.4747 - val_accuracy: 0.1778\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.4370 - accuracy: 0.1468 - val_loss: 39.4188 - val_accuracy: 0.1778\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.3821 - accuracy: 0.1468 - val_loss: 39.3632 - val_accuracy: 0.1556\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.3288 - accuracy: 0.1542 - val_loss: 39.3083 - val_accuracy: 0.1556\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.2761 - accuracy: 0.1542 - val_loss: 39.2554 - val_accuracy: 0.1556\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.2216 - accuracy: 0.1542 - val_loss: 39.2014 - val_accuracy: 0.1556\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.1667 - accuracy: 0.1542 - val_loss: 39.1486 - val_accuracy: 0.1556\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.1125 - accuracy: 0.1343 - val_loss: 39.0940 - val_accuracy: 0.1778\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.0574 - accuracy: 0.1468 - val_loss: 39.0402 - val_accuracy: 0.1778\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.0041 - accuracy: 0.1294 - val_loss: 38.9870 - val_accuracy: 0.1556\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.9501 - accuracy: 0.1542 - val_loss: 38.9311 - val_accuracy: 0.1556\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8953 - accuracy: 0.1493 - val_loss: 38.8740 - val_accuracy: 0.1778\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8420 - accuracy: 0.1468 - val_loss: 38.8182 - val_accuracy: 0.2000\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.7876 - accuracy: 0.1642 - val_loss: 38.7661 - val_accuracy: 0.2000\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.7337 - accuracy: 0.1716 - val_loss: 38.7137 - val_accuracy: 0.2000\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.6801 - accuracy: 0.2015 - val_loss: 38.6613 - val_accuracy: 0.2000\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.6263 - accuracy: 0.1990 - val_loss: 38.6087 - val_accuracy: 0.2000\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.5731 - accuracy: 0.1990 - val_loss: 38.5592 - val_accuracy: 0.1778\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5191 - accuracy: 0.1915 - val_loss: 38.5033 - val_accuracy: 0.1778\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4656 - accuracy: 0.1990 - val_loss: 38.4492 - val_accuracy: 0.1556\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4122 - accuracy: 0.1891 - val_loss: 38.3970 - val_accuracy: 0.1556\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.3595 - accuracy: 0.1617 - val_loss: 38.3408 - val_accuracy: 0.1556\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.3052 - accuracy: 0.1542 - val_loss: 38.2867 - val_accuracy: 0.1556\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.2515 - accuracy: 0.1766 - val_loss: 38.2328 - val_accuracy: 0.2000\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.1988 - accuracy: 0.1866 - val_loss: 38.1797 - val_accuracy: 0.2000\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.1455 - accuracy: 0.1692 - val_loss: 38.1250 - val_accuracy: 0.2000\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0929 - accuracy: 0.1567 - val_loss: 38.0720 - val_accuracy: 0.2000\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.0391 - accuracy: 0.1667 - val_loss: 38.0224 - val_accuracy: 0.2000\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.9863 - accuracy: 0.1915 - val_loss: 37.9745 - val_accuracy: 0.1333\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37.9340 - accuracy: 0.1791 - val_loss: 37.9261 - val_accuracy: 0.1111\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.8834 - accuracy: 0.1741 - val_loss: 37.8762 - val_accuracy: 0.1111\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.8296 - accuracy: 0.1841 - val_loss: 37.8197 - val_accuracy: 0.1778\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37.7754 - accuracy: 0.1915 - val_loss: 37.7623 - val_accuracy: 0.1778\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.7219 - accuracy: 0.1791 - val_loss: 37.7052 - val_accuracy: 0.1556\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.6677 - accuracy: 0.1716 - val_loss: 37.6505 - val_accuracy: 0.1556\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.6158 - accuracy: 0.1368 - val_loss: 37.5977 - val_accuracy: 0.1778\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5630 - accuracy: 0.1468 - val_loss: 37.5455 - val_accuracy: 0.1778\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.5104 - accuracy: 0.1517 - val_loss: 37.4967 - val_accuracy: 0.1556\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4583 - accuracy: 0.1990 - val_loss: 37.4447 - val_accuracy: 0.1556\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4062 - accuracy: 0.1915 - val_loss: 37.3912 - val_accuracy: 0.1111\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3547 - accuracy: 0.1940 - val_loss: 37.3329 - val_accuracy: 0.2000\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.3014 - accuracy: 0.2114 - val_loss: 37.2777 - val_accuracy: 0.2000\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2492 - accuracy: 0.2065 - val_loss: 37.2254 - val_accuracy: 0.2000\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.1956 - accuracy: 0.2114 - val_loss: 37.1743 - val_accuracy: 0.2000\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.1427 - accuracy: 0.1617 - val_loss: 37.1243 - val_accuracy: 0.2000\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.0916 - accuracy: 0.1418 - val_loss: 37.0727 - val_accuracy: 0.1778\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.0396 - accuracy: 0.1468 - val_loss: 37.0195 - val_accuracy: 0.1778\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9870 - accuracy: 0.1468 - val_loss: 36.9654 - val_accuracy: 0.1778\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.9341 - accuracy: 0.1418 - val_loss: 36.9126 - val_accuracy: 0.1556\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36.8825 - accuracy: 0.1517 - val_loss: 36.8623 - val_accuracy: 0.2000\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.8307 - accuracy: 0.1692 - val_loss: 36.8106 - val_accuracy: 0.2000\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.7782 - accuracy: 0.1567 - val_loss: 36.7597 - val_accuracy: 0.1778\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7263 - accuracy: 0.1468 - val_loss: 36.7068 - val_accuracy: 0.1778\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.6754 - accuracy: 0.1468 - val_loss: 36.6547 - val_accuracy: 0.1778\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6237 - accuracy: 0.1468 - val_loss: 36.6026 - val_accuracy: 0.1778\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5714 - accuracy: 0.1468 - val_loss: 36.5516 - val_accuracy: 0.1778\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5193 - accuracy: 0.1468 - val_loss: 36.5017 - val_accuracy: 0.1778\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.4677 - accuracy: 0.1468 - val_loss: 36.4499 - val_accuracy: 0.1778\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4156 - accuracy: 0.1468 - val_loss: 36.3963 - val_accuracy: 0.1778\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.3645 - accuracy: 0.1468 - val_loss: 36.3436 - val_accuracy: 0.1778\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.3136 - accuracy: 0.1642 - val_loss: 36.2929 - val_accuracy: 0.2000\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2633 - accuracy: 0.1567 - val_loss: 36.2435 - val_accuracy: 0.2000\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.2127 - accuracy: 0.1567 - val_loss: 36.1922 - val_accuracy: 0.2000\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1606 - accuracy: 0.1592 - val_loss: 36.1406 - val_accuracy: 0.2222\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1084 - accuracy: 0.1716 - val_loss: 36.0899 - val_accuracy: 0.2222\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0577 - accuracy: 0.1692 - val_loss: 36.0391 - val_accuracy: 0.1556\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0073 - accuracy: 0.1567 - val_loss: 35.9915 - val_accuracy: 0.1556\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.9554 - accuracy: 0.1841 - val_loss: 35.9420 - val_accuracy: 0.1556\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.9043 - accuracy: 0.1542 - val_loss: 35.8904 - val_accuracy: 0.1778\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.8522 - accuracy: 0.1468 - val_loss: 35.8359 - val_accuracy: 0.1778\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.8017 - accuracy: 0.1542 - val_loss: 35.7836 - val_accuracy: 0.2000\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.7513 - accuracy: 0.1567 - val_loss: 35.7319 - val_accuracy: 0.2000\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7011 - accuracy: 0.1592 - val_loss: 35.6802 - val_accuracy: 0.2222\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6499 - accuracy: 0.1866 - val_loss: 35.6293 - val_accuracy: 0.2000\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.5975 - accuracy: 0.1891 - val_loss: 35.5785 - val_accuracy: 0.2000\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.5462 - accuracy: 0.1716 - val_loss: 35.5268 - val_accuracy: 0.1778\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4955 - accuracy: 0.1468 - val_loss: 35.4744 - val_accuracy: 0.1778\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4455 - accuracy: 0.1468 - val_loss: 35.4235 - val_accuracy: 0.1778\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.3940 - accuracy: 0.1468 - val_loss: 35.3775 - val_accuracy: 0.1778\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.3439 - accuracy: 0.1493 - val_loss: 35.3305 - val_accuracy: 0.1778\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2939 - accuracy: 0.1468 - val_loss: 35.2821 - val_accuracy: 0.1778\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2429 - accuracy: 0.1468 - val_loss: 35.2295 - val_accuracy: 0.1778\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1925 - accuracy: 0.1443 - val_loss: 35.1768 - val_accuracy: 0.1556\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.1421 - accuracy: 0.1542 - val_loss: 35.1255 - val_accuracy: 0.1778\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0918 - accuracy: 0.1468 - val_loss: 35.0762 - val_accuracy: 0.1778\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0412 - accuracy: 0.1468 - val_loss: 35.0276 - val_accuracy: 0.1778\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.9911 - accuracy: 0.1791 - val_loss: 34.9771 - val_accuracy: 0.2000\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.9406 - accuracy: 0.2040 - val_loss: 34.9275 - val_accuracy: 0.2000\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.8910 - accuracy: 0.2114 - val_loss: 34.8782 - val_accuracy: 0.2000\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.8409 - accuracy: 0.1990 - val_loss: 34.8293 - val_accuracy: 0.1778\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.7912 - accuracy: 0.1915 - val_loss: 34.7795 - val_accuracy: 0.1778\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7407 - accuracy: 0.1841 - val_loss: 34.7276 - val_accuracy: 0.1778\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34.6905 - accuracy: 0.1542 - val_loss: 34.6764 - val_accuracy: 0.1778\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6411 - accuracy: 0.1468 - val_loss: 34.6283 - val_accuracy: 0.1778\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5911 - accuracy: 0.1468 - val_loss: 34.5790 - val_accuracy: 0.1778\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5409 - accuracy: 0.1468 - val_loss: 34.5273 - val_accuracy: 0.1778\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.4913 - accuracy: 0.1468 - val_loss: 34.4759 - val_accuracy: 0.1778\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.4413 - accuracy: 0.1418 - val_loss: 34.4245 - val_accuracy: 0.1556\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3921 - accuracy: 0.1493 - val_loss: 34.3723 - val_accuracy: 0.1778\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3418 - accuracy: 0.1468 - val_loss: 34.3228 - val_accuracy: 0.1778\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.2930 - accuracy: 0.1468 - val_loss: 34.2740 - val_accuracy: 0.1778\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34.2433 - accuracy: 0.1468 - val_loss: 34.2268 - val_accuracy: 0.1778\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.1932 - accuracy: 0.1468 - val_loss: 34.1773 - val_accuracy: 0.1778\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1441 - accuracy: 0.1741 - val_loss: 34.1292 - val_accuracy: 0.1778\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.0953 - accuracy: 0.1915 - val_loss: 34.0792 - val_accuracy: 0.1778\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0453 - accuracy: 0.1866 - val_loss: 34.0301 - val_accuracy: 0.1778\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9958 - accuracy: 0.1468 - val_loss: 33.9830 - val_accuracy: 0.1778\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.9474 - accuracy: 0.1468 - val_loss: 33.9326 - val_accuracy: 0.1778\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.8991 - accuracy: 0.1468 - val_loss: 33.8815 - val_accuracy: 0.1778\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.8494 - accuracy: 0.1517 - val_loss: 33.8302 - val_accuracy: 0.1556\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7995 - accuracy: 0.1542 - val_loss: 33.7823 - val_accuracy: 0.1556\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7509 - accuracy: 0.1493 - val_loss: 33.7345 - val_accuracy: 0.1778\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7011 - accuracy: 0.1468 - val_loss: 33.6826 - val_accuracy: 0.1778\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6523 - accuracy: 0.1493 - val_loss: 33.6317 - val_accuracy: 0.2000\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6034 - accuracy: 0.1816 - val_loss: 33.5824 - val_accuracy: 0.2000\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5550 - accuracy: 0.1617 - val_loss: 33.5338 - val_accuracy: 0.2000\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5060 - accuracy: 0.1567 - val_loss: 33.4866 - val_accuracy: 0.2000\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.4570 - accuracy: 0.1841 - val_loss: 33.4401 - val_accuracy: 0.2000\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.4085 - accuracy: 0.1816 - val_loss: 33.3937 - val_accuracy: 0.2000\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.3595 - accuracy: 0.1716 - val_loss: 33.3436 - val_accuracy: 0.2000\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3116 - accuracy: 0.1642 - val_loss: 33.2961 - val_accuracy: 0.2000\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2622 - accuracy: 0.1667 - val_loss: 33.2457 - val_accuracy: 0.2000\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2132 - accuracy: 0.1642 - val_loss: 33.1956 - val_accuracy: 0.2000\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1649 - accuracy: 0.1617 - val_loss: 33.1468 - val_accuracy: 0.2000\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.1175 - accuracy: 0.1741 - val_loss: 33.0974 - val_accuracy: 0.1556\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.0680 - accuracy: 0.1542 - val_loss: 33.0498 - val_accuracy: 0.1556\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.0196 - accuracy: 0.1542 - val_loss: 33.0023 - val_accuracy: 0.1556\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9711 - accuracy: 0.1517 - val_loss: 32.9545 - val_accuracy: 0.1778\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.9224 - accuracy: 0.1468 - val_loss: 32.9063 - val_accuracy: 0.1778\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.8753 - accuracy: 0.1468 - val_loss: 32.8600 - val_accuracy: 0.1778\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8268 - accuracy: 0.1468 - val_loss: 32.8101 - val_accuracy: 0.1778\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7788 - accuracy: 0.1493 - val_loss: 32.7609 - val_accuracy: 0.1556\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7311 - accuracy: 0.1542 - val_loss: 32.7124 - val_accuracy: 0.1556\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32.6828 - accuracy: 0.1542 - val_loss: 32.6642 - val_accuracy: 0.1778\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.6339 - accuracy: 0.1468 - val_loss: 32.6155 - val_accuracy: 0.1778\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5860 - accuracy: 0.1318 - val_loss: 32.5673 - val_accuracy: 0.1778\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5378 - accuracy: 0.1468 - val_loss: 32.5204 - val_accuracy: 0.1778\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4899 - accuracy: 0.1542 - val_loss: 32.4738 - val_accuracy: 0.2000\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4427 - accuracy: 0.1592 - val_loss: 32.4279 - val_accuracy: 0.2000\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.3949 - accuracy: 0.1592 - val_loss: 32.3809 - val_accuracy: 0.2000\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.3473 - accuracy: 0.1816 - val_loss: 32.3335 - val_accuracy: 0.2000\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3001 - accuracy: 0.1891 - val_loss: 32.2874 - val_accuracy: 0.2000\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2520 - accuracy: 0.1891 - val_loss: 32.2404 - val_accuracy: 0.2000\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2039 - accuracy: 0.2090 - val_loss: 32.1929 - val_accuracy: 0.2000\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.1561 - accuracy: 0.2189 - val_loss: 32.1466 - val_accuracy: 0.2000\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.1093 - accuracy: 0.2413 - val_loss: 32.1001 - val_accuracy: 0.1778\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.0616 - accuracy: 0.2289 - val_loss: 32.0526 - val_accuracy: 0.2000\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0148 - accuracy: 0.1791 - val_loss: 32.0028 - val_accuracy: 0.2000\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9673 - accuracy: 0.1716 - val_loss: 31.9540 - val_accuracy: 0.2000\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9201 - accuracy: 0.1716 - val_loss: 31.9055 - val_accuracy: 0.2000\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31.8721 - accuracy: 0.1816 - val_loss: 31.8585 - val_accuracy: 0.2000\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.8252 - accuracy: 0.2065 - val_loss: 31.8130 - val_accuracy: 0.2000\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.7775 - accuracy: 0.1567 - val_loss: 31.7635 - val_accuracy: 0.1778\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.7303 - accuracy: 0.1468 - val_loss: 31.7176 - val_accuracy: 0.1778\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.6835 - accuracy: 0.1468 - val_loss: 31.6714 - val_accuracy: 0.1778\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.6370 - accuracy: 0.1468 - val_loss: 31.6254 - val_accuracy: 0.1556\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.5901 - accuracy: 0.1542 - val_loss: 31.5800 - val_accuracy: 0.1556\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.5433 - accuracy: 0.1567 - val_loss: 31.5320 - val_accuracy: 0.1556\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.4958 - accuracy: 0.1866 - val_loss: 31.4831 - val_accuracy: 0.1778\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.4489 - accuracy: 0.1667 - val_loss: 31.4337 - val_accuracy: 0.2000\n",
      "========== Fold 6 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 207.6955 - accuracy: 0.1194 - val_loss: 196.5618 - val_accuracy: 0.1111\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 190.4491 - accuracy: 0.1418 - val_loss: 177.9051 - val_accuracy: 0.1778\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 172.3969 - accuracy: 0.1468 - val_loss: 161.6934 - val_accuracy: 0.1778\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 157.2384 - accuracy: 0.1418 - val_loss: 148.7827 - val_accuracy: 0.1333\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 145.3079 - accuracy: 0.1517 - val_loss: 138.7747 - val_accuracy: 0.1556\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 136.0815 - accuracy: 0.1343 - val_loss: 131.0460 - val_accuracy: 0.1556\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 128.9341 - accuracy: 0.1468 - val_loss: 124.9977 - val_accuracy: 0.0889\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 123.3459 - accuracy: 0.1443 - val_loss: 120.2329 - val_accuracy: 0.1111\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 118.9122 - accuracy: 0.1468 - val_loss: 116.4306 - val_accuracy: 0.0444\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 115.3373 - accuracy: 0.1816 - val_loss: 113.3244 - val_accuracy: 0.1556\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 112.4161 - accuracy: 0.1741 - val_loss: 110.7523 - val_accuracy: 0.1556\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 109.9960 - accuracy: 0.1592 - val_loss: 108.6162 - val_accuracy: 0.1778\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 107.9588 - accuracy: 0.1343 - val_loss: 106.8154 - val_accuracy: 0.0667\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 106.2296 - accuracy: 0.1617 - val_loss: 105.2640 - val_accuracy: 0.0889\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 104.7379 - accuracy: 0.1517 - val_loss: 103.9035 - val_accuracy: 0.0444\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103.4385 - accuracy: 0.1692 - val_loss: 102.7061 - val_accuracy: 0.0444\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 102.2950 - accuracy: 0.1891 - val_loss: 101.6394 - val_accuracy: 0.1333\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101.2806 - accuracy: 0.1592 - val_loss: 100.7092 - val_accuracy: 0.2222\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 100.3764 - accuracy: 0.1692 - val_loss: 99.8669 - val_accuracy: 0.1556\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 99.5626 - accuracy: 0.1617 - val_loss: 99.1047 - val_accuracy: 0.1556\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.8236 - accuracy: 0.1617 - val_loss: 98.4137 - val_accuracy: 0.1778\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.1506 - accuracy: 0.1418 - val_loss: 97.7836 - val_accuracy: 0.1556\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 97.5330 - accuracy: 0.1418 - val_loss: 97.2081 - val_accuracy: 0.1333\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 96.9624 - accuracy: 0.1542 - val_loss: 96.6631 - val_accuracy: 0.0667\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.4342 - accuracy: 0.1766 - val_loss: 96.1529 - val_accuracy: 0.1556\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95.9407 - accuracy: 0.1667 - val_loss: 95.6790 - val_accuracy: 0.2000\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.4794 - accuracy: 0.1418 - val_loss: 95.2385 - val_accuracy: 0.1556\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.0481 - accuracy: 0.1393 - val_loss: 94.8243 - val_accuracy: 0.2000\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.6388 - accuracy: 0.1617 - val_loss: 94.4241 - val_accuracy: 0.1556\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94.2556 - accuracy: 0.1343 - val_loss: 94.0490 - val_accuracy: 0.1556\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.8929 - accuracy: 0.1368 - val_loss: 93.6858 - val_accuracy: 0.1556\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.5448 - accuracy: 0.1443 - val_loss: 93.3440 - val_accuracy: 0.1111\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.2085 - accuracy: 0.1667 - val_loss: 93.0176 - val_accuracy: 0.1778\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.8896 - accuracy: 0.1617 - val_loss: 92.7121 - val_accuracy: 0.1556\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92.5810 - accuracy: 0.1617 - val_loss: 92.4213 - val_accuracy: 0.1556\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92.2859 - accuracy: 0.1642 - val_loss: 92.1437 - val_accuracy: 0.1778\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.0008 - accuracy: 0.1741 - val_loss: 91.8715 - val_accuracy: 0.2222\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.7261 - accuracy: 0.1667 - val_loss: 91.6079 - val_accuracy: 0.1556\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.4624 - accuracy: 0.1667 - val_loss: 91.3564 - val_accuracy: 0.0444\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.2043 - accuracy: 0.1642 - val_loss: 91.0969 - val_accuracy: 0.1333\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.9533 - accuracy: 0.1567 - val_loss: 90.8439 - val_accuracy: 0.1333\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.7096 - accuracy: 0.1567 - val_loss: 90.6030 - val_accuracy: 0.1333\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.4722 - accuracy: 0.1816 - val_loss: 90.3761 - val_accuracy: 0.0444\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.2403 - accuracy: 0.1841 - val_loss: 90.1458 - val_accuracy: 0.0889\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.0156 - accuracy: 0.1642 - val_loss: 89.9190 - val_accuracy: 0.0889\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.7933 - accuracy: 0.1766 - val_loss: 89.7026 - val_accuracy: 0.0889\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.5763 - accuracy: 0.1741 - val_loss: 89.4876 - val_accuracy: 0.1778\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.3643 - accuracy: 0.1567 - val_loss: 89.2747 - val_accuracy: 0.1778\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.1564 - accuracy: 0.1791 - val_loss: 89.0722 - val_accuracy: 0.0889\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.9546 - accuracy: 0.1567 - val_loss: 88.8729 - val_accuracy: 0.0889\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.7552 - accuracy: 0.1343 - val_loss: 88.6772 - val_accuracy: 0.0889\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 88.5568 - accuracy: 0.1493 - val_loss: 88.4750 - val_accuracy: 0.0889\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.3609 - accuracy: 0.1766 - val_loss: 88.2829 - val_accuracy: 0.1556\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.1720 - accuracy: 0.1617 - val_loss: 88.0954 - val_accuracy: 0.1556\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.9857 - accuracy: 0.1617 - val_loss: 87.9095 - val_accuracy: 0.1556\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.7985 - accuracy: 0.1617 - val_loss: 87.7284 - val_accuracy: 0.1556\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.6151 - accuracy: 0.1617 - val_loss: 87.5569 - val_accuracy: 0.1556\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 87.4334 - accuracy: 0.1816 - val_loss: 87.3799 - val_accuracy: 0.0444\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.2578 - accuracy: 0.1617 - val_loss: 87.2022 - val_accuracy: 0.0667\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.0822 - accuracy: 0.1642 - val_loss: 87.0208 - val_accuracy: 0.0667\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.9072 - accuracy: 0.1592 - val_loss: 86.8455 - val_accuracy: 0.0667\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.7327 - accuracy: 0.1667 - val_loss: 86.6749 - val_accuracy: 0.1333\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.5631 - accuracy: 0.1567 - val_loss: 86.5102 - val_accuracy: 0.1333\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.3949 - accuracy: 0.1567 - val_loss: 86.3384 - val_accuracy: 0.1333\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.2275 - accuracy: 0.1766 - val_loss: 86.1673 - val_accuracy: 0.1556\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0667 - accuracy: 0.1542 - val_loss: 86.0006 - val_accuracy: 0.1556\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.9031 - accuracy: 0.1418 - val_loss: 85.8358 - val_accuracy: 0.1556\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 85.7395 - accuracy: 0.1617 - val_loss: 85.6758 - val_accuracy: 0.0889\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.5798 - accuracy: 0.1617 - val_loss: 85.5265 - val_accuracy: 0.1111\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.4221 - accuracy: 0.1891 - val_loss: 85.3703 - val_accuracy: 0.1333\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.2647 - accuracy: 0.1368 - val_loss: 85.2145 - val_accuracy: 0.0889\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.1079 - accuracy: 0.1343 - val_loss: 85.0630 - val_accuracy: 0.0889\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.9529 - accuracy: 0.1642 - val_loss: 84.9120 - val_accuracy: 0.0667\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.7998 - accuracy: 0.1617 - val_loss: 84.7611 - val_accuracy: 0.1111\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.6472 - accuracy: 0.1716 - val_loss: 84.6092 - val_accuracy: 0.0889\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.4961 - accuracy: 0.1542 - val_loss: 84.4569 - val_accuracy: 0.1333\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.3466 - accuracy: 0.1443 - val_loss: 84.3025 - val_accuracy: 0.1556\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.1974 - accuracy: 0.1418 - val_loss: 84.1521 - val_accuracy: 0.2222\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.0498 - accuracy: 0.1741 - val_loss: 84.0084 - val_accuracy: 0.1111\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 83.9036 - accuracy: 0.1692 - val_loss: 83.8640 - val_accuracy: 0.1556\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.7582 - accuracy: 0.1617 - val_loss: 83.7199 - val_accuracy: 0.1556\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.6140 - accuracy: 0.1617 - val_loss: 83.5668 - val_accuracy: 0.1556\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.4702 - accuracy: 0.1617 - val_loss: 83.4221 - val_accuracy: 0.1778\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3268 - accuracy: 0.1567 - val_loss: 83.2828 - val_accuracy: 0.1778\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.1859 - accuracy: 0.1468 - val_loss: 83.1498 - val_accuracy: 0.1333\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.0462 - accuracy: 0.1567 - val_loss: 83.0150 - val_accuracy: 0.1333\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.9054 - accuracy: 0.1567 - val_loss: 82.8717 - val_accuracy: 0.1333\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.7647 - accuracy: 0.1766 - val_loss: 82.7223 - val_accuracy: 0.1778\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.6269 - accuracy: 0.1741 - val_loss: 82.5783 - val_accuracy: 0.1778\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 82.4906 - accuracy: 0.1766 - val_loss: 82.4518 - val_accuracy: 0.1333\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82.3529 - accuracy: 0.1791 - val_loss: 82.3151 - val_accuracy: 0.1778\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2177 - accuracy: 0.1841 - val_loss: 82.1818 - val_accuracy: 0.1333\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.0815 - accuracy: 0.1791 - val_loss: 82.0532 - val_accuracy: 0.1333\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.9473 - accuracy: 0.1617 - val_loss: 81.9182 - val_accuracy: 0.1333\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.8140 - accuracy: 0.1418 - val_loss: 81.7817 - val_accuracy: 0.1778\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.6806 - accuracy: 0.1468 - val_loss: 81.6490 - val_accuracy: 0.1778\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.5497 - accuracy: 0.1642 - val_loss: 81.5241 - val_accuracy: 0.1333\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.4182 - accuracy: 0.1567 - val_loss: 81.3971 - val_accuracy: 0.1333\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.2871 - accuracy: 0.1667 - val_loss: 81.2771 - val_accuracy: 0.0444\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.1570 - accuracy: 0.1841 - val_loss: 81.1491 - val_accuracy: 0.0444\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.0268 - accuracy: 0.1667 - val_loss: 81.0144 - val_accuracy: 0.1111\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.8977 - accuracy: 0.1692 - val_loss: 80.8795 - val_accuracy: 0.1556\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.7694 - accuracy: 0.1716 - val_loss: 80.7472 - val_accuracy: 0.0667\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.6413 - accuracy: 0.1642 - val_loss: 80.6096 - val_accuracy: 0.1778\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.5144 - accuracy: 0.1468 - val_loss: 80.4795 - val_accuracy: 0.1778\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.3875 - accuracy: 0.1468 - val_loss: 80.3549 - val_accuracy: 0.1778\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.2618 - accuracy: 0.1468 - val_loss: 80.2314 - val_accuracy: 0.1778\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1360 - accuracy: 0.1468 - val_loss: 80.1095 - val_accuracy: 0.1778\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.0111 - accuracy: 0.1567 - val_loss: 79.9969 - val_accuracy: 0.1333\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.8883 - accuracy: 0.1567 - val_loss: 79.8784 - val_accuracy: 0.1333\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.7659 - accuracy: 0.1567 - val_loss: 79.7501 - val_accuracy: 0.1333\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79.6408 - accuracy: 0.1567 - val_loss: 79.6216 - val_accuracy: 0.1333\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.5165 - accuracy: 0.1965 - val_loss: 79.4926 - val_accuracy: 0.0889\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.3967 - accuracy: 0.1642 - val_loss: 79.3657 - val_accuracy: 0.1111\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.2783 - accuracy: 0.1443 - val_loss: 79.2406 - val_accuracy: 0.1111\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.1549 - accuracy: 0.1567 - val_loss: 79.1245 - val_accuracy: 0.1556\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0337 - accuracy: 0.1617 - val_loss: 79.0075 - val_accuracy: 0.1556\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.9119 - accuracy: 0.1617 - val_loss: 78.8935 - val_accuracy: 0.1778\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.7921 - accuracy: 0.1791 - val_loss: 78.7765 - val_accuracy: 0.1333\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.6733 - accuracy: 0.1567 - val_loss: 78.6539 - val_accuracy: 0.1333\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5557 - accuracy: 0.1567 - val_loss: 78.5386 - val_accuracy: 0.1333\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.4382 - accuracy: 0.1567 - val_loss: 78.4261 - val_accuracy: 0.1333\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.3205 - accuracy: 0.1567 - val_loss: 78.3068 - val_accuracy: 0.1333\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.2030 - accuracy: 0.1617 - val_loss: 78.1944 - val_accuracy: 0.0444\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.0857 - accuracy: 0.1841 - val_loss: 78.0744 - val_accuracy: 0.0444\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.9678 - accuracy: 0.1841 - val_loss: 77.9498 - val_accuracy: 0.0444\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.8515 - accuracy: 0.1866 - val_loss: 77.8294 - val_accuracy: 0.0889\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.7346 - accuracy: 0.1741 - val_loss: 77.7111 - val_accuracy: 0.0889\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.6195 - accuracy: 0.1766 - val_loss: 77.5935 - val_accuracy: 0.2222\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.5055 - accuracy: 0.1517 - val_loss: 77.4825 - val_accuracy: 0.1778\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.3918 - accuracy: 0.1517 - val_loss: 77.3737 - val_accuracy: 0.1333\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.2774 - accuracy: 0.1567 - val_loss: 77.2612 - val_accuracy: 0.1333\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1641 - accuracy: 0.1567 - val_loss: 77.1512 - val_accuracy: 0.1333\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.0510 - accuracy: 0.1567 - val_loss: 77.0414 - val_accuracy: 0.1778\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.9392 - accuracy: 0.1592 - val_loss: 76.9301 - val_accuracy: 0.0889\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.8254 - accuracy: 0.1741 - val_loss: 76.8127 - val_accuracy: 0.0889\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.7139 - accuracy: 0.1741 - val_loss: 76.6943 - val_accuracy: 0.0889\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76.6015 - accuracy: 0.1741 - val_loss: 76.5792 - val_accuracy: 0.0889\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.4901 - accuracy: 0.1791 - val_loss: 76.4653 - val_accuracy: 0.1778\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.3794 - accuracy: 0.1468 - val_loss: 76.3508 - val_accuracy: 0.1778\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.2686 - accuracy: 0.1468 - val_loss: 76.2450 - val_accuracy: 0.1778\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.1582 - accuracy: 0.1716 - val_loss: 76.1410 - val_accuracy: 0.1556\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.0480 - accuracy: 0.1716 - val_loss: 76.0326 - val_accuracy: 0.2444\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.9389 - accuracy: 0.1567 - val_loss: 75.9191 - val_accuracy: 0.1778\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8292 - accuracy: 0.1468 - val_loss: 75.8097 - val_accuracy: 0.1778\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.7225 - accuracy: 0.1617 - val_loss: 75.7051 - val_accuracy: 0.1778\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.6137 - accuracy: 0.1791 - val_loss: 75.5994 - val_accuracy: 0.0889\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.5048 - accuracy: 0.1741 - val_loss: 75.4958 - val_accuracy: 0.1111\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.3969 - accuracy: 0.1567 - val_loss: 75.3857 - val_accuracy: 0.1111\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.2881 - accuracy: 0.1716 - val_loss: 75.2782 - val_accuracy: 0.1333\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.1802 - accuracy: 0.1667 - val_loss: 75.1761 - val_accuracy: 0.1333\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.0744 - accuracy: 0.1567 - val_loss: 75.0696 - val_accuracy: 0.1333\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.9694 - accuracy: 0.1567 - val_loss: 74.9597 - val_accuracy: 0.1333\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8626 - accuracy: 0.1567 - val_loss: 74.8531 - val_accuracy: 0.1333\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7556 - accuracy: 0.1567 - val_loss: 74.7480 - val_accuracy: 0.1333\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.6500 - accuracy: 0.1891 - val_loss: 74.6469 - val_accuracy: 0.0444\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.5438 - accuracy: 0.1841 - val_loss: 74.5402 - val_accuracy: 0.1333\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 74.4398 - accuracy: 0.1517 - val_loss: 74.4366 - val_accuracy: 0.1778\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.3358 - accuracy: 0.1443 - val_loss: 74.3370 - val_accuracy: 0.1333\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.2315 - accuracy: 0.1567 - val_loss: 74.2313 - val_accuracy: 0.1333\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.1265 - accuracy: 0.1567 - val_loss: 74.1247 - val_accuracy: 0.1333\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.0220 - accuracy: 0.1493 - val_loss: 74.0169 - val_accuracy: 0.0889\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.9185 - accuracy: 0.1741 - val_loss: 73.9108 - val_accuracy: 0.0889\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.8160 - accuracy: 0.1741 - val_loss: 73.8063 - val_accuracy: 0.0889\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.7126 - accuracy: 0.1692 - val_loss: 73.7011 - val_accuracy: 0.1556\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.6095 - accuracy: 0.1592 - val_loss: 73.5995 - val_accuracy: 0.1556\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.5070 - accuracy: 0.1617 - val_loss: 73.4934 - val_accuracy: 0.1556\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.4050 - accuracy: 0.1617 - val_loss: 73.3881 - val_accuracy: 0.1556\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3033 - accuracy: 0.1716 - val_loss: 73.2832 - val_accuracy: 0.2444\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.2013 - accuracy: 0.1493 - val_loss: 73.1812 - val_accuracy: 0.1778\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.0998 - accuracy: 0.1493 - val_loss: 73.0833 - val_accuracy: 0.1333\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.9989 - accuracy: 0.1567 - val_loss: 72.9828 - val_accuracy: 0.1333\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.8986 - accuracy: 0.1567 - val_loss: 72.8833 - val_accuracy: 0.1333\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.7969 - accuracy: 0.1567 - val_loss: 72.7827 - val_accuracy: 0.1778\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.6973 - accuracy: 0.1741 - val_loss: 72.6849 - val_accuracy: 0.1556\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.5979 - accuracy: 0.1617 - val_loss: 72.5910 - val_accuracy: 0.1556\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.4985 - accuracy: 0.1617 - val_loss: 72.4914 - val_accuracy: 0.1556\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.3981 - accuracy: 0.1617 - val_loss: 72.3929 - val_accuracy: 0.1556\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.2982 - accuracy: 0.1617 - val_loss: 72.2931 - val_accuracy: 0.1556\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.1989 - accuracy: 0.1617 - val_loss: 72.1966 - val_accuracy: 0.2222\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.1005 - accuracy: 0.1443 - val_loss: 72.1005 - val_accuracy: 0.1333\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.0020 - accuracy: 0.1567 - val_loss: 72.0001 - val_accuracy: 0.1333\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.9035 - accuracy: 0.1368 - val_loss: 71.8953 - val_accuracy: 0.1778\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8056 - accuracy: 0.1791 - val_loss: 71.7923 - val_accuracy: 0.0667\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.7081 - accuracy: 0.1642 - val_loss: 71.6928 - val_accuracy: 0.0889\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.6099 - accuracy: 0.1741 - val_loss: 71.5937 - val_accuracy: 0.0889\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71.5128 - accuracy: 0.1866 - val_loss: 71.5004 - val_accuracy: 0.2222\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4154 - accuracy: 0.1393 - val_loss: 71.4080 - val_accuracy: 0.1333\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.3174 - accuracy: 0.1443 - val_loss: 71.3134 - val_accuracy: 0.2222\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.2207 - accuracy: 0.1642 - val_loss: 71.2188 - val_accuracy: 0.2000\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1244 - accuracy: 0.1692 - val_loss: 71.1238 - val_accuracy: 0.1556\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.0282 - accuracy: 0.1617 - val_loss: 71.0322 - val_accuracy: 0.1556\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.9324 - accuracy: 0.1617 - val_loss: 70.9403 - val_accuracy: 0.1111\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.8363 - accuracy: 0.1766 - val_loss: 70.8463 - val_accuracy: 0.0444\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7401 - accuracy: 0.1866 - val_loss: 70.7451 - val_accuracy: 0.0889\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.6443 - accuracy: 0.1915 - val_loss: 70.6437 - val_accuracy: 0.1333\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.5492 - accuracy: 0.1592 - val_loss: 70.5437 - val_accuracy: 0.1333\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.4552 - accuracy: 0.1667 - val_loss: 70.4440 - val_accuracy: 0.0889\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.3607 - accuracy: 0.1816 - val_loss: 70.3450 - val_accuracy: 0.1778\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.2657 - accuracy: 0.1741 - val_loss: 70.2519 - val_accuracy: 0.0889\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.1713 - accuracy: 0.1716 - val_loss: 70.1585 - val_accuracy: 0.0889\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0764 - accuracy: 0.1741 - val_loss: 70.0686 - val_accuracy: 0.0889\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.9828 - accuracy: 0.1791 - val_loss: 69.9765 - val_accuracy: 0.0667\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8911 - accuracy: 0.1642 - val_loss: 69.8820 - val_accuracy: 0.0667\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.7974 - accuracy: 0.1642 - val_loss: 69.7886 - val_accuracy: 0.0889\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.7030 - accuracy: 0.1716 - val_loss: 69.6965 - val_accuracy: 0.1556\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.6098 - accuracy: 0.1617 - val_loss: 69.6064 - val_accuracy: 0.1556\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.5164 - accuracy: 0.1617 - val_loss: 69.5094 - val_accuracy: 0.1556\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4227 - accuracy: 0.1617 - val_loss: 69.4185 - val_accuracy: 0.1556\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.3304 - accuracy: 0.1567 - val_loss: 69.3312 - val_accuracy: 0.0889\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.2374 - accuracy: 0.1741 - val_loss: 69.2412 - val_accuracy: 0.0444\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.1448 - accuracy: 0.1716 - val_loss: 69.1483 - val_accuracy: 0.1333\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.0544 - accuracy: 0.1567 - val_loss: 69.0523 - val_accuracy: 0.1333\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.9641 - accuracy: 0.1617 - val_loss: 68.9527 - val_accuracy: 0.1778\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.8723 - accuracy: 0.1468 - val_loss: 68.8519 - val_accuracy: 0.1778\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68.7802 - accuracy: 0.1493 - val_loss: 68.7598 - val_accuracy: 0.1556\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.6915 - accuracy: 0.1617 - val_loss: 68.6717 - val_accuracy: 0.1556\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68.5989 - accuracy: 0.1617 - val_loss: 68.5820 - val_accuracy: 0.1556\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.5078 - accuracy: 0.1617 - val_loss: 68.4942 - val_accuracy: 0.1556\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.4149 - accuracy: 0.1617 - val_loss: 68.4083 - val_accuracy: 0.2444\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.3245 - accuracy: 0.1567 - val_loss: 68.3181 - val_accuracy: 0.1778\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.2341 - accuracy: 0.1468 - val_loss: 68.2291 - val_accuracy: 0.1778\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.1434 - accuracy: 0.1542 - val_loss: 68.1427 - val_accuracy: 0.1556\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.0532 - accuracy: 0.1517 - val_loss: 68.0569 - val_accuracy: 0.0889\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.9633 - accuracy: 0.1542 - val_loss: 67.9693 - val_accuracy: 0.0444\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.8729 - accuracy: 0.1841 - val_loss: 67.8803 - val_accuracy: 0.0444\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.7842 - accuracy: 0.1741 - val_loss: 67.7860 - val_accuracy: 0.1556\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.6964 - accuracy: 0.1617 - val_loss: 67.6853 - val_accuracy: 0.1556\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6055 - accuracy: 0.1617 - val_loss: 67.5936 - val_accuracy: 0.1556\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.5166 - accuracy: 0.1567 - val_loss: 67.5046 - val_accuracy: 0.2000\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.4277 - accuracy: 0.1617 - val_loss: 67.4169 - val_accuracy: 0.1778\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3390 - accuracy: 0.1667 - val_loss: 67.3331 - val_accuracy: 0.0889\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.2506 - accuracy: 0.1766 - val_loss: 67.2486 - val_accuracy: 0.0444\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.1618 - accuracy: 0.1841 - val_loss: 67.1599 - val_accuracy: 0.1778\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.0735 - accuracy: 0.1667 - val_loss: 67.0752 - val_accuracy: 0.1778\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9859 - accuracy: 0.1542 - val_loss: 66.9889 - val_accuracy: 0.1778\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.8979 - accuracy: 0.1468 - val_loss: 66.9037 - val_accuracy: 0.1778\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8107 - accuracy: 0.1468 - val_loss: 66.8207 - val_accuracy: 0.1778\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.7236 - accuracy: 0.1468 - val_loss: 66.7362 - val_accuracy: 0.1333\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.6364 - accuracy: 0.1567 - val_loss: 66.6541 - val_accuracy: 0.1333\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5492 - accuracy: 0.1891 - val_loss: 66.5680 - val_accuracy: 0.1333\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.4632 - accuracy: 0.1816 - val_loss: 66.4850 - val_accuracy: 0.0444\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3756 - accuracy: 0.1841 - val_loss: 66.3954 - val_accuracy: 0.0444\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.2888 - accuracy: 0.1841 - val_loss: 66.3049 - val_accuracy: 0.0444\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.2023 - accuracy: 0.1667 - val_loss: 66.2137 - val_accuracy: 0.1333\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.1164 - accuracy: 0.1368 - val_loss: 66.1196 - val_accuracy: 0.1778\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.0293 - accuracy: 0.1567 - val_loss: 66.0320 - val_accuracy: 0.1556\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.9436 - accuracy: 0.1617 - val_loss: 65.9468 - val_accuracy: 0.1556\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.8581 - accuracy: 0.1617 - val_loss: 65.8619 - val_accuracy: 0.1556\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.7726 - accuracy: 0.1617 - val_loss: 65.7763 - val_accuracy: 0.1556\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.6861 - accuracy: 0.1617 - val_loss: 65.6939 - val_accuracy: 0.1556\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6008 - accuracy: 0.1642 - val_loss: 65.6072 - val_accuracy: 0.1333\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.5146 - accuracy: 0.1567 - val_loss: 65.5158 - val_accuracy: 0.1333\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4300 - accuracy: 0.1567 - val_loss: 65.4271 - val_accuracy: 0.1333\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65.3445 - accuracy: 0.1617 - val_loss: 65.3476 - val_accuracy: 0.0667\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.2594 - accuracy: 0.1642 - val_loss: 65.2670 - val_accuracy: 0.0667\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.1752 - accuracy: 0.1816 - val_loss: 65.1859 - val_accuracy: 0.0444\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.0898 - accuracy: 0.1841 - val_loss: 65.1007 - val_accuracy: 0.0889\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0049 - accuracy: 0.1692 - val_loss: 65.0127 - val_accuracy: 0.1333\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.9207 - accuracy: 0.1368 - val_loss: 64.9271 - val_accuracy: 0.1333\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.8368 - accuracy: 0.1567 - val_loss: 64.8459 - val_accuracy: 0.1333\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.7530 - accuracy: 0.1393 - val_loss: 64.7597 - val_accuracy: 0.1778\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.6690 - accuracy: 0.1294 - val_loss: 64.6749 - val_accuracy: 0.1778\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.5851 - accuracy: 0.1468 - val_loss: 64.5894 - val_accuracy: 0.1778\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.5021 - accuracy: 0.1567 - val_loss: 64.5063 - val_accuracy: 0.0889\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.4188 - accuracy: 0.1692 - val_loss: 64.4220 - val_accuracy: 0.0889\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.3352 - accuracy: 0.1692 - val_loss: 64.3477 - val_accuracy: 0.0444\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.2512 - accuracy: 0.1866 - val_loss: 64.2670 - val_accuracy: 0.1333\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.1686 - accuracy: 0.1791 - val_loss: 64.1834 - val_accuracy: 0.0889\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.0850 - accuracy: 0.1891 - val_loss: 64.0974 - val_accuracy: 0.1333\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.0028 - accuracy: 0.1393 - val_loss: 64.0073 - val_accuracy: 0.1778\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.9199 - accuracy: 0.1418 - val_loss: 63.9244 - val_accuracy: 0.2222\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.8374 - accuracy: 0.1517 - val_loss: 63.8391 - val_accuracy: 0.1556\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.7547 - accuracy: 0.1617 - val_loss: 63.7587 - val_accuracy: 0.1778\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.6719 - accuracy: 0.1567 - val_loss: 63.6809 - val_accuracy: 0.1333\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.5906 - accuracy: 0.1567 - val_loss: 63.5993 - val_accuracy: 0.1333\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.5082 - accuracy: 0.1567 - val_loss: 63.5178 - val_accuracy: 0.1333\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4261 - accuracy: 0.1567 - val_loss: 63.4402 - val_accuracy: 0.1333\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3446 - accuracy: 0.1567 - val_loss: 63.3605 - val_accuracy: 0.1333\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.2632 - accuracy: 0.1567 - val_loss: 63.2739 - val_accuracy: 0.1333\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.1818 - accuracy: 0.1567 - val_loss: 63.1924 - val_accuracy: 0.1333\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.1006 - accuracy: 0.1567 - val_loss: 63.1156 - val_accuracy: 0.1333\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.0189 - accuracy: 0.1567 - val_loss: 63.0353 - val_accuracy: 0.1333\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.9385 - accuracy: 0.1567 - val_loss: 62.9520 - val_accuracy: 0.1333\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.8590 - accuracy: 0.1567 - val_loss: 62.8684 - val_accuracy: 0.1333\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.7780 - accuracy: 0.1567 - val_loss: 62.7825 - val_accuracy: 0.1333\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.6958 - accuracy: 0.1567 - val_loss: 62.6978 - val_accuracy: 0.1333\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.6145 - accuracy: 0.1567 - val_loss: 62.6157 - val_accuracy: 0.1333\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.5342 - accuracy: 0.1443 - val_loss: 62.5363 - val_accuracy: 0.1778\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.4541 - accuracy: 0.1791 - val_loss: 62.4597 - val_accuracy: 0.1778\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.3733 - accuracy: 0.1791 - val_loss: 62.3802 - val_accuracy: 0.0667\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.2935 - accuracy: 0.1567 - val_loss: 62.2965 - val_accuracy: 0.0667\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62.2131 - accuracy: 0.1642 - val_loss: 62.2183 - val_accuracy: 0.0667\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1325 - accuracy: 0.1692 - val_loss: 62.1397 - val_accuracy: 0.0889\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.0527 - accuracy: 0.1716 - val_loss: 62.0645 - val_accuracy: 0.1111\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.9740 - accuracy: 0.1542 - val_loss: 61.9866 - val_accuracy: 0.1556\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.8938 - accuracy: 0.1692 - val_loss: 61.9068 - val_accuracy: 0.1778\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8143 - accuracy: 0.1667 - val_loss: 61.8267 - val_accuracy: 0.0444\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7351 - accuracy: 0.1841 - val_loss: 61.7448 - val_accuracy: 0.0444\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.6548 - accuracy: 0.1841 - val_loss: 61.6655 - val_accuracy: 0.0889\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.5769 - accuracy: 0.1766 - val_loss: 61.5849 - val_accuracy: 0.1778\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4981 - accuracy: 0.1468 - val_loss: 61.5068 - val_accuracy: 0.1778\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4192 - accuracy: 0.1692 - val_loss: 61.4306 - val_accuracy: 0.1778\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3408 - accuracy: 0.1692 - val_loss: 61.3549 - val_accuracy: 0.1556\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.2628 - accuracy: 0.1617 - val_loss: 61.2772 - val_accuracy: 0.1556\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.1840 - accuracy: 0.1617 - val_loss: 61.1954 - val_accuracy: 0.1556\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.1038 - accuracy: 0.1617 - val_loss: 61.1134 - val_accuracy: 0.1778\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0266 - accuracy: 0.1542 - val_loss: 61.0338 - val_accuracy: 0.1778\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.9483 - accuracy: 0.1468 - val_loss: 60.9600 - val_accuracy: 0.1778\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.8709 - accuracy: 0.1517 - val_loss: 60.8868 - val_accuracy: 0.1778\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.7923 - accuracy: 0.1766 - val_loss: 60.8068 - val_accuracy: 0.2222\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.7143 - accuracy: 0.1517 - val_loss: 60.7251 - val_accuracy: 0.1778\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6368 - accuracy: 0.1517 - val_loss: 60.6430 - val_accuracy: 0.2444\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5594 - accuracy: 0.1716 - val_loss: 60.5619 - val_accuracy: 0.2444\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4821 - accuracy: 0.1542 - val_loss: 60.4853 - val_accuracy: 0.1778\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.4050 - accuracy: 0.1368 - val_loss: 60.4157 - val_accuracy: 0.1333\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3274 - accuracy: 0.1567 - val_loss: 60.3413 - val_accuracy: 0.1333\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.2497 - accuracy: 0.1567 - val_loss: 60.2615 - val_accuracy: 0.1333\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.1722 - accuracy: 0.1567 - val_loss: 60.1805 - val_accuracy: 0.1333\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0952 - accuracy: 0.1567 - val_loss: 60.1064 - val_accuracy: 0.1333\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.0180 - accuracy: 0.1567 - val_loss: 60.0284 - val_accuracy: 0.1333\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.9415 - accuracy: 0.1567 - val_loss: 59.9509 - val_accuracy: 0.1333\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8651 - accuracy: 0.1915 - val_loss: 59.8742 - val_accuracy: 0.0444\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59.7894 - accuracy: 0.1841 - val_loss: 59.7974 - val_accuracy: 0.0444\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7128 - accuracy: 0.1841 - val_loss: 59.7160 - val_accuracy: 0.0444\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.6363 - accuracy: 0.1816 - val_loss: 59.6362 - val_accuracy: 0.0444\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.5599 - accuracy: 0.1841 - val_loss: 59.5605 - val_accuracy: 0.0444\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.4836 - accuracy: 0.1791 - val_loss: 59.4839 - val_accuracy: 0.1111\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.4075 - accuracy: 0.1766 - val_loss: 59.4046 - val_accuracy: 0.1778\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.3318 - accuracy: 0.1692 - val_loss: 59.3299 - val_accuracy: 0.0889\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2559 - accuracy: 0.1741 - val_loss: 59.2543 - val_accuracy: 0.0444\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.1800 - accuracy: 0.1841 - val_loss: 59.1866 - val_accuracy: 0.0444\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.1047 - accuracy: 0.1841 - val_loss: 59.1187 - val_accuracy: 0.0444\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.0291 - accuracy: 0.1766 - val_loss: 59.0451 - val_accuracy: 0.1111\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.9535 - accuracy: 0.1667 - val_loss: 58.9703 - val_accuracy: 0.1111\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.8782 - accuracy: 0.1891 - val_loss: 58.8933 - val_accuracy: 0.0444\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.8025 - accuracy: 0.1816 - val_loss: 58.8158 - val_accuracy: 0.1333\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.7274 - accuracy: 0.1891 - val_loss: 58.7368 - val_accuracy: 0.1333\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.6530 - accuracy: 0.1617 - val_loss: 58.6603 - val_accuracy: 0.1333\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.5790 - accuracy: 0.1567 - val_loss: 58.5848 - val_accuracy: 0.1333\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5036 - accuracy: 0.1443 - val_loss: 58.5043 - val_accuracy: 0.2000\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.4284 - accuracy: 0.1741 - val_loss: 58.4291 - val_accuracy: 0.1556\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.3538 - accuracy: 0.1617 - val_loss: 58.3528 - val_accuracy: 0.1556\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.2797 - accuracy: 0.1617 - val_loss: 58.2785 - val_accuracy: 0.1556\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.2049 - accuracy: 0.1617 - val_loss: 58.2104 - val_accuracy: 0.1556\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.1308 - accuracy: 0.1866 - val_loss: 58.1426 - val_accuracy: 0.1778\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.0563 - accuracy: 0.1791 - val_loss: 58.0685 - val_accuracy: 0.1778\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.9825 - accuracy: 0.1617 - val_loss: 57.9932 - val_accuracy: 0.1778\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.9081 - accuracy: 0.1468 - val_loss: 57.9153 - val_accuracy: 0.1778\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.8343 - accuracy: 0.1567 - val_loss: 57.8429 - val_accuracy: 0.1778\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.7597 - accuracy: 0.1493 - val_loss: 57.7681 - val_accuracy: 0.1778\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.6862 - accuracy: 0.1468 - val_loss: 57.6926 - val_accuracy: 0.1778\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.6129 - accuracy: 0.1542 - val_loss: 57.6203 - val_accuracy: 0.1333\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.5397 - accuracy: 0.1393 - val_loss: 57.5496 - val_accuracy: 0.1333\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.4654 - accuracy: 0.1567 - val_loss: 57.4806 - val_accuracy: 0.1333\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.3938 - accuracy: 0.1567 - val_loss: 57.4176 - val_accuracy: 0.1333\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.3199 - accuracy: 0.1567 - val_loss: 57.3418 - val_accuracy: 0.1333\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.2462 - accuracy: 0.1567 - val_loss: 57.2626 - val_accuracy: 0.1333\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1725 - accuracy: 0.1567 - val_loss: 57.1828 - val_accuracy: 0.1333\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0991 - accuracy: 0.1816 - val_loss: 57.1072 - val_accuracy: 0.0889\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0273 - accuracy: 0.1642 - val_loss: 57.0321 - val_accuracy: 0.1556\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.9538 - accuracy: 0.1716 - val_loss: 56.9583 - val_accuracy: 0.1778\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8815 - accuracy: 0.1418 - val_loss: 56.8887 - val_accuracy: 0.1778\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56.8091 - accuracy: 0.1468 - val_loss: 56.8174 - val_accuracy: 0.1778\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56.7364 - accuracy: 0.1468 - val_loss: 56.7481 - val_accuracy: 0.1778\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.6631 - accuracy: 0.1468 - val_loss: 56.6736 - val_accuracy: 0.1333\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5906 - accuracy: 0.1567 - val_loss: 56.5977 - val_accuracy: 0.1333\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.5185 - accuracy: 0.1741 - val_loss: 56.5214 - val_accuracy: 0.1778\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.4459 - accuracy: 0.1667 - val_loss: 56.4472 - val_accuracy: 0.1778\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.3738 - accuracy: 0.1741 - val_loss: 56.3734 - val_accuracy: 0.1556\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.3024 - accuracy: 0.1617 - val_loss: 56.3046 - val_accuracy: 0.1556\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56.2304 - accuracy: 0.1617 - val_loss: 56.2371 - val_accuracy: 0.1556\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.1584 - accuracy: 0.1567 - val_loss: 56.1711 - val_accuracy: 0.1333\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.0869 - accuracy: 0.1716 - val_loss: 56.1029 - val_accuracy: 0.1333\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0153 - accuracy: 0.1567 - val_loss: 56.0363 - val_accuracy: 0.1333\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.9437 - accuracy: 0.1915 - val_loss: 55.9669 - val_accuracy: 0.0444\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.8728 - accuracy: 0.1841 - val_loss: 55.8937 - val_accuracy: 0.0444\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.8011 - accuracy: 0.1841 - val_loss: 55.8168 - val_accuracy: 0.0444\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.7304 - accuracy: 0.1841 - val_loss: 55.7402 - val_accuracy: 0.0444\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.6603 - accuracy: 0.1841 - val_loss: 55.6610 - val_accuracy: 0.0889\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5890 - accuracy: 0.1741 - val_loss: 55.5849 - val_accuracy: 0.0889\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5170 - accuracy: 0.1766 - val_loss: 55.5174 - val_accuracy: 0.0667\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.4457 - accuracy: 0.1642 - val_loss: 55.4508 - val_accuracy: 0.0667\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.3746 - accuracy: 0.1642 - val_loss: 55.3847 - val_accuracy: 0.0667\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55.3032 - accuracy: 0.1642 - val_loss: 55.3151 - val_accuracy: 0.0444\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55.2314 - accuracy: 0.1816 - val_loss: 55.2467 - val_accuracy: 0.0889\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1608 - accuracy: 0.1891 - val_loss: 55.1797 - val_accuracy: 0.1333\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0904 - accuracy: 0.1891 - val_loss: 55.1114 - val_accuracy: 0.1333\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0204 - accuracy: 0.1891 - val_loss: 55.0435 - val_accuracy: 0.1333\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.9500 - accuracy: 0.1866 - val_loss: 54.9748 - val_accuracy: 0.0444\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.8799 - accuracy: 0.1841 - val_loss: 54.9048 - val_accuracy: 0.0889\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8095 - accuracy: 0.1741 - val_loss: 54.8315 - val_accuracy: 0.0889\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.7402 - accuracy: 0.1741 - val_loss: 54.7521 - val_accuracy: 0.1333\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.6690 - accuracy: 0.1841 - val_loss: 54.6798 - val_accuracy: 0.1111\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.5989 - accuracy: 0.1791 - val_loss: 54.6084 - val_accuracy: 0.0889\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.5291 - accuracy: 0.1741 - val_loss: 54.5404 - val_accuracy: 0.0889\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.4601 - accuracy: 0.1692 - val_loss: 54.4721 - val_accuracy: 0.0444\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.3902 - accuracy: 0.1841 - val_loss: 54.4055 - val_accuracy: 0.0444\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.3199 - accuracy: 0.1766 - val_loss: 54.3342 - val_accuracy: 0.0889\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.2504 - accuracy: 0.1741 - val_loss: 54.2634 - val_accuracy: 0.1333\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1815 - accuracy: 0.1567 - val_loss: 54.1953 - val_accuracy: 0.1778\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1139 - accuracy: 0.1269 - val_loss: 54.1321 - val_accuracy: 0.1333\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0434 - accuracy: 0.1567 - val_loss: 54.0619 - val_accuracy: 0.1333\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.9739 - accuracy: 0.1567 - val_loss: 53.9936 - val_accuracy: 0.2000\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.9042 - accuracy: 0.1816 - val_loss: 53.9224 - val_accuracy: 0.1556\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.8350 - accuracy: 0.1617 - val_loss: 53.8509 - val_accuracy: 0.1556\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53.7655 - accuracy: 0.1617 - val_loss: 53.7779 - val_accuracy: 0.1778\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6973 - accuracy: 0.1716 - val_loss: 53.7057 - val_accuracy: 0.1778\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6277 - accuracy: 0.1468 - val_loss: 53.6380 - val_accuracy: 0.1778\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.5595 - accuracy: 0.1368 - val_loss: 53.5799 - val_accuracy: 0.1333\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4903 - accuracy: 0.1617 - val_loss: 53.5174 - val_accuracy: 0.2000\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.4221 - accuracy: 0.1866 - val_loss: 53.4531 - val_accuracy: 0.1333\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.3535 - accuracy: 0.1841 - val_loss: 53.3828 - val_accuracy: 0.1333\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2845 - accuracy: 0.1791 - val_loss: 53.3072 - val_accuracy: 0.1556\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2170 - accuracy: 0.1617 - val_loss: 53.2351 - val_accuracy: 0.1556\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1482 - accuracy: 0.1617 - val_loss: 53.1682 - val_accuracy: 0.1556\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.0795 - accuracy: 0.1741 - val_loss: 53.1032 - val_accuracy: 0.1333\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.0109 - accuracy: 0.1667 - val_loss: 53.0386 - val_accuracy: 0.1333\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.9432 - accuracy: 0.1642 - val_loss: 52.9721 - val_accuracy: 0.1333\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.8756 - accuracy: 0.1891 - val_loss: 52.9039 - val_accuracy: 0.0667\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.8083 - accuracy: 0.1791 - val_loss: 52.8345 - val_accuracy: 0.0444\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.7393 - accuracy: 0.1841 - val_loss: 52.7624 - val_accuracy: 0.0444\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6716 - accuracy: 0.1891 - val_loss: 52.6903 - val_accuracy: 0.0889\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6034 - accuracy: 0.1891 - val_loss: 52.6220 - val_accuracy: 0.0444\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.5359 - accuracy: 0.1841 - val_loss: 52.5540 - val_accuracy: 0.0444\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.4684 - accuracy: 0.1841 - val_loss: 52.4893 - val_accuracy: 0.0444\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.4016 - accuracy: 0.1841 - val_loss: 52.4267 - val_accuracy: 0.0444\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.3341 - accuracy: 0.1841 - val_loss: 52.3567 - val_accuracy: 0.0444\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.2664 - accuracy: 0.1791 - val_loss: 52.2832 - val_accuracy: 0.1333\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.1991 - accuracy: 0.1741 - val_loss: 52.2154 - val_accuracy: 0.1333\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1319 - accuracy: 0.1542 - val_loss: 52.1481 - val_accuracy: 0.1778\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.0653 - accuracy: 0.1692 - val_loss: 52.0819 - val_accuracy: 0.1556\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9992 - accuracy: 0.1617 - val_loss: 52.0141 - val_accuracy: 0.1556\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.9320 - accuracy: 0.1617 - val_loss: 51.9488 - val_accuracy: 0.1333\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.8652 - accuracy: 0.1617 - val_loss: 51.8820 - val_accuracy: 0.1333\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.7981 - accuracy: 0.1567 - val_loss: 51.8156 - val_accuracy: 0.1333\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7315 - accuracy: 0.1567 - val_loss: 51.7518 - val_accuracy: 0.1333\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6643 - accuracy: 0.1567 - val_loss: 51.6842 - val_accuracy: 0.1333\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5971 - accuracy: 0.1592 - val_loss: 51.6165 - val_accuracy: 0.1778\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5311 - accuracy: 0.1592 - val_loss: 51.5533 - val_accuracy: 0.1333\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.4640 - accuracy: 0.1567 - val_loss: 51.4922 - val_accuracy: 0.1333\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.3984 - accuracy: 0.1915 - val_loss: 51.4280 - val_accuracy: 0.1111\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.3322 - accuracy: 0.1716 - val_loss: 51.3604 - val_accuracy: 0.1111\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.2664 - accuracy: 0.1716 - val_loss: 51.2890 - val_accuracy: 0.1111\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.1989 - accuracy: 0.1692 - val_loss: 51.2150 - val_accuracy: 0.1556\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.1327 - accuracy: 0.1617 - val_loss: 51.1416 - val_accuracy: 0.1556\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.0665 - accuracy: 0.1667 - val_loss: 51.0739 - val_accuracy: 0.1778\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0009 - accuracy: 0.1741 - val_loss: 51.0105 - val_accuracy: 0.1556\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9345 - accuracy: 0.1617 - val_loss: 50.9469 - val_accuracy: 0.1556\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8690 - accuracy: 0.1791 - val_loss: 50.8872 - val_accuracy: 0.0667\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8036 - accuracy: 0.1791 - val_loss: 50.8297 - val_accuracy: 0.0444\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.7377 - accuracy: 0.1841 - val_loss: 50.7697 - val_accuracy: 0.0444\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6723 - accuracy: 0.1841 - val_loss: 50.7043 - val_accuracy: 0.0444\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6065 - accuracy: 0.1841 - val_loss: 50.6371 - val_accuracy: 0.0444\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.5408 - accuracy: 0.1841 - val_loss: 50.5670 - val_accuracy: 0.0444\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.4753 - accuracy: 0.1866 - val_loss: 50.4951 - val_accuracy: 0.1333\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.4107 - accuracy: 0.1567 - val_loss: 50.4234 - val_accuracy: 0.1333\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.3456 - accuracy: 0.1567 - val_loss: 50.3543 - val_accuracy: 0.1778\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2809 - accuracy: 0.1468 - val_loss: 50.2826 - val_accuracy: 0.1778\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2161 - accuracy: 0.1468 - val_loss: 50.2161 - val_accuracy: 0.1778\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.1504 - accuracy: 0.1468 - val_loss: 50.1510 - val_accuracy: 0.1778\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.0853 - accuracy: 0.1468 - val_loss: 50.0847 - val_accuracy: 0.1778\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50.0205 - accuracy: 0.1542 - val_loss: 50.0202 - val_accuracy: 0.2222\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.9558 - accuracy: 0.1592 - val_loss: 49.9575 - val_accuracy: 0.1778\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8902 - accuracy: 0.1642 - val_loss: 49.8988 - val_accuracy: 0.1556\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8249 - accuracy: 0.1617 - val_loss: 49.8403 - val_accuracy: 0.1556\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7605 - accuracy: 0.1667 - val_loss: 49.7821 - val_accuracy: 0.0889\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.6960 - accuracy: 0.1816 - val_loss: 49.7220 - val_accuracy: 0.0889\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6330 - accuracy: 0.1592 - val_loss: 49.6599 - val_accuracy: 0.1111\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5684 - accuracy: 0.1716 - val_loss: 49.5902 - val_accuracy: 0.1111\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.5041 - accuracy: 0.2015 - val_loss: 49.5216 - val_accuracy: 0.1778\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.4393 - accuracy: 0.1741 - val_loss: 49.4571 - val_accuracy: 0.1333\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49.3747 - accuracy: 0.1716 - val_loss: 49.3907 - val_accuracy: 0.1333\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3097 - accuracy: 0.1567 - val_loss: 49.3265 - val_accuracy: 0.1333\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2456 - accuracy: 0.1716 - val_loss: 49.2628 - val_accuracy: 0.1111\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1821 - accuracy: 0.1766 - val_loss: 49.2012 - val_accuracy: 0.0889\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.1179 - accuracy: 0.1741 - val_loss: 49.1408 - val_accuracy: 0.0889\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.0544 - accuracy: 0.1741 - val_loss: 49.0795 - val_accuracy: 0.0889\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9907 - accuracy: 0.1741 - val_loss: 49.0112 - val_accuracy: 0.0889\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9274 - accuracy: 0.1741 - val_loss: 48.9473 - val_accuracy: 0.0889\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.8640 - accuracy: 0.1791 - val_loss: 48.8808 - val_accuracy: 0.1778\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.8005 - accuracy: 0.1468 - val_loss: 48.8127 - val_accuracy: 0.1778\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.7364 - accuracy: 0.1468 - val_loss: 48.7505 - val_accuracy: 0.1778\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6719 - accuracy: 0.1493 - val_loss: 48.6936 - val_accuracy: 0.1333\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6090 - accuracy: 0.1567 - val_loss: 48.6372 - val_accuracy: 0.1333\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.5451 - accuracy: 0.1617 - val_loss: 48.5770 - val_accuracy: 0.2000\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.4822 - accuracy: 0.1741 - val_loss: 48.5148 - val_accuracy: 0.1556\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.4192 - accuracy: 0.1816 - val_loss: 48.4509 - val_accuracy: 0.0889\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.3558 - accuracy: 0.1866 - val_loss: 48.3862 - val_accuracy: 0.0444\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48.2928 - accuracy: 0.1816 - val_loss: 48.3216 - val_accuracy: 0.0444\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.2290 - accuracy: 0.1841 - val_loss: 48.2575 - val_accuracy: 0.0444\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48.1665 - accuracy: 0.1841 - val_loss: 48.1923 - val_accuracy: 0.0444\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1036 - accuracy: 0.1791 - val_loss: 48.1250 - val_accuracy: 0.1333\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.0400 - accuracy: 0.1567 - val_loss: 48.0589 - val_accuracy: 0.1333\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.9781 - accuracy: 0.1567 - val_loss: 47.9987 - val_accuracy: 0.1333\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.9151 - accuracy: 0.1567 - val_loss: 47.9388 - val_accuracy: 0.1333\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8529 - accuracy: 0.1567 - val_loss: 47.8767 - val_accuracy: 0.1333\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.7896 - accuracy: 0.1567 - val_loss: 47.8153 - val_accuracy: 0.2222\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.7284 - accuracy: 0.1667 - val_loss: 47.7532 - val_accuracy: 0.1556\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.6650 - accuracy: 0.1716 - val_loss: 47.6961 - val_accuracy: 0.0889\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.6024 - accuracy: 0.1766 - val_loss: 47.6383 - val_accuracy: 0.0444\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5405 - accuracy: 0.1841 - val_loss: 47.5767 - val_accuracy: 0.0444\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.4779 - accuracy: 0.1841 - val_loss: 47.5110 - val_accuracy: 0.0444\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.4154 - accuracy: 0.1766 - val_loss: 47.4367 - val_accuracy: 0.1333\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3529 - accuracy: 0.1891 - val_loss: 47.3661 - val_accuracy: 0.2444\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2909 - accuracy: 0.1542 - val_loss: 47.2996 - val_accuracy: 0.1778\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2295 - accuracy: 0.1567 - val_loss: 47.2353 - val_accuracy: 0.2444\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.1684 - accuracy: 0.1692 - val_loss: 47.1739 - val_accuracy: 0.1778\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.1064 - accuracy: 0.1766 - val_loss: 47.1159 - val_accuracy: 0.1778\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.0442 - accuracy: 0.1791 - val_loss: 47.0549 - val_accuracy: 0.1778\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.9820 - accuracy: 0.1741 - val_loss: 46.9938 - val_accuracy: 0.1333\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9210 - accuracy: 0.1891 - val_loss: 46.9325 - val_accuracy: 0.0667\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.8591 - accuracy: 0.1791 - val_loss: 46.8695 - val_accuracy: 0.0444\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.7977 - accuracy: 0.1816 - val_loss: 46.8067 - val_accuracy: 0.0889\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7356 - accuracy: 0.1741 - val_loss: 46.7479 - val_accuracy: 0.0889\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6737 - accuracy: 0.1816 - val_loss: 46.6913 - val_accuracy: 0.1333\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.6118 - accuracy: 0.1667 - val_loss: 46.6287 - val_accuracy: 0.1333\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5516 - accuracy: 0.1716 - val_loss: 46.5714 - val_accuracy: 0.1333\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4897 - accuracy: 0.1692 - val_loss: 46.5126 - val_accuracy: 0.2000\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46.4280 - accuracy: 0.1816 - val_loss: 46.4553 - val_accuracy: 0.1556\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3676 - accuracy: 0.1766 - val_loss: 46.3976 - val_accuracy: 0.0667\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3055 - accuracy: 0.1841 - val_loss: 46.3368 - val_accuracy: 0.0444\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2447 - accuracy: 0.1841 - val_loss: 46.2710 - val_accuracy: 0.0889\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1832 - accuracy: 0.1816 - val_loss: 46.2129 - val_accuracy: 0.0889\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1230 - accuracy: 0.1841 - val_loss: 46.1538 - val_accuracy: 0.0889\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0628 - accuracy: 0.1841 - val_loss: 46.0885 - val_accuracy: 0.1111\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0008 - accuracy: 0.1841 - val_loss: 46.0243 - val_accuracy: 0.1778\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.9403 - accuracy: 0.1567 - val_loss: 45.9606 - val_accuracy: 0.1333\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8805 - accuracy: 0.1567 - val_loss: 45.8958 - val_accuracy: 0.1333\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8188 - accuracy: 0.1567 - val_loss: 45.8344 - val_accuracy: 0.1333\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.7588 - accuracy: 0.1592 - val_loss: 45.7745 - val_accuracy: 0.1778\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6980 - accuracy: 0.1816 - val_loss: 45.7182 - val_accuracy: 0.0444\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45.6371 - accuracy: 0.1841 - val_loss: 45.6644 - val_accuracy: 0.0444\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5766 - accuracy: 0.1841 - val_loss: 45.6075 - val_accuracy: 0.0444\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5172 - accuracy: 0.1841 - val_loss: 45.5484 - val_accuracy: 0.0444\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.4570 - accuracy: 0.1716 - val_loss: 45.4822 - val_accuracy: 0.1333\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3964 - accuracy: 0.1567 - val_loss: 45.4206 - val_accuracy: 0.1333\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.3358 - accuracy: 0.1567 - val_loss: 45.3606 - val_accuracy: 0.1333\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.2756 - accuracy: 0.1667 - val_loss: 45.2994 - val_accuracy: 0.1556\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.2159 - accuracy: 0.1741 - val_loss: 45.2393 - val_accuracy: 0.1111\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1561 - accuracy: 0.1716 - val_loss: 45.1807 - val_accuracy: 0.1111\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.0960 - accuracy: 0.1766 - val_loss: 45.1251 - val_accuracy: 0.1333\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45.0362 - accuracy: 0.1816 - val_loss: 45.0651 - val_accuracy: 0.1333\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9763 - accuracy: 0.1667 - val_loss: 45.0024 - val_accuracy: 0.1333\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.9165 - accuracy: 0.1692 - val_loss: 44.9345 - val_accuracy: 0.1333\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.8569 - accuracy: 0.1692 - val_loss: 44.8706 - val_accuracy: 0.1778\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7975 - accuracy: 0.1617 - val_loss: 44.8095 - val_accuracy: 0.1778\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.7377 - accuracy: 0.1716 - val_loss: 44.7504 - val_accuracy: 0.1778\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.6781 - accuracy: 0.1716 - val_loss: 44.6963 - val_accuracy: 0.1333\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.6186 - accuracy: 0.1841 - val_loss: 44.6467 - val_accuracy: 0.0444\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.5602 - accuracy: 0.1841 - val_loss: 44.5951 - val_accuracy: 0.0444\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.5012 - accuracy: 0.1841 - val_loss: 44.5357 - val_accuracy: 0.0444\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.4412 - accuracy: 0.1841 - val_loss: 44.4749 - val_accuracy: 0.0444\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3818 - accuracy: 0.1841 - val_loss: 44.4149 - val_accuracy: 0.0444\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.3226 - accuracy: 0.1841 - val_loss: 44.3535 - val_accuracy: 0.0444\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2639 - accuracy: 0.1841 - val_loss: 44.2902 - val_accuracy: 0.0444\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.2051 - accuracy: 0.1841 - val_loss: 44.2294 - val_accuracy: 0.0444\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.1455 - accuracy: 0.1841 - val_loss: 44.1692 - val_accuracy: 0.0444\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0879 - accuracy: 0.1791 - val_loss: 44.1130 - val_accuracy: 0.1556\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0282 - accuracy: 0.1617 - val_loss: 44.0518 - val_accuracy: 0.1778\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.9693 - accuracy: 0.1741 - val_loss: 43.9901 - val_accuracy: 0.2222\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.9104 - accuracy: 0.1468 - val_loss: 43.9279 - val_accuracy: 0.1778\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.8521 - accuracy: 0.1517 - val_loss: 43.8712 - val_accuracy: 0.1333\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7927 - accuracy: 0.1567 - val_loss: 43.8184 - val_accuracy: 0.1333\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7339 - accuracy: 0.1567 - val_loss: 43.7639 - val_accuracy: 0.1333\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.6760 - accuracy: 0.1567 - val_loss: 43.7055 - val_accuracy: 0.1333\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6173 - accuracy: 0.1716 - val_loss: 43.6460 - val_accuracy: 0.0444\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5592 - accuracy: 0.1841 - val_loss: 43.5820 - val_accuracy: 0.0889\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5004 - accuracy: 0.1741 - val_loss: 43.5208 - val_accuracy: 0.0889\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.4419 - accuracy: 0.1642 - val_loss: 43.4642 - val_accuracy: 0.1556\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3837 - accuracy: 0.1617 - val_loss: 43.4067 - val_accuracy: 0.1556\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.3252 - accuracy: 0.1766 - val_loss: 43.3477 - val_accuracy: 0.1778\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.2665 - accuracy: 0.1443 - val_loss: 43.2865 - val_accuracy: 0.1333\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2095 - accuracy: 0.1567 - val_loss: 43.2245 - val_accuracy: 0.1333\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.1522 - accuracy: 0.1791 - val_loss: 43.1673 - val_accuracy: 0.0889\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0932 - accuracy: 0.1866 - val_loss: 43.1134 - val_accuracy: 0.0444\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.0353 - accuracy: 0.1841 - val_loss: 43.0600 - val_accuracy: 0.1333\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9789 - accuracy: 0.1891 - val_loss: 43.0037 - val_accuracy: 0.1333\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.9210 - accuracy: 0.1866 - val_loss: 42.9455 - val_accuracy: 0.2000\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.8623 - accuracy: 0.1816 - val_loss: 42.8855 - val_accuracy: 0.1333\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.8046 - accuracy: 0.1816 - val_loss: 42.8285 - val_accuracy: 0.0444\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.7469 - accuracy: 0.1741 - val_loss: 42.7732 - val_accuracy: 0.0889\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.6895 - accuracy: 0.1741 - val_loss: 42.7169 - val_accuracy: 0.0889\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42.6320 - accuracy: 0.1741 - val_loss: 42.6583 - val_accuracy: 0.0889\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5749 - accuracy: 0.1741 - val_loss: 42.5983 - val_accuracy: 0.1111\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5165 - accuracy: 0.1766 - val_loss: 42.5446 - val_accuracy: 0.1333\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4591 - accuracy: 0.1866 - val_loss: 42.4875 - val_accuracy: 0.2000\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.4019 - accuracy: 0.1716 - val_loss: 42.4264 - val_accuracy: 0.1778\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.3446 - accuracy: 0.1567 - val_loss: 42.3655 - val_accuracy: 0.2444\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.2874 - accuracy: 0.1692 - val_loss: 42.3085 - val_accuracy: 0.2444\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2307 - accuracy: 0.1567 - val_loss: 42.2538 - val_accuracy: 0.1778\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1740 - accuracy: 0.1468 - val_loss: 42.1973 - val_accuracy: 0.1778\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1161 - accuracy: 0.1468 - val_loss: 42.1421 - val_accuracy: 0.1778\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.0591 - accuracy: 0.1741 - val_loss: 42.0868 - val_accuracy: 0.1111\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.0024 - accuracy: 0.1716 - val_loss: 42.0337 - val_accuracy: 0.1111\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.9461 - accuracy: 0.1716 - val_loss: 41.9775 - val_accuracy: 0.1111\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.8893 - accuracy: 0.1766 - val_loss: 41.9169 - val_accuracy: 0.1556\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.8334 - accuracy: 0.1617 - val_loss: 41.8566 - val_accuracy: 0.1556\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7761 - accuracy: 0.1617 - val_loss: 41.7976 - val_accuracy: 0.1556\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7189 - accuracy: 0.1642 - val_loss: 41.7378 - val_accuracy: 0.0889\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.6631 - accuracy: 0.1567 - val_loss: 41.6830 - val_accuracy: 0.0444\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6060 - accuracy: 0.1841 - val_loss: 41.6260 - val_accuracy: 0.0444\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.5499 - accuracy: 0.1692 - val_loss: 41.5724 - val_accuracy: 0.0667\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4939 - accuracy: 0.1741 - val_loss: 41.5206 - val_accuracy: 0.0444\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.4372 - accuracy: 0.1841 - val_loss: 41.4680 - val_accuracy: 0.0444\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.3800 - accuracy: 0.1841 - val_loss: 41.4136 - val_accuracy: 0.0444\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3240 - accuracy: 0.1841 - val_loss: 41.3572 - val_accuracy: 0.1333\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2680 - accuracy: 0.1667 - val_loss: 41.3004 - val_accuracy: 0.1333\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2121 - accuracy: 0.1567 - val_loss: 41.2447 - val_accuracy: 0.1333\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1556 - accuracy: 0.1567 - val_loss: 41.1881 - val_accuracy: 0.1333\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0998 - accuracy: 0.1567 - val_loss: 41.1270 - val_accuracy: 0.1778\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0440 - accuracy: 0.1468 - val_loss: 41.0638 - val_accuracy: 0.2444\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.9876 - accuracy: 0.1716 - val_loss: 41.0074 - val_accuracy: 0.1556\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.9315 - accuracy: 0.1617 - val_loss: 40.9521 - val_accuracy: 0.1556\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.8757 - accuracy: 0.1617 - val_loss: 40.8997 - val_accuracy: 0.1556\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.8207 - accuracy: 0.1318 - val_loss: 40.8438 - val_accuracy: 0.0444\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.7642 - accuracy: 0.1866 - val_loss: 40.7890 - val_accuracy: 0.0444\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.7082 - accuracy: 0.1841 - val_loss: 40.7371 - val_accuracy: 0.0444\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6520 - accuracy: 0.1766 - val_loss: 40.6861 - val_accuracy: 0.1111\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.5971 - accuracy: 0.1667 - val_loss: 40.6320 - val_accuracy: 0.1778\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.5415 - accuracy: 0.1667 - val_loss: 40.5744 - val_accuracy: 0.1333\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.4868 - accuracy: 0.1567 - val_loss: 40.5170 - val_accuracy: 0.1333\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.4299 - accuracy: 0.1567 - val_loss: 40.4538 - val_accuracy: 0.1333\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3750 - accuracy: 0.1567 - val_loss: 40.3956 - val_accuracy: 0.1333\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.3202 - accuracy: 0.1741 - val_loss: 40.3394 - val_accuracy: 0.1333\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.2646 - accuracy: 0.1592 - val_loss: 40.2845 - val_accuracy: 0.1778\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2089 - accuracy: 0.1468 - val_loss: 40.2286 - val_accuracy: 0.1778\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.1541 - accuracy: 0.1468 - val_loss: 40.1749 - val_accuracy: 0.1778\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.0994 - accuracy: 0.1468 - val_loss: 40.1187 - val_accuracy: 0.1778\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0435 - accuracy: 0.1468 - val_loss: 40.0630 - val_accuracy: 0.1778\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9892 - accuracy: 0.1493 - val_loss: 40.0072 - val_accuracy: 0.1333\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9341 - accuracy: 0.1567 - val_loss: 39.9564 - val_accuracy: 0.1333\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.8788 - accuracy: 0.1443 - val_loss: 39.9039 - val_accuracy: 0.2000\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.8245 - accuracy: 0.1791 - val_loss: 39.8545 - val_accuracy: 0.1333\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7698 - accuracy: 0.1841 - val_loss: 39.8016 - val_accuracy: 0.1333\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.7146 - accuracy: 0.1791 - val_loss: 39.7455 - val_accuracy: 0.0444\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.6607 - accuracy: 0.1866 - val_loss: 39.6882 - val_accuracy: 0.0889\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.6058 - accuracy: 0.1667 - val_loss: 39.6273 - val_accuracy: 0.1333\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.5521 - accuracy: 0.1766 - val_loss: 39.5685 - val_accuracy: 0.0667\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4977 - accuracy: 0.1891 - val_loss: 39.5124 - val_accuracy: 0.0444\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4439 - accuracy: 0.1716 - val_loss: 39.4590 - val_accuracy: 0.0889\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.3886 - accuracy: 0.1741 - val_loss: 39.4049 - val_accuracy: 0.0889\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.3336 - accuracy: 0.1741 - val_loss: 39.3501 - val_accuracy: 0.0889\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.2794 - accuracy: 0.1716 - val_loss: 39.3002 - val_accuracy: 0.1778\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.2246 - accuracy: 0.1716 - val_loss: 39.2503 - val_accuracy: 0.0889\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1709 - accuracy: 0.1766 - val_loss: 39.1996 - val_accuracy: 0.1778\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1161 - accuracy: 0.1692 - val_loss: 39.1461 - val_accuracy: 0.1778\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.0624 - accuracy: 0.1841 - val_loss: 39.0930 - val_accuracy: 0.1111\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.0087 - accuracy: 0.1716 - val_loss: 39.0434 - val_accuracy: 0.1111\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9553 - accuracy: 0.1716 - val_loss: 38.9905 - val_accuracy: 0.1111\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.9010 - accuracy: 0.1841 - val_loss: 38.9381 - val_accuracy: 0.1333\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8470 - accuracy: 0.1866 - val_loss: 38.8853 - val_accuracy: 0.1556\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7931 - accuracy: 0.1816 - val_loss: 38.8328 - val_accuracy: 0.1778\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7390 - accuracy: 0.1791 - val_loss: 38.7782 - val_accuracy: 0.1333\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6851 - accuracy: 0.1841 - val_loss: 38.7234 - val_accuracy: 0.0444\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.6316 - accuracy: 0.1816 - val_loss: 38.6658 - val_accuracy: 0.0444\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.5780 - accuracy: 0.1841 - val_loss: 38.6105 - val_accuracy: 0.0444\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.5247 - accuracy: 0.1841 - val_loss: 38.5568 - val_accuracy: 0.0444\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.4705 - accuracy: 0.1841 - val_loss: 38.5031 - val_accuracy: 0.0444\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.4171 - accuracy: 0.1841 - val_loss: 38.4505 - val_accuracy: 0.1556\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.3631 - accuracy: 0.1866 - val_loss: 38.3926 - val_accuracy: 0.2222\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.3097 - accuracy: 0.1567 - val_loss: 38.3370 - val_accuracy: 0.1778\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.2575 - accuracy: 0.1468 - val_loss: 38.2825 - val_accuracy: 0.1778\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2038 - accuracy: 0.1468 - val_loss: 38.2287 - val_accuracy: 0.1778\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.1506 - accuracy: 0.1617 - val_loss: 38.1733 - val_accuracy: 0.1778\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0964 - accuracy: 0.1766 - val_loss: 38.1232 - val_accuracy: 0.2444\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0433 - accuracy: 0.1468 - val_loss: 38.0756 - val_accuracy: 0.1333\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9904 - accuracy: 0.1791 - val_loss: 38.0265 - val_accuracy: 0.0444\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9371 - accuracy: 0.1841 - val_loss: 37.9755 - val_accuracy: 0.1111\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.8843 - accuracy: 0.1816 - val_loss: 37.9242 - val_accuracy: 0.0444\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.8316 - accuracy: 0.1841 - val_loss: 37.8731 - val_accuracy: 0.0444\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.7791 - accuracy: 0.1841 - val_loss: 37.8210 - val_accuracy: 0.0889\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.7272 - accuracy: 0.1741 - val_loss: 37.7674 - val_accuracy: 0.0889\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.6736 - accuracy: 0.1741 - val_loss: 37.7100 - val_accuracy: 0.0889\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.6206 - accuracy: 0.1716 - val_loss: 37.6543 - val_accuracy: 0.0444\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.5681 - accuracy: 0.1841 - val_loss: 37.6056 - val_accuracy: 0.0444\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5152 - accuracy: 0.1841 - val_loss: 37.5547 - val_accuracy: 0.0444\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4619 - accuracy: 0.1841 - val_loss: 37.5026 - val_accuracy: 0.0444\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4096 - accuracy: 0.1791 - val_loss: 37.4454 - val_accuracy: 0.1778\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3562 - accuracy: 0.1692 - val_loss: 37.3845 - val_accuracy: 0.1778\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3040 - accuracy: 0.1716 - val_loss: 37.3306 - val_accuracy: 0.1333\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.2519 - accuracy: 0.1915 - val_loss: 37.2786 - val_accuracy: 0.1778\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1992 - accuracy: 0.1592 - val_loss: 37.2258 - val_accuracy: 0.1333\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.1482 - accuracy: 0.1567 - val_loss: 37.1749 - val_accuracy: 0.1333\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0963 - accuracy: 0.1567 - val_loss: 37.1217 - val_accuracy: 0.1333\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0440 - accuracy: 0.1567 - val_loss: 37.0696 - val_accuracy: 0.1333\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9916 - accuracy: 0.1567 - val_loss: 37.0186 - val_accuracy: 0.1333\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9390 - accuracy: 0.1741 - val_loss: 36.9659 - val_accuracy: 0.1333\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8864 - accuracy: 0.1891 - val_loss: 36.9131 - val_accuracy: 0.1333\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36.8343 - accuracy: 0.1940 - val_loss: 36.8647 - val_accuracy: 0.0444\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7819 - accuracy: 0.1841 - val_loss: 36.8135 - val_accuracy: 0.0444\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.7314 - accuracy: 0.1692 - val_loss: 36.7617 - val_accuracy: 0.1111\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6791 - accuracy: 0.1716 - val_loss: 36.7087 - val_accuracy: 0.1111\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.6272 - accuracy: 0.1716 - val_loss: 36.6546 - val_accuracy: 0.1333\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5754 - accuracy: 0.1642 - val_loss: 36.5986 - val_accuracy: 0.1333\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.5238 - accuracy: 0.1443 - val_loss: 36.5445 - val_accuracy: 0.1778\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.4720 - accuracy: 0.1468 - val_loss: 36.4918 - val_accuracy: 0.1778\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4202 - accuracy: 0.1468 - val_loss: 36.4416 - val_accuracy: 0.1778\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3687 - accuracy: 0.1468 - val_loss: 36.3938 - val_accuracy: 0.1778\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.3169 - accuracy: 0.1468 - val_loss: 36.3457 - val_accuracy: 0.1778\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2656 - accuracy: 0.1468 - val_loss: 36.2965 - val_accuracy: 0.1778\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2141 - accuracy: 0.1468 - val_loss: 36.2467 - val_accuracy: 0.1778\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1629 - accuracy: 0.1393 - val_loss: 36.1978 - val_accuracy: 0.1333\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.1119 - accuracy: 0.1567 - val_loss: 36.1470 - val_accuracy: 0.1333\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.0611 - accuracy: 0.1542 - val_loss: 36.0988 - val_accuracy: 0.1778\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.0111 - accuracy: 0.1617 - val_loss: 36.0483 - val_accuracy: 0.1556\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.9601 - accuracy: 0.1617 - val_loss: 35.9963 - val_accuracy: 0.1556\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.9084 - accuracy: 0.1617 - val_loss: 35.9418 - val_accuracy: 0.1556\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8567 - accuracy: 0.1692 - val_loss: 35.8924 - val_accuracy: 0.1778\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8053 - accuracy: 0.1567 - val_loss: 35.8427 - val_accuracy: 0.1333\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7542 - accuracy: 0.1567 - val_loss: 35.7923 - val_accuracy: 0.1333\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.7034 - accuracy: 0.1567 - val_loss: 35.7411 - val_accuracy: 0.1333\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6540 - accuracy: 0.1567 - val_loss: 35.6921 - val_accuracy: 0.1333\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6029 - accuracy: 0.1567 - val_loss: 35.6438 - val_accuracy: 0.1333\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5513 - accuracy: 0.1567 - val_loss: 35.5905 - val_accuracy: 0.1333\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5000 - accuracy: 0.1741 - val_loss: 35.5376 - val_accuracy: 0.0889\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.4489 - accuracy: 0.1766 - val_loss: 35.4865 - val_accuracy: 0.0444\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.3980 - accuracy: 0.1841 - val_loss: 35.4327 - val_accuracy: 0.0444\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.3480 - accuracy: 0.1841 - val_loss: 35.3769 - val_accuracy: 0.0444\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.2969 - accuracy: 0.1841 - val_loss: 35.3223 - val_accuracy: 0.0667\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.2470 - accuracy: 0.1741 - val_loss: 35.2679 - val_accuracy: 0.1778\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1959 - accuracy: 0.1468 - val_loss: 35.2203 - val_accuracy: 0.1778\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1455 - accuracy: 0.1642 - val_loss: 35.1722 - val_accuracy: 0.1778\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0958 - accuracy: 0.1741 - val_loss: 35.1203 - val_accuracy: 0.1778\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0452 - accuracy: 0.1741 - val_loss: 35.0714 - val_accuracy: 0.1778\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9954 - accuracy: 0.1741 - val_loss: 35.0226 - val_accuracy: 0.1556\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.9445 - accuracy: 0.1841 - val_loss: 34.9709 - val_accuracy: 0.1333\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.8942 - accuracy: 0.1567 - val_loss: 34.9195 - val_accuracy: 0.1333\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8436 - accuracy: 0.1567 - val_loss: 34.8677 - val_accuracy: 0.1333\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.7938 - accuracy: 0.1567 - val_loss: 34.8209 - val_accuracy: 0.1333\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7441 - accuracy: 0.1567 - val_loss: 34.7766 - val_accuracy: 0.1333\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6942 - accuracy: 0.1567 - val_loss: 34.7295 - val_accuracy: 0.1333\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34.6442 - accuracy: 0.1766 - val_loss: 34.6800 - val_accuracy: 0.0667\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5936 - accuracy: 0.1841 - val_loss: 34.6308 - val_accuracy: 0.0444\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.5437 - accuracy: 0.1841 - val_loss: 34.5800 - val_accuracy: 0.0667\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.4947 - accuracy: 0.1791 - val_loss: 34.5270 - val_accuracy: 0.1333\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.4455 - accuracy: 0.1567 - val_loss: 34.4743 - val_accuracy: 0.1333\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3954 - accuracy: 0.1667 - val_loss: 34.4220 - val_accuracy: 0.1778\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.3459 - accuracy: 0.1766 - val_loss: 34.3728 - val_accuracy: 0.1778\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.2959 - accuracy: 0.1741 - val_loss: 34.3246 - val_accuracy: 0.2000\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.2454 - accuracy: 0.1940 - val_loss: 34.2769 - val_accuracy: 0.1333\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.1968 - accuracy: 0.1567 - val_loss: 34.2296 - val_accuracy: 0.1333\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.1474 - accuracy: 0.1567 - val_loss: 34.1789 - val_accuracy: 0.1333\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34.0977 - accuracy: 0.1567 - val_loss: 34.1292 - val_accuracy: 0.1333\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0483 - accuracy: 0.1841 - val_loss: 34.0815 - val_accuracy: 0.0444\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9988 - accuracy: 0.1841 - val_loss: 34.0305 - val_accuracy: 0.0444\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.9499 - accuracy: 0.1841 - val_loss: 33.9758 - val_accuracy: 0.0444\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.9001 - accuracy: 0.1791 - val_loss: 33.9244 - val_accuracy: 0.1556\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.8510 - accuracy: 0.1617 - val_loss: 33.8751 - val_accuracy: 0.1556\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.8022 - accuracy: 0.1692 - val_loss: 33.8271 - val_accuracy: 0.1778\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.7531 - accuracy: 0.1567 - val_loss: 33.7813 - val_accuracy: 0.1333\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.7044 - accuracy: 0.1617 - val_loss: 33.7327 - val_accuracy: 0.1778\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6542 - accuracy: 0.1468 - val_loss: 33.6830 - val_accuracy: 0.1778\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.6057 - accuracy: 0.1493 - val_loss: 33.6332 - val_accuracy: 0.2444\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.5568 - accuracy: 0.1667 - val_loss: 33.5832 - val_accuracy: 0.1556\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5082 - accuracy: 0.1692 - val_loss: 33.5324 - val_accuracy: 0.1111\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4601 - accuracy: 0.1741 - val_loss: 33.4830 - val_accuracy: 0.1333\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4106 - accuracy: 0.1915 - val_loss: 33.4334 - val_accuracy: 0.1556\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3615 - accuracy: 0.1741 - val_loss: 33.3858 - val_accuracy: 0.1778\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.3143 - accuracy: 0.1716 - val_loss: 33.3426 - val_accuracy: 0.0889\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.2652 - accuracy: 0.1791 - val_loss: 33.2947 - val_accuracy: 0.1778\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2158 - accuracy: 0.1741 - val_loss: 33.2472 - val_accuracy: 0.1333\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.1675 - accuracy: 0.1766 - val_loss: 33.1996 - val_accuracy: 0.0444\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.1192 - accuracy: 0.1816 - val_loss: 33.1514 - val_accuracy: 0.1333\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.0714 - accuracy: 0.1891 - val_loss: 33.1068 - val_accuracy: 0.1333\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.0223 - accuracy: 0.1716 - val_loss: 33.0567 - val_accuracy: 0.1556\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9738 - accuracy: 0.1716 - val_loss: 33.0023 - val_accuracy: 0.1556\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.9265 - accuracy: 0.1617 - val_loss: 32.9524 - val_accuracy: 0.1556\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8785 - accuracy: 0.1617 - val_loss: 32.9032 - val_accuracy: 0.1556\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8298 - accuracy: 0.1617 - val_loss: 32.8530 - val_accuracy: 0.1556\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.7811 - accuracy: 0.1617 - val_loss: 32.8047 - val_accuracy: 0.0889\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7330 - accuracy: 0.1716 - val_loss: 32.7546 - val_accuracy: 0.1778\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.6852 - accuracy: 0.1542 - val_loss: 32.7060 - val_accuracy: 0.1333\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.6365 - accuracy: 0.1542 - val_loss: 32.6583 - val_accuracy: 0.1778\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5889 - accuracy: 0.1468 - val_loss: 32.6101 - val_accuracy: 0.1778\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.5416 - accuracy: 0.1468 - val_loss: 32.5619 - val_accuracy: 0.1778\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.4936 - accuracy: 0.1468 - val_loss: 32.5119 - val_accuracy: 0.2444\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.4453 - accuracy: 0.1716 - val_loss: 32.4659 - val_accuracy: 0.1556\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3975 - accuracy: 0.1741 - val_loss: 32.4215 - val_accuracy: 0.1556\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.3502 - accuracy: 0.1766 - val_loss: 32.3760 - val_accuracy: 0.1778\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3016 - accuracy: 0.1841 - val_loss: 32.3285 - val_accuracy: 0.0889\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2542 - accuracy: 0.1741 - val_loss: 32.2816 - val_accuracy: 0.0889\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2074 - accuracy: 0.1741 - val_loss: 32.2335 - val_accuracy: 0.0889\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.1603 - accuracy: 0.1741 - val_loss: 32.1850 - val_accuracy: 0.0889\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.1122 - accuracy: 0.1741 - val_loss: 32.1388 - val_accuracy: 0.0889\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.0651 - accuracy: 0.1741 - val_loss: 32.0964 - val_accuracy: 0.0889\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.0178 - accuracy: 0.1741 - val_loss: 32.0492 - val_accuracy: 0.1111\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9705 - accuracy: 0.1716 - val_loss: 31.9994 - val_accuracy: 0.1333\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9222 - accuracy: 0.1716 - val_loss: 31.9501 - val_accuracy: 0.0889\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.8745 - accuracy: 0.1741 - val_loss: 31.9014 - val_accuracy: 0.0889\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8273 - accuracy: 0.1741 - val_loss: 31.8551 - val_accuracy: 0.1778\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.7800 - accuracy: 0.1468 - val_loss: 31.8080 - val_accuracy: 0.1778\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.7330 - accuracy: 0.1468 - val_loss: 31.7581 - val_accuracy: 0.1778\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.6864 - accuracy: 0.1468 - val_loss: 31.7081 - val_accuracy: 0.1333\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.6396 - accuracy: 0.1567 - val_loss: 31.6632 - val_accuracy: 0.1333\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.5927 - accuracy: 0.1567 - val_loss: 31.6211 - val_accuracy: 0.1333\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.5450 - accuracy: 0.1617 - val_loss: 31.5769 - val_accuracy: 0.1333\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.4979 - accuracy: 0.1667 - val_loss: 31.5350 - val_accuracy: 0.1333\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.4510 - accuracy: 0.1816 - val_loss: 31.4920 - val_accuracy: 0.1111\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.4043 - accuracy: 0.1716 - val_loss: 31.4479 - val_accuracy: 0.1111\n",
      "========== Fold 7 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 207.7213 - accuracy: 0.0871 - val_loss: 196.5522 - val_accuracy: 0.1333\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 190.4546 - accuracy: 0.1119 - val_loss: 177.9242 - val_accuracy: 0.0889\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 172.3992 - accuracy: 0.1418 - val_loss: 161.7311 - val_accuracy: 0.0444\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 157.2491 - accuracy: 0.1493 - val_loss: 148.8188 - val_accuracy: 0.0889\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 145.3272 - accuracy: 0.1716 - val_loss: 138.7874 - val_accuracy: 0.1778\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136.1180 - accuracy: 0.1343 - val_loss: 131.0494 - val_accuracy: 0.1778\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 128.9881 - accuracy: 0.1368 - val_loss: 125.0338 - val_accuracy: 0.0889\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 123.4061 - accuracy: 0.1791 - val_loss: 120.2980 - val_accuracy: 0.1111\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 118.9820 - accuracy: 0.1866 - val_loss: 116.5096 - val_accuracy: 0.1111\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115.4181 - accuracy: 0.1592 - val_loss: 113.4253 - val_accuracy: 0.0889\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 112.5092 - accuracy: 0.1567 - val_loss: 110.8676 - val_accuracy: 0.0889\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 110.1001 - accuracy: 0.1592 - val_loss: 108.7153 - val_accuracy: 0.0889\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 108.0735 - accuracy: 0.1567 - val_loss: 106.9141 - val_accuracy: 0.0889\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 106.3526 - accuracy: 0.1567 - val_loss: 105.3744 - val_accuracy: 0.0444\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 104.8692 - accuracy: 0.1443 - val_loss: 104.0288 - val_accuracy: 0.0667\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 103.5774 - accuracy: 0.1468 - val_loss: 102.8509 - val_accuracy: 0.0667\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 102.4440 - accuracy: 0.1468 - val_loss: 101.8056 - val_accuracy: 0.0889\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101.4387 - accuracy: 0.1642 - val_loss: 100.8800 - val_accuracy: 0.0889\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100.5418 - accuracy: 0.1667 - val_loss: 100.0458 - val_accuracy: 0.0889\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.7348 - accuracy: 0.1592 - val_loss: 99.2975 - val_accuracy: 0.0889\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99.0026 - accuracy: 0.1567 - val_loss: 98.5983 - val_accuracy: 0.0889\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 98.3353 - accuracy: 0.1567 - val_loss: 97.9539 - val_accuracy: 0.0889\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 97.7230 - accuracy: 0.1567 - val_loss: 97.3613 - val_accuracy: 0.0889\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.1586 - accuracy: 0.1592 - val_loss: 96.8278 - val_accuracy: 0.0889\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 96.6329 - accuracy: 0.1592 - val_loss: 96.3305 - val_accuracy: 0.0889\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.1460 - accuracy: 0.1567 - val_loss: 95.8694 - val_accuracy: 0.0889\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.6869 - accuracy: 0.1567 - val_loss: 95.4427 - val_accuracy: 0.0889\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 95.2592 - accuracy: 0.1542 - val_loss: 95.0272 - val_accuracy: 0.0444\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.8559 - accuracy: 0.1567 - val_loss: 94.6281 - val_accuracy: 0.0889\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94.4731 - accuracy: 0.1567 - val_loss: 94.2648 - val_accuracy: 0.0889\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.1107 - accuracy: 0.1567 - val_loss: 93.9257 - val_accuracy: 0.0889\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.7660 - accuracy: 0.1567 - val_loss: 93.6073 - val_accuracy: 0.0889\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.4374 - accuracy: 0.1567 - val_loss: 93.2881 - val_accuracy: 0.0889\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.1217 - accuracy: 0.1567 - val_loss: 92.9690 - val_accuracy: 0.0889\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.8176 - accuracy: 0.1567 - val_loss: 92.6623 - val_accuracy: 0.0889\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.5256 - accuracy: 0.1567 - val_loss: 92.3777 - val_accuracy: 0.0889\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 92.2437 - accuracy: 0.1567 - val_loss: 92.0983 - val_accuracy: 0.0889\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.9718 - accuracy: 0.1567 - val_loss: 91.8371 - val_accuracy: 0.0889\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.7113 - accuracy: 0.1567 - val_loss: 91.5913 - val_accuracy: 0.0889\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.4568 - accuracy: 0.1592 - val_loss: 91.3464 - val_accuracy: 0.0889\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.2071 - accuracy: 0.1542 - val_loss: 91.0980 - val_accuracy: 0.1111\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.9662 - accuracy: 0.1642 - val_loss: 90.8530 - val_accuracy: 0.0889\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.7327 - accuracy: 0.1617 - val_loss: 90.6200 - val_accuracy: 0.0889\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.5040 - accuracy: 0.1567 - val_loss: 90.3943 - val_accuracy: 0.0889\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 90.2778 - accuracy: 0.1567 - val_loss: 90.1704 - val_accuracy: 0.0889\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90.0592 - accuracy: 0.1567 - val_loss: 89.9587 - val_accuracy: 0.0889\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.8453 - accuracy: 0.1493 - val_loss: 89.7526 - val_accuracy: 0.1111\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.6357 - accuracy: 0.1517 - val_loss: 89.5475 - val_accuracy: 0.0889\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 89.4289 - accuracy: 0.1567 - val_loss: 89.3426 - val_accuracy: 0.0889\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.2258 - accuracy: 0.1567 - val_loss: 89.1452 - val_accuracy: 0.0889\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.0298 - accuracy: 0.1542 - val_loss: 88.9459 - val_accuracy: 0.0889\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.8362 - accuracy: 0.1567 - val_loss: 88.7502 - val_accuracy: 0.0889\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88.6421 - accuracy: 0.1567 - val_loss: 88.5510 - val_accuracy: 0.0889\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.4517 - accuracy: 0.1567 - val_loss: 88.3681 - val_accuracy: 0.0889\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88.2650 - accuracy: 0.1567 - val_loss: 88.1959 - val_accuracy: 0.0889\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0818 - accuracy: 0.1567 - val_loss: 88.0243 - val_accuracy: 0.0889\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.9011 - accuracy: 0.1567 - val_loss: 87.8347 - val_accuracy: 0.0889\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.7211 - accuracy: 0.1567 - val_loss: 87.6471 - val_accuracy: 0.0889\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.5436 - accuracy: 0.1567 - val_loss: 87.4707 - val_accuracy: 0.1556\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.3703 - accuracy: 0.1766 - val_loss: 87.2980 - val_accuracy: 0.1333\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.1993 - accuracy: 0.1393 - val_loss: 87.1341 - val_accuracy: 0.1333\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.0281 - accuracy: 0.1617 - val_loss: 86.9718 - val_accuracy: 0.0889\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.8576 - accuracy: 0.1567 - val_loss: 86.7940 - val_accuracy: 0.0889\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.6921 - accuracy: 0.1567 - val_loss: 86.6229 - val_accuracy: 0.0889\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.5276 - accuracy: 0.1567 - val_loss: 86.4654 - val_accuracy: 0.0889\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86.3633 - accuracy: 0.1567 - val_loss: 86.3097 - val_accuracy: 0.0889\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 86.2025 - accuracy: 0.1567 - val_loss: 86.1582 - val_accuracy: 0.0889\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0417 - accuracy: 0.1567 - val_loss: 85.9905 - val_accuracy: 0.0889\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.8828 - accuracy: 0.1567 - val_loss: 85.8352 - val_accuracy: 0.0889\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.7246 - accuracy: 0.1567 - val_loss: 85.6710 - val_accuracy: 0.0889\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.5683 - accuracy: 0.1567 - val_loss: 85.5108 - val_accuracy: 0.0889\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.4144 - accuracy: 0.1567 - val_loss: 85.3424 - val_accuracy: 0.0889\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.2609 - accuracy: 0.1716 - val_loss: 85.1841 - val_accuracy: 0.0889\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.1094 - accuracy: 0.1716 - val_loss: 85.0413 - val_accuracy: 0.0889\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.9565 - accuracy: 0.1592 - val_loss: 84.8970 - val_accuracy: 0.0889\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84.8058 - accuracy: 0.1567 - val_loss: 84.7556 - val_accuracy: 0.0889\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.6595 - accuracy: 0.1567 - val_loss: 84.6171 - val_accuracy: 0.0889\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.5124 - accuracy: 0.1567 - val_loss: 84.4675 - val_accuracy: 0.0889\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.3643 - accuracy: 0.1567 - val_loss: 84.3168 - val_accuracy: 0.0889\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.2183 - accuracy: 0.1567 - val_loss: 84.1721 - val_accuracy: 0.0889\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84.0741 - accuracy: 0.1567 - val_loss: 84.0227 - val_accuracy: 0.0889\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.9292 - accuracy: 0.1567 - val_loss: 83.8811 - val_accuracy: 0.0889\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.7867 - accuracy: 0.1567 - val_loss: 83.7444 - val_accuracy: 0.0889\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.6470 - accuracy: 0.1517 - val_loss: 83.6144 - val_accuracy: 0.0444\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.5066 - accuracy: 0.1517 - val_loss: 83.4771 - val_accuracy: 0.0889\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.3653 - accuracy: 0.1567 - val_loss: 83.3425 - val_accuracy: 0.0889\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.2263 - accuracy: 0.1567 - val_loss: 83.2058 - val_accuracy: 0.0889\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.0893 - accuracy: 0.1567 - val_loss: 83.0601 - val_accuracy: 0.0889\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.9506 - accuracy: 0.1567 - val_loss: 82.9275 - val_accuracy: 0.0889\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.8137 - accuracy: 0.1567 - val_loss: 82.7879 - val_accuracy: 0.0889\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 82.6770 - accuracy: 0.1567 - val_loss: 82.6444 - val_accuracy: 0.0889\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.5419 - accuracy: 0.1567 - val_loss: 82.4964 - val_accuracy: 0.0889\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.4071 - accuracy: 0.1567 - val_loss: 82.3575 - val_accuracy: 0.0889\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2743 - accuracy: 0.1567 - val_loss: 82.2229 - val_accuracy: 0.0889\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.1414 - accuracy: 0.1567 - val_loss: 82.0918 - val_accuracy: 0.0889\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.0084 - accuracy: 0.1567 - val_loss: 81.9684 - val_accuracy: 0.0889\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.8776 - accuracy: 0.1567 - val_loss: 81.8436 - val_accuracy: 0.0889\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.7467 - accuracy: 0.1567 - val_loss: 81.7107 - val_accuracy: 0.0889\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.6161 - accuracy: 0.1567 - val_loss: 81.5837 - val_accuracy: 0.0889\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.4865 - accuracy: 0.1468 - val_loss: 81.4513 - val_accuracy: 0.0889\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.3572 - accuracy: 0.1542 - val_loss: 81.3194 - val_accuracy: 0.0889\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.2290 - accuracy: 0.1567 - val_loss: 81.1924 - val_accuracy: 0.0889\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.1019 - accuracy: 0.1542 - val_loss: 81.0686 - val_accuracy: 0.0889\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.9745 - accuracy: 0.1617 - val_loss: 80.9496 - val_accuracy: 0.0889\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.8484 - accuracy: 0.1617 - val_loss: 80.8239 - val_accuracy: 0.0889\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.7231 - accuracy: 0.1642 - val_loss: 80.6984 - val_accuracy: 0.0889\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.5974 - accuracy: 0.1567 - val_loss: 80.5675 - val_accuracy: 0.0889\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.4717 - accuracy: 0.1567 - val_loss: 80.4422 - val_accuracy: 0.0889\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.3486 - accuracy: 0.1642 - val_loss: 80.3175 - val_accuracy: 0.1111\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80.2256 - accuracy: 0.1716 - val_loss: 80.1929 - val_accuracy: 0.0889\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1022 - accuracy: 0.1741 - val_loss: 80.0642 - val_accuracy: 0.0889\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.9793 - accuracy: 0.1592 - val_loss: 79.9462 - val_accuracy: 0.0889\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8563 - accuracy: 0.1567 - val_loss: 79.8269 - val_accuracy: 0.0889\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.7339 - accuracy: 0.1567 - val_loss: 79.7106 - val_accuracy: 0.0889\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6132 - accuracy: 0.1567 - val_loss: 79.5983 - val_accuracy: 0.0889\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.4927 - accuracy: 0.1567 - val_loss: 79.4823 - val_accuracy: 0.0889\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.3733 - accuracy: 0.1617 - val_loss: 79.3568 - val_accuracy: 0.0889\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.2530 - accuracy: 0.1567 - val_loss: 79.2355 - val_accuracy: 0.0889\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.1333 - accuracy: 0.1567 - val_loss: 79.1136 - val_accuracy: 0.0889\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0149 - accuracy: 0.1567 - val_loss: 78.9834 - val_accuracy: 0.0889\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.8962 - accuracy: 0.1567 - val_loss: 78.8568 - val_accuracy: 0.0889\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.7789 - accuracy: 0.1567 - val_loss: 78.7381 - val_accuracy: 0.0889\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.6614 - accuracy: 0.1567 - val_loss: 78.6292 - val_accuracy: 0.0889\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5445 - accuracy: 0.1567 - val_loss: 78.5161 - val_accuracy: 0.0889\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.4288 - accuracy: 0.1542 - val_loss: 78.4023 - val_accuracy: 0.0889\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.3123 - accuracy: 0.1617 - val_loss: 78.2898 - val_accuracy: 0.0889\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.1968 - accuracy: 0.1617 - val_loss: 78.1773 - val_accuracy: 0.0889\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.0816 - accuracy: 0.1617 - val_loss: 78.0656 - val_accuracy: 0.0889\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.9666 - accuracy: 0.1617 - val_loss: 77.9503 - val_accuracy: 0.0889\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.8522 - accuracy: 0.1567 - val_loss: 77.8422 - val_accuracy: 0.0889\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.7390 - accuracy: 0.1567 - val_loss: 77.7303 - val_accuracy: 0.0889\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6254 - accuracy: 0.1567 - val_loss: 77.6110 - val_accuracy: 0.0889\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5110 - accuracy: 0.1567 - val_loss: 77.4886 - val_accuracy: 0.0889\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.3974 - accuracy: 0.1567 - val_loss: 77.3696 - val_accuracy: 0.0889\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.2848 - accuracy: 0.1567 - val_loss: 77.2595 - val_accuracy: 0.0889\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.1728 - accuracy: 0.1567 - val_loss: 77.1523 - val_accuracy: 0.0889\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.0620 - accuracy: 0.1567 - val_loss: 77.0512 - val_accuracy: 0.0889\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.9503 - accuracy: 0.1567 - val_loss: 76.9389 - val_accuracy: 0.0889\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.8399 - accuracy: 0.1567 - val_loss: 76.8235 - val_accuracy: 0.0889\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.7280 - accuracy: 0.1567 - val_loss: 76.7041 - val_accuracy: 0.0889\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.6173 - accuracy: 0.1567 - val_loss: 76.5841 - val_accuracy: 0.0889\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.5083 - accuracy: 0.1617 - val_loss: 76.4701 - val_accuracy: 0.1111\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.3984 - accuracy: 0.1741 - val_loss: 76.3690 - val_accuracy: 0.0889\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.2896 - accuracy: 0.1567 - val_loss: 76.2631 - val_accuracy: 0.0889\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.1797 - accuracy: 0.1567 - val_loss: 76.1561 - val_accuracy: 0.0889\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.0707 - accuracy: 0.1567 - val_loss: 76.0544 - val_accuracy: 0.0889\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75.9626 - accuracy: 0.1567 - val_loss: 75.9557 - val_accuracy: 0.0889\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8558 - accuracy: 0.1567 - val_loss: 75.8537 - val_accuracy: 0.0889\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7497 - accuracy: 0.1567 - val_loss: 75.7454 - val_accuracy: 0.1111\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75.6417 - accuracy: 0.1642 - val_loss: 75.6277 - val_accuracy: 0.0889\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.5331 - accuracy: 0.1567 - val_loss: 75.5073 - val_accuracy: 0.0889\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.4266 - accuracy: 0.1567 - val_loss: 75.3947 - val_accuracy: 0.0889\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.3224 - accuracy: 0.1642 - val_loss: 75.2884 - val_accuracy: 0.0889\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.2174 - accuracy: 0.1642 - val_loss: 75.1825 - val_accuracy: 0.0889\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.1113 - accuracy: 0.1567 - val_loss: 75.0830 - val_accuracy: 0.0889\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.0031 - accuracy: 0.1567 - val_loss: 74.9791 - val_accuracy: 0.0889\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74.8986 - accuracy: 0.1567 - val_loss: 74.8756 - val_accuracy: 0.0889\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7923 - accuracy: 0.1567 - val_loss: 74.7736 - val_accuracy: 0.0889\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.6885 - accuracy: 0.1567 - val_loss: 74.6649 - val_accuracy: 0.0889\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.5834 - accuracy: 0.1567 - val_loss: 74.5642 - val_accuracy: 0.0889\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.4795 - accuracy: 0.1567 - val_loss: 74.4640 - val_accuracy: 0.0889\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.3764 - accuracy: 0.1567 - val_loss: 74.3659 - val_accuracy: 0.0889\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.2730 - accuracy: 0.1567 - val_loss: 74.2621 - val_accuracy: 0.0889\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.1702 - accuracy: 0.1567 - val_loss: 74.1580 - val_accuracy: 0.0889\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.0672 - accuracy: 0.1567 - val_loss: 74.0575 - val_accuracy: 0.0889\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.9648 - accuracy: 0.1567 - val_loss: 73.9604 - val_accuracy: 0.0889\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.8631 - accuracy: 0.1567 - val_loss: 73.8538 - val_accuracy: 0.0889\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.7616 - accuracy: 0.1567 - val_loss: 73.7503 - val_accuracy: 0.0889\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.6602 - accuracy: 0.1567 - val_loss: 73.6447 - val_accuracy: 0.0889\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.5581 - accuracy: 0.1567 - val_loss: 73.5367 - val_accuracy: 0.0889\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4557 - accuracy: 0.1567 - val_loss: 73.4308 - val_accuracy: 0.0889\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.3558 - accuracy: 0.1567 - val_loss: 73.3287 - val_accuracy: 0.0889\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.2549 - accuracy: 0.1567 - val_loss: 73.2264 - val_accuracy: 0.0889\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.1543 - accuracy: 0.1567 - val_loss: 73.1281 - val_accuracy: 0.0889\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.0532 - accuracy: 0.1567 - val_loss: 73.0337 - val_accuracy: 0.0889\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 72.9538 - accuracy: 0.1567 - val_loss: 72.9378 - val_accuracy: 0.0889\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.8547 - accuracy: 0.1567 - val_loss: 72.8366 - val_accuracy: 0.0889\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.7550 - accuracy: 0.1567 - val_loss: 72.7349 - val_accuracy: 0.0889\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.6548 - accuracy: 0.1567 - val_loss: 72.6380 - val_accuracy: 0.0889\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.5554 - accuracy: 0.1567 - val_loss: 72.5423 - val_accuracy: 0.0889\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.4578 - accuracy: 0.1567 - val_loss: 72.4482 - val_accuracy: 0.0889\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.3590 - accuracy: 0.1567 - val_loss: 72.3559 - val_accuracy: 0.0889\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 72.2613 - accuracy: 0.1517 - val_loss: 72.2580 - val_accuracy: 0.0667\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.1633 - accuracy: 0.1517 - val_loss: 72.1557 - val_accuracy: 0.0889\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.0652 - accuracy: 0.1567 - val_loss: 72.0486 - val_accuracy: 0.0889\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9671 - accuracy: 0.1567 - val_loss: 71.9482 - val_accuracy: 0.0889\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8704 - accuracy: 0.1567 - val_loss: 71.8500 - val_accuracy: 0.0889\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.7729 - accuracy: 0.1567 - val_loss: 71.7562 - val_accuracy: 0.0889\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.6762 - accuracy: 0.1567 - val_loss: 71.6678 - val_accuracy: 0.0889\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.5802 - accuracy: 0.1567 - val_loss: 71.5811 - val_accuracy: 0.0889\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4847 - accuracy: 0.1567 - val_loss: 71.4900 - val_accuracy: 0.0889\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.3888 - accuracy: 0.1567 - val_loss: 71.3921 - val_accuracy: 0.0889\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.2921 - accuracy: 0.1617 - val_loss: 71.2950 - val_accuracy: 0.0889\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1958 - accuracy: 0.1617 - val_loss: 71.1964 - val_accuracy: 0.0889\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.0992 - accuracy: 0.1592 - val_loss: 71.0882 - val_accuracy: 0.0889\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.0032 - accuracy: 0.1567 - val_loss: 70.9858 - val_accuracy: 0.0889\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.9081 - accuracy: 0.1567 - val_loss: 70.8881 - val_accuracy: 0.0889\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.8134 - accuracy: 0.1567 - val_loss: 70.7931 - val_accuracy: 0.0889\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7182 - accuracy: 0.1567 - val_loss: 70.7006 - val_accuracy: 0.0889\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.6239 - accuracy: 0.1567 - val_loss: 70.6076 - val_accuracy: 0.0889\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.5303 - accuracy: 0.1567 - val_loss: 70.5186 - val_accuracy: 0.0889\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.4360 - accuracy: 0.1567 - val_loss: 70.4277 - val_accuracy: 0.0889\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.3424 - accuracy: 0.1567 - val_loss: 70.3310 - val_accuracy: 0.0889\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.2478 - accuracy: 0.1567 - val_loss: 70.2413 - val_accuracy: 0.0889\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.1547 - accuracy: 0.1567 - val_loss: 70.1476 - val_accuracy: 0.0889\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.0615 - accuracy: 0.1567 - val_loss: 70.0490 - val_accuracy: 0.0889\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.9672 - accuracy: 0.1567 - val_loss: 69.9613 - val_accuracy: 0.0889\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8745 - accuracy: 0.1567 - val_loss: 69.8730 - val_accuracy: 0.0889\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.7817 - accuracy: 0.1567 - val_loss: 69.7815 - val_accuracy: 0.0889\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.6902 - accuracy: 0.1567 - val_loss: 69.6884 - val_accuracy: 0.0889\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.5977 - accuracy: 0.1567 - val_loss: 69.5906 - val_accuracy: 0.0889\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.5064 - accuracy: 0.1567 - val_loss: 69.4901 - val_accuracy: 0.0889\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.4131 - accuracy: 0.1567 - val_loss: 69.3976 - val_accuracy: 0.0889\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.3201 - accuracy: 0.1567 - val_loss: 69.3032 - val_accuracy: 0.0889\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.2303 - accuracy: 0.1567 - val_loss: 69.2142 - val_accuracy: 0.0889\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.1384 - accuracy: 0.1567 - val_loss: 69.1275 - val_accuracy: 0.0889\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.0476 - accuracy: 0.1567 - val_loss: 69.0402 - val_accuracy: 0.0889\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.9570 - accuracy: 0.1567 - val_loss: 68.9529 - val_accuracy: 0.0889\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.8651 - accuracy: 0.1567 - val_loss: 68.8590 - val_accuracy: 0.0889\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.7737 - accuracy: 0.1567 - val_loss: 68.7625 - val_accuracy: 0.0889\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.6831 - accuracy: 0.1567 - val_loss: 68.6728 - val_accuracy: 0.0889\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.5934 - accuracy: 0.1567 - val_loss: 68.5804 - val_accuracy: 0.0889\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 68.5040 - accuracy: 0.1567 - val_loss: 68.4917 - val_accuracy: 0.0889\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.4141 - accuracy: 0.1567 - val_loss: 68.4115 - val_accuracy: 0.0889\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.3240 - accuracy: 0.1567 - val_loss: 68.3271 - val_accuracy: 0.0889\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2335 - accuracy: 0.1567 - val_loss: 68.2414 - val_accuracy: 0.0889\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.1447 - accuracy: 0.1567 - val_loss: 68.1553 - val_accuracy: 0.0889\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.0551 - accuracy: 0.1567 - val_loss: 68.0578 - val_accuracy: 0.0889\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9659 - accuracy: 0.1567 - val_loss: 67.9652 - val_accuracy: 0.0889\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.8764 - accuracy: 0.1567 - val_loss: 67.8773 - val_accuracy: 0.0889\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.7876 - accuracy: 0.1567 - val_loss: 67.7898 - val_accuracy: 0.0889\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6992 - accuracy: 0.1567 - val_loss: 67.7091 - val_accuracy: 0.0889\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6113 - accuracy: 0.1567 - val_loss: 67.6255 - val_accuracy: 0.0889\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.5232 - accuracy: 0.1567 - val_loss: 67.5387 - val_accuracy: 0.0889\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.4349 - accuracy: 0.1567 - val_loss: 67.4420 - val_accuracy: 0.0889\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67.3462 - accuracy: 0.1567 - val_loss: 67.3442 - val_accuracy: 0.0889\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.2578 - accuracy: 0.1567 - val_loss: 67.2557 - val_accuracy: 0.0889\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.1698 - accuracy: 0.1567 - val_loss: 67.1657 - val_accuracy: 0.0889\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.0821 - accuracy: 0.1567 - val_loss: 67.0781 - val_accuracy: 0.0889\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9952 - accuracy: 0.1567 - val_loss: 66.9905 - val_accuracy: 0.0889\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.9089 - accuracy: 0.1567 - val_loss: 66.8976 - val_accuracy: 0.0889\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8224 - accuracy: 0.1567 - val_loss: 66.8145 - val_accuracy: 0.0889\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.7338 - accuracy: 0.1567 - val_loss: 66.7296 - val_accuracy: 0.0889\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.6473 - accuracy: 0.1567 - val_loss: 66.6405 - val_accuracy: 0.0889\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.5607 - accuracy: 0.1567 - val_loss: 66.5488 - val_accuracy: 0.0889\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.4746 - accuracy: 0.1567 - val_loss: 66.4572 - val_accuracy: 0.0889\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3882 - accuracy: 0.1567 - val_loss: 66.3642 - val_accuracy: 0.0889\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.3029 - accuracy: 0.1791 - val_loss: 66.2750 - val_accuracy: 0.0889\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.2174 - accuracy: 0.1692 - val_loss: 66.1889 - val_accuracy: 0.0889\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.1317 - accuracy: 0.1667 - val_loss: 66.1092 - val_accuracy: 0.0889\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66.0453 - accuracy: 0.1617 - val_loss: 66.0356 - val_accuracy: 0.0889\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.9594 - accuracy: 0.1567 - val_loss: 65.9623 - val_accuracy: 0.0889\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.8749 - accuracy: 0.1567 - val_loss: 65.8798 - val_accuracy: 0.0889\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7900 - accuracy: 0.1567 - val_loss: 65.7952 - val_accuracy: 0.0889\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.7051 - accuracy: 0.1816 - val_loss: 65.7092 - val_accuracy: 0.1333\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6190 - accuracy: 0.1692 - val_loss: 65.6167 - val_accuracy: 0.1333\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.5344 - accuracy: 0.1692 - val_loss: 65.5275 - val_accuracy: 0.1333\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65.4507 - accuracy: 0.1692 - val_loss: 65.4410 - val_accuracy: 0.0889\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.3648 - accuracy: 0.1567 - val_loss: 65.3597 - val_accuracy: 0.0889\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.2804 - accuracy: 0.1567 - val_loss: 65.2758 - val_accuracy: 0.0889\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.1957 - accuracy: 0.1567 - val_loss: 65.1900 - val_accuracy: 0.0889\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.1112 - accuracy: 0.1567 - val_loss: 65.1078 - val_accuracy: 0.0889\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.0270 - accuracy: 0.1567 - val_loss: 65.0238 - val_accuracy: 0.0889\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.9435 - accuracy: 0.1567 - val_loss: 64.9435 - val_accuracy: 0.0889\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.8592 - accuracy: 0.1567 - val_loss: 64.8592 - val_accuracy: 0.0889\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.7756 - accuracy: 0.1567 - val_loss: 64.7743 - val_accuracy: 0.0889\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.6922 - accuracy: 0.1567 - val_loss: 64.6871 - val_accuracy: 0.0889\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.6095 - accuracy: 0.1567 - val_loss: 64.6028 - val_accuracy: 0.0889\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.5263 - accuracy: 0.1567 - val_loss: 64.5207 - val_accuracy: 0.0889\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.4437 - accuracy: 0.1567 - val_loss: 64.4382 - val_accuracy: 0.1333\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.3603 - accuracy: 0.1617 - val_loss: 64.3574 - val_accuracy: 0.0889\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.2775 - accuracy: 0.1567 - val_loss: 64.2755 - val_accuracy: 0.0889\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.1951 - accuracy: 0.1567 - val_loss: 64.1946 - val_accuracy: 0.0889\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.1124 - accuracy: 0.1567 - val_loss: 64.1135 - val_accuracy: 0.0889\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.0299 - accuracy: 0.1567 - val_loss: 64.0279 - val_accuracy: 0.0889\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.9480 - accuracy: 0.1567 - val_loss: 63.9450 - val_accuracy: 0.0889\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.8658 - accuracy: 0.1567 - val_loss: 63.8627 - val_accuracy: 0.0889\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7838 - accuracy: 0.1567 - val_loss: 63.7840 - val_accuracy: 0.0889\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7025 - accuracy: 0.1567 - val_loss: 63.7062 - val_accuracy: 0.0889\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.6208 - accuracy: 0.1567 - val_loss: 63.6230 - val_accuracy: 0.0889\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.5405 - accuracy: 0.1567 - val_loss: 63.5414 - val_accuracy: 0.0889\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.4584 - accuracy: 0.1567 - val_loss: 63.4557 - val_accuracy: 0.0889\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3761 - accuracy: 0.1567 - val_loss: 63.3681 - val_accuracy: 0.0889\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.2947 - accuracy: 0.1567 - val_loss: 63.2876 - val_accuracy: 0.0889\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.2132 - accuracy: 0.1567 - val_loss: 63.2112 - val_accuracy: 0.0889\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.1323 - accuracy: 0.1567 - val_loss: 63.1306 - val_accuracy: 0.0889\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.0508 - accuracy: 0.1567 - val_loss: 63.0529 - val_accuracy: 0.0889\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9709 - accuracy: 0.1567 - val_loss: 62.9751 - val_accuracy: 0.0889\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.8907 - accuracy: 0.1567 - val_loss: 62.9021 - val_accuracy: 0.0889\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.8102 - accuracy: 0.1567 - val_loss: 62.8255 - val_accuracy: 0.0889\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.7299 - accuracy: 0.1567 - val_loss: 62.7458 - val_accuracy: 0.0889\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.6501 - accuracy: 0.1617 - val_loss: 62.6685 - val_accuracy: 0.0889\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.5699 - accuracy: 0.1617 - val_loss: 62.5869 - val_accuracy: 0.0889\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.4903 - accuracy: 0.1617 - val_loss: 62.4977 - val_accuracy: 0.0889\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.4113 - accuracy: 0.1617 - val_loss: 62.4094 - val_accuracy: 0.0889\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.3306 - accuracy: 0.1617 - val_loss: 62.3285 - val_accuracy: 0.0889\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.2499 - accuracy: 0.1567 - val_loss: 62.2475 - val_accuracy: 0.0889\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62.1697 - accuracy: 0.1567 - val_loss: 62.1657 - val_accuracy: 0.0889\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.0905 - accuracy: 0.1567 - val_loss: 62.0854 - val_accuracy: 0.0889\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.0111 - accuracy: 0.1567 - val_loss: 62.0075 - val_accuracy: 0.0889\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9322 - accuracy: 0.1567 - val_loss: 61.9305 - val_accuracy: 0.0889\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.8538 - accuracy: 0.1617 - val_loss: 61.8514 - val_accuracy: 0.0889\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.7766 - accuracy: 0.1617 - val_loss: 61.7751 - val_accuracy: 0.0889\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.6969 - accuracy: 0.1617 - val_loss: 61.6948 - val_accuracy: 0.0889\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.6179 - accuracy: 0.1567 - val_loss: 61.6086 - val_accuracy: 0.0889\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.5371 - accuracy: 0.1567 - val_loss: 61.5272 - val_accuracy: 0.0889\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4590 - accuracy: 0.1567 - val_loss: 61.4529 - val_accuracy: 0.0889\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3817 - accuracy: 0.1567 - val_loss: 61.3767 - val_accuracy: 0.0889\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3030 - accuracy: 0.1567 - val_loss: 61.3017 - val_accuracy: 0.0889\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2244 - accuracy: 0.1567 - val_loss: 61.2252 - val_accuracy: 0.0889\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.1456 - accuracy: 0.1567 - val_loss: 61.1472 - val_accuracy: 0.0889\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 61.0685 - accuracy: 0.1567 - val_loss: 61.0713 - val_accuracy: 0.0889\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.9903 - accuracy: 0.1567 - val_loss: 60.9907 - val_accuracy: 0.0889\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.9123 - accuracy: 0.1567 - val_loss: 60.9141 - val_accuracy: 0.0889\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.8353 - accuracy: 0.1567 - val_loss: 60.8390 - val_accuracy: 0.0889\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.7573 - accuracy: 0.1567 - val_loss: 60.7598 - val_accuracy: 0.0889\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6809 - accuracy: 0.1567 - val_loss: 60.6836 - val_accuracy: 0.0889\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.6025 - accuracy: 0.1567 - val_loss: 60.6049 - val_accuracy: 0.0889\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5253 - accuracy: 0.1567 - val_loss: 60.5292 - val_accuracy: 0.0889\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.4483 - accuracy: 0.1567 - val_loss: 60.4473 - val_accuracy: 0.0889\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3719 - accuracy: 0.1567 - val_loss: 60.3667 - val_accuracy: 0.0889\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.2952 - accuracy: 0.1567 - val_loss: 60.2905 - val_accuracy: 0.0889\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.2189 - accuracy: 0.1567 - val_loss: 60.2211 - val_accuracy: 0.0889\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.1411 - accuracy: 0.1567 - val_loss: 60.1431 - val_accuracy: 0.0889\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.0643 - accuracy: 0.1567 - val_loss: 60.0655 - val_accuracy: 0.0889\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.9877 - accuracy: 0.1567 - val_loss: 59.9861 - val_accuracy: 0.0889\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.9121 - accuracy: 0.1567 - val_loss: 59.9085 - val_accuracy: 0.0889\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.8358 - accuracy: 0.1567 - val_loss: 59.8355 - val_accuracy: 0.0889\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7595 - accuracy: 0.1567 - val_loss: 59.7622 - val_accuracy: 0.0889\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6834 - accuracy: 0.1567 - val_loss: 59.6869 - val_accuracy: 0.0889\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.6081 - accuracy: 0.1567 - val_loss: 59.6165 - val_accuracy: 0.0889\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.5321 - accuracy: 0.1567 - val_loss: 59.5356 - val_accuracy: 0.0889\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.4563 - accuracy: 0.1567 - val_loss: 59.4534 - val_accuracy: 0.0889\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.3802 - accuracy: 0.1567 - val_loss: 59.3728 - val_accuracy: 0.0889\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.3053 - accuracy: 0.1567 - val_loss: 59.2895 - val_accuracy: 0.0889\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.2312 - accuracy: 0.1567 - val_loss: 59.2115 - val_accuracy: 0.0889\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.1561 - accuracy: 0.1567 - val_loss: 59.1401 - val_accuracy: 0.0889\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0800 - accuracy: 0.1567 - val_loss: 59.0693 - val_accuracy: 0.0889\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0042 - accuracy: 0.1567 - val_loss: 58.9967 - val_accuracy: 0.0889\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.9282 - accuracy: 0.1567 - val_loss: 58.9257 - val_accuracy: 0.0889\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.8531 - accuracy: 0.1567 - val_loss: 58.8602 - val_accuracy: 0.0889\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.7789 - accuracy: 0.1567 - val_loss: 58.7902 - val_accuracy: 0.0889\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.7042 - accuracy: 0.1567 - val_loss: 58.7131 - val_accuracy: 0.0889\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.6297 - accuracy: 0.1567 - val_loss: 58.6343 - val_accuracy: 0.0889\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.5544 - accuracy: 0.1567 - val_loss: 58.5567 - val_accuracy: 0.0889\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.4802 - accuracy: 0.1567 - val_loss: 58.4823 - val_accuracy: 0.0889\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.4065 - accuracy: 0.1567 - val_loss: 58.4129 - val_accuracy: 0.0889\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.3324 - accuracy: 0.1567 - val_loss: 58.3442 - val_accuracy: 0.0889\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.2579 - accuracy: 0.1567 - val_loss: 58.2694 - val_accuracy: 0.0889\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.1845 - accuracy: 0.1567 - val_loss: 58.1965 - val_accuracy: 0.0889\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.1107 - accuracy: 0.1567 - val_loss: 58.1275 - val_accuracy: 0.0889\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.0361 - accuracy: 0.1567 - val_loss: 58.0570 - val_accuracy: 0.0889\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.9625 - accuracy: 0.1567 - val_loss: 57.9859 - val_accuracy: 0.0889\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.8893 - accuracy: 0.1567 - val_loss: 57.9061 - val_accuracy: 0.0889\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.8147 - accuracy: 0.1567 - val_loss: 57.8256 - val_accuracy: 0.0889\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7414 - accuracy: 0.1468 - val_loss: 57.7462 - val_accuracy: 0.0889\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.6673 - accuracy: 0.1567 - val_loss: 57.6665 - val_accuracy: 0.0889\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.5937 - accuracy: 0.1567 - val_loss: 57.5950 - val_accuracy: 0.0889\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5201 - accuracy: 0.1567 - val_loss: 57.5197 - val_accuracy: 0.0889\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.4471 - accuracy: 0.1567 - val_loss: 57.4439 - val_accuracy: 0.0889\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3745 - accuracy: 0.1567 - val_loss: 57.3679 - val_accuracy: 0.0889\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3011 - accuracy: 0.1567 - val_loss: 57.2950 - val_accuracy: 0.0889\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.2285 - accuracy: 0.1567 - val_loss: 57.2241 - val_accuracy: 0.0889\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.1551 - accuracy: 0.1567 - val_loss: 57.1569 - val_accuracy: 0.0889\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.0828 - accuracy: 0.1567 - val_loss: 57.0950 - val_accuracy: 0.0889\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0111 - accuracy: 0.1567 - val_loss: 57.0297 - val_accuracy: 0.0889\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.9384 - accuracy: 0.1567 - val_loss: 56.9501 - val_accuracy: 0.0889\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8650 - accuracy: 0.1567 - val_loss: 56.8675 - val_accuracy: 0.0889\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.7929 - accuracy: 0.1567 - val_loss: 56.7936 - val_accuracy: 0.0889\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.7204 - accuracy: 0.1567 - val_loss: 56.7223 - val_accuracy: 0.0889\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.6485 - accuracy: 0.1567 - val_loss: 56.6476 - val_accuracy: 0.0889\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.5763 - accuracy: 0.1567 - val_loss: 56.5742 - val_accuracy: 0.0889\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5040 - accuracy: 0.1567 - val_loss: 56.4997 - val_accuracy: 0.0889\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.4323 - accuracy: 0.1567 - val_loss: 56.4296 - val_accuracy: 0.0889\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.3602 - accuracy: 0.1567 - val_loss: 56.3590 - val_accuracy: 0.0889\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.2880 - accuracy: 0.1567 - val_loss: 56.2876 - val_accuracy: 0.0889\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2169 - accuracy: 0.1567 - val_loss: 56.2226 - val_accuracy: 0.0889\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.1448 - accuracy: 0.1567 - val_loss: 56.1523 - val_accuracy: 0.0889\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56.0732 - accuracy: 0.1567 - val_loss: 56.0805 - val_accuracy: 0.0889\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.0032 - accuracy: 0.1567 - val_loss: 56.0072 - val_accuracy: 0.0889\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.9324 - accuracy: 0.1567 - val_loss: 55.9422 - val_accuracy: 0.0889\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.8603 - accuracy: 0.1567 - val_loss: 55.8753 - val_accuracy: 0.0889\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.7885 - accuracy: 0.1567 - val_loss: 55.8049 - val_accuracy: 0.0889\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.7184 - accuracy: 0.1567 - val_loss: 55.7277 - val_accuracy: 0.0889\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.6467 - accuracy: 0.1567 - val_loss: 55.6513 - val_accuracy: 0.0889\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5765 - accuracy: 0.1567 - val_loss: 55.5818 - val_accuracy: 0.0889\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.5058 - accuracy: 0.1542 - val_loss: 55.5134 - val_accuracy: 0.0889\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55.4349 - accuracy: 0.1567 - val_loss: 55.4460 - val_accuracy: 0.0889\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.3646 - accuracy: 0.1567 - val_loss: 55.3691 - val_accuracy: 0.0889\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.2933 - accuracy: 0.1567 - val_loss: 55.2973 - val_accuracy: 0.0889\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.2232 - accuracy: 0.1567 - val_loss: 55.2311 - val_accuracy: 0.0889\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1535 - accuracy: 0.1567 - val_loss: 55.1640 - val_accuracy: 0.0889\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0827 - accuracy: 0.1567 - val_loss: 55.0926 - val_accuracy: 0.0889\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.0119 - accuracy: 0.1567 - val_loss: 55.0159 - val_accuracy: 0.0889\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.9408 - accuracy: 0.1567 - val_loss: 54.9475 - val_accuracy: 0.0889\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.8724 - accuracy: 0.1567 - val_loss: 54.8820 - val_accuracy: 0.0889\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8030 - accuracy: 0.1617 - val_loss: 54.8138 - val_accuracy: 0.1111\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 54.7326 - accuracy: 0.1766 - val_loss: 54.7409 - val_accuracy: 0.0889\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.6613 - accuracy: 0.1567 - val_loss: 54.6656 - val_accuracy: 0.0889\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.5916 - accuracy: 0.1567 - val_loss: 54.5915 - val_accuracy: 0.0889\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.5221 - accuracy: 0.1567 - val_loss: 54.5184 - val_accuracy: 0.0889\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.4535 - accuracy: 0.1567 - val_loss: 54.4509 - val_accuracy: 0.0889\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.3839 - accuracy: 0.1567 - val_loss: 54.3797 - val_accuracy: 0.0889\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.3148 - accuracy: 0.1692 - val_loss: 54.3088 - val_accuracy: 0.0889\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.2446 - accuracy: 0.1592 - val_loss: 54.2385 - val_accuracy: 0.0889\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.1755 - accuracy: 0.1567 - val_loss: 54.1654 - val_accuracy: 0.0889\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.1055 - accuracy: 0.1567 - val_loss: 54.0988 - val_accuracy: 0.0889\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0363 - accuracy: 0.1567 - val_loss: 54.0332 - val_accuracy: 0.0889\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.9681 - accuracy: 0.1567 - val_loss: 53.9661 - val_accuracy: 0.0889\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.8993 - accuracy: 0.1567 - val_loss: 53.8939 - val_accuracy: 0.0889\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.8304 - accuracy: 0.1567 - val_loss: 53.8248 - val_accuracy: 0.0889\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.7617 - accuracy: 0.1567 - val_loss: 53.7582 - val_accuracy: 0.0889\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6928 - accuracy: 0.1567 - val_loss: 53.6894 - val_accuracy: 0.0889\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.6235 - accuracy: 0.1567 - val_loss: 53.6188 - val_accuracy: 0.0889\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.5545 - accuracy: 0.1567 - val_loss: 53.5521 - val_accuracy: 0.0889\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4858 - accuracy: 0.1567 - val_loss: 53.4859 - val_accuracy: 0.0889\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.4177 - accuracy: 0.1567 - val_loss: 53.4174 - val_accuracy: 0.0889\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.3491 - accuracy: 0.1567 - val_loss: 53.3538 - val_accuracy: 0.0889\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.2811 - accuracy: 0.1567 - val_loss: 53.2921 - val_accuracy: 0.0889\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2131 - accuracy: 0.1567 - val_loss: 53.2283 - val_accuracy: 0.0889\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1448 - accuracy: 0.1567 - val_loss: 53.1625 - val_accuracy: 0.0889\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0768 - accuracy: 0.1567 - val_loss: 53.0928 - val_accuracy: 0.0889\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0100 - accuracy: 0.1567 - val_loss: 53.0252 - val_accuracy: 0.0889\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.9427 - accuracy: 0.1567 - val_loss: 52.9619 - val_accuracy: 0.0889\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.8751 - accuracy: 0.1567 - val_loss: 52.8918 - val_accuracy: 0.0889\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.8070 - accuracy: 0.1567 - val_loss: 52.8226 - val_accuracy: 0.0889\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.7390 - accuracy: 0.1567 - val_loss: 52.7553 - val_accuracy: 0.0889\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6708 - accuracy: 0.1567 - val_loss: 52.6909 - val_accuracy: 0.0889\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.6034 - accuracy: 0.1567 - val_loss: 52.6174 - val_accuracy: 0.0889\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52.5353 - accuracy: 0.1567 - val_loss: 52.5441 - val_accuracy: 0.0889\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.4677 - accuracy: 0.1567 - val_loss: 52.4692 - val_accuracy: 0.0889\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.4004 - accuracy: 0.1567 - val_loss: 52.4002 - val_accuracy: 0.0889\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3338 - accuracy: 0.1567 - val_loss: 52.3319 - val_accuracy: 0.0889\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.2663 - accuracy: 0.1567 - val_loss: 52.2673 - val_accuracy: 0.0889\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1989 - accuracy: 0.1567 - val_loss: 52.2040 - val_accuracy: 0.0889\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1319 - accuracy: 0.1567 - val_loss: 52.1401 - val_accuracy: 0.0889\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.0645 - accuracy: 0.1567 - val_loss: 52.0766 - val_accuracy: 0.0889\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.9981 - accuracy: 0.1567 - val_loss: 52.0116 - val_accuracy: 0.0889\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9321 - accuracy: 0.1567 - val_loss: 51.9445 - val_accuracy: 0.0889\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.8646 - accuracy: 0.1567 - val_loss: 51.8737 - val_accuracy: 0.0889\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7984 - accuracy: 0.1567 - val_loss: 51.8018 - val_accuracy: 0.0889\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.7306 - accuracy: 0.1567 - val_loss: 51.7404 - val_accuracy: 0.0889\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6641 - accuracy: 0.1567 - val_loss: 51.6745 - val_accuracy: 0.0889\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6001 - accuracy: 0.1567 - val_loss: 51.6099 - val_accuracy: 0.0889\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5336 - accuracy: 0.1567 - val_loss: 51.5462 - val_accuracy: 0.0889\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.4666 - accuracy: 0.1567 - val_loss: 51.4789 - val_accuracy: 0.0889\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.4003 - accuracy: 0.1567 - val_loss: 51.4144 - val_accuracy: 0.0889\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.3332 - accuracy: 0.1567 - val_loss: 51.3445 - val_accuracy: 0.0889\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.2671 - accuracy: 0.1567 - val_loss: 51.2752 - val_accuracy: 0.0889\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.2015 - accuracy: 0.1567 - val_loss: 51.2114 - val_accuracy: 0.0889\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.1352 - accuracy: 0.1567 - val_loss: 51.1417 - val_accuracy: 0.0889\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0697 - accuracy: 0.1567 - val_loss: 51.0735 - val_accuracy: 0.0889\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.0043 - accuracy: 0.1567 - val_loss: 51.0094 - val_accuracy: 0.0889\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.9378 - accuracy: 0.1567 - val_loss: 50.9432 - val_accuracy: 0.0889\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.8719 - accuracy: 0.1567 - val_loss: 50.8767 - val_accuracy: 0.0889\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8077 - accuracy: 0.1567 - val_loss: 50.8141 - val_accuracy: 0.0889\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50.7423 - accuracy: 0.1567 - val_loss: 50.7480 - val_accuracy: 0.0889\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.6761 - accuracy: 0.1517 - val_loss: 50.6870 - val_accuracy: 0.0889\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.6110 - accuracy: 0.1617 - val_loss: 50.6263 - val_accuracy: 0.0889\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.5456 - accuracy: 0.1617 - val_loss: 50.5577 - val_accuracy: 0.0889\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4806 - accuracy: 0.1642 - val_loss: 50.4937 - val_accuracy: 0.0889\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4150 - accuracy: 0.1567 - val_loss: 50.4346 - val_accuracy: 0.0889\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.3499 - accuracy: 0.1567 - val_loss: 50.3677 - val_accuracy: 0.0889\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.2847 - accuracy: 0.1567 - val_loss: 50.3035 - val_accuracy: 0.0889\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2195 - accuracy: 0.1567 - val_loss: 50.2365 - val_accuracy: 0.0889\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.1542 - accuracy: 0.1567 - val_loss: 50.1643 - val_accuracy: 0.0889\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.0891 - accuracy: 0.1567 - val_loss: 50.0982 - val_accuracy: 0.0889\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.0248 - accuracy: 0.1567 - val_loss: 50.0298 - val_accuracy: 0.0889\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.9599 - accuracy: 0.1567 - val_loss: 49.9576 - val_accuracy: 0.0889\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8968 - accuracy: 0.1567 - val_loss: 49.8887 - val_accuracy: 0.0889\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8320 - accuracy: 0.1567 - val_loss: 49.8236 - val_accuracy: 0.0889\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.7675 - accuracy: 0.1567 - val_loss: 49.7681 - val_accuracy: 0.0889\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7031 - accuracy: 0.1567 - val_loss: 49.7148 - val_accuracy: 0.0889\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6395 - accuracy: 0.1567 - val_loss: 49.6610 - val_accuracy: 0.0889\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.5747 - accuracy: 0.1567 - val_loss: 49.5943 - val_accuracy: 0.0889\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49.5105 - accuracy: 0.1567 - val_loss: 49.5204 - val_accuracy: 0.0889\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4465 - accuracy: 0.1567 - val_loss: 49.4512 - val_accuracy: 0.0889\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.3818 - accuracy: 0.1567 - val_loss: 49.3813 - val_accuracy: 0.0889\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3179 - accuracy: 0.1567 - val_loss: 49.3170 - val_accuracy: 0.0889\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2529 - accuracy: 0.1567 - val_loss: 49.2627 - val_accuracy: 0.0889\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.1888 - accuracy: 0.1567 - val_loss: 49.2085 - val_accuracy: 0.0889\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1259 - accuracy: 0.1567 - val_loss: 49.1472 - val_accuracy: 0.0889\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.0627 - accuracy: 0.1642 - val_loss: 49.0832 - val_accuracy: 0.0889\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.9990 - accuracy: 0.1542 - val_loss: 49.0179 - val_accuracy: 0.0889\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.9349 - accuracy: 0.1567 - val_loss: 48.9494 - val_accuracy: 0.0889\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.8707 - accuracy: 0.1567 - val_loss: 48.8827 - val_accuracy: 0.0889\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8071 - accuracy: 0.1567 - val_loss: 48.8163 - val_accuracy: 0.0889\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7435 - accuracy: 0.1567 - val_loss: 48.7563 - val_accuracy: 0.0889\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.6799 - accuracy: 0.1567 - val_loss: 48.6959 - val_accuracy: 0.0889\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.6176 - accuracy: 0.1567 - val_loss: 48.6376 - val_accuracy: 0.0889\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5545 - accuracy: 0.1567 - val_loss: 48.5785 - val_accuracy: 0.0889\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.4906 - accuracy: 0.1567 - val_loss: 48.5119 - val_accuracy: 0.0889\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.4282 - accuracy: 0.1567 - val_loss: 48.4436 - val_accuracy: 0.0889\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.3645 - accuracy: 0.1567 - val_loss: 48.3786 - val_accuracy: 0.0889\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.3012 - accuracy: 0.1567 - val_loss: 48.3125 - val_accuracy: 0.0889\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.2385 - accuracy: 0.1567 - val_loss: 48.2536 - val_accuracy: 0.0889\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.1754 - accuracy: 0.1567 - val_loss: 48.1991 - val_accuracy: 0.0889\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1139 - accuracy: 0.1567 - val_loss: 48.1452 - val_accuracy: 0.0889\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0519 - accuracy: 0.1567 - val_loss: 48.0854 - val_accuracy: 0.0889\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.9896 - accuracy: 0.1567 - val_loss: 48.0220 - val_accuracy: 0.0889\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.9267 - accuracy: 0.1567 - val_loss: 47.9596 - val_accuracy: 0.0889\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8634 - accuracy: 0.1468 - val_loss: 47.8911 - val_accuracy: 0.0889\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8003 - accuracy: 0.1443 - val_loss: 47.8210 - val_accuracy: 0.0889\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.7374 - accuracy: 0.1567 - val_loss: 47.7596 - val_accuracy: 0.0889\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.6766 - accuracy: 0.1567 - val_loss: 47.7049 - val_accuracy: 0.0889\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.6134 - accuracy: 0.1567 - val_loss: 47.6382 - val_accuracy: 0.0889\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5515 - accuracy: 0.1567 - val_loss: 47.5675 - val_accuracy: 0.0889\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.4878 - accuracy: 0.1567 - val_loss: 47.5036 - val_accuracy: 0.0889\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.4257 - accuracy: 0.1567 - val_loss: 47.4423 - val_accuracy: 0.0889\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3639 - accuracy: 0.1567 - val_loss: 47.3811 - val_accuracy: 0.0889\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3022 - accuracy: 0.1567 - val_loss: 47.3161 - val_accuracy: 0.0889\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.2403 - accuracy: 0.1567 - val_loss: 47.2518 - val_accuracy: 0.0889\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.1783 - accuracy: 0.1517 - val_loss: 47.1881 - val_accuracy: 0.0889\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1160 - accuracy: 0.1567 - val_loss: 47.1307 - val_accuracy: 0.0889\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0546 - accuracy: 0.1567 - val_loss: 47.0667 - val_accuracy: 0.0889\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9930 - accuracy: 0.1567 - val_loss: 46.9981 - val_accuracy: 0.0889\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.9318 - accuracy: 0.1567 - val_loss: 46.9322 - val_accuracy: 0.0889\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.8699 - accuracy: 0.1567 - val_loss: 46.8713 - val_accuracy: 0.0889\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.8081 - accuracy: 0.1567 - val_loss: 46.8139 - val_accuracy: 0.0889\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7466 - accuracy: 0.1567 - val_loss: 46.7567 - val_accuracy: 0.0889\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6856 - accuracy: 0.1617 - val_loss: 46.6995 - val_accuracy: 0.0889\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.6241 - accuracy: 0.1567 - val_loss: 46.6384 - val_accuracy: 0.0889\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.5630 - accuracy: 0.1493 - val_loss: 46.5760 - val_accuracy: 0.0889\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.5012 - accuracy: 0.1567 - val_loss: 46.5183 - val_accuracy: 0.0889\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4405 - accuracy: 0.1567 - val_loss: 46.4555 - val_accuracy: 0.0889\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3791 - accuracy: 0.1567 - val_loss: 46.3950 - val_accuracy: 0.0889\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3191 - accuracy: 0.1567 - val_loss: 46.3358 - val_accuracy: 0.0889\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2580 - accuracy: 0.1567 - val_loss: 46.2718 - val_accuracy: 0.0889\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.1963 - accuracy: 0.1567 - val_loss: 46.2090 - val_accuracy: 0.0889\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.1360 - accuracy: 0.1567 - val_loss: 46.1500 - val_accuracy: 0.0889\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0754 - accuracy: 0.1567 - val_loss: 46.0841 - val_accuracy: 0.0889\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.0148 - accuracy: 0.1567 - val_loss: 46.0192 - val_accuracy: 0.0889\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.9542 - accuracy: 0.1567 - val_loss: 45.9591 - val_accuracy: 0.0889\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8934 - accuracy: 0.1567 - val_loss: 45.9042 - val_accuracy: 0.0889\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8333 - accuracy: 0.1567 - val_loss: 45.8484 - val_accuracy: 0.0889\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7733 - accuracy: 0.1567 - val_loss: 45.7920 - val_accuracy: 0.0889\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7119 - accuracy: 0.1567 - val_loss: 45.7248 - val_accuracy: 0.0889\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.6515 - accuracy: 0.1567 - val_loss: 45.6571 - val_accuracy: 0.0889\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.5916 - accuracy: 0.1915 - val_loss: 45.5898 - val_accuracy: 0.0889\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5322 - accuracy: 0.1692 - val_loss: 45.5220 - val_accuracy: 0.0889\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.4728 - accuracy: 0.1692 - val_loss: 45.4617 - val_accuracy: 0.0889\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.4113 - accuracy: 0.1692 - val_loss: 45.4088 - val_accuracy: 0.1333\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.3506 - accuracy: 0.1667 - val_loss: 45.3542 - val_accuracy: 0.0889\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.2907 - accuracy: 0.1567 - val_loss: 45.2964 - val_accuracy: 0.0889\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.2305 - accuracy: 0.1567 - val_loss: 45.2313 - val_accuracy: 0.0889\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45.1707 - accuracy: 0.1567 - val_loss: 45.1656 - val_accuracy: 0.0889\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.1116 - accuracy: 0.1567 - val_loss: 45.1073 - val_accuracy: 0.0889\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.0510 - accuracy: 0.1567 - val_loss: 45.0563 - val_accuracy: 0.0889\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9911 - accuracy: 0.1567 - val_loss: 45.0007 - val_accuracy: 0.0889\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.9312 - accuracy: 0.1567 - val_loss: 44.9406 - val_accuracy: 0.0889\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8718 - accuracy: 0.1567 - val_loss: 44.8805 - val_accuracy: 0.0889\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.8123 - accuracy: 0.1567 - val_loss: 44.8214 - val_accuracy: 0.0889\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7524 - accuracy: 0.1567 - val_loss: 44.7669 - val_accuracy: 0.0889\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6945 - accuracy: 0.1567 - val_loss: 44.7124 - val_accuracy: 0.0889\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.6348 - accuracy: 0.1567 - val_loss: 44.6543 - val_accuracy: 0.0889\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.5756 - accuracy: 0.1567 - val_loss: 44.5919 - val_accuracy: 0.0889\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44.5154 - accuracy: 0.1567 - val_loss: 44.5302 - val_accuracy: 0.0889\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.4561 - accuracy: 0.1567 - val_loss: 44.4734 - val_accuracy: 0.0889\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3974 - accuracy: 0.1567 - val_loss: 44.4171 - val_accuracy: 0.0889\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.3384 - accuracy: 0.1567 - val_loss: 44.3585 - val_accuracy: 0.0889\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2795 - accuracy: 0.1567 - val_loss: 44.3000 - val_accuracy: 0.0889\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.2202 - accuracy: 0.1567 - val_loss: 44.2414 - val_accuracy: 0.0889\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1609 - accuracy: 0.1567 - val_loss: 44.1814 - val_accuracy: 0.0889\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.1017 - accuracy: 0.1567 - val_loss: 44.1141 - val_accuracy: 0.0889\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0432 - accuracy: 0.1567 - val_loss: 44.0491 - val_accuracy: 0.0889\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9845 - accuracy: 0.1567 - val_loss: 43.9881 - val_accuracy: 0.0889\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9266 - accuracy: 0.1567 - val_loss: 43.9267 - val_accuracy: 0.0889\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.8685 - accuracy: 0.1741 - val_loss: 43.8626 - val_accuracy: 0.1111\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.8102 - accuracy: 0.1692 - val_loss: 43.8023 - val_accuracy: 0.1111\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.7513 - accuracy: 0.1791 - val_loss: 43.7458 - val_accuracy: 0.0889\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6927 - accuracy: 0.1716 - val_loss: 43.6907 - val_accuracy: 0.0889\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.6345 - accuracy: 0.1642 - val_loss: 43.6345 - val_accuracy: 0.0889\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.5760 - accuracy: 0.1567 - val_loss: 43.5816 - val_accuracy: 0.0889\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.5165 - accuracy: 0.1567 - val_loss: 43.5271 - val_accuracy: 0.0889\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.4588 - accuracy: 0.1567 - val_loss: 43.4691 - val_accuracy: 0.0889\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.4018 - accuracy: 0.1567 - val_loss: 43.4124 - val_accuracy: 0.0889\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.3440 - accuracy: 0.1567 - val_loss: 43.3578 - val_accuracy: 0.0889\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.2855 - accuracy: 0.1567 - val_loss: 43.3022 - val_accuracy: 0.0889\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.2277 - accuracy: 0.1567 - val_loss: 43.2453 - val_accuracy: 0.0889\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.1684 - accuracy: 0.1567 - val_loss: 43.1830 - val_accuracy: 0.0889\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.1102 - accuracy: 0.1567 - val_loss: 43.1293 - val_accuracy: 0.0889\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.0525 - accuracy: 0.1567 - val_loss: 43.0717 - val_accuracy: 0.0889\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.9945 - accuracy: 0.1567 - val_loss: 43.0102 - val_accuracy: 0.0889\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9372 - accuracy: 0.1567 - val_loss: 42.9550 - val_accuracy: 0.0889\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.8794 - accuracy: 0.1567 - val_loss: 42.8986 - val_accuracy: 0.0889\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.8220 - accuracy: 0.1567 - val_loss: 42.8432 - val_accuracy: 0.0889\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7648 - accuracy: 0.1567 - val_loss: 42.7830 - val_accuracy: 0.0889\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7069 - accuracy: 0.1567 - val_loss: 42.7221 - val_accuracy: 0.0889\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.6487 - accuracy: 0.1567 - val_loss: 42.6626 - val_accuracy: 0.0889\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.5913 - accuracy: 0.1567 - val_loss: 42.6031 - val_accuracy: 0.0889\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.5339 - accuracy: 0.1567 - val_loss: 42.5430 - val_accuracy: 0.0889\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.4760 - accuracy: 0.1567 - val_loss: 42.4828 - val_accuracy: 0.0889\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.4193 - accuracy: 0.1567 - val_loss: 42.4295 - val_accuracy: 0.0889\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3638 - accuracy: 0.1567 - val_loss: 42.3755 - val_accuracy: 0.0889\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.3070 - accuracy: 0.1567 - val_loss: 42.3251 - val_accuracy: 0.0889\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2499 - accuracy: 0.1567 - val_loss: 42.2706 - val_accuracy: 0.0889\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1912 - accuracy: 0.1567 - val_loss: 42.2080 - val_accuracy: 0.0889\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.1340 - accuracy: 0.1567 - val_loss: 42.1453 - val_accuracy: 0.0889\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.0783 - accuracy: 0.1567 - val_loss: 42.0866 - val_accuracy: 0.0889\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.0211 - accuracy: 0.1567 - val_loss: 42.0249 - val_accuracy: 0.0889\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.9638 - accuracy: 0.1567 - val_loss: 41.9693 - val_accuracy: 0.0889\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.9069 - accuracy: 0.1567 - val_loss: 41.9134 - val_accuracy: 0.0889\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.8506 - accuracy: 0.1567 - val_loss: 41.8611 - val_accuracy: 0.0889\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7947 - accuracy: 0.1567 - val_loss: 41.8070 - val_accuracy: 0.0889\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.7382 - accuracy: 0.1567 - val_loss: 41.7474 - val_accuracy: 0.0889\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.6807 - accuracy: 0.1567 - val_loss: 41.6929 - val_accuracy: 0.0889\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.6246 - accuracy: 0.1567 - val_loss: 41.6391 - val_accuracy: 0.0889\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.5678 - accuracy: 0.1517 - val_loss: 41.5782 - val_accuracy: 0.0889\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.5121 - accuracy: 0.1617 - val_loss: 41.5188 - val_accuracy: 0.0889\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.4560 - accuracy: 0.1617 - val_loss: 41.4610 - val_accuracy: 0.0889\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.3990 - accuracy: 0.1567 - val_loss: 41.4099 - val_accuracy: 0.0889\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.3421 - accuracy: 0.1567 - val_loss: 41.3527 - val_accuracy: 0.0889\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.2860 - accuracy: 0.1567 - val_loss: 41.2998 - val_accuracy: 0.0889\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2304 - accuracy: 0.1567 - val_loss: 41.2507 - val_accuracy: 0.0889\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1742 - accuracy: 0.1567 - val_loss: 41.1992 - val_accuracy: 0.0889\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.1182 - accuracy: 0.1517 - val_loss: 41.1397 - val_accuracy: 0.0889\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0624 - accuracy: 0.1617 - val_loss: 41.0799 - val_accuracy: 0.0889\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.0065 - accuracy: 0.1567 - val_loss: 41.0272 - val_accuracy: 0.0889\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.9505 - accuracy: 0.1567 - val_loss: 40.9689 - val_accuracy: 0.0889\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.8949 - accuracy: 0.1567 - val_loss: 40.9109 - val_accuracy: 0.0889\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8392 - accuracy: 0.1567 - val_loss: 40.8532 - val_accuracy: 0.0889\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.7831 - accuracy: 0.1567 - val_loss: 40.7929 - val_accuracy: 0.0889\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.7279 - accuracy: 0.1567 - val_loss: 40.7321 - val_accuracy: 0.0889\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6720 - accuracy: 0.1567 - val_loss: 40.6802 - val_accuracy: 0.0889\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6161 - accuracy: 0.1567 - val_loss: 40.6320 - val_accuracy: 0.0889\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5610 - accuracy: 0.1567 - val_loss: 40.5822 - val_accuracy: 0.0889\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.5058 - accuracy: 0.1567 - val_loss: 40.5304 - val_accuracy: 0.0889\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.4496 - accuracy: 0.1567 - val_loss: 40.4720 - val_accuracy: 0.0889\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.3951 - accuracy: 0.1567 - val_loss: 40.4102 - val_accuracy: 0.0889\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.3400 - accuracy: 0.1567 - val_loss: 40.3561 - val_accuracy: 0.0889\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.2847 - accuracy: 0.1567 - val_loss: 40.3032 - val_accuracy: 0.0889\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.2291 - accuracy: 0.1567 - val_loss: 40.2442 - val_accuracy: 0.0889\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.1733 - accuracy: 0.1567 - val_loss: 40.1845 - val_accuracy: 0.0889\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.1188 - accuracy: 0.1567 - val_loss: 40.1265 - val_accuracy: 0.0889\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.0637 - accuracy: 0.1567 - val_loss: 40.0674 - val_accuracy: 0.0889\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0090 - accuracy: 0.1567 - val_loss: 40.0081 - val_accuracy: 0.0889\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9543 - accuracy: 0.1567 - val_loss: 39.9601 - val_accuracy: 0.0889\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.9002 - accuracy: 0.1567 - val_loss: 39.9200 - val_accuracy: 0.0889\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.8468 - accuracy: 0.1567 - val_loss: 39.8730 - val_accuracy: 0.0889\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7913 - accuracy: 0.1567 - val_loss: 39.8116 - val_accuracy: 0.0889\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7353 - accuracy: 0.1567 - val_loss: 39.7512 - val_accuracy: 0.0889\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.6805 - accuracy: 0.1567 - val_loss: 39.6946 - val_accuracy: 0.0889\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.6252 - accuracy: 0.1567 - val_loss: 39.6411 - val_accuracy: 0.0889\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5709 - accuracy: 0.1567 - val_loss: 39.5894 - val_accuracy: 0.0889\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.5174 - accuracy: 0.1567 - val_loss: 39.5371 - val_accuracy: 0.0889\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.4624 - accuracy: 0.1567 - val_loss: 39.4738 - val_accuracy: 0.0889\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.4081 - accuracy: 0.1567 - val_loss: 39.4191 - val_accuracy: 0.0889\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3538 - accuracy: 0.1567 - val_loss: 39.3618 - val_accuracy: 0.0889\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.2991 - accuracy: 0.1567 - val_loss: 39.3074 - val_accuracy: 0.0889\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.2449 - accuracy: 0.1567 - val_loss: 39.2530 - val_accuracy: 0.1556\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.1914 - accuracy: 0.1716 - val_loss: 39.2004 - val_accuracy: 0.1333\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1375 - accuracy: 0.1692 - val_loss: 39.1477 - val_accuracy: 0.1333\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.0829 - accuracy: 0.1791 - val_loss: 39.0882 - val_accuracy: 0.0889\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.0285 - accuracy: 0.1567 - val_loss: 39.0376 - val_accuracy: 0.0889\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9744 - accuracy: 0.1567 - val_loss: 38.9860 - val_accuracy: 0.0889\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9212 - accuracy: 0.1567 - val_loss: 38.9282 - val_accuracy: 0.0889\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8668 - accuracy: 0.1567 - val_loss: 38.8749 - val_accuracy: 0.0889\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.8133 - accuracy: 0.1567 - val_loss: 38.8214 - val_accuracy: 0.0889\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7592 - accuracy: 0.1567 - val_loss: 38.7692 - val_accuracy: 0.0889\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.7059 - accuracy: 0.1567 - val_loss: 38.7165 - val_accuracy: 0.0889\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.6523 - accuracy: 0.1567 - val_loss: 38.6739 - val_accuracy: 0.0889\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.5982 - accuracy: 0.1567 - val_loss: 38.6217 - val_accuracy: 0.0889\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.5447 - accuracy: 0.1567 - val_loss: 38.5720 - val_accuracy: 0.0889\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4908 - accuracy: 0.1567 - val_loss: 38.5179 - val_accuracy: 0.0889\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4373 - accuracy: 0.1567 - val_loss: 38.4668 - val_accuracy: 0.0889\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38.3843 - accuracy: 0.1567 - val_loss: 38.4128 - val_accuracy: 0.0889\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.3315 - accuracy: 0.1567 - val_loss: 38.3585 - val_accuracy: 0.0889\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.2776 - accuracy: 0.1567 - val_loss: 38.3053 - val_accuracy: 0.0889\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.2239 - accuracy: 0.1567 - val_loss: 38.2522 - val_accuracy: 0.0889\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38.1708 - accuracy: 0.1567 - val_loss: 38.2000 - val_accuracy: 0.0889\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.1182 - accuracy: 0.1567 - val_loss: 38.1445 - val_accuracy: 0.0889\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0654 - accuracy: 0.1567 - val_loss: 38.0813 - val_accuracy: 0.0889\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0118 - accuracy: 0.1567 - val_loss: 38.0192 - val_accuracy: 0.0889\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.9592 - accuracy: 0.1567 - val_loss: 37.9608 - val_accuracy: 0.0889\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9062 - accuracy: 0.1567 - val_loss: 37.9079 - val_accuracy: 0.0889\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.8536 - accuracy: 0.1567 - val_loss: 37.8546 - val_accuracy: 0.0889\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7997 - accuracy: 0.1567 - val_loss: 37.8082 - val_accuracy: 0.0889\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7464 - accuracy: 0.1567 - val_loss: 37.7640 - val_accuracy: 0.0889\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.6941 - accuracy: 0.1567 - val_loss: 37.7159 - val_accuracy: 0.0889\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37.6413 - accuracy: 0.1567 - val_loss: 37.6645 - val_accuracy: 0.0889\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.5887 - accuracy: 0.1567 - val_loss: 37.6095 - val_accuracy: 0.0889\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5358 - accuracy: 0.1567 - val_loss: 37.5551 - val_accuracy: 0.0889\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4832 - accuracy: 0.1567 - val_loss: 37.5064 - val_accuracy: 0.0889\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4309 - accuracy: 0.1567 - val_loss: 37.4540 - val_accuracy: 0.0889\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.3786 - accuracy: 0.1567 - val_loss: 37.3981 - val_accuracy: 0.0889\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.3260 - accuracy: 0.1567 - val_loss: 37.3435 - val_accuracy: 0.0889\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.2735 - accuracy: 0.1567 - val_loss: 37.2881 - val_accuracy: 0.0889\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2205 - accuracy: 0.1567 - val_loss: 37.2357 - val_accuracy: 0.0889\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.1685 - accuracy: 0.1567 - val_loss: 37.1853 - val_accuracy: 0.0889\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.1173 - accuracy: 0.1567 - val_loss: 37.1315 - val_accuracy: 0.0889\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0649 - accuracy: 0.1567 - val_loss: 37.0804 - val_accuracy: 0.0889\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0132 - accuracy: 0.1567 - val_loss: 37.0240 - val_accuracy: 0.0889\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36.9601 - accuracy: 0.1567 - val_loss: 36.9708 - val_accuracy: 0.0889\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9080 - accuracy: 0.1567 - val_loss: 36.9160 - val_accuracy: 0.0889\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8564 - accuracy: 0.1567 - val_loss: 36.8662 - val_accuracy: 0.0889\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.8042 - accuracy: 0.1567 - val_loss: 36.8173 - val_accuracy: 0.0889\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7525 - accuracy: 0.1567 - val_loss: 36.7669 - val_accuracy: 0.0889\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.7008 - accuracy: 0.1567 - val_loss: 36.7196 - val_accuracy: 0.0889\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6492 - accuracy: 0.1567 - val_loss: 36.6705 - val_accuracy: 0.0889\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5968 - accuracy: 0.1567 - val_loss: 36.6152 - val_accuracy: 0.0889\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5449 - accuracy: 0.1567 - val_loss: 36.5651 - val_accuracy: 0.0889\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4930 - accuracy: 0.1567 - val_loss: 36.5195 - val_accuracy: 0.0889\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4423 - accuracy: 0.1567 - val_loss: 36.4688 - val_accuracy: 0.0889\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.3906 - accuracy: 0.1567 - val_loss: 36.4119 - val_accuracy: 0.0889\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.3396 - accuracy: 0.1567 - val_loss: 36.3525 - val_accuracy: 0.0889\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2877 - accuracy: 0.1567 - val_loss: 36.2981 - val_accuracy: 0.0889\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2364 - accuracy: 0.1567 - val_loss: 36.2484 - val_accuracy: 0.0889\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.1849 - accuracy: 0.1567 - val_loss: 36.1999 - val_accuracy: 0.0889\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.1336 - accuracy: 0.1567 - val_loss: 36.1491 - val_accuracy: 0.0889\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0822 - accuracy: 0.1567 - val_loss: 36.0995 - val_accuracy: 0.0889\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.0308 - accuracy: 0.1567 - val_loss: 36.0534 - val_accuracy: 0.0889\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.9794 - accuracy: 0.1567 - val_loss: 36.0051 - val_accuracy: 0.0889\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.9289 - accuracy: 0.1493 - val_loss: 35.9552 - val_accuracy: 0.0889\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.8784 - accuracy: 0.1468 - val_loss: 35.9069 - val_accuracy: 0.0889\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8274 - accuracy: 0.1567 - val_loss: 35.8535 - val_accuracy: 0.0889\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7765 - accuracy: 0.1667 - val_loss: 35.7953 - val_accuracy: 0.0889\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.7247 - accuracy: 0.1493 - val_loss: 35.7426 - val_accuracy: 0.0889\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.6735 - accuracy: 0.1567 - val_loss: 35.6966 - val_accuracy: 0.0889\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.6227 - accuracy: 0.1567 - val_loss: 35.6511 - val_accuracy: 0.0889\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5722 - accuracy: 0.1567 - val_loss: 35.6000 - val_accuracy: 0.0889\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.5215 - accuracy: 0.1567 - val_loss: 35.5485 - val_accuracy: 0.0889\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.4707 - accuracy: 0.1567 - val_loss: 35.4991 - val_accuracy: 0.0889\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.4207 - accuracy: 0.1567 - val_loss: 35.4495 - val_accuracy: 0.0889\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.3692 - accuracy: 0.1567 - val_loss: 35.3901 - val_accuracy: 0.0889\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.3188 - accuracy: 0.1567 - val_loss: 35.3314 - val_accuracy: 0.0889\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.2690 - accuracy: 0.1567 - val_loss: 35.2773 - val_accuracy: 0.0889\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.2183 - accuracy: 0.1567 - val_loss: 35.2291 - val_accuracy: 0.0889\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1673 - accuracy: 0.1567 - val_loss: 35.1868 - val_accuracy: 0.0889\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1170 - accuracy: 0.1567 - val_loss: 35.1433 - val_accuracy: 0.0889\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0672 - accuracy: 0.1567 - val_loss: 35.0963 - val_accuracy: 0.0889\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0171 - accuracy: 0.1567 - val_loss: 35.0481 - val_accuracy: 0.0889\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9658 - accuracy: 0.1567 - val_loss: 34.9891 - val_accuracy: 0.0889\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9157 - accuracy: 0.1567 - val_loss: 34.9366 - val_accuracy: 0.0889\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8657 - accuracy: 0.1567 - val_loss: 34.8880 - val_accuracy: 0.0889\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.8158 - accuracy: 0.1567 - val_loss: 34.8350 - val_accuracy: 0.0889\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7657 - accuracy: 0.1567 - val_loss: 34.7846 - val_accuracy: 0.0889\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7162 - accuracy: 0.1567 - val_loss: 34.7314 - val_accuracy: 0.0889\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6669 - accuracy: 0.1567 - val_loss: 34.6802 - val_accuracy: 0.0889\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6161 - accuracy: 0.1567 - val_loss: 34.6391 - val_accuracy: 0.0889\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.5661 - accuracy: 0.1567 - val_loss: 34.5906 - val_accuracy: 0.0889\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.5172 - accuracy: 0.1567 - val_loss: 34.5353 - val_accuracy: 0.0889\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.4663 - accuracy: 0.1567 - val_loss: 34.4844 - val_accuracy: 0.0889\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.4177 - accuracy: 0.1567 - val_loss: 34.4377 - val_accuracy: 0.0889\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34.3680 - accuracy: 0.1567 - val_loss: 34.3902 - val_accuracy: 0.0889\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.3182 - accuracy: 0.1567 - val_loss: 34.3397 - val_accuracy: 0.0889\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.2688 - accuracy: 0.1567 - val_loss: 34.2838 - val_accuracy: 0.0889\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.2197 - accuracy: 0.1567 - val_loss: 34.2341 - val_accuracy: 0.0889\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1707 - accuracy: 0.1791 - val_loss: 34.1801 - val_accuracy: 0.1111\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.1208 - accuracy: 0.1766 - val_loss: 34.1315 - val_accuracy: 0.0889\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.0712 - accuracy: 0.1567 - val_loss: 34.0877 - val_accuracy: 0.0889\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.0221 - accuracy: 0.1567 - val_loss: 34.0398 - val_accuracy: 0.0889\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.9726 - accuracy: 0.1567 - val_loss: 33.9903 - val_accuracy: 0.0889\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.9225 - accuracy: 0.1667 - val_loss: 33.9405 - val_accuracy: 0.0889\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.8731 - accuracy: 0.1567 - val_loss: 33.8932 - val_accuracy: 0.0889\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.8240 - accuracy: 0.1567 - val_loss: 33.8475 - val_accuracy: 0.0889\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7750 - accuracy: 0.1567 - val_loss: 33.8001 - val_accuracy: 0.0889\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7264 - accuracy: 0.1567 - val_loss: 33.7484 - val_accuracy: 0.0889\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6771 - accuracy: 0.1567 - val_loss: 33.6967 - val_accuracy: 0.0889\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6293 - accuracy: 0.1567 - val_loss: 33.6548 - val_accuracy: 0.0889\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5795 - accuracy: 0.1642 - val_loss: 33.6124 - val_accuracy: 0.0889\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.5309 - accuracy: 0.1567 - val_loss: 33.5719 - val_accuracy: 0.0889\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4830 - accuracy: 0.1567 - val_loss: 33.5247 - val_accuracy: 0.0889\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.4344 - accuracy: 0.1517 - val_loss: 33.4723 - val_accuracy: 0.0889\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3856 - accuracy: 0.1567 - val_loss: 33.4184 - val_accuracy: 0.0889\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3361 - accuracy: 0.1567 - val_loss: 33.3644 - val_accuracy: 0.0889\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2872 - accuracy: 0.1567 - val_loss: 33.3078 - val_accuracy: 0.0889\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2388 - accuracy: 0.1567 - val_loss: 33.2513 - val_accuracy: 0.0889\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.1903 - accuracy: 0.1567 - val_loss: 33.2047 - val_accuracy: 0.0889\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.1420 - accuracy: 0.1567 - val_loss: 33.1587 - val_accuracy: 0.0889\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.0939 - accuracy: 0.1567 - val_loss: 33.1147 - val_accuracy: 0.0889\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.0462 - accuracy: 0.1567 - val_loss: 33.0689 - val_accuracy: 0.0889\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9973 - accuracy: 0.1567 - val_loss: 33.0151 - val_accuracy: 0.0889\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9482 - accuracy: 0.1567 - val_loss: 32.9639 - val_accuracy: 0.0889\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9006 - accuracy: 0.1567 - val_loss: 32.9142 - val_accuracy: 0.0889\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.8519 - accuracy: 0.1567 - val_loss: 32.8684 - val_accuracy: 0.0889\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8039 - accuracy: 0.1567 - val_loss: 32.8259 - val_accuracy: 0.0889\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.7548 - accuracy: 0.1567 - val_loss: 32.7767 - val_accuracy: 0.0889\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7068 - accuracy: 0.1567 - val_loss: 32.7266 - val_accuracy: 0.0889\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.6594 - accuracy: 0.1567 - val_loss: 32.6726 - val_accuracy: 0.0889\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.6116 - accuracy: 0.1567 - val_loss: 32.6196 - val_accuracy: 0.0889\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.5636 - accuracy: 0.1567 - val_loss: 32.5725 - val_accuracy: 0.0889\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.5156 - accuracy: 0.1567 - val_loss: 32.5306 - val_accuracy: 0.0889\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4674 - accuracy: 0.1567 - val_loss: 32.4898 - val_accuracy: 0.0889\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.4197 - accuracy: 0.1567 - val_loss: 32.4487 - val_accuracy: 0.0889\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.3718 - accuracy: 0.1667 - val_loss: 32.4017 - val_accuracy: 0.0889\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3248 - accuracy: 0.1617 - val_loss: 32.3568 - val_accuracy: 0.0889\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2768 - accuracy: 0.1617 - val_loss: 32.3079 - val_accuracy: 0.0889\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32.2288 - accuracy: 0.1617 - val_loss: 32.2593 - val_accuracy: 0.0889\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.1814 - accuracy: 0.1567 - val_loss: 32.2154 - val_accuracy: 0.0889\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.1343 - accuracy: 0.1567 - val_loss: 32.1667 - val_accuracy: 0.0889\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.0866 - accuracy: 0.1567 - val_loss: 32.1167 - val_accuracy: 0.0889\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.0388 - accuracy: 0.1567 - val_loss: 32.0648 - val_accuracy: 0.0889\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.9914 - accuracy: 0.1567 - val_loss: 32.0180 - val_accuracy: 0.0889\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9442 - accuracy: 0.1567 - val_loss: 31.9762 - val_accuracy: 0.0889\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8974 - accuracy: 0.1567 - val_loss: 31.9313 - val_accuracy: 0.0889\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8503 - accuracy: 0.1567 - val_loss: 31.8833 - val_accuracy: 0.0889\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8032 - accuracy: 0.1567 - val_loss: 31.8289 - val_accuracy: 0.0889\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.7554 - accuracy: 0.1567 - val_loss: 31.7774 - val_accuracy: 0.0889\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.7084 - accuracy: 0.1567 - val_loss: 31.7262 - val_accuracy: 0.0889\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.6615 - accuracy: 0.1567 - val_loss: 31.6804 - val_accuracy: 0.0889\n",
      "========== Fold 8 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 207.7324 - accuracy: 0.0995 - val_loss: 196.5258 - val_accuracy: 0.1333\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 190.4294 - accuracy: 0.1095 - val_loss: 177.8381 - val_accuracy: 0.1111\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 172.3408 - accuracy: 0.1318 - val_loss: 161.5826 - val_accuracy: 0.1333\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 157.1704 - accuracy: 0.1493 - val_loss: 148.6710 - val_accuracy: 0.1333\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 145.2443 - accuracy: 0.1393 - val_loss: 138.6712 - val_accuracy: 0.1333\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 136.0203 - accuracy: 0.1393 - val_loss: 130.9327 - val_accuracy: 0.1333\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 128.8862 - accuracy: 0.1517 - val_loss: 124.9132 - val_accuracy: 0.0889\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 123.3052 - accuracy: 0.1468 - val_loss: 120.1573 - val_accuracy: 0.0889\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 118.8772 - accuracy: 0.1617 - val_loss: 116.3512 - val_accuracy: 0.1333\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 115.3174 - accuracy: 0.1393 - val_loss: 113.2533 - val_accuracy: 0.1333\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 112.4053 - accuracy: 0.1542 - val_loss: 110.6971 - val_accuracy: 0.2000\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 109.9940 - accuracy: 0.1542 - val_loss: 108.5628 - val_accuracy: 0.1778\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 107.9667 - accuracy: 0.1542 - val_loss: 106.7515 - val_accuracy: 0.1778\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 106.2411 - accuracy: 0.1443 - val_loss: 105.1966 - val_accuracy: 0.1111\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 104.7556 - accuracy: 0.1144 - val_loss: 103.8477 - val_accuracy: 0.1333\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 103.4648 - accuracy: 0.1542 - val_loss: 102.6681 - val_accuracy: 0.1111\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 102.3295 - accuracy: 0.1318 - val_loss: 101.6201 - val_accuracy: 0.1111\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101.3219 - accuracy: 0.1343 - val_loss: 100.6866 - val_accuracy: 0.1333\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 100.4239 - accuracy: 0.1443 - val_loss: 99.8499 - val_accuracy: 0.1556\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 99.6135 - accuracy: 0.1642 - val_loss: 99.0939 - val_accuracy: 0.1556\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 98.8786 - accuracy: 0.1517 - val_loss: 98.4058 - val_accuracy: 0.1778\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98.2091 - accuracy: 0.1517 - val_loss: 97.7773 - val_accuracy: 0.1778\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 97.5966 - accuracy: 0.1716 - val_loss: 97.1949 - val_accuracy: 0.1556\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.0304 - accuracy: 0.1617 - val_loss: 96.6580 - val_accuracy: 0.1556\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96.5040 - accuracy: 0.1617 - val_loss: 96.1579 - val_accuracy: 0.1556\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.0144 - accuracy: 0.1617 - val_loss: 95.6903 - val_accuracy: 0.1556\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 95.5579 - accuracy: 0.1642 - val_loss: 95.2558 - val_accuracy: 0.1556\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 95.1262 - accuracy: 0.1393 - val_loss: 94.8456 - val_accuracy: 0.1333\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.7223 - accuracy: 0.1393 - val_loss: 94.4633 - val_accuracy: 0.1556\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94.3413 - accuracy: 0.1642 - val_loss: 94.0960 - val_accuracy: 0.1111\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.9759 - accuracy: 0.1517 - val_loss: 93.7423 - val_accuracy: 0.1111\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 93.6279 - accuracy: 0.1517 - val_loss: 93.4042 - val_accuracy: 0.1111\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.2966 - accuracy: 0.1517 - val_loss: 93.0804 - val_accuracy: 0.1111\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.9781 - accuracy: 0.1517 - val_loss: 92.7674 - val_accuracy: 0.1333\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92.6749 - accuracy: 0.1418 - val_loss: 92.4670 - val_accuracy: 0.1333\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.3825 - accuracy: 0.1617 - val_loss: 92.1785 - val_accuracy: 0.1778\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 92.0989 - accuracy: 0.1517 - val_loss: 91.9012 - val_accuracy: 0.1778\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91.8248 - accuracy: 0.1343 - val_loss: 91.6317 - val_accuracy: 0.1778\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.5603 - accuracy: 0.1517 - val_loss: 91.3707 - val_accuracy: 0.1333\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.3035 - accuracy: 0.1940 - val_loss: 91.1199 - val_accuracy: 0.1333\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 91.0568 - accuracy: 0.1393 - val_loss: 90.8764 - val_accuracy: 0.1333\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90.8145 - accuracy: 0.1393 - val_loss: 90.6391 - val_accuracy: 0.1333\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90.5780 - accuracy: 0.1393 - val_loss: 90.4079 - val_accuracy: 0.1333\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90.3466 - accuracy: 0.1443 - val_loss: 90.1824 - val_accuracy: 0.1556\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.1207 - accuracy: 0.1617 - val_loss: 89.9616 - val_accuracy: 0.2000\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.9006 - accuracy: 0.1667 - val_loss: 89.7497 - val_accuracy: 0.1556\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.6861 - accuracy: 0.1667 - val_loss: 89.5441 - val_accuracy: 0.1111\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.4766 - accuracy: 0.1592 - val_loss: 89.3374 - val_accuracy: 0.1333\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.2701 - accuracy: 0.1592 - val_loss: 89.1320 - val_accuracy: 0.1111\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89.0663 - accuracy: 0.1617 - val_loss: 88.9222 - val_accuracy: 0.1556\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.8642 - accuracy: 0.1692 - val_loss: 88.7188 - val_accuracy: 0.1778\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.6703 - accuracy: 0.1468 - val_loss: 88.5212 - val_accuracy: 0.1778\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88.4768 - accuracy: 0.1542 - val_loss: 88.3296 - val_accuracy: 0.2000\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.2860 - accuracy: 0.1542 - val_loss: 88.1407 - val_accuracy: 0.1778\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0982 - accuracy: 0.1517 - val_loss: 87.9569 - val_accuracy: 0.1778\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.9129 - accuracy: 0.1667 - val_loss: 87.7774 - val_accuracy: 0.1778\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.7314 - accuracy: 0.1542 - val_loss: 87.5989 - val_accuracy: 0.1778\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.5512 - accuracy: 0.1866 - val_loss: 87.4228 - val_accuracy: 0.2000\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.3765 - accuracy: 0.1443 - val_loss: 87.2464 - val_accuracy: 0.1778\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.2023 - accuracy: 0.1194 - val_loss: 87.0692 - val_accuracy: 0.1778\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.0283 - accuracy: 0.1468 - val_loss: 86.8932 - val_accuracy: 0.1778\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 86.8570 - accuracy: 0.1468 - val_loss: 86.7228 - val_accuracy: 0.1778\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.6868 - accuracy: 0.1468 - val_loss: 86.5566 - val_accuracy: 0.1778\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.5197 - accuracy: 0.1418 - val_loss: 86.3977 - val_accuracy: 0.1333\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 86.3537 - accuracy: 0.1468 - val_loss: 86.2330 - val_accuracy: 0.1556\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.1887 - accuracy: 0.1716 - val_loss: 86.0666 - val_accuracy: 0.2222\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.0266 - accuracy: 0.1642 - val_loss: 85.9038 - val_accuracy: 0.1556\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.8650 - accuracy: 0.1617 - val_loss: 85.7407 - val_accuracy: 0.1556\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.7048 - accuracy: 0.1617 - val_loss: 85.5796 - val_accuracy: 0.1556\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.5473 - accuracy: 0.1592 - val_loss: 85.4198 - val_accuracy: 0.1556\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.3919 - accuracy: 0.1642 - val_loss: 85.2619 - val_accuracy: 0.2000\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.2357 - accuracy: 0.1692 - val_loss: 85.1101 - val_accuracy: 0.2222\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.0804 - accuracy: 0.1468 - val_loss: 84.9601 - val_accuracy: 0.1778\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84.9301 - accuracy: 0.1418 - val_loss: 84.8164 - val_accuracy: 0.1556\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.7763 - accuracy: 0.1443 - val_loss: 84.6710 - val_accuracy: 0.2000\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.6277 - accuracy: 0.1766 - val_loss: 84.5275 - val_accuracy: 0.1556\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.4789 - accuracy: 0.1617 - val_loss: 84.3748 - val_accuracy: 0.1556\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.3289 - accuracy: 0.1617 - val_loss: 84.2203 - val_accuracy: 0.1556\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.1808 - accuracy: 0.1667 - val_loss: 84.0688 - val_accuracy: 0.1556\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.0343 - accuracy: 0.1617 - val_loss: 83.9243 - val_accuracy: 0.1556\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.8901 - accuracy: 0.1617 - val_loss: 83.7790 - val_accuracy: 0.1333\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.7464 - accuracy: 0.1567 - val_loss: 83.6361 - val_accuracy: 0.1778\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.6027 - accuracy: 0.1468 - val_loss: 83.4955 - val_accuracy: 0.1556\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.4605 - accuracy: 0.1542 - val_loss: 83.3545 - val_accuracy: 0.1556\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.3184 - accuracy: 0.1617 - val_loss: 83.2163 - val_accuracy: 0.1556\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.1782 - accuracy: 0.1766 - val_loss: 83.0787 - val_accuracy: 0.1778\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.0391 - accuracy: 0.1517 - val_loss: 82.9400 - val_accuracy: 0.1778\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.9008 - accuracy: 0.1592 - val_loss: 82.8006 - val_accuracy: 0.2000\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.7619 - accuracy: 0.1716 - val_loss: 82.6624 - val_accuracy: 0.1556\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 82.6250 - accuracy: 0.1617 - val_loss: 82.5260 - val_accuracy: 0.1556\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.4901 - accuracy: 0.1617 - val_loss: 82.3940 - val_accuracy: 0.1556\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.3546 - accuracy: 0.2090 - val_loss: 82.2549 - val_accuracy: 0.1778\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2192 - accuracy: 0.2015 - val_loss: 82.1180 - val_accuracy: 0.1556\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82.0842 - accuracy: 0.1642 - val_loss: 81.9816 - val_accuracy: 0.1556\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.9505 - accuracy: 0.1617 - val_loss: 81.8506 - val_accuracy: 0.1556\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.8178 - accuracy: 0.1692 - val_loss: 81.7168 - val_accuracy: 0.1778\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.6866 - accuracy: 0.1592 - val_loss: 81.5837 - val_accuracy: 0.2000\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81.5544 - accuracy: 0.1592 - val_loss: 81.4516 - val_accuracy: 0.1778\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.4242 - accuracy: 0.1468 - val_loss: 81.3207 - val_accuracy: 0.1778\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.2954 - accuracy: 0.1468 - val_loss: 81.1917 - val_accuracy: 0.1778\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.1676 - accuracy: 0.1468 - val_loss: 81.0661 - val_accuracy: 0.1778\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 81.0383 - accuracy: 0.1468 - val_loss: 80.9403 - val_accuracy: 0.1778\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.9101 - accuracy: 0.1567 - val_loss: 80.8186 - val_accuracy: 0.0889\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.7822 - accuracy: 0.1592 - val_loss: 80.6923 - val_accuracy: 0.0889\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.6543 - accuracy: 0.1567 - val_loss: 80.5629 - val_accuracy: 0.1111\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.5276 - accuracy: 0.1542 - val_loss: 80.4343 - val_accuracy: 0.1333\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80.4030 - accuracy: 0.1393 - val_loss: 80.3084 - val_accuracy: 0.1333\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.2797 - accuracy: 0.1517 - val_loss: 80.1850 - val_accuracy: 0.1556\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.1541 - accuracy: 0.1617 - val_loss: 80.0628 - val_accuracy: 0.2000\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.0289 - accuracy: 0.1617 - val_loss: 79.9405 - val_accuracy: 0.1778\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.9075 - accuracy: 0.1468 - val_loss: 79.8203 - val_accuracy: 0.1778\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.7848 - accuracy: 0.1343 - val_loss: 79.6950 - val_accuracy: 0.1778\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6622 - accuracy: 0.1368 - val_loss: 79.5713 - val_accuracy: 0.1778\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.5389 - accuracy: 0.1542 - val_loss: 79.4465 - val_accuracy: 0.1333\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.4174 - accuracy: 0.1766 - val_loss: 79.3220 - val_accuracy: 0.1333\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79.2959 - accuracy: 0.1766 - val_loss: 79.2002 - val_accuracy: 0.2222\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.1756 - accuracy: 0.1667 - val_loss: 79.0800 - val_accuracy: 0.1778\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.0570 - accuracy: 0.1468 - val_loss: 78.9612 - val_accuracy: 0.1778\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.9382 - accuracy: 0.1468 - val_loss: 78.8404 - val_accuracy: 0.1778\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.8176 - accuracy: 0.1468 - val_loss: 78.7247 - val_accuracy: 0.1778\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.6996 - accuracy: 0.1468 - val_loss: 78.6087 - val_accuracy: 0.1778\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.5802 - accuracy: 0.1791 - val_loss: 78.4896 - val_accuracy: 0.1556\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78.4623 - accuracy: 0.1617 - val_loss: 78.3727 - val_accuracy: 0.1556\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.3452 - accuracy: 0.1617 - val_loss: 78.2544 - val_accuracy: 0.1556\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 78.2292 - accuracy: 0.1617 - val_loss: 78.1373 - val_accuracy: 0.2000\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.1151 - accuracy: 0.1642 - val_loss: 78.0219 - val_accuracy: 0.1778\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.9992 - accuracy: 0.1642 - val_loss: 77.9050 - val_accuracy: 0.1333\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.8826 - accuracy: 0.1592 - val_loss: 77.7873 - val_accuracy: 0.1333\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.7687 - accuracy: 0.1617 - val_loss: 77.6742 - val_accuracy: 0.1333\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6537 - accuracy: 0.1567 - val_loss: 77.5628 - val_accuracy: 0.1333\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.5394 - accuracy: 0.1567 - val_loss: 77.4510 - val_accuracy: 0.1778\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77.4238 - accuracy: 0.1368 - val_loss: 77.3358 - val_accuracy: 0.1778\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.3097 - accuracy: 0.1468 - val_loss: 77.2225 - val_accuracy: 0.1778\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.1979 - accuracy: 0.1468 - val_loss: 77.1121 - val_accuracy: 0.2000\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77.0852 - accuracy: 0.1716 - val_loss: 76.9996 - val_accuracy: 0.1778\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.9728 - accuracy: 0.1617 - val_loss: 76.8884 - val_accuracy: 0.1778\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.8598 - accuracy: 0.1493 - val_loss: 76.7735 - val_accuracy: 0.1778\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.7477 - accuracy: 0.1468 - val_loss: 76.6610 - val_accuracy: 0.1778\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.6371 - accuracy: 0.1493 - val_loss: 76.5457 - val_accuracy: 0.2000\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.5269 - accuracy: 0.1592 - val_loss: 76.4328 - val_accuracy: 0.1556\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.4167 - accuracy: 0.1617 - val_loss: 76.3226 - val_accuracy: 0.1556\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76.3078 - accuracy: 0.1592 - val_loss: 76.2154 - val_accuracy: 0.1778\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76.1989 - accuracy: 0.1642 - val_loss: 76.1091 - val_accuracy: 0.1778\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76.0888 - accuracy: 0.1493 - val_loss: 75.9992 - val_accuracy: 0.1778\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.9787 - accuracy: 0.1418 - val_loss: 75.8925 - val_accuracy: 0.1778\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.8695 - accuracy: 0.1343 - val_loss: 75.7889 - val_accuracy: 0.1778\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.7620 - accuracy: 0.1667 - val_loss: 75.6807 - val_accuracy: 0.1333\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.6527 - accuracy: 0.1617 - val_loss: 75.5694 - val_accuracy: 0.0889\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.5445 - accuracy: 0.1866 - val_loss: 75.4575 - val_accuracy: 0.1556\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.4383 - accuracy: 0.1542 - val_loss: 75.3464 - val_accuracy: 0.1778\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75.3308 - accuracy: 0.1468 - val_loss: 75.2387 - val_accuracy: 0.1778\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75.2240 - accuracy: 0.1468 - val_loss: 75.1329 - val_accuracy: 0.1778\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.1176 - accuracy: 0.1468 - val_loss: 75.0290 - val_accuracy: 0.1778\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.0112 - accuracy: 0.1468 - val_loss: 74.9207 - val_accuracy: 0.1778\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.9057 - accuracy: 0.1468 - val_loss: 74.8136 - val_accuracy: 0.1778\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7995 - accuracy: 0.1468 - val_loss: 74.7066 - val_accuracy: 0.1778\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.6945 - accuracy: 0.1716 - val_loss: 74.6025 - val_accuracy: 0.1556\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.5901 - accuracy: 0.1617 - val_loss: 74.4962 - val_accuracy: 0.1556\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.4861 - accuracy: 0.1617 - val_loss: 74.3934 - val_accuracy: 0.1556\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.3812 - accuracy: 0.1617 - val_loss: 74.2916 - val_accuracy: 0.1333\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.2757 - accuracy: 0.1692 - val_loss: 74.1885 - val_accuracy: 0.1778\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.1735 - accuracy: 0.1468 - val_loss: 74.0835 - val_accuracy: 0.1778\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.0719 - accuracy: 0.1468 - val_loss: 73.9767 - val_accuracy: 0.1778\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.9677 - accuracy: 0.1468 - val_loss: 73.8739 - val_accuracy: 0.1778\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.8654 - accuracy: 0.1468 - val_loss: 73.7727 - val_accuracy: 0.1778\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.7603 - accuracy: 0.1592 - val_loss: 73.6734 - val_accuracy: 0.1778\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.6583 - accuracy: 0.1493 - val_loss: 73.5746 - val_accuracy: 0.1778\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.5556 - accuracy: 0.1617 - val_loss: 73.4721 - val_accuracy: 0.1778\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.4538 - accuracy: 0.1542 - val_loss: 73.3672 - val_accuracy: 0.1778\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.3518 - accuracy: 0.1468 - val_loss: 73.2671 - val_accuracy: 0.1778\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.2504 - accuracy: 0.1642 - val_loss: 73.1670 - val_accuracy: 0.1333\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73.1493 - accuracy: 0.1617 - val_loss: 73.0652 - val_accuracy: 0.1778\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.0484 - accuracy: 0.1692 - val_loss: 72.9635 - val_accuracy: 0.1778\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.9483 - accuracy: 0.1468 - val_loss: 72.8625 - val_accuracy: 0.1778\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.8479 - accuracy: 0.1468 - val_loss: 72.7614 - val_accuracy: 0.1778\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.7475 - accuracy: 0.1468 - val_loss: 72.6626 - val_accuracy: 0.1778\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.6482 - accuracy: 0.1493 - val_loss: 72.5650 - val_accuracy: 0.1778\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5499 - accuracy: 0.1617 - val_loss: 72.4694 - val_accuracy: 0.1333\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.4511 - accuracy: 0.1642 - val_loss: 72.3719 - val_accuracy: 0.1333\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.3516 - accuracy: 0.1766 - val_loss: 72.2731 - val_accuracy: 0.1111\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.2521 - accuracy: 0.1741 - val_loss: 72.1722 - val_accuracy: 0.2000\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.1521 - accuracy: 0.1692 - val_loss: 72.0709 - val_accuracy: 0.1778\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.0543 - accuracy: 0.1567 - val_loss: 71.9706 - val_accuracy: 0.2000\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.9575 - accuracy: 0.1468 - val_loss: 71.8737 - val_accuracy: 0.1778\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.8588 - accuracy: 0.1468 - val_loss: 71.7756 - val_accuracy: 0.1778\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.7611 - accuracy: 0.1468 - val_loss: 71.6770 - val_accuracy: 0.1778\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.6645 - accuracy: 0.1468 - val_loss: 71.5805 - val_accuracy: 0.1778\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.5665 - accuracy: 0.1468 - val_loss: 71.4830 - val_accuracy: 0.1778\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.4700 - accuracy: 0.1542 - val_loss: 71.3870 - val_accuracy: 0.2000\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.3732 - accuracy: 0.1592 - val_loss: 71.2929 - val_accuracy: 0.1556\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.2771 - accuracy: 0.1716 - val_loss: 71.1987 - val_accuracy: 0.1778\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1822 - accuracy: 0.1493 - val_loss: 71.1033 - val_accuracy: 0.1333\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.0856 - accuracy: 0.1667 - val_loss: 71.0072 - val_accuracy: 0.2000\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.9910 - accuracy: 0.1642 - val_loss: 70.9135 - val_accuracy: 0.1778\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.8941 - accuracy: 0.1468 - val_loss: 70.8189 - val_accuracy: 0.1778\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7975 - accuracy: 0.1716 - val_loss: 70.7260 - val_accuracy: 0.1333\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7029 - accuracy: 0.1816 - val_loss: 70.6335 - val_accuracy: 0.1333\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.6078 - accuracy: 0.1741 - val_loss: 70.5387 - val_accuracy: 0.0889\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.5137 - accuracy: 0.1617 - val_loss: 70.4392 - val_accuracy: 0.1111\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.4180 - accuracy: 0.1517 - val_loss: 70.3397 - val_accuracy: 0.1556\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.3241 - accuracy: 0.1642 - val_loss: 70.2415 - val_accuracy: 0.1778\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.2290 - accuracy: 0.1617 - val_loss: 70.1472 - val_accuracy: 0.1556\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.1349 - accuracy: 0.1617 - val_loss: 70.0531 - val_accuracy: 0.2000\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.0419 - accuracy: 0.1443 - val_loss: 69.9593 - val_accuracy: 0.1778\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69.9475 - accuracy: 0.1468 - val_loss: 69.8691 - val_accuracy: 0.1778\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.8552 - accuracy: 0.1617 - val_loss: 69.7801 - val_accuracy: 0.1111\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.7618 - accuracy: 0.1692 - val_loss: 69.6855 - val_accuracy: 0.1556\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.6684 - accuracy: 0.1617 - val_loss: 69.5906 - val_accuracy: 0.1556\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.5753 - accuracy: 0.1617 - val_loss: 69.4994 - val_accuracy: 0.1556\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.4834 - accuracy: 0.1617 - val_loss: 69.4076 - val_accuracy: 0.1333\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.3917 - accuracy: 0.1542 - val_loss: 69.3164 - val_accuracy: 0.1333\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69.2995 - accuracy: 0.1468 - val_loss: 69.2221 - val_accuracy: 0.1778\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69.2074 - accuracy: 0.1592 - val_loss: 69.1276 - val_accuracy: 0.1556\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.1151 - accuracy: 0.1716 - val_loss: 69.0351 - val_accuracy: 0.1333\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.0233 - accuracy: 0.1493 - val_loss: 68.9432 - val_accuracy: 0.1778\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.9313 - accuracy: 0.1468 - val_loss: 68.8540 - val_accuracy: 0.1778\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.8403 - accuracy: 0.1468 - val_loss: 68.7641 - val_accuracy: 0.1778\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 68.7499 - accuracy: 0.1468 - val_loss: 68.6735 - val_accuracy: 0.1778\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.6590 - accuracy: 0.1468 - val_loss: 68.5829 - val_accuracy: 0.1778\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.5687 - accuracy: 0.1468 - val_loss: 68.4930 - val_accuracy: 0.1778\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.4775 - accuracy: 0.1468 - val_loss: 68.4003 - val_accuracy: 0.1778\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.3870 - accuracy: 0.1468 - val_loss: 68.3063 - val_accuracy: 0.1778\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.2962 - accuracy: 0.1468 - val_loss: 68.2158 - val_accuracy: 0.1778\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.2061 - accuracy: 0.1468 - val_loss: 68.1269 - val_accuracy: 0.1778\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.1170 - accuracy: 0.1692 - val_loss: 68.0397 - val_accuracy: 0.1556\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.0278 - accuracy: 0.1617 - val_loss: 67.9527 - val_accuracy: 0.1556\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9383 - accuracy: 0.1667 - val_loss: 67.8655 - val_accuracy: 0.1778\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.8493 - accuracy: 0.1517 - val_loss: 67.7791 - val_accuracy: 0.1778\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.7609 - accuracy: 0.1343 - val_loss: 67.6902 - val_accuracy: 0.1778\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.6719 - accuracy: 0.1343 - val_loss: 67.6001 - val_accuracy: 0.1778\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.5818 - accuracy: 0.1468 - val_loss: 67.5097 - val_accuracy: 0.1778\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.4928 - accuracy: 0.1468 - val_loss: 67.4198 - val_accuracy: 0.2000\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.4039 - accuracy: 0.1642 - val_loss: 67.3343 - val_accuracy: 0.1556\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3177 - accuracy: 0.1517 - val_loss: 67.2497 - val_accuracy: 0.1556\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.2293 - accuracy: 0.1592 - val_loss: 67.1591 - val_accuracy: 0.1111\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.1400 - accuracy: 0.1617 - val_loss: 67.0681 - val_accuracy: 0.1778\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.0522 - accuracy: 0.1841 - val_loss: 66.9783 - val_accuracy: 0.1556\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.9648 - accuracy: 0.1592 - val_loss: 66.8903 - val_accuracy: 0.1778\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.8765 - accuracy: 0.1567 - val_loss: 66.8007 - val_accuracy: 0.2000\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.7888 - accuracy: 0.1617 - val_loss: 66.7121 - val_accuracy: 0.1556\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.7010 - accuracy: 0.1617 - val_loss: 66.6260 - val_accuracy: 0.1556\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6162 - accuracy: 0.1617 - val_loss: 66.5433 - val_accuracy: 0.1556\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5278 - accuracy: 0.1617 - val_loss: 66.4565 - val_accuracy: 0.1556\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.4407 - accuracy: 0.1617 - val_loss: 66.3709 - val_accuracy: 0.1556\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.3542 - accuracy: 0.1617 - val_loss: 66.2879 - val_accuracy: 0.1556\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.2687 - accuracy: 0.1766 - val_loss: 66.2050 - val_accuracy: 0.1333\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.1824 - accuracy: 0.1965 - val_loss: 66.1213 - val_accuracy: 0.1556\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.0970 - accuracy: 0.1567 - val_loss: 66.0328 - val_accuracy: 0.1778\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66.0107 - accuracy: 0.1468 - val_loss: 65.9433 - val_accuracy: 0.1778\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.9254 - accuracy: 0.1468 - val_loss: 65.8545 - val_accuracy: 0.1778\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.8397 - accuracy: 0.1517 - val_loss: 65.7674 - val_accuracy: 0.2000\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.7543 - accuracy: 0.1692 - val_loss: 65.6802 - val_accuracy: 0.2000\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.6693 - accuracy: 0.1766 - val_loss: 65.5957 - val_accuracy: 0.2000\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.5823 - accuracy: 0.1692 - val_loss: 65.5119 - val_accuracy: 0.1778\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4980 - accuracy: 0.1468 - val_loss: 65.4290 - val_accuracy: 0.1778\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.4128 - accuracy: 0.1816 - val_loss: 65.3446 - val_accuracy: 0.1333\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3292 - accuracy: 0.1567 - val_loss: 65.2571 - val_accuracy: 0.1333\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.2437 - accuracy: 0.1493 - val_loss: 65.1705 - val_accuracy: 0.1778\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.1583 - accuracy: 0.1468 - val_loss: 65.0885 - val_accuracy: 0.1778\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0739 - accuracy: 0.1642 - val_loss: 65.0070 - val_accuracy: 0.1333\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64.9907 - accuracy: 0.1791 - val_loss: 64.9241 - val_accuracy: 0.0889\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.9072 - accuracy: 0.1542 - val_loss: 64.8394 - val_accuracy: 0.1111\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.8219 - accuracy: 0.1517 - val_loss: 64.7537 - val_accuracy: 0.1111\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.7384 - accuracy: 0.1791 - val_loss: 64.6700 - val_accuracy: 0.1556\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.6548 - accuracy: 0.1791 - val_loss: 64.5900 - val_accuracy: 0.2000\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.5716 - accuracy: 0.1791 - val_loss: 64.5068 - val_accuracy: 0.1778\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.4893 - accuracy: 0.1468 - val_loss: 64.4212 - val_accuracy: 0.1778\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.4048 - accuracy: 0.1468 - val_loss: 64.3346 - val_accuracy: 0.1778\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.3213 - accuracy: 0.1468 - val_loss: 64.2507 - val_accuracy: 0.1778\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.2388 - accuracy: 0.1468 - val_loss: 64.1676 - val_accuracy: 0.1778\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.1557 - accuracy: 0.1468 - val_loss: 64.0848 - val_accuracy: 0.1778\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.0732 - accuracy: 0.1468 - val_loss: 64.0017 - val_accuracy: 0.1778\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.9909 - accuracy: 0.1617 - val_loss: 63.9165 - val_accuracy: 0.2000\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.9074 - accuracy: 0.1716 - val_loss: 63.8331 - val_accuracy: 0.1778\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.8247 - accuracy: 0.1468 - val_loss: 63.7515 - val_accuracy: 0.1778\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.7429 - accuracy: 0.1468 - val_loss: 63.6719 - val_accuracy: 0.1778\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.6614 - accuracy: 0.1468 - val_loss: 63.5927 - val_accuracy: 0.1778\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.5795 - accuracy: 0.1468 - val_loss: 63.5111 - val_accuracy: 0.1778\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.4979 - accuracy: 0.1592 - val_loss: 63.4278 - val_accuracy: 0.1556\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4160 - accuracy: 0.1617 - val_loss: 63.3453 - val_accuracy: 0.1556\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.3353 - accuracy: 0.1617 - val_loss: 63.2620 - val_accuracy: 0.2000\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63.2532 - accuracy: 0.1741 - val_loss: 63.1832 - val_accuracy: 0.2000\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.1717 - accuracy: 0.1741 - val_loss: 63.1025 - val_accuracy: 0.2000\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.0901 - accuracy: 0.1667 - val_loss: 63.0224 - val_accuracy: 0.1556\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.0107 - accuracy: 0.1617 - val_loss: 62.9408 - val_accuracy: 0.1556\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.9302 - accuracy: 0.1617 - val_loss: 62.8598 - val_accuracy: 0.1556\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.8485 - accuracy: 0.1617 - val_loss: 62.7768 - val_accuracy: 0.1556\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.7669 - accuracy: 0.1617 - val_loss: 62.6969 - val_accuracy: 0.1556\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.6860 - accuracy: 0.1617 - val_loss: 62.6182 - val_accuracy: 0.1556\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.6052 - accuracy: 0.1617 - val_loss: 62.5391 - val_accuracy: 0.1556\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.5252 - accuracy: 0.1617 - val_loss: 62.4628 - val_accuracy: 0.1556\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.4450 - accuracy: 0.1642 - val_loss: 62.3835 - val_accuracy: 0.1778\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.3655 - accuracy: 0.1468 - val_loss: 62.3014 - val_accuracy: 0.1778\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.2860 - accuracy: 0.1468 - val_loss: 62.2189 - val_accuracy: 0.1778\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62.2062 - accuracy: 0.1468 - val_loss: 62.1370 - val_accuracy: 0.1778\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.1268 - accuracy: 0.1468 - val_loss: 62.0563 - val_accuracy: 0.1778\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.0472 - accuracy: 0.1468 - val_loss: 61.9763 - val_accuracy: 0.1778\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.9666 - accuracy: 0.1468 - val_loss: 61.8979 - val_accuracy: 0.1778\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8876 - accuracy: 0.1517 - val_loss: 61.8234 - val_accuracy: 0.1333\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8086 - accuracy: 0.1692 - val_loss: 61.7434 - val_accuracy: 0.1333\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61.7306 - accuracy: 0.1692 - val_loss: 61.6638 - val_accuracy: 0.1333\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.6504 - accuracy: 0.1692 - val_loss: 61.5819 - val_accuracy: 0.1333\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.5714 - accuracy: 0.1592 - val_loss: 61.5001 - val_accuracy: 0.1333\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.4918 - accuracy: 0.1667 - val_loss: 61.4258 - val_accuracy: 0.1333\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4136 - accuracy: 0.1692 - val_loss: 61.3493 - val_accuracy: 0.1778\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.3357 - accuracy: 0.1517 - val_loss: 61.2716 - val_accuracy: 0.1778\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.2572 - accuracy: 0.1468 - val_loss: 61.1937 - val_accuracy: 0.1778\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.1798 - accuracy: 0.1468 - val_loss: 61.1160 - val_accuracy: 0.1778\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.1020 - accuracy: 0.1468 - val_loss: 61.0362 - val_accuracy: 0.1778\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.0228 - accuracy: 0.1468 - val_loss: 60.9559 - val_accuracy: 0.1778\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.9450 - accuracy: 0.1468 - val_loss: 60.8753 - val_accuracy: 0.1778\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.8660 - accuracy: 0.1468 - val_loss: 60.7951 - val_accuracy: 0.1778\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.7884 - accuracy: 0.1468 - val_loss: 60.7175 - val_accuracy: 0.1778\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.7106 - accuracy: 0.1592 - val_loss: 60.6420 - val_accuracy: 0.1778\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.6325 - accuracy: 0.1567 - val_loss: 60.5667 - val_accuracy: 0.1778\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.5567 - accuracy: 0.1567 - val_loss: 60.4907 - val_accuracy: 0.1333\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4802 - accuracy: 0.1493 - val_loss: 60.4113 - val_accuracy: 0.2222\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.4040 - accuracy: 0.1468 - val_loss: 60.3325 - val_accuracy: 0.2222\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.3265 - accuracy: 0.1468 - val_loss: 60.2559 - val_accuracy: 0.2222\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.2477 - accuracy: 0.1368 - val_loss: 60.1787 - val_accuracy: 0.1778\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.1687 - accuracy: 0.1468 - val_loss: 60.1019 - val_accuracy: 0.1778\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0932 - accuracy: 0.1567 - val_loss: 60.0260 - val_accuracy: 0.1556\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.0174 - accuracy: 0.1667 - val_loss: 59.9513 - val_accuracy: 0.1778\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.9409 - accuracy: 0.1915 - val_loss: 59.8735 - val_accuracy: 0.1556\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.8638 - accuracy: 0.1617 - val_loss: 59.7962 - val_accuracy: 0.1556\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7865 - accuracy: 0.1642 - val_loss: 59.7219 - val_accuracy: 0.2000\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.7100 - accuracy: 0.1567 - val_loss: 59.6466 - val_accuracy: 0.1778\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6335 - accuracy: 0.1667 - val_loss: 59.5708 - val_accuracy: 0.2000\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.5579 - accuracy: 0.2040 - val_loss: 59.4950 - val_accuracy: 0.1778\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59.4827 - accuracy: 0.1915 - val_loss: 59.4173 - val_accuracy: 0.1778\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.4064 - accuracy: 0.1567 - val_loss: 59.3408 - val_accuracy: 0.1778\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.3305 - accuracy: 0.1642 - val_loss: 59.2639 - val_accuracy: 0.2222\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.2541 - accuracy: 0.1741 - val_loss: 59.1884 - val_accuracy: 0.2000\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1795 - accuracy: 0.1667 - val_loss: 59.1127 - val_accuracy: 0.1556\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1048 - accuracy: 0.1617 - val_loss: 59.0351 - val_accuracy: 0.1556\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59.0293 - accuracy: 0.1617 - val_loss: 58.9600 - val_accuracy: 0.1556\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.9539 - accuracy: 0.1617 - val_loss: 58.8846 - val_accuracy: 0.2000\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.8779 - accuracy: 0.1692 - val_loss: 58.8110 - val_accuracy: 0.1778\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.8039 - accuracy: 0.1692 - val_loss: 58.7369 - val_accuracy: 0.1778\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.7287 - accuracy: 0.1816 - val_loss: 58.6626 - val_accuracy: 0.1556\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.6533 - accuracy: 0.2114 - val_loss: 58.5898 - val_accuracy: 0.1778\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.5794 - accuracy: 0.1990 - val_loss: 58.5175 - val_accuracy: 0.1778\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5040 - accuracy: 0.1716 - val_loss: 58.4456 - val_accuracy: 0.1556\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.4307 - accuracy: 0.1617 - val_loss: 58.3731 - val_accuracy: 0.1333\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58.3567 - accuracy: 0.1667 - val_loss: 58.2963 - val_accuracy: 0.1778\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2805 - accuracy: 0.1692 - val_loss: 58.2178 - val_accuracy: 0.1778\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.2067 - accuracy: 0.1468 - val_loss: 58.1402 - val_accuracy: 0.1778\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.1310 - accuracy: 0.1567 - val_loss: 58.0648 - val_accuracy: 0.2000\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.0577 - accuracy: 0.1592 - val_loss: 57.9895 - val_accuracy: 0.1556\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.9838 - accuracy: 0.1617 - val_loss: 57.9154 - val_accuracy: 0.2000\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.9095 - accuracy: 0.1617 - val_loss: 57.8418 - val_accuracy: 0.1778\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.8358 - accuracy: 0.1468 - val_loss: 57.7664 - val_accuracy: 0.1778\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.7631 - accuracy: 0.1468 - val_loss: 57.6926 - val_accuracy: 0.1778\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.6888 - accuracy: 0.1468 - val_loss: 57.6203 - val_accuracy: 0.1778\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.6151 - accuracy: 0.1493 - val_loss: 57.5515 - val_accuracy: 0.1778\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.5424 - accuracy: 0.1741 - val_loss: 57.4817 - val_accuracy: 0.1111\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.4699 - accuracy: 0.1517 - val_loss: 57.4089 - val_accuracy: 0.1111\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.3964 - accuracy: 0.1517 - val_loss: 57.3362 - val_accuracy: 0.1778\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3235 - accuracy: 0.2040 - val_loss: 57.2625 - val_accuracy: 0.2444\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.2496 - accuracy: 0.2214 - val_loss: 57.1887 - val_accuracy: 0.2000\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1757 - accuracy: 0.2065 - val_loss: 57.1167 - val_accuracy: 0.2222\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57.1034 - accuracy: 0.2090 - val_loss: 57.0425 - val_accuracy: 0.2222\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.0296 - accuracy: 0.1965 - val_loss: 56.9686 - val_accuracy: 0.1556\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9568 - accuracy: 0.1617 - val_loss: 56.8959 - val_accuracy: 0.2222\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8856 - accuracy: 0.1542 - val_loss: 56.8231 - val_accuracy: 0.1778\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8127 - accuracy: 0.1468 - val_loss: 56.7518 - val_accuracy: 0.1778\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.7398 - accuracy: 0.1468 - val_loss: 56.6802 - val_accuracy: 0.1778\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.6672 - accuracy: 0.1716 - val_loss: 56.6092 - val_accuracy: 0.1556\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5959 - accuracy: 0.1667 - val_loss: 56.5363 - val_accuracy: 0.1556\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.5236 - accuracy: 0.1617 - val_loss: 56.4638 - val_accuracy: 0.1556\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.4507 - accuracy: 0.1617 - val_loss: 56.3922 - val_accuracy: 0.1556\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.3786 - accuracy: 0.1617 - val_loss: 56.3219 - val_accuracy: 0.1556\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.3082 - accuracy: 0.1816 - val_loss: 56.2509 - val_accuracy: 0.1778\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.2367 - accuracy: 0.2090 - val_loss: 56.1791 - val_accuracy: 0.1778\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.1647 - accuracy: 0.2114 - val_loss: 56.1080 - val_accuracy: 0.1778\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0938 - accuracy: 0.1791 - val_loss: 56.0346 - val_accuracy: 0.2000\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0207 - accuracy: 0.1766 - val_loss: 55.9621 - val_accuracy: 0.2000\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.9485 - accuracy: 0.1617 - val_loss: 55.8889 - val_accuracy: 0.1556\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.8773 - accuracy: 0.1617 - val_loss: 55.8158 - val_accuracy: 0.1556\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.8069 - accuracy: 0.1617 - val_loss: 55.7426 - val_accuracy: 0.1556\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.7361 - accuracy: 0.1617 - val_loss: 55.6698 - val_accuracy: 0.1556\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6639 - accuracy: 0.1617 - val_loss: 55.5978 - val_accuracy: 0.1556\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.5928 - accuracy: 0.1791 - val_loss: 55.5267 - val_accuracy: 0.1778\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5224 - accuracy: 0.1542 - val_loss: 55.4567 - val_accuracy: 0.1333\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.4515 - accuracy: 0.1692 - val_loss: 55.3861 - val_accuracy: 0.1333\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.3797 - accuracy: 0.1791 - val_loss: 55.3161 - val_accuracy: 0.1778\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.3087 - accuracy: 0.1468 - val_loss: 55.2453 - val_accuracy: 0.1778\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.2392 - accuracy: 0.1468 - val_loss: 55.1745 - val_accuracy: 0.1778\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.1689 - accuracy: 0.1567 - val_loss: 55.1048 - val_accuracy: 0.1778\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.0985 - accuracy: 0.1592 - val_loss: 55.0339 - val_accuracy: 0.1778\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.0272 - accuracy: 0.1741 - val_loss: 54.9637 - val_accuracy: 0.1556\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.9571 - accuracy: 0.1617 - val_loss: 54.8928 - val_accuracy: 0.1556\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.8865 - accuracy: 0.1617 - val_loss: 54.8199 - val_accuracy: 0.1556\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.8168 - accuracy: 0.1617 - val_loss: 54.7484 - val_accuracy: 0.1556\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.7462 - accuracy: 0.1617 - val_loss: 54.6788 - val_accuracy: 0.1556\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.6768 - accuracy: 0.1617 - val_loss: 54.6113 - val_accuracy: 0.1556\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.6066 - accuracy: 0.1716 - val_loss: 54.5442 - val_accuracy: 0.1778\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5363 - accuracy: 0.2065 - val_loss: 54.4767 - val_accuracy: 0.1778\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.4677 - accuracy: 0.1990 - val_loss: 54.4079 - val_accuracy: 0.1778\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.3979 - accuracy: 0.1816 - val_loss: 54.3345 - val_accuracy: 0.2000\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.3275 - accuracy: 0.1692 - val_loss: 54.2630 - val_accuracy: 0.1778\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.2572 - accuracy: 0.1617 - val_loss: 54.1958 - val_accuracy: 0.2222\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.1878 - accuracy: 0.1741 - val_loss: 54.1267 - val_accuracy: 0.2000\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.1192 - accuracy: 0.1866 - val_loss: 54.0572 - val_accuracy: 0.1333\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.0506 - accuracy: 0.1891 - val_loss: 53.9862 - val_accuracy: 0.1778\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.9814 - accuracy: 0.2114 - val_loss: 53.9178 - val_accuracy: 0.1556\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.9115 - accuracy: 0.1642 - val_loss: 53.8490 - val_accuracy: 0.1556\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.8428 - accuracy: 0.1667 - val_loss: 53.7807 - val_accuracy: 0.1778\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.7734 - accuracy: 0.1542 - val_loss: 53.7118 - val_accuracy: 0.1778\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.7047 - accuracy: 0.1791 - val_loss: 53.6442 - val_accuracy: 0.1333\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.6357 - accuracy: 0.1692 - val_loss: 53.5769 - val_accuracy: 0.1333\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.5679 - accuracy: 0.1692 - val_loss: 53.5102 - val_accuracy: 0.1333\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.4997 - accuracy: 0.1741 - val_loss: 53.4442 - val_accuracy: 0.1333\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.4314 - accuracy: 0.1741 - val_loss: 53.3731 - val_accuracy: 0.1333\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.3619 - accuracy: 0.1692 - val_loss: 53.3024 - val_accuracy: 0.1556\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2933 - accuracy: 0.1642 - val_loss: 53.2321 - val_accuracy: 0.1556\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2247 - accuracy: 0.1617 - val_loss: 53.1633 - val_accuracy: 0.1556\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1563 - accuracy: 0.1617 - val_loss: 53.0939 - val_accuracy: 0.2000\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0883 - accuracy: 0.1567 - val_loss: 53.0254 - val_accuracy: 0.1778\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.0200 - accuracy: 0.1468 - val_loss: 52.9586 - val_accuracy: 0.1778\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.9520 - accuracy: 0.1468 - val_loss: 52.8893 - val_accuracy: 0.1778\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52.8844 - accuracy: 0.1468 - val_loss: 52.8208 - val_accuracy: 0.1778\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.8170 - accuracy: 0.1468 - val_loss: 52.7543 - val_accuracy: 0.1778\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.7493 - accuracy: 0.1468 - val_loss: 52.6889 - val_accuracy: 0.1778\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6806 - accuracy: 0.1468 - val_loss: 52.6201 - val_accuracy: 0.1778\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.6136 - accuracy: 0.1468 - val_loss: 52.5506 - val_accuracy: 0.1778\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.5456 - accuracy: 0.1617 - val_loss: 52.4818 - val_accuracy: 0.2000\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.4785 - accuracy: 0.1716 - val_loss: 52.4137 - val_accuracy: 0.1556\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.4114 - accuracy: 0.1617 - val_loss: 52.3481 - val_accuracy: 0.1556\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.3442 - accuracy: 0.1617 - val_loss: 52.2818 - val_accuracy: 0.1556\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52.2764 - accuracy: 0.1617 - val_loss: 52.2189 - val_accuracy: 0.1556\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.2093 - accuracy: 0.1617 - val_loss: 52.1543 - val_accuracy: 0.1556\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.1427 - accuracy: 0.1667 - val_loss: 52.0874 - val_accuracy: 0.1778\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.0750 - accuracy: 0.1542 - val_loss: 52.0166 - val_accuracy: 0.1778\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.0087 - accuracy: 0.1468 - val_loss: 51.9475 - val_accuracy: 0.1778\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.9412 - accuracy: 0.1468 - val_loss: 51.8775 - val_accuracy: 0.1778\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8740 - accuracy: 0.1468 - val_loss: 51.8089 - val_accuracy: 0.2000\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8082 - accuracy: 0.1567 - val_loss: 51.7450 - val_accuracy: 0.1556\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51.7435 - accuracy: 0.1642 - val_loss: 51.6800 - val_accuracy: 0.1778\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.6762 - accuracy: 0.1667 - val_loss: 51.6112 - val_accuracy: 0.1556\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.6085 - accuracy: 0.1741 - val_loss: 51.5423 - val_accuracy: 0.1778\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.5416 - accuracy: 0.1468 - val_loss: 51.4756 - val_accuracy: 0.1778\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.4753 - accuracy: 0.1468 - val_loss: 51.4100 - val_accuracy: 0.1778\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.4101 - accuracy: 0.1468 - val_loss: 51.3443 - val_accuracy: 0.1778\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51.3439 - accuracy: 0.1468 - val_loss: 51.2804 - val_accuracy: 0.1778\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.2771 - accuracy: 0.1468 - val_loss: 51.2147 - val_accuracy: 0.1778\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.2105 - accuracy: 0.1468 - val_loss: 51.1485 - val_accuracy: 0.1778\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.1436 - accuracy: 0.1667 - val_loss: 51.0827 - val_accuracy: 0.1556\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0778 - accuracy: 0.1617 - val_loss: 51.0180 - val_accuracy: 0.1556\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.0132 - accuracy: 0.1617 - val_loss: 50.9548 - val_accuracy: 0.1556\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.9479 - accuracy: 0.1617 - val_loss: 50.8914 - val_accuracy: 0.1556\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8827 - accuracy: 0.1617 - val_loss: 50.8258 - val_accuracy: 0.1556\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8161 - accuracy: 0.1617 - val_loss: 50.7602 - val_accuracy: 0.1556\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.7493 - accuracy: 0.1617 - val_loss: 50.6930 - val_accuracy: 0.1556\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6828 - accuracy: 0.1592 - val_loss: 50.6252 - val_accuracy: 0.1778\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50.6187 - accuracy: 0.1617 - val_loss: 50.5595 - val_accuracy: 0.1778\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.5529 - accuracy: 0.1791 - val_loss: 50.4943 - val_accuracy: 0.1778\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.4873 - accuracy: 0.1493 - val_loss: 50.4276 - val_accuracy: 0.1778\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.4219 - accuracy: 0.1468 - val_loss: 50.3630 - val_accuracy: 0.1778\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.3572 - accuracy: 0.1468 - val_loss: 50.2980 - val_accuracy: 0.1778\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.2937 - accuracy: 0.1468 - val_loss: 50.2339 - val_accuracy: 0.1778\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2301 - accuracy: 0.1468 - val_loss: 50.1689 - val_accuracy: 0.1778\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.1649 - accuracy: 0.1468 - val_loss: 50.1005 - val_accuracy: 0.1778\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.0982 - accuracy: 0.1468 - val_loss: 50.0352 - val_accuracy: 0.1778\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.0322 - accuracy: 0.1468 - val_loss: 49.9695 - val_accuracy: 0.1778\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.9676 - accuracy: 0.1766 - val_loss: 49.9076 - val_accuracy: 0.2000\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.9022 - accuracy: 0.1741 - val_loss: 49.8440 - val_accuracy: 0.2000\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.8376 - accuracy: 0.1542 - val_loss: 49.7791 - val_accuracy: 0.1778\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7733 - accuracy: 0.1617 - val_loss: 49.7123 - val_accuracy: 0.2000\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.7088 - accuracy: 0.1617 - val_loss: 49.6477 - val_accuracy: 0.1556\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6453 - accuracy: 0.1692 - val_loss: 49.5806 - val_accuracy: 0.1778\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.5797 - accuracy: 0.1517 - val_loss: 49.5159 - val_accuracy: 0.1778\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49.5157 - accuracy: 0.1468 - val_loss: 49.4538 - val_accuracy: 0.1778\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4518 - accuracy: 0.1542 - val_loss: 49.3914 - val_accuracy: 0.1778\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49.3871 - accuracy: 0.1716 - val_loss: 49.3287 - val_accuracy: 0.2000\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3232 - accuracy: 0.1667 - val_loss: 49.2697 - val_accuracy: 0.1556\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.2589 - accuracy: 0.1617 - val_loss: 49.2086 - val_accuracy: 0.1556\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.1958 - accuracy: 0.1741 - val_loss: 49.1473 - val_accuracy: 0.1778\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.1324 - accuracy: 0.1667 - val_loss: 49.0853 - val_accuracy: 0.1111\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0687 - accuracy: 0.1517 - val_loss: 49.0205 - val_accuracy: 0.1111\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0047 - accuracy: 0.1517 - val_loss: 48.9532 - val_accuracy: 0.1111\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.9407 - accuracy: 0.1766 - val_loss: 48.8868 - val_accuracy: 0.1556\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8770 - accuracy: 0.1617 - val_loss: 48.8207 - val_accuracy: 0.1556\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.8124 - accuracy: 0.1617 - val_loss: 48.7556 - val_accuracy: 0.1556\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7484 - accuracy: 0.1617 - val_loss: 48.6906 - val_accuracy: 0.1556\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.6852 - accuracy: 0.2015 - val_loss: 48.6260 - val_accuracy: 0.1778\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6229 - accuracy: 0.2090 - val_loss: 48.5617 - val_accuracy: 0.1556\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.5588 - accuracy: 0.1642 - val_loss: 48.4995 - val_accuracy: 0.1556\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.4954 - accuracy: 0.1542 - val_loss: 48.4377 - val_accuracy: 0.1333\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.4328 - accuracy: 0.1592 - val_loss: 48.3739 - val_accuracy: 0.1778\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.3697 - accuracy: 0.1716 - val_loss: 48.3115 - val_accuracy: 0.2000\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.3064 - accuracy: 0.1741 - val_loss: 48.2480 - val_accuracy: 0.2000\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.2435 - accuracy: 0.1592 - val_loss: 48.1854 - val_accuracy: 0.1778\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1806 - accuracy: 0.1617 - val_loss: 48.1232 - val_accuracy: 0.2000\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.1175 - accuracy: 0.1567 - val_loss: 48.0607 - val_accuracy: 0.1556\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0548 - accuracy: 0.1617 - val_loss: 47.9986 - val_accuracy: 0.1778\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.9922 - accuracy: 0.1617 - val_loss: 47.9365 - val_accuracy: 0.1333\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.9291 - accuracy: 0.1642 - val_loss: 47.8740 - val_accuracy: 0.1556\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.8669 - accuracy: 0.1617 - val_loss: 47.8073 - val_accuracy: 0.1778\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.8035 - accuracy: 0.1468 - val_loss: 47.7432 - val_accuracy: 0.1778\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.7419 - accuracy: 0.1517 - val_loss: 47.6807 - val_accuracy: 0.2000\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.6789 - accuracy: 0.1741 - val_loss: 47.6190 - val_accuracy: 0.2222\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.6165 - accuracy: 0.1692 - val_loss: 47.5579 - val_accuracy: 0.1556\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.5550 - accuracy: 0.1592 - val_loss: 47.4998 - val_accuracy: 0.1778\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.4925 - accuracy: 0.1617 - val_loss: 47.4379 - val_accuracy: 0.1556\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.4310 - accuracy: 0.1617 - val_loss: 47.3761 - val_accuracy: 0.1556\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.3674 - accuracy: 0.1617 - val_loss: 47.3133 - val_accuracy: 0.2222\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.3057 - accuracy: 0.1692 - val_loss: 47.2514 - val_accuracy: 0.1778\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.2445 - accuracy: 0.1468 - val_loss: 47.1910 - val_accuracy: 0.1778\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.1827 - accuracy: 0.1493 - val_loss: 47.1302 - val_accuracy: 0.2000\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.1209 - accuracy: 0.1891 - val_loss: 47.0687 - val_accuracy: 0.2000\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0593 - accuracy: 0.1816 - val_loss: 47.0058 - val_accuracy: 0.1778\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.9969 - accuracy: 0.1766 - val_loss: 46.9413 - val_accuracy: 0.1333\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.9348 - accuracy: 0.1692 - val_loss: 46.8765 - val_accuracy: 0.1333\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46.8730 - accuracy: 0.1642 - val_loss: 46.8139 - val_accuracy: 0.1556\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.8119 - accuracy: 0.1617 - val_loss: 46.7555 - val_accuracy: 0.1556\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.7520 - accuracy: 0.1617 - val_loss: 46.6959 - val_accuracy: 0.1556\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.6905 - accuracy: 0.1642 - val_loss: 46.6338 - val_accuracy: 0.1556\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.6282 - accuracy: 0.1617 - val_loss: 46.5736 - val_accuracy: 0.1556\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46.5673 - accuracy: 0.1617 - val_loss: 46.5138 - val_accuracy: 0.1556\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5057 - accuracy: 0.1617 - val_loss: 46.4512 - val_accuracy: 0.1556\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.4440 - accuracy: 0.1617 - val_loss: 46.3878 - val_accuracy: 0.1556\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.3829 - accuracy: 0.1667 - val_loss: 46.3251 - val_accuracy: 0.1778\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3219 - accuracy: 0.1592 - val_loss: 46.2663 - val_accuracy: 0.2000\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2611 - accuracy: 0.1791 - val_loss: 46.2074 - val_accuracy: 0.1556\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.2011 - accuracy: 0.1617 - val_loss: 46.1489 - val_accuracy: 0.1556\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.1392 - accuracy: 0.1617 - val_loss: 46.0860 - val_accuracy: 0.1556\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0780 - accuracy: 0.1617 - val_loss: 46.0225 - val_accuracy: 0.1556\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.0179 - accuracy: 0.1716 - val_loss: 45.9593 - val_accuracy: 0.1778\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.9574 - accuracy: 0.1617 - val_loss: 45.8992 - val_accuracy: 0.1778\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8959 - accuracy: 0.1542 - val_loss: 45.8395 - val_accuracy: 0.1778\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.8363 - accuracy: 0.1468 - val_loss: 45.7809 - val_accuracy: 0.1778\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7767 - accuracy: 0.1493 - val_loss: 45.7209 - val_accuracy: 0.1778\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.7160 - accuracy: 0.1592 - val_loss: 45.6617 - val_accuracy: 0.1333\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.6547 - accuracy: 0.1567 - val_loss: 45.6019 - val_accuracy: 0.1333\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5935 - accuracy: 0.1692 - val_loss: 45.5434 - val_accuracy: 0.1333\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.5335 - accuracy: 0.1567 - val_loss: 45.4848 - val_accuracy: 0.1556\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.4741 - accuracy: 0.1617 - val_loss: 45.4242 - val_accuracy: 0.1556\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.4140 - accuracy: 0.1617 - val_loss: 45.3609 - val_accuracy: 0.1556\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.3540 - accuracy: 0.1617 - val_loss: 45.2994 - val_accuracy: 0.2000\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.2928 - accuracy: 0.1592 - val_loss: 45.2376 - val_accuracy: 0.1778\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.2329 - accuracy: 0.1468 - val_loss: 45.1788 - val_accuracy: 0.1778\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.1733 - accuracy: 0.1716 - val_loss: 45.1187 - val_accuracy: 0.1778\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1139 - accuracy: 0.1642 - val_loss: 45.0577 - val_accuracy: 0.1778\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.0538 - accuracy: 0.1468 - val_loss: 44.9990 - val_accuracy: 0.1778\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9934 - accuracy: 0.1468 - val_loss: 44.9388 - val_accuracy: 0.1778\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.9342 - accuracy: 0.1841 - val_loss: 44.8803 - val_accuracy: 0.1333\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44.8741 - accuracy: 0.1692 - val_loss: 44.8195 - val_accuracy: 0.1333\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.8140 - accuracy: 0.1692 - val_loss: 44.7610 - val_accuracy: 0.1333\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.7543 - accuracy: 0.1692 - val_loss: 44.7014 - val_accuracy: 0.1333\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.6951 - accuracy: 0.1692 - val_loss: 44.6419 - val_accuracy: 0.1333\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.6357 - accuracy: 0.1692 - val_loss: 44.5813 - val_accuracy: 0.1333\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.5756 - accuracy: 0.1692 - val_loss: 44.5214 - val_accuracy: 0.1333\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.5163 - accuracy: 0.1692 - val_loss: 44.4613 - val_accuracy: 0.1333\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.4577 - accuracy: 0.1692 - val_loss: 44.4009 - val_accuracy: 0.1333\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3989 - accuracy: 0.1692 - val_loss: 44.3404 - val_accuracy: 0.1333\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3401 - accuracy: 0.1667 - val_loss: 44.2809 - val_accuracy: 0.1556\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44.2805 - accuracy: 0.1741 - val_loss: 44.2223 - val_accuracy: 0.2000\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2212 - accuracy: 0.1667 - val_loss: 44.1635 - val_accuracy: 0.1778\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1643 - accuracy: 0.1617 - val_loss: 44.1061 - val_accuracy: 0.1778\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.1036 - accuracy: 0.1617 - val_loss: 44.0476 - val_accuracy: 0.1778\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.0448 - accuracy: 0.1517 - val_loss: 43.9882 - val_accuracy: 0.1778\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9854 - accuracy: 0.1468 - val_loss: 43.9320 - val_accuracy: 0.1778\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9277 - accuracy: 0.1468 - val_loss: 43.8757 - val_accuracy: 0.1778\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.8695 - accuracy: 0.1493 - val_loss: 43.8177 - val_accuracy: 0.1778\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.8105 - accuracy: 0.1791 - val_loss: 43.7598 - val_accuracy: 0.1333\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.7515 - accuracy: 0.1741 - val_loss: 43.6993 - val_accuracy: 0.1778\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6924 - accuracy: 0.1617 - val_loss: 43.6395 - val_accuracy: 0.1778\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.6340 - accuracy: 0.1567 - val_loss: 43.5803 - val_accuracy: 0.1778\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.5753 - accuracy: 0.1741 - val_loss: 43.5207 - val_accuracy: 0.2000\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.5167 - accuracy: 0.1642 - val_loss: 43.4627 - val_accuracy: 0.1556\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.4592 - accuracy: 0.1915 - val_loss: 43.4048 - val_accuracy: 0.1778\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.4011 - accuracy: 0.2114 - val_loss: 43.3462 - val_accuracy: 0.2000\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.3426 - accuracy: 0.1816 - val_loss: 43.2876 - val_accuracy: 0.1778\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.2843 - accuracy: 0.1468 - val_loss: 43.2286 - val_accuracy: 0.1778\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.2271 - accuracy: 0.1468 - val_loss: 43.1699 - val_accuracy: 0.1778\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.1694 - accuracy: 0.1468 - val_loss: 43.1110 - val_accuracy: 0.1778\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.1115 - accuracy: 0.1468 - val_loss: 43.0523 - val_accuracy: 0.1778\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0534 - accuracy: 0.1468 - val_loss: 42.9956 - val_accuracy: 0.1778\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.9943 - accuracy: 0.1468 - val_loss: 42.9391 - val_accuracy: 0.1778\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.9374 - accuracy: 0.1567 - val_loss: 42.8830 - val_accuracy: 0.2222\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.8799 - accuracy: 0.1791 - val_loss: 42.8244 - val_accuracy: 0.2000\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.8226 - accuracy: 0.1741 - val_loss: 42.7651 - val_accuracy: 0.2000\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.7645 - accuracy: 0.1741 - val_loss: 42.7068 - val_accuracy: 0.2000\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.7068 - accuracy: 0.1716 - val_loss: 42.6486 - val_accuracy: 0.2000\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.6493 - accuracy: 0.1716 - val_loss: 42.5920 - val_accuracy: 0.2000\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42.5919 - accuracy: 0.1716 - val_loss: 42.5345 - val_accuracy: 0.2000\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5348 - accuracy: 0.1692 - val_loss: 42.4790 - val_accuracy: 0.1556\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.4769 - accuracy: 0.1617 - val_loss: 42.4232 - val_accuracy: 0.1556\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.4200 - accuracy: 0.1617 - val_loss: 42.3656 - val_accuracy: 0.1778\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.3622 - accuracy: 0.1468 - val_loss: 42.3068 - val_accuracy: 0.1778\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.3048 - accuracy: 0.1468 - val_loss: 42.2485 - val_accuracy: 0.1778\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2481 - accuracy: 0.1493 - val_loss: 42.1906 - val_accuracy: 0.1778\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1916 - accuracy: 0.1617 - val_loss: 42.1338 - val_accuracy: 0.2000\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.1343 - accuracy: 0.1617 - val_loss: 42.0777 - val_accuracy: 0.1556\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0781 - accuracy: 0.1567 - val_loss: 42.0202 - val_accuracy: 0.1778\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0205 - accuracy: 0.1468 - val_loss: 41.9635 - val_accuracy: 0.1778\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.9632 - accuracy: 0.1468 - val_loss: 41.9052 - val_accuracy: 0.1778\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.9067 - accuracy: 0.1468 - val_loss: 41.8478 - val_accuracy: 0.1778\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.8507 - accuracy: 0.1468 - val_loss: 41.7907 - val_accuracy: 0.1778\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.7943 - accuracy: 0.1493 - val_loss: 41.7360 - val_accuracy: 0.2000\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.7376 - accuracy: 0.1592 - val_loss: 41.6832 - val_accuracy: 0.1556\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6808 - accuracy: 0.1692 - val_loss: 41.6284 - val_accuracy: 0.1556\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.6236 - accuracy: 0.1716 - val_loss: 41.5716 - val_accuracy: 0.1556\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.5667 - accuracy: 0.1642 - val_loss: 41.5144 - val_accuracy: 0.2222\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.5100 - accuracy: 0.1716 - val_loss: 41.4571 - val_accuracy: 0.1778\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.4541 - accuracy: 0.1493 - val_loss: 41.4020 - val_accuracy: 0.1778\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.3976 - accuracy: 0.1940 - val_loss: 41.3465 - val_accuracy: 0.2222\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.3419 - accuracy: 0.2189 - val_loss: 41.2901 - val_accuracy: 0.2000\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2860 - accuracy: 0.1642 - val_loss: 41.2350 - val_accuracy: 0.1556\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.2312 - accuracy: 0.1617 - val_loss: 41.1797 - val_accuracy: 0.1556\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1741 - accuracy: 0.1667 - val_loss: 41.1234 - val_accuracy: 0.1778\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.1177 - accuracy: 0.2114 - val_loss: 41.0660 - val_accuracy: 0.1556\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.0617 - accuracy: 0.1816 - val_loss: 41.0100 - val_accuracy: 0.2000\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41.0052 - accuracy: 0.1716 - val_loss: 40.9524 - val_accuracy: 0.2222\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.9490 - accuracy: 0.1766 - val_loss: 40.8960 - val_accuracy: 0.1778\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.8932 - accuracy: 0.1493 - val_loss: 40.8400 - val_accuracy: 0.1778\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.8378 - accuracy: 0.1468 - val_loss: 40.7839 - val_accuracy: 0.1778\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.7818 - accuracy: 0.1617 - val_loss: 40.7279 - val_accuracy: 0.2000\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.7264 - accuracy: 0.1716 - val_loss: 40.6739 - val_accuracy: 0.1556\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6714 - accuracy: 0.1617 - val_loss: 40.6175 - val_accuracy: 0.1556\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6154 - accuracy: 0.1617 - val_loss: 40.5609 - val_accuracy: 0.1556\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5596 - accuracy: 0.1617 - val_loss: 40.5056 - val_accuracy: 0.1556\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.5044 - accuracy: 0.1617 - val_loss: 40.4525 - val_accuracy: 0.1556\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.4488 - accuracy: 0.1617 - val_loss: 40.3989 - val_accuracy: 0.2000\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.3940 - accuracy: 0.1617 - val_loss: 40.3476 - val_accuracy: 0.1556\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.3384 - accuracy: 0.1617 - val_loss: 40.2935 - val_accuracy: 0.1556\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.2834 - accuracy: 0.1617 - val_loss: 40.2356 - val_accuracy: 0.2222\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.2278 - accuracy: 0.1667 - val_loss: 40.1804 - val_accuracy: 0.1778\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.1732 - accuracy: 0.1468 - val_loss: 40.1253 - val_accuracy: 0.1778\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.1183 - accuracy: 0.1468 - val_loss: 40.0705 - val_accuracy: 0.1778\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0631 - accuracy: 0.1493 - val_loss: 40.0149 - val_accuracy: 0.1778\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40.0079 - accuracy: 0.1692 - val_loss: 39.9595 - val_accuracy: 0.1556\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.9529 - accuracy: 0.1617 - val_loss: 39.9048 - val_accuracy: 0.1556\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.8984 - accuracy: 0.1741 - val_loss: 39.8497 - val_accuracy: 0.1778\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.8438 - accuracy: 0.2114 - val_loss: 39.7976 - val_accuracy: 0.1778\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7897 - accuracy: 0.2015 - val_loss: 39.7452 - val_accuracy: 0.1333\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.7356 - accuracy: 0.1741 - val_loss: 39.6916 - val_accuracy: 0.1333\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.6798 - accuracy: 0.1990 - val_loss: 39.6358 - val_accuracy: 0.2000\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.6252 - accuracy: 0.2164 - val_loss: 39.5804 - val_accuracy: 0.2000\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5715 - accuracy: 0.1891 - val_loss: 39.5251 - val_accuracy: 0.1778\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.5162 - accuracy: 0.1468 - val_loss: 39.4685 - val_accuracy: 0.1778\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4619 - accuracy: 0.1468 - val_loss: 39.4131 - val_accuracy: 0.1778\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.4080 - accuracy: 0.1468 - val_loss: 39.3586 - val_accuracy: 0.1778\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.3534 - accuracy: 0.1468 - val_loss: 39.3043 - val_accuracy: 0.1778\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.2997 - accuracy: 0.1915 - val_loss: 39.2484 - val_accuracy: 0.2000\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.2443 - accuracy: 0.2214 - val_loss: 39.1931 - val_accuracy: 0.2222\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1902 - accuracy: 0.2164 - val_loss: 39.1396 - val_accuracy: 0.1778\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.1356 - accuracy: 0.2114 - val_loss: 39.0833 - val_accuracy: 0.1556\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.0810 - accuracy: 0.1667 - val_loss: 39.0262 - val_accuracy: 0.1556\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.0282 - accuracy: 0.1617 - val_loss: 38.9698 - val_accuracy: 0.2000\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.9745 - accuracy: 0.1692 - val_loss: 38.9148 - val_accuracy: 0.1778\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.9203 - accuracy: 0.1468 - val_loss: 38.8618 - val_accuracy: 0.1778\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8662 - accuracy: 0.1468 - val_loss: 38.8115 - val_accuracy: 0.1778\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.8113 - accuracy: 0.1617 - val_loss: 38.7592 - val_accuracy: 0.2000\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.7571 - accuracy: 0.1716 - val_loss: 38.7073 - val_accuracy: 0.1556\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.7038 - accuracy: 0.1617 - val_loss: 38.6554 - val_accuracy: 0.1556\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6504 - accuracy: 0.1617 - val_loss: 38.6030 - val_accuracy: 0.1556\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5967 - accuracy: 0.1617 - val_loss: 38.5486 - val_accuracy: 0.1556\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.5426 - accuracy: 0.1915 - val_loss: 38.4974 - val_accuracy: 0.2444\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4894 - accuracy: 0.2040 - val_loss: 38.4440 - val_accuracy: 0.1778\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.4360 - accuracy: 0.1468 - val_loss: 38.3893 - val_accuracy: 0.1778\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.3825 - accuracy: 0.1468 - val_loss: 38.3343 - val_accuracy: 0.1778\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.3285 - accuracy: 0.1468 - val_loss: 38.2802 - val_accuracy: 0.1778\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2753 - accuracy: 0.1567 - val_loss: 38.2267 - val_accuracy: 0.2000\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.2217 - accuracy: 0.1716 - val_loss: 38.1720 - val_accuracy: 0.2000\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.1683 - accuracy: 0.1716 - val_loss: 38.1185 - val_accuracy: 0.1556\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.1153 - accuracy: 0.1617 - val_loss: 38.0648 - val_accuracy: 0.1556\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.0623 - accuracy: 0.1617 - val_loss: 38.0118 - val_accuracy: 0.1556\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.0089 - accuracy: 0.1716 - val_loss: 37.9581 - val_accuracy: 0.2000\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37.9562 - accuracy: 0.1642 - val_loss: 37.9044 - val_accuracy: 0.1778\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.9033 - accuracy: 0.1468 - val_loss: 37.8509 - val_accuracy: 0.1778\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.8500 - accuracy: 0.1468 - val_loss: 37.7999 - val_accuracy: 0.1778\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.7975 - accuracy: 0.1766 - val_loss: 37.7478 - val_accuracy: 0.1333\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.7452 - accuracy: 0.1692 - val_loss: 37.6955 - val_accuracy: 0.1333\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.6924 - accuracy: 0.1692 - val_loss: 37.6433 - val_accuracy: 0.1333\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.6391 - accuracy: 0.1692 - val_loss: 37.5910 - val_accuracy: 0.1333\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5870 - accuracy: 0.1766 - val_loss: 37.5379 - val_accuracy: 0.1333\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.5341 - accuracy: 0.1841 - val_loss: 37.4865 - val_accuracy: 0.1556\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.4810 - accuracy: 0.1617 - val_loss: 37.4338 - val_accuracy: 0.1556\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4288 - accuracy: 0.1617 - val_loss: 37.3817 - val_accuracy: 0.2000\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.3761 - accuracy: 0.1741 - val_loss: 37.3287 - val_accuracy: 0.1778\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.3232 - accuracy: 0.1468 - val_loss: 37.2759 - val_accuracy: 0.1778\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.2713 - accuracy: 0.1468 - val_loss: 37.2236 - val_accuracy: 0.1778\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.2190 - accuracy: 0.1468 - val_loss: 37.1705 - val_accuracy: 0.1778\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1661 - accuracy: 0.1617 - val_loss: 37.1172 - val_accuracy: 0.2000\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1139 - accuracy: 0.1816 - val_loss: 37.0653 - val_accuracy: 0.1556\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.0621 - accuracy: 0.1915 - val_loss: 37.0140 - val_accuracy: 0.1556\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0098 - accuracy: 0.2065 - val_loss: 36.9612 - val_accuracy: 0.1778\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.9578 - accuracy: 0.2139 - val_loss: 36.9086 - val_accuracy: 0.1333\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9065 - accuracy: 0.1791 - val_loss: 36.8581 - val_accuracy: 0.1111\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.8547 - accuracy: 0.1642 - val_loss: 36.8081 - val_accuracy: 0.1111\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.8027 - accuracy: 0.1891 - val_loss: 36.7572 - val_accuracy: 0.1778\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.7504 - accuracy: 0.2090 - val_loss: 36.7070 - val_accuracy: 0.1556\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6986 - accuracy: 0.1965 - val_loss: 36.6574 - val_accuracy: 0.1778\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6474 - accuracy: 0.2114 - val_loss: 36.6052 - val_accuracy: 0.1778\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.5946 - accuracy: 0.2090 - val_loss: 36.5507 - val_accuracy: 0.2000\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.5438 - accuracy: 0.1766 - val_loss: 36.4953 - val_accuracy: 0.1778\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.4914 - accuracy: 0.1468 - val_loss: 36.4412 - val_accuracy: 0.1778\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.4392 - accuracy: 0.1468 - val_loss: 36.3879 - val_accuracy: 0.1778\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3876 - accuracy: 0.1592 - val_loss: 36.3371 - val_accuracy: 0.2000\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3361 - accuracy: 0.1667 - val_loss: 36.2862 - val_accuracy: 0.1556\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2848 - accuracy: 0.1617 - val_loss: 36.2361 - val_accuracy: 0.1556\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.2335 - accuracy: 0.1866 - val_loss: 36.1853 - val_accuracy: 0.1778\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.1821 - accuracy: 0.1940 - val_loss: 36.1339 - val_accuracy: 0.1556\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.1306 - accuracy: 0.1617 - val_loss: 36.0830 - val_accuracy: 0.1556\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.0791 - accuracy: 0.1617 - val_loss: 36.0331 - val_accuracy: 0.1556\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36.0282 - accuracy: 0.1617 - val_loss: 35.9813 - val_accuracy: 0.1556\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.9764 - accuracy: 0.1642 - val_loss: 35.9282 - val_accuracy: 0.1778\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.9257 - accuracy: 0.1617 - val_loss: 35.8766 - val_accuracy: 0.1778\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35.8745 - accuracy: 0.1642 - val_loss: 35.8259 - val_accuracy: 0.2000\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.8243 - accuracy: 0.1517 - val_loss: 35.7745 - val_accuracy: 0.1778\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.7729 - accuracy: 0.1617 - val_loss: 35.7243 - val_accuracy: 0.2000\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.7225 - accuracy: 0.1965 - val_loss: 35.6724 - val_accuracy: 0.2222\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.6723 - accuracy: 0.2065 - val_loss: 35.6199 - val_accuracy: 0.2444\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.6208 - accuracy: 0.2313 - val_loss: 35.5698 - val_accuracy: 0.2444\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.5699 - accuracy: 0.2189 - val_loss: 35.5195 - val_accuracy: 0.2222\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.5189 - accuracy: 0.2040 - val_loss: 35.4689 - val_accuracy: 0.2000\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4684 - accuracy: 0.1716 - val_loss: 35.4173 - val_accuracy: 0.1778\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.4171 - accuracy: 0.1468 - val_loss: 35.3667 - val_accuracy: 0.1778\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.3666 - accuracy: 0.1493 - val_loss: 35.3175 - val_accuracy: 0.2000\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.3163 - accuracy: 0.1791 - val_loss: 35.2683 - val_accuracy: 0.1556\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.2662 - accuracy: 0.1866 - val_loss: 35.2184 - val_accuracy: 0.2222\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.2148 - accuracy: 0.2114 - val_loss: 35.1669 - val_accuracy: 0.1778\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.1640 - accuracy: 0.1667 - val_loss: 35.1162 - val_accuracy: 0.1778\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1142 - accuracy: 0.1542 - val_loss: 35.0659 - val_accuracy: 0.1778\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.0654 - accuracy: 0.1468 - val_loss: 35.0140 - val_accuracy: 0.1778\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0149 - accuracy: 0.1468 - val_loss: 34.9630 - val_accuracy: 0.1778\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.9646 - accuracy: 0.1468 - val_loss: 34.9126 - val_accuracy: 0.1778\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9136 - accuracy: 0.1667 - val_loss: 34.8636 - val_accuracy: 0.2000\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8633 - accuracy: 0.1766 - val_loss: 34.8143 - val_accuracy: 0.2000\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.8145 - accuracy: 0.1741 - val_loss: 34.7652 - val_accuracy: 0.2000\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.7638 - accuracy: 0.1692 - val_loss: 34.7127 - val_accuracy: 0.1778\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.7134 - accuracy: 0.1617 - val_loss: 34.6620 - val_accuracy: 0.1778\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6640 - accuracy: 0.1468 - val_loss: 34.6130 - val_accuracy: 0.1778\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.6143 - accuracy: 0.1592 - val_loss: 34.5631 - val_accuracy: 0.1778\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.5645 - accuracy: 0.2065 - val_loss: 34.5149 - val_accuracy: 0.2000\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.5143 - accuracy: 0.1915 - val_loss: 34.4672 - val_accuracy: 0.1333\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.4648 - accuracy: 0.1692 - val_loss: 34.4173 - val_accuracy: 0.1778\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.4145 - accuracy: 0.1866 - val_loss: 34.3682 - val_accuracy: 0.2000\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.3646 - accuracy: 0.2363 - val_loss: 34.3174 - val_accuracy: 0.2000\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.3153 - accuracy: 0.2512 - val_loss: 34.2686 - val_accuracy: 0.1556\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.2656 - accuracy: 0.2438 - val_loss: 34.2199 - val_accuracy: 0.1556\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.2160 - accuracy: 0.1891 - val_loss: 34.1691 - val_accuracy: 0.1333\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1664 - accuracy: 0.1692 - val_loss: 34.1196 - val_accuracy: 0.1333\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.1170 - accuracy: 0.1692 - val_loss: 34.0703 - val_accuracy: 0.1333\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34.0682 - accuracy: 0.1567 - val_loss: 34.0199 - val_accuracy: 0.1556\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0183 - accuracy: 0.1642 - val_loss: 33.9699 - val_accuracy: 0.1333\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.9693 - accuracy: 0.1642 - val_loss: 33.9204 - val_accuracy: 0.1333\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.9200 - accuracy: 0.1816 - val_loss: 33.8716 - val_accuracy: 0.1556\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.8703 - accuracy: 0.1617 - val_loss: 33.8236 - val_accuracy: 0.2222\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.8213 - accuracy: 0.1716 - val_loss: 33.7757 - val_accuracy: 0.1778\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.7729 - accuracy: 0.1468 - val_loss: 33.7276 - val_accuracy: 0.1778\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7243 - accuracy: 0.1468 - val_loss: 33.6792 - val_accuracy: 0.1778\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.6751 - accuracy: 0.1468 - val_loss: 33.6304 - val_accuracy: 0.1778\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.6268 - accuracy: 0.1517 - val_loss: 33.5809 - val_accuracy: 0.1778\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5775 - accuracy: 0.1692 - val_loss: 33.5327 - val_accuracy: 0.1778\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5289 - accuracy: 0.1642 - val_loss: 33.4833 - val_accuracy: 0.1778\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.4800 - accuracy: 0.1716 - val_loss: 33.4338 - val_accuracy: 0.2000\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.4308 - accuracy: 0.2065 - val_loss: 33.3841 - val_accuracy: 0.2222\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3816 - accuracy: 0.1766 - val_loss: 33.3349 - val_accuracy: 0.1556\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33.3335 - accuracy: 0.1617 - val_loss: 33.2857 - val_accuracy: 0.1556\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2850 - accuracy: 0.1692 - val_loss: 33.2374 - val_accuracy: 0.2000\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.2360 - accuracy: 0.2040 - val_loss: 33.1884 - val_accuracy: 0.1778\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.1875 - accuracy: 0.2463 - val_loss: 33.1402 - val_accuracy: 0.2000\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.1395 - accuracy: 0.2637 - val_loss: 33.0921 - val_accuracy: 0.2000\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.0914 - accuracy: 0.2463 - val_loss: 33.0435 - val_accuracy: 0.1778\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.0421 - accuracy: 0.2189 - val_loss: 32.9943 - val_accuracy: 0.1556\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.9944 - accuracy: 0.2363 - val_loss: 32.9461 - val_accuracy: 0.2222\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.9460 - accuracy: 0.2438 - val_loss: 32.8966 - val_accuracy: 0.1778\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8980 - accuracy: 0.1542 - val_loss: 32.8477 - val_accuracy: 0.1778\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.8491 - accuracy: 0.1468 - val_loss: 32.8009 - val_accuracy: 0.1778\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.8008 - accuracy: 0.1468 - val_loss: 32.7542 - val_accuracy: 0.1778\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.7526 - accuracy: 0.1468 - val_loss: 32.7080 - val_accuracy: 0.1778\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.7048 - accuracy: 0.1567 - val_loss: 32.6628 - val_accuracy: 0.2000\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.6565 - accuracy: 0.1766 - val_loss: 32.6150 - val_accuracy: 0.1778\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.6082 - accuracy: 0.1965 - val_loss: 32.5667 - val_accuracy: 0.1778\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.5605 - accuracy: 0.2139 - val_loss: 32.5189 - val_accuracy: 0.1778\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.5127 - accuracy: 0.2289 - val_loss: 32.4693 - val_accuracy: 0.1778\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.4641 - accuracy: 0.1841 - val_loss: 32.4187 - val_accuracy: 0.1556\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.4173 - accuracy: 0.1617 - val_loss: 32.3692 - val_accuracy: 0.1556\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.3691 - accuracy: 0.1617 - val_loss: 32.3215 - val_accuracy: 0.1556\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.3212 - accuracy: 0.1617 - val_loss: 32.2763 - val_accuracy: 0.1556\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.2740 - accuracy: 0.2040 - val_loss: 32.2312 - val_accuracy: 0.1778\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2267 - accuracy: 0.2214 - val_loss: 32.1843 - val_accuracy: 0.1778\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.1799 - accuracy: 0.1791 - val_loss: 32.1375 - val_accuracy: 0.1556\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.1319 - accuracy: 0.1642 - val_loss: 32.0883 - val_accuracy: 0.1556\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0835 - accuracy: 0.2040 - val_loss: 32.0401 - val_accuracy: 0.2000\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0366 - accuracy: 0.1915 - val_loss: 31.9917 - val_accuracy: 0.1778\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.9892 - accuracy: 0.1493 - val_loss: 31.9445 - val_accuracy: 0.1778\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31.9420 - accuracy: 0.1841 - val_loss: 31.8991 - val_accuracy: 0.2000\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.8940 - accuracy: 0.1841 - val_loss: 31.8502 - val_accuracy: 0.1778\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.8467 - accuracy: 0.1617 - val_loss: 31.8020 - val_accuracy: 0.2222\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.7996 - accuracy: 0.1741 - val_loss: 31.7539 - val_accuracy: 0.2000\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.7524 - accuracy: 0.1692 - val_loss: 31.7075 - val_accuracy: 0.2000\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.7049 - accuracy: 0.1990 - val_loss: 31.6612 - val_accuracy: 0.2222\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.6582 - accuracy: 0.1940 - val_loss: 31.6151 - val_accuracy: 0.1333\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.6111 - accuracy: 0.1915 - val_loss: 31.5671 - val_accuracy: 0.1333\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.5641 - accuracy: 0.1965 - val_loss: 31.5178 - val_accuracy: 0.1333\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.5171 - accuracy: 0.1965 - val_loss: 31.4694 - val_accuracy: 0.2000\n",
      "========== Fold 9 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 207.7313 - accuracy: 0.0771 - val_loss: 196.6007 - val_accuracy: 0.1333\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 190.4602 - accuracy: 0.1617 - val_loss: 177.9466 - val_accuracy: 0.0444\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 172.3946 - accuracy: 0.1592 - val_loss: 161.7235 - val_accuracy: 0.0444\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 157.2450 - accuracy: 0.1468 - val_loss: 148.8019 - val_accuracy: 0.0667\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 145.3187 - accuracy: 0.1468 - val_loss: 138.7884 - val_accuracy: 0.0667\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 136.0970 - accuracy: 0.1468 - val_loss: 131.0652 - val_accuracy: 0.0889\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 128.9624 - accuracy: 0.1443 - val_loss: 125.0643 - val_accuracy: 0.0444\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 123.3827 - accuracy: 0.1517 - val_loss: 120.3303 - val_accuracy: 0.0889\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 118.9608 - accuracy: 0.1468 - val_loss: 116.5270 - val_accuracy: 0.0667\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 115.3983 - accuracy: 0.1592 - val_loss: 113.4104 - val_accuracy: 0.1556\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 112.4905 - accuracy: 0.1617 - val_loss: 110.8416 - val_accuracy: 0.0444\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 110.0740 - accuracy: 0.1617 - val_loss: 108.7062 - val_accuracy: 0.0444\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 108.0481 - accuracy: 0.1617 - val_loss: 106.8999 - val_accuracy: 0.0444\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 106.3260 - accuracy: 0.1617 - val_loss: 105.3507 - val_accuracy: 0.0444\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104.8407 - accuracy: 0.1617 - val_loss: 104.0010 - val_accuracy: 0.0444\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 103.5489 - accuracy: 0.1716 - val_loss: 102.8209 - val_accuracy: 0.1556\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102.4150 - accuracy: 0.1617 - val_loss: 101.7785 - val_accuracy: 0.1556\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 101.4105 - accuracy: 0.1617 - val_loss: 100.8458 - val_accuracy: 0.1556\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 100.5089 - accuracy: 0.1716 - val_loss: 100.0139 - val_accuracy: 0.0444\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 99.7033 - accuracy: 0.1617 - val_loss: 99.2600 - val_accuracy: 0.0444\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 98.9732 - accuracy: 0.1617 - val_loss: 98.5744 - val_accuracy: 0.0444\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 98.3026 - accuracy: 0.1567 - val_loss: 97.9329 - val_accuracy: 0.1556\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 97.6872 - accuracy: 0.1617 - val_loss: 97.3615 - val_accuracy: 0.1556\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 97.1225 - accuracy: 0.1617 - val_loss: 96.8334 - val_accuracy: 0.0444\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 96.5981 - accuracy: 0.1617 - val_loss: 96.3511 - val_accuracy: 0.0444\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96.1113 - accuracy: 0.1617 - val_loss: 95.8923 - val_accuracy: 0.0444\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.6576 - accuracy: 0.1617 - val_loss: 95.4450 - val_accuracy: 0.0444\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95.2259 - accuracy: 0.1642 - val_loss: 95.0182 - val_accuracy: 0.1556\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 94.8200 - accuracy: 0.1617 - val_loss: 94.6299 - val_accuracy: 0.1556\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 94.4406 - accuracy: 0.1567 - val_loss: 94.2697 - val_accuracy: 0.0444\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94.0773 - accuracy: 0.1617 - val_loss: 93.9162 - val_accuracy: 0.0444\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93.7305 - accuracy: 0.1617 - val_loss: 93.5813 - val_accuracy: 0.0444\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.4028 - accuracy: 0.1493 - val_loss: 93.2551 - val_accuracy: 0.0444\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93.0826 - accuracy: 0.1667 - val_loss: 92.9370 - val_accuracy: 0.0444\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 92.7783 - accuracy: 0.1692 - val_loss: 92.6419 - val_accuracy: 0.1333\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92.4855 - accuracy: 0.1617 - val_loss: 92.3593 - val_accuracy: 0.0444\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92.2033 - accuracy: 0.1642 - val_loss: 92.0885 - val_accuracy: 0.0444\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 91.9313 - accuracy: 0.1617 - val_loss: 91.8264 - val_accuracy: 0.0444\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91.6684 - accuracy: 0.1617 - val_loss: 91.5768 - val_accuracy: 0.0444\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91.4159 - accuracy: 0.1617 - val_loss: 91.3277 - val_accuracy: 0.0444\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91.1678 - accuracy: 0.1741 - val_loss: 91.0815 - val_accuracy: 0.1333\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.9252 - accuracy: 0.1791 - val_loss: 90.8373 - val_accuracy: 0.1333\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.6895 - accuracy: 0.1791 - val_loss: 90.5990 - val_accuracy: 0.0444\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90.4596 - accuracy: 0.1692 - val_loss: 90.3637 - val_accuracy: 0.0444\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 90.2354 - accuracy: 0.1617 - val_loss: 90.1419 - val_accuracy: 0.0444\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90.0170 - accuracy: 0.1443 - val_loss: 89.9307 - val_accuracy: 0.0444\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.8031 - accuracy: 0.1617 - val_loss: 89.7236 - val_accuracy: 0.0444\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89.5919 - accuracy: 0.1617 - val_loss: 89.5133 - val_accuracy: 0.0444\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89.3865 - accuracy: 0.1617 - val_loss: 89.3056 - val_accuracy: 0.0444\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89.1845 - accuracy: 0.1617 - val_loss: 89.1035 - val_accuracy: 0.0889\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.9851 - accuracy: 0.1617 - val_loss: 88.8959 - val_accuracy: 0.0667\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88.7896 - accuracy: 0.1517 - val_loss: 88.7065 - val_accuracy: 0.1556\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.5963 - accuracy: 0.1791 - val_loss: 88.5274 - val_accuracy: 0.0444\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.4079 - accuracy: 0.1617 - val_loss: 88.3457 - val_accuracy: 0.0444\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.2207 - accuracy: 0.1617 - val_loss: 88.1705 - val_accuracy: 0.0444\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 88.0370 - accuracy: 0.1617 - val_loss: 87.9883 - val_accuracy: 0.0444\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.8540 - accuracy: 0.1617 - val_loss: 87.8104 - val_accuracy: 0.0444\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87.6757 - accuracy: 0.1567 - val_loss: 87.6307 - val_accuracy: 0.0444\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 87.4993 - accuracy: 0.1493 - val_loss: 87.4529 - val_accuracy: 0.0444\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87.3242 - accuracy: 0.1617 - val_loss: 87.2735 - val_accuracy: 0.0444\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87.1505 - accuracy: 0.1617 - val_loss: 87.0981 - val_accuracy: 0.0444\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.9803 - accuracy: 0.1617 - val_loss: 86.9277 - val_accuracy: 0.0444\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.8111 - accuracy: 0.1692 - val_loss: 86.7583 - val_accuracy: 0.0444\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.6441 - accuracy: 0.1766 - val_loss: 86.5931 - val_accuracy: 0.0444\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86.4798 - accuracy: 0.1567 - val_loss: 86.4341 - val_accuracy: 0.0444\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 86.3161 - accuracy: 0.1617 - val_loss: 86.2738 - val_accuracy: 0.0444\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 86.1534 - accuracy: 0.1617 - val_loss: 86.1129 - val_accuracy: 0.0444\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.9928 - accuracy: 0.1617 - val_loss: 85.9494 - val_accuracy: 0.0444\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.8342 - accuracy: 0.1617 - val_loss: 85.7894 - val_accuracy: 0.0444\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85.6760 - accuracy: 0.1716 - val_loss: 85.6313 - val_accuracy: 0.1111\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85.5189 - accuracy: 0.1716 - val_loss: 85.4842 - val_accuracy: 0.0444\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.3655 - accuracy: 0.1617 - val_loss: 85.3428 - val_accuracy: 0.0444\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 85.2124 - accuracy: 0.1617 - val_loss: 85.1901 - val_accuracy: 0.0444\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85.0593 - accuracy: 0.1617 - val_loss: 85.0326 - val_accuracy: 0.0444\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.9071 - accuracy: 0.1617 - val_loss: 84.8755 - val_accuracy: 0.0444\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84.7577 - accuracy: 0.1617 - val_loss: 84.7295 - val_accuracy: 0.0444\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.6088 - accuracy: 0.1617 - val_loss: 84.5818 - val_accuracy: 0.0444\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.4613 - accuracy: 0.1617 - val_loss: 84.4351 - val_accuracy: 0.0444\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.3138 - accuracy: 0.1617 - val_loss: 84.2931 - val_accuracy: 0.0444\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84.1682 - accuracy: 0.1617 - val_loss: 84.1460 - val_accuracy: 0.0444\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84.0243 - accuracy: 0.1617 - val_loss: 83.9973 - val_accuracy: 0.0444\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.8801 - accuracy: 0.1816 - val_loss: 83.8466 - val_accuracy: 0.1556\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.7386 - accuracy: 0.1617 - val_loss: 83.7069 - val_accuracy: 0.1556\n",
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83.5976 - accuracy: 0.1617 - val_loss: 83.5686 - val_accuracy: 0.1333\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83.4551 - accuracy: 0.1716 - val_loss: 83.4278 - val_accuracy: 0.0444\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.3146 - accuracy: 0.1766 - val_loss: 83.2845 - val_accuracy: 0.0444\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 83.1738 - accuracy: 0.1617 - val_loss: 83.1445 - val_accuracy: 0.0444\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83.0368 - accuracy: 0.1617 - val_loss: 83.0051 - val_accuracy: 0.0444\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.9005 - accuracy: 0.1617 - val_loss: 82.8675 - val_accuracy: 0.0444\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.7631 - accuracy: 0.1617 - val_loss: 82.7338 - val_accuracy: 0.0444\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82.6259 - accuracy: 0.1617 - val_loss: 82.6076 - val_accuracy: 0.0444\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.4914 - accuracy: 0.1617 - val_loss: 82.4792 - val_accuracy: 0.0444\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.3581 - accuracy: 0.1716 - val_loss: 82.3545 - val_accuracy: 0.0444\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.2245 - accuracy: 0.1766 - val_loss: 82.2161 - val_accuracy: 0.0444\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82.0900 - accuracy: 0.1667 - val_loss: 82.0769 - val_accuracy: 0.0444\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.9579 - accuracy: 0.1617 - val_loss: 81.9385 - val_accuracy: 0.0444\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.8261 - accuracy: 0.1617 - val_loss: 81.8061 - val_accuracy: 0.0444\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81.6957 - accuracy: 0.1642 - val_loss: 81.6754 - val_accuracy: 0.0444\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81.5649 - accuracy: 0.1617 - val_loss: 81.5499 - val_accuracy: 0.0444\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.4356 - accuracy: 0.1617 - val_loss: 81.4222 - val_accuracy: 0.0444\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.3054 - accuracy: 0.1617 - val_loss: 81.2898 - val_accuracy: 0.0444\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81.1768 - accuracy: 0.1716 - val_loss: 81.1579 - val_accuracy: 0.1556\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 81.0503 - accuracy: 0.1617 - val_loss: 81.0293 - val_accuracy: 0.1556\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.9243 - accuracy: 0.1617 - val_loss: 80.9005 - val_accuracy: 0.1556\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.7963 - accuracy: 0.1617 - val_loss: 80.7708 - val_accuracy: 0.1333\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.6693 - accuracy: 0.1741 - val_loss: 80.6478 - val_accuracy: 0.0444\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80.5446 - accuracy: 0.1617 - val_loss: 80.5250 - val_accuracy: 0.0444\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80.4199 - accuracy: 0.1617 - val_loss: 80.4043 - val_accuracy: 0.0444\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 80.2961 - accuracy: 0.1617 - val_loss: 80.2792 - val_accuracy: 0.0444\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80.1739 - accuracy: 0.1617 - val_loss: 80.1567 - val_accuracy: 0.0444\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80.0488 - accuracy: 0.1617 - val_loss: 80.0360 - val_accuracy: 0.0444\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79.9262 - accuracy: 0.1617 - val_loss: 79.9097 - val_accuracy: 0.0444\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.8033 - accuracy: 0.1617 - val_loss: 79.7794 - val_accuracy: 0.0444\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.6815 - accuracy: 0.1617 - val_loss: 79.6541 - val_accuracy: 0.0444\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.5603 - accuracy: 0.1617 - val_loss: 79.5425 - val_accuracy: 0.0444\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79.4397 - accuracy: 0.1617 - val_loss: 79.4327 - val_accuracy: 0.0444\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.3191 - accuracy: 0.1617 - val_loss: 79.3161 - val_accuracy: 0.0444\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79.2003 - accuracy: 0.1617 - val_loss: 79.2016 - val_accuracy: 0.0444\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 79.0806 - accuracy: 0.1617 - val_loss: 79.0814 - val_accuracy: 0.0444\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.9617 - accuracy: 0.1617 - val_loss: 78.9550 - val_accuracy: 0.0444\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.8435 - accuracy: 0.1617 - val_loss: 78.8335 - val_accuracy: 0.0444\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78.7249 - accuracy: 0.1617 - val_loss: 78.7173 - val_accuracy: 0.0444\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.6078 - accuracy: 0.1617 - val_loss: 78.6011 - val_accuracy: 0.0444\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.4916 - accuracy: 0.1617 - val_loss: 78.4869 - val_accuracy: 0.0444\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.3746 - accuracy: 0.1617 - val_loss: 78.3656 - val_accuracy: 0.0444\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.2589 - accuracy: 0.1617 - val_loss: 78.2469 - val_accuracy: 0.0444\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78.1424 - accuracy: 0.1617 - val_loss: 78.1340 - val_accuracy: 0.0444\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78.0269 - accuracy: 0.1617 - val_loss: 78.0212 - val_accuracy: 0.0444\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77.9129 - accuracy: 0.1617 - val_loss: 77.9118 - val_accuracy: 0.0444\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.8006 - accuracy: 0.1617 - val_loss: 77.7963 - val_accuracy: 0.0444\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.6850 - accuracy: 0.1617 - val_loss: 77.6848 - val_accuracy: 0.0444\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.5697 - accuracy: 0.1617 - val_loss: 77.5746 - val_accuracy: 0.0444\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77.4569 - accuracy: 0.1617 - val_loss: 77.4634 - val_accuracy: 0.0444\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.3444 - accuracy: 0.1617 - val_loss: 77.3549 - val_accuracy: 0.0444\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.2322 - accuracy: 0.1617 - val_loss: 77.2384 - val_accuracy: 0.0444\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77.1195 - accuracy: 0.1617 - val_loss: 77.1178 - val_accuracy: 0.0444\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 77.0070 - accuracy: 0.1617 - val_loss: 77.0044 - val_accuracy: 0.0444\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.8950 - accuracy: 0.1617 - val_loss: 76.8999 - val_accuracy: 0.0444\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.7842 - accuracy: 0.1617 - val_loss: 76.7953 - val_accuracy: 0.0444\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.6747 - accuracy: 0.1617 - val_loss: 76.6974 - val_accuracy: 0.0444\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76.5650 - accuracy: 0.1617 - val_loss: 76.5955 - val_accuracy: 0.0444\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76.4564 - accuracy: 0.1667 - val_loss: 76.4852 - val_accuracy: 0.0444\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76.3460 - accuracy: 0.1766 - val_loss: 76.3647 - val_accuracy: 0.0444\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76.2358 - accuracy: 0.1617 - val_loss: 76.2411 - val_accuracy: 0.0444\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.1267 - accuracy: 0.1617 - val_loss: 76.1243 - val_accuracy: 0.0444\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76.0170 - accuracy: 0.1617 - val_loss: 76.0094 - val_accuracy: 0.0444\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.9086 - accuracy: 0.1617 - val_loss: 75.9025 - val_accuracy: 0.0444\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.8009 - accuracy: 0.1617 - val_loss: 75.7992 - val_accuracy: 0.0444\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75.6931 - accuracy: 0.1617 - val_loss: 75.6918 - val_accuracy: 0.0444\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.5849 - accuracy: 0.1617 - val_loss: 75.5915 - val_accuracy: 0.0444\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.4784 - accuracy: 0.1617 - val_loss: 75.4912 - val_accuracy: 0.0444\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75.3716 - accuracy: 0.1617 - val_loss: 75.3881 - val_accuracy: 0.0444\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75.2660 - accuracy: 0.1617 - val_loss: 75.2836 - val_accuracy: 0.0444\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75.1612 - accuracy: 0.1617 - val_loss: 75.1766 - val_accuracy: 0.0444\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75.0545 - accuracy: 0.1617 - val_loss: 75.0651 - val_accuracy: 0.0444\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74.9491 - accuracy: 0.1617 - val_loss: 74.9483 - val_accuracy: 0.0444\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.8433 - accuracy: 0.1617 - val_loss: 74.8394 - val_accuracy: 0.0444\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.7386 - accuracy: 0.1816 - val_loss: 74.7310 - val_accuracy: 0.0444\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.6349 - accuracy: 0.1642 - val_loss: 74.6255 - val_accuracy: 0.0444\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.5306 - accuracy: 0.1617 - val_loss: 74.5219 - val_accuracy: 0.0444\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.4267 - accuracy: 0.1617 - val_loss: 74.4150 - val_accuracy: 0.0444\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.3224 - accuracy: 0.1617 - val_loss: 74.3152 - val_accuracy: 0.0444\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74.2188 - accuracy: 0.1617 - val_loss: 74.2130 - val_accuracy: 0.0444\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 74.1178 - accuracy: 0.1617 - val_loss: 74.1056 - val_accuracy: 0.0444\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74.0130 - accuracy: 0.1617 - val_loss: 74.0037 - val_accuracy: 0.0444\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.9099 - accuracy: 0.1617 - val_loss: 73.9060 - val_accuracy: 0.0444\n",
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.8074 - accuracy: 0.1617 - val_loss: 73.8080 - val_accuracy: 0.0444\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.7055 - accuracy: 0.1617 - val_loss: 73.7096 - val_accuracy: 0.0444\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73.6037 - accuracy: 0.1617 - val_loss: 73.6082 - val_accuracy: 0.0444\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73.5040 - accuracy: 0.1617 - val_loss: 73.5051 - val_accuracy: 0.0444\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.4042 - accuracy: 0.1667 - val_loss: 73.4037 - val_accuracy: 0.0444\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 73.3024 - accuracy: 0.1741 - val_loss: 73.2958 - val_accuracy: 0.0444\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.2000 - accuracy: 0.1617 - val_loss: 73.1904 - val_accuracy: 0.0444\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73.0988 - accuracy: 0.1617 - val_loss: 73.0957 - val_accuracy: 0.0444\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.9989 - accuracy: 0.1617 - val_loss: 72.9999 - val_accuracy: 0.0444\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.8997 - accuracy: 0.1617 - val_loss: 72.9038 - val_accuracy: 0.0444\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 72.7990 - accuracy: 0.1617 - val_loss: 72.8054 - val_accuracy: 0.0444\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72.6993 - accuracy: 0.1617 - val_loss: 72.7015 - val_accuracy: 0.0444\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.6007 - accuracy: 0.1617 - val_loss: 72.5974 - val_accuracy: 0.0444\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.5012 - accuracy: 0.1617 - val_loss: 72.5003 - val_accuracy: 0.0444\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 72.4020 - accuracy: 0.1716 - val_loss: 72.4055 - val_accuracy: 0.1111\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 72.3035 - accuracy: 0.1766 - val_loss: 72.3065 - val_accuracy: 0.0444\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.2057 - accuracy: 0.1667 - val_loss: 72.2157 - val_accuracy: 0.0444\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.1084 - accuracy: 0.1617 - val_loss: 72.1258 - val_accuracy: 0.0444\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72.0116 - accuracy: 0.1617 - val_loss: 72.0369 - val_accuracy: 0.0444\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.9130 - accuracy: 0.1617 - val_loss: 71.9424 - val_accuracy: 0.0444\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.8153 - accuracy: 0.1617 - val_loss: 71.8415 - val_accuracy: 0.0444\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71.7186 - accuracy: 0.1617 - val_loss: 71.7379 - val_accuracy: 0.0444\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.6205 - accuracy: 0.1617 - val_loss: 71.6353 - val_accuracy: 0.0444\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71.5246 - accuracy: 0.1617 - val_loss: 71.5400 - val_accuracy: 0.0444\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.4276 - accuracy: 0.1617 - val_loss: 71.4375 - val_accuracy: 0.0444\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.3320 - accuracy: 0.1617 - val_loss: 71.3394 - val_accuracy: 0.0444\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.2354 - accuracy: 0.1617 - val_loss: 71.2424 - val_accuracy: 0.0444\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71.1399 - accuracy: 0.1617 - val_loss: 71.1416 - val_accuracy: 0.0444\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71.0439 - accuracy: 0.1791 - val_loss: 71.0539 - val_accuracy: 0.1333\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70.9490 - accuracy: 0.1816 - val_loss: 70.9624 - val_accuracy: 0.0444\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70.8533 - accuracy: 0.1642 - val_loss: 70.8680 - val_accuracy: 0.0444\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.7593 - accuracy: 0.1617 - val_loss: 70.7768 - val_accuracy: 0.0444\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70.6643 - accuracy: 0.1617 - val_loss: 70.6852 - val_accuracy: 0.0444\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.5699 - accuracy: 0.1617 - val_loss: 70.5831 - val_accuracy: 0.0444\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70.4754 - accuracy: 0.1617 - val_loss: 70.4872 - val_accuracy: 0.0444\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.3812 - accuracy: 0.1617 - val_loss: 70.3869 - val_accuracy: 0.0444\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.2878 - accuracy: 0.1617 - val_loss: 70.2907 - val_accuracy: 0.0444\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70.1926 - accuracy: 0.1617 - val_loss: 70.1965 - val_accuracy: 0.0444\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.0989 - accuracy: 0.1617 - val_loss: 70.1061 - val_accuracy: 0.0444\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.0063 - accuracy: 0.1716 - val_loss: 70.0157 - val_accuracy: 0.0444\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.9139 - accuracy: 0.1667 - val_loss: 69.9288 - val_accuracy: 0.0444\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69.8210 - accuracy: 0.1692 - val_loss: 69.8394 - val_accuracy: 0.0444\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69.7290 - accuracy: 0.1766 - val_loss: 69.7514 - val_accuracy: 0.0444\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69.6373 - accuracy: 0.1617 - val_loss: 69.6600 - val_accuracy: 0.0444\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.5420 - accuracy: 0.1617 - val_loss: 69.5628 - val_accuracy: 0.0444\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.4493 - accuracy: 0.1617 - val_loss: 69.4696 - val_accuracy: 0.0444\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.3572 - accuracy: 0.1617 - val_loss: 69.3797 - val_accuracy: 0.0444\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.2656 - accuracy: 0.1617 - val_loss: 69.2864 - val_accuracy: 0.0444\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69.1737 - accuracy: 0.1617 - val_loss: 69.1891 - val_accuracy: 0.0444\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69.0824 - accuracy: 0.1617 - val_loss: 69.0892 - val_accuracy: 0.0444\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.9913 - accuracy: 0.1617 - val_loss: 68.9956 - val_accuracy: 0.0444\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.9003 - accuracy: 0.1617 - val_loss: 68.9049 - val_accuracy: 0.0444\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.8095 - accuracy: 0.1617 - val_loss: 68.8206 - val_accuracy: 0.0444\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.7192 - accuracy: 0.1617 - val_loss: 68.7345 - val_accuracy: 0.0444\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.6297 - accuracy: 0.1617 - val_loss: 68.6451 - val_accuracy: 0.0444\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.5375 - accuracy: 0.1617 - val_loss: 68.5518 - val_accuracy: 0.0444\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.4468 - accuracy: 0.1617 - val_loss: 68.4592 - val_accuracy: 0.0444\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.3574 - accuracy: 0.1642 - val_loss: 68.3687 - val_accuracy: 0.0444\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68.2679 - accuracy: 0.1766 - val_loss: 68.2754 - val_accuracy: 0.0444\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68.1794 - accuracy: 0.1617 - val_loss: 68.1902 - val_accuracy: 0.0444\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68.0900 - accuracy: 0.1617 - val_loss: 68.1019 - val_accuracy: 0.0444\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.9991 - accuracy: 0.1617 - val_loss: 68.0144 - val_accuracy: 0.0444\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.9103 - accuracy: 0.1617 - val_loss: 67.9234 - val_accuracy: 0.0444\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.8223 - accuracy: 0.1617 - val_loss: 67.8325 - val_accuracy: 0.0444\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67.7335 - accuracy: 0.1617 - val_loss: 67.7426 - val_accuracy: 0.0444\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67.6440 - accuracy: 0.1617 - val_loss: 67.6538 - val_accuracy: 0.0444\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.5561 - accuracy: 0.1617 - val_loss: 67.5654 - val_accuracy: 0.0444\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.4677 - accuracy: 0.1617 - val_loss: 67.4741 - val_accuracy: 0.0444\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.3798 - accuracy: 0.1617 - val_loss: 67.3891 - val_accuracy: 0.0444\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.2901 - accuracy: 0.1617 - val_loss: 67.3049 - val_accuracy: 0.0444\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67.2022 - accuracy: 0.1617 - val_loss: 67.2235 - val_accuracy: 0.0444\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 67.1159 - accuracy: 0.1617 - val_loss: 67.1397 - val_accuracy: 0.0444\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67.0282 - accuracy: 0.1617 - val_loss: 67.0489 - val_accuracy: 0.0444\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.9407 - accuracy: 0.1617 - val_loss: 66.9614 - val_accuracy: 0.0444\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.8528 - accuracy: 0.1617 - val_loss: 66.8773 - val_accuracy: 0.0444\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.7660 - accuracy: 0.1617 - val_loss: 66.7872 - val_accuracy: 0.0444\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.6785 - accuracy: 0.1617 - val_loss: 66.6956 - val_accuracy: 0.0444\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.5938 - accuracy: 0.1617 - val_loss: 66.6053 - val_accuracy: 0.0444\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.5064 - accuracy: 0.1617 - val_loss: 66.5222 - val_accuracy: 0.0444\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.4211 - accuracy: 0.1692 - val_loss: 66.4391 - val_accuracy: 0.0444\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.3344 - accuracy: 0.1692 - val_loss: 66.3507 - val_accuracy: 0.0444\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66.2475 - accuracy: 0.1617 - val_loss: 66.2693 - val_accuracy: 0.0444\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66.1609 - accuracy: 0.1617 - val_loss: 66.1846 - val_accuracy: 0.0444\n",
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66.0748 - accuracy: 0.1617 - val_loss: 66.0949 - val_accuracy: 0.0444\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.9890 - accuracy: 0.1617 - val_loss: 66.0080 - val_accuracy: 0.0444\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.9039 - accuracy: 0.1617 - val_loss: 65.9214 - val_accuracy: 0.0444\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.8182 - accuracy: 0.1617 - val_loss: 65.8365 - val_accuracy: 0.0444\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65.7333 - accuracy: 0.1667 - val_loss: 65.7507 - val_accuracy: 0.0444\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65.6489 - accuracy: 0.1617 - val_loss: 65.6708 - val_accuracy: 0.0444\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.5642 - accuracy: 0.1617 - val_loss: 65.5839 - val_accuracy: 0.0444\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.4794 - accuracy: 0.1617 - val_loss: 65.4928 - val_accuracy: 0.0444\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3946 - accuracy: 0.1617 - val_loss: 65.3991 - val_accuracy: 0.0444\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 65.3096 - accuracy: 0.1617 - val_loss: 65.3140 - val_accuracy: 0.0444\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65.2251 - accuracy: 0.1617 - val_loss: 65.2311 - val_accuracy: 0.0444\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65.1405 - accuracy: 0.1617 - val_loss: 65.1547 - val_accuracy: 0.0444\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65.0563 - accuracy: 0.1617 - val_loss: 65.0806 - val_accuracy: 0.0444\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.9727 - accuracy: 0.1741 - val_loss: 65.0030 - val_accuracy: 0.0444\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.8896 - accuracy: 0.1642 - val_loss: 64.9223 - val_accuracy: 0.0444\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.8063 - accuracy: 0.1617 - val_loss: 64.8380 - val_accuracy: 0.0444\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.7226 - accuracy: 0.1617 - val_loss: 64.7524 - val_accuracy: 0.0444\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64.6399 - accuracy: 0.1841 - val_loss: 64.6678 - val_accuracy: 0.1333\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.5572 - accuracy: 0.1816 - val_loss: 64.5838 - val_accuracy: 0.0444\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64.4733 - accuracy: 0.1642 - val_loss: 64.5011 - val_accuracy: 0.0444\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.3887 - accuracy: 0.1617 - val_loss: 64.4155 - val_accuracy: 0.0444\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64.3063 - accuracy: 0.1617 - val_loss: 64.3228 - val_accuracy: 0.0444\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64.2236 - accuracy: 0.1692 - val_loss: 64.2355 - val_accuracy: 0.1333\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.1407 - accuracy: 0.1816 - val_loss: 64.1570 - val_accuracy: 0.1333\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64.0574 - accuracy: 0.1766 - val_loss: 64.0714 - val_accuracy: 0.1556\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.9752 - accuracy: 0.1667 - val_loss: 63.9879 - val_accuracy: 0.0444\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.8933 - accuracy: 0.1766 - val_loss: 63.9005 - val_accuracy: 0.0444\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.8108 - accuracy: 0.1617 - val_loss: 63.8167 - val_accuracy: 0.0444\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.7299 - accuracy: 0.1866 - val_loss: 63.7235 - val_accuracy: 0.2000\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63.6508 - accuracy: 0.1667 - val_loss: 63.6324 - val_accuracy: 0.2000\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.5691 - accuracy: 0.1816 - val_loss: 63.5521 - val_accuracy: 0.0889\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4866 - accuracy: 0.1617 - val_loss: 63.4723 - val_accuracy: 0.0444\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.4046 - accuracy: 0.1617 - val_loss: 63.3964 - val_accuracy: 0.0444\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.3215 - accuracy: 0.1617 - val_loss: 63.3225 - val_accuracy: 0.0444\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.2395 - accuracy: 0.1617 - val_loss: 63.2487 - val_accuracy: 0.0444\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 63.1597 - accuracy: 0.1617 - val_loss: 63.1750 - val_accuracy: 0.0444\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63.0780 - accuracy: 0.1617 - val_loss: 63.0979 - val_accuracy: 0.0444\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62.9965 - accuracy: 0.1617 - val_loss: 63.0191 - val_accuracy: 0.0444\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.9155 - accuracy: 0.1617 - val_loss: 62.9411 - val_accuracy: 0.0444\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.8366 - accuracy: 0.1617 - val_loss: 62.8628 - val_accuracy: 0.0444\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.7564 - accuracy: 0.1617 - val_loss: 62.7853 - val_accuracy: 0.0444\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.6758 - accuracy: 0.1617 - val_loss: 62.7049 - val_accuracy: 0.0444\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.5946 - accuracy: 0.1617 - val_loss: 62.6152 - val_accuracy: 0.0444\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.5141 - accuracy: 0.1617 - val_loss: 62.5317 - val_accuracy: 0.0444\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.4349 - accuracy: 0.1617 - val_loss: 62.4513 - val_accuracy: 0.0444\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.3552 - accuracy: 0.1617 - val_loss: 62.3797 - val_accuracy: 0.0444\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.2768 - accuracy: 0.1617 - val_loss: 62.3024 - val_accuracy: 0.1556\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1970 - accuracy: 0.1741 - val_loss: 62.2259 - val_accuracy: 0.0444\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62.1154 - accuracy: 0.1766 - val_loss: 62.1437 - val_accuracy: 0.0444\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62.0367 - accuracy: 0.1766 - val_loss: 62.0607 - val_accuracy: 0.0444\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.9574 - accuracy: 0.1692 - val_loss: 61.9827 - val_accuracy: 0.0444\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.8788 - accuracy: 0.1617 - val_loss: 61.9073 - val_accuracy: 0.0444\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.7986 - accuracy: 0.1617 - val_loss: 61.8245 - val_accuracy: 0.0444\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.7201 - accuracy: 0.1617 - val_loss: 61.7447 - val_accuracy: 0.0444\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.6416 - accuracy: 0.1617 - val_loss: 61.6654 - val_accuracy: 0.0444\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61.5624 - accuracy: 0.1617 - val_loss: 61.5885 - val_accuracy: 0.0444\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4839 - accuracy: 0.1617 - val_loss: 61.5119 - val_accuracy: 0.0444\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.4052 - accuracy: 0.1617 - val_loss: 61.4321 - val_accuracy: 0.0444\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.3274 - accuracy: 0.1617 - val_loss: 61.3475 - val_accuracy: 0.0444\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.2491 - accuracy: 0.1617 - val_loss: 61.2635 - val_accuracy: 0.0444\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61.1711 - accuracy: 0.1617 - val_loss: 61.1804 - val_accuracy: 0.0444\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0932 - accuracy: 0.1617 - val_loss: 61.0956 - val_accuracy: 0.0444\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61.0149 - accuracy: 0.1617 - val_loss: 61.0175 - val_accuracy: 0.0444\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.9370 - accuracy: 0.1617 - val_loss: 60.9484 - val_accuracy: 0.0444\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.8584 - accuracy: 0.1617 - val_loss: 60.8744 - val_accuracy: 0.0444\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60.7810 - accuracy: 0.1617 - val_loss: 60.7969 - val_accuracy: 0.0444\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.7032 - accuracy: 0.1617 - val_loss: 60.7145 - val_accuracy: 0.0444\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.6263 - accuracy: 0.1617 - val_loss: 60.6366 - val_accuracy: 0.0444\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.5493 - accuracy: 0.1617 - val_loss: 60.5546 - val_accuracy: 0.0444\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60.4726 - accuracy: 0.1841 - val_loss: 60.4775 - val_accuracy: 0.0889\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60.3952 - accuracy: 0.1816 - val_loss: 60.4046 - val_accuracy: 0.0444\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.3184 - accuracy: 0.1617 - val_loss: 60.3291 - val_accuracy: 0.0444\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.2404 - accuracy: 0.1617 - val_loss: 60.2538 - val_accuracy: 0.0444\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60.1640 - accuracy: 0.1741 - val_loss: 60.1784 - val_accuracy: 0.1111\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0879 - accuracy: 0.1816 - val_loss: 60.1017 - val_accuracy: 0.0444\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60.0117 - accuracy: 0.1816 - val_loss: 60.0214 - val_accuracy: 0.1333\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.9354 - accuracy: 0.1841 - val_loss: 59.9455 - val_accuracy: 0.0444\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.8579 - accuracy: 0.1617 - val_loss: 59.8743 - val_accuracy: 0.0444\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.7822 - accuracy: 0.1617 - val_loss: 59.7995 - val_accuracy: 0.0444\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.7058 - accuracy: 0.1716 - val_loss: 59.7207 - val_accuracy: 0.1111\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.6298 - accuracy: 0.1816 - val_loss: 59.6430 - val_accuracy: 0.1111\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.5542 - accuracy: 0.1741 - val_loss: 59.5692 - val_accuracy: 0.0444\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.4777 - accuracy: 0.1617 - val_loss: 59.4997 - val_accuracy: 0.0444\n",
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59.4048 - accuracy: 0.1716 - val_loss: 59.4331 - val_accuracy: 0.1556\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.3285 - accuracy: 0.1617 - val_loss: 59.3620 - val_accuracy: 0.0444\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.2521 - accuracy: 0.1741 - val_loss: 59.2937 - val_accuracy: 0.0444\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.1777 - accuracy: 0.1617 - val_loss: 59.2257 - val_accuracy: 0.0444\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 59.1021 - accuracy: 0.1617 - val_loss: 59.1518 - val_accuracy: 0.0444\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 59.0260 - accuracy: 0.1617 - val_loss: 59.0698 - val_accuracy: 0.0444\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 58.9512 - accuracy: 0.1617 - val_loss: 58.9870 - val_accuracy: 0.0444\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.8760 - accuracy: 0.1617 - val_loss: 58.9049 - val_accuracy: 0.0444\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.8004 - accuracy: 0.1617 - val_loss: 58.8272 - val_accuracy: 0.0444\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.7249 - accuracy: 0.1617 - val_loss: 58.7536 - val_accuracy: 0.0444\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.6501 - accuracy: 0.1617 - val_loss: 58.6772 - val_accuracy: 0.0444\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.5757 - accuracy: 0.1617 - val_loss: 58.6014 - val_accuracy: 0.0444\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58.5020 - accuracy: 0.1617 - val_loss: 58.5287 - val_accuracy: 0.0444\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.4268 - accuracy: 0.1617 - val_loss: 58.4524 - val_accuracy: 0.0444\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.3517 - accuracy: 0.1617 - val_loss: 58.3769 - val_accuracy: 0.0444\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.2782 - accuracy: 0.1617 - val_loss: 58.3034 - val_accuracy: 0.0444\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.2034 - accuracy: 0.1617 - val_loss: 58.2253 - val_accuracy: 0.0444\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58.1308 - accuracy: 0.1542 - val_loss: 58.1456 - val_accuracy: 0.0889\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58.0578 - accuracy: 0.1642 - val_loss: 58.0719 - val_accuracy: 0.0444\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.9838 - accuracy: 0.1617 - val_loss: 58.0035 - val_accuracy: 0.0444\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.9090 - accuracy: 0.1617 - val_loss: 57.9337 - val_accuracy: 0.0444\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.8346 - accuracy: 0.1617 - val_loss: 57.8665 - val_accuracy: 0.0444\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.7611 - accuracy: 0.1617 - val_loss: 57.7941 - val_accuracy: 0.0444\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.6883 - accuracy: 0.1617 - val_loss: 57.7243 - val_accuracy: 0.0444\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.6146 - accuracy: 0.1617 - val_loss: 57.6473 - val_accuracy: 0.0444\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.5402 - accuracy: 0.1617 - val_loss: 57.5709 - val_accuracy: 0.0444\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.4672 - accuracy: 0.1617 - val_loss: 57.4920 - val_accuracy: 0.0444\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.3940 - accuracy: 0.1617 - val_loss: 57.4140 - val_accuracy: 0.0444\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.3210 - accuracy: 0.1642 - val_loss: 57.3401 - val_accuracy: 0.0444\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57.2485 - accuracy: 0.1617 - val_loss: 57.2704 - val_accuracy: 0.0444\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57.1755 - accuracy: 0.1617 - val_loss: 57.2042 - val_accuracy: 0.0444\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.1024 - accuracy: 0.1617 - val_loss: 57.1339 - val_accuracy: 0.0444\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57.0302 - accuracy: 0.1617 - val_loss: 57.0638 - val_accuracy: 0.0444\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.9570 - accuracy: 0.1617 - val_loss: 56.9892 - val_accuracy: 0.0444\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.8843 - accuracy: 0.1617 - val_loss: 56.9116 - val_accuracy: 0.0444\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.8127 - accuracy: 0.1617 - val_loss: 56.8311 - val_accuracy: 0.0444\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.7403 - accuracy: 0.1617 - val_loss: 56.7603 - val_accuracy: 0.0444\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.6681 - accuracy: 0.1692 - val_loss: 56.6880 - val_accuracy: 0.0444\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.5952 - accuracy: 0.1716 - val_loss: 56.6198 - val_accuracy: 0.0444\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.5238 - accuracy: 0.1617 - val_loss: 56.5581 - val_accuracy: 0.0444\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.4519 - accuracy: 0.1617 - val_loss: 56.4859 - val_accuracy: 0.0444\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56.3801 - accuracy: 0.1617 - val_loss: 56.4105 - val_accuracy: 0.0444\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.3081 - accuracy: 0.1617 - val_loss: 56.3407 - val_accuracy: 0.0444\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.2363 - accuracy: 0.1816 - val_loss: 56.2705 - val_accuracy: 0.1333\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.1658 - accuracy: 0.1692 - val_loss: 56.1956 - val_accuracy: 0.1556\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.0940 - accuracy: 0.1617 - val_loss: 56.1245 - val_accuracy: 0.1556\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.0227 - accuracy: 0.1617 - val_loss: 56.0556 - val_accuracy: 0.1556\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.9505 - accuracy: 0.1716 - val_loss: 55.9855 - val_accuracy: 0.0444\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.8792 - accuracy: 0.1617 - val_loss: 55.9129 - val_accuracy: 0.0444\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.8081 - accuracy: 0.1617 - val_loss: 55.8344 - val_accuracy: 0.0444\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.7358 - accuracy: 0.1617 - val_loss: 55.7560 - val_accuracy: 0.0444\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.6651 - accuracy: 0.1617 - val_loss: 55.6803 - val_accuracy: 0.0444\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5944 - accuracy: 0.1617 - val_loss: 55.6101 - val_accuracy: 0.0444\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.5239 - accuracy: 0.1617 - val_loss: 55.5431 - val_accuracy: 0.0444\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55.4524 - accuracy: 0.1617 - val_loss: 55.4756 - val_accuracy: 0.0444\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55.3814 - accuracy: 0.1617 - val_loss: 55.4071 - val_accuracy: 0.0444\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.3125 - accuracy: 0.1617 - val_loss: 55.3383 - val_accuracy: 0.0444\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55.2414 - accuracy: 0.1617 - val_loss: 55.2684 - val_accuracy: 0.0444\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.1716 - accuracy: 0.1617 - val_loss: 55.1961 - val_accuracy: 0.0444\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55.1001 - accuracy: 0.1617 - val_loss: 55.1193 - val_accuracy: 0.0444\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55.0304 - accuracy: 0.1617 - val_loss: 55.0467 - val_accuracy: 0.0444\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.9602 - accuracy: 0.1617 - val_loss: 54.9794 - val_accuracy: 0.0444\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.8889 - accuracy: 0.1617 - val_loss: 54.9183 - val_accuracy: 0.0444\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.8197 - accuracy: 0.1617 - val_loss: 54.8593 - val_accuracy: 0.0444\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.7488 - accuracy: 0.1617 - val_loss: 54.7887 - val_accuracy: 0.0444\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.6787 - accuracy: 0.1617 - val_loss: 54.7159 - val_accuracy: 0.0444\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.6098 - accuracy: 0.1617 - val_loss: 54.6426 - val_accuracy: 0.0444\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.5396 - accuracy: 0.1766 - val_loss: 54.5721 - val_accuracy: 0.0444\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.4698 - accuracy: 0.1617 - val_loss: 54.5034 - val_accuracy: 0.0444\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.4010 - accuracy: 0.1617 - val_loss: 54.4303 - val_accuracy: 0.0444\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54.3308 - accuracy: 0.1617 - val_loss: 54.3535 - val_accuracy: 0.0444\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.2612 - accuracy: 0.1617 - val_loss: 54.2802 - val_accuracy: 0.0444\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1921 - accuracy: 0.1617 - val_loss: 54.2058 - val_accuracy: 0.0444\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54.1234 - accuracy: 0.1766 - val_loss: 54.1349 - val_accuracy: 0.0444\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54.0544 - accuracy: 0.1617 - val_loss: 54.0718 - val_accuracy: 0.0444\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.9849 - accuracy: 0.1617 - val_loss: 54.0135 - val_accuracy: 0.0444\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.9150 - accuracy: 0.1617 - val_loss: 53.9483 - val_accuracy: 0.0444\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.8467 - accuracy: 0.1617 - val_loss: 53.8831 - val_accuracy: 0.0444\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.7786 - accuracy: 0.1617 - val_loss: 53.8172 - val_accuracy: 0.0444\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.7105 - accuracy: 0.1617 - val_loss: 53.7466 - val_accuracy: 0.0444\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.6420 - accuracy: 0.1617 - val_loss: 53.6755 - val_accuracy: 0.0444\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53.5728 - accuracy: 0.1617 - val_loss: 53.6030 - val_accuracy: 0.0444\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.5045 - accuracy: 0.1617 - val_loss: 53.5321 - val_accuracy: 0.0444\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53.4353 - accuracy: 0.1617 - val_loss: 53.4595 - val_accuracy: 0.0444\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53.3663 - accuracy: 0.1617 - val_loss: 53.3910 - val_accuracy: 0.0444\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 53.2983 - accuracy: 0.1617 - val_loss: 53.3237 - val_accuracy: 0.0444\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.2302 - accuracy: 0.1617 - val_loss: 53.2616 - val_accuracy: 0.0444\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.1616 - accuracy: 0.1617 - val_loss: 53.2008 - val_accuracy: 0.0444\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.0929 - accuracy: 0.1617 - val_loss: 53.1304 - val_accuracy: 0.0444\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 53.0250 - accuracy: 0.1617 - val_loss: 53.0575 - val_accuracy: 0.0444\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.9576 - accuracy: 0.1617 - val_loss: 52.9847 - val_accuracy: 0.0444\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.8902 - accuracy: 0.1617 - val_loss: 52.9137 - val_accuracy: 0.0444\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.8224 - accuracy: 0.1617 - val_loss: 52.8468 - val_accuracy: 0.0444\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.7545 - accuracy: 0.1617 - val_loss: 52.7779 - val_accuracy: 0.0444\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.6870 - accuracy: 0.1617 - val_loss: 52.7096 - val_accuracy: 0.0444\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.6198 - accuracy: 0.1617 - val_loss: 52.6427 - val_accuracy: 0.0444\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.5519 - accuracy: 0.1617 - val_loss: 52.5765 - val_accuracy: 0.0444\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52.4837 - accuracy: 0.1617 - val_loss: 52.5124 - val_accuracy: 0.0444\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.4171 - accuracy: 0.1617 - val_loss: 52.4488 - val_accuracy: 0.0444\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.3494 - accuracy: 0.1617 - val_loss: 52.3829 - val_accuracy: 0.0444\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.2826 - accuracy: 0.1617 - val_loss: 52.3144 - val_accuracy: 0.0444\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52.2153 - accuracy: 0.1617 - val_loss: 52.2492 - val_accuracy: 0.0444\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.1482 - accuracy: 0.1617 - val_loss: 52.1810 - val_accuracy: 0.0444\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52.0816 - accuracy: 0.1617 - val_loss: 52.1106 - val_accuracy: 0.0444\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52.0146 - accuracy: 0.1617 - val_loss: 52.0450 - val_accuracy: 0.0444\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.9477 - accuracy: 0.1592 - val_loss: 51.9800 - val_accuracy: 0.0889\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8812 - accuracy: 0.1567 - val_loss: 51.9161 - val_accuracy: 0.0889\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.8141 - accuracy: 0.1617 - val_loss: 51.8496 - val_accuracy: 0.0889\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.7472 - accuracy: 0.1617 - val_loss: 51.7832 - val_accuracy: 0.0444\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.6806 - accuracy: 0.1617 - val_loss: 51.7190 - val_accuracy: 0.0444\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.6140 - accuracy: 0.1617 - val_loss: 51.6503 - val_accuracy: 0.0444\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.5481 - accuracy: 0.1642 - val_loss: 51.5817 - val_accuracy: 0.1111\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.4823 - accuracy: 0.1741 - val_loss: 51.5173 - val_accuracy: 0.1556\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.4167 - accuracy: 0.1617 - val_loss: 51.4520 - val_accuracy: 0.1556\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.3516 - accuracy: 0.1617 - val_loss: 51.3847 - val_accuracy: 0.1556\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.2852 - accuracy: 0.1592 - val_loss: 51.3168 - val_accuracy: 0.0444\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.2173 - accuracy: 0.1617 - val_loss: 51.2505 - val_accuracy: 0.0444\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51.1511 - accuracy: 0.1617 - val_loss: 51.1825 - val_accuracy: 0.0444\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51.0849 - accuracy: 0.1766 - val_loss: 51.1137 - val_accuracy: 0.1111\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.0196 - accuracy: 0.1766 - val_loss: 51.0457 - val_accuracy: 0.1333\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.9533 - accuracy: 0.1741 - val_loss: 50.9825 - val_accuracy: 0.0444\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.8874 - accuracy: 0.1617 - val_loss: 50.9214 - val_accuracy: 0.0444\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50.8221 - accuracy: 0.1617 - val_loss: 50.8599 - val_accuracy: 0.0444\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.7572 - accuracy: 0.1617 - val_loss: 50.7932 - val_accuracy: 0.0444\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.6919 - accuracy: 0.1617 - val_loss: 50.7220 - val_accuracy: 0.0444\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.6256 - accuracy: 0.1617 - val_loss: 50.6546 - val_accuracy: 0.0444\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.5600 - accuracy: 0.1617 - val_loss: 50.5865 - val_accuracy: 0.0444\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.4948 - accuracy: 0.1617 - val_loss: 50.5222 - val_accuracy: 0.0444\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.4297 - accuracy: 0.1617 - val_loss: 50.4504 - val_accuracy: 0.0444\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.3649 - accuracy: 0.1766 - val_loss: 50.3849 - val_accuracy: 0.0444\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50.3000 - accuracy: 0.1766 - val_loss: 50.3221 - val_accuracy: 0.0444\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50.2345 - accuracy: 0.1617 - val_loss: 50.2604 - val_accuracy: 0.0444\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.1695 - accuracy: 0.1617 - val_loss: 50.1967 - val_accuracy: 0.0444\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50.1057 - accuracy: 0.1617 - val_loss: 50.1363 - val_accuracy: 0.0444\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50.0406 - accuracy: 0.1617 - val_loss: 50.0702 - val_accuracy: 0.0444\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.9758 - accuracy: 0.1617 - val_loss: 50.0042 - val_accuracy: 0.0444\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.9112 - accuracy: 0.1617 - val_loss: 49.9485 - val_accuracy: 0.0444\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.8468 - accuracy: 0.1617 - val_loss: 49.8880 - val_accuracy: 0.0444\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.7821 - accuracy: 0.1617 - val_loss: 49.8268 - val_accuracy: 0.0444\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49.7177 - accuracy: 0.1617 - val_loss: 49.7667 - val_accuracy: 0.0444\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.6536 - accuracy: 0.1617 - val_loss: 49.7065 - val_accuracy: 0.0444\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5894 - accuracy: 0.1617 - val_loss: 49.6401 - val_accuracy: 0.0444\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.5249 - accuracy: 0.1617 - val_loss: 49.5730 - val_accuracy: 0.0444\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.4607 - accuracy: 0.1617 - val_loss: 49.4998 - val_accuracy: 0.0444\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.3970 - accuracy: 0.1617 - val_loss: 49.4286 - val_accuracy: 0.0444\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49.3313 - accuracy: 0.1617 - val_loss: 49.3646 - val_accuracy: 0.0444\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.2671 - accuracy: 0.1617 - val_loss: 49.3028 - val_accuracy: 0.0444\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49.2041 - accuracy: 0.1617 - val_loss: 49.2478 - val_accuracy: 0.0444\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.1406 - accuracy: 0.1617 - val_loss: 49.1838 - val_accuracy: 0.0444\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49.0762 - accuracy: 0.1617 - val_loss: 49.1069 - val_accuracy: 0.0444\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49.0120 - accuracy: 0.1617 - val_loss: 49.0327 - val_accuracy: 0.0444\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.9492 - accuracy: 0.1617 - val_loss: 48.9670 - val_accuracy: 0.0444\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8863 - accuracy: 0.1766 - val_loss: 48.9037 - val_accuracy: 0.0444\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.8222 - accuracy: 0.1741 - val_loss: 48.8460 - val_accuracy: 0.0444\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.7581 - accuracy: 0.1617 - val_loss: 48.7857 - val_accuracy: 0.0444\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.6945 - accuracy: 0.1617 - val_loss: 48.7240 - val_accuracy: 0.0444\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 48.6313 - accuracy: 0.1617 - val_loss: 48.6599 - val_accuracy: 0.0444\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 48.5680 - accuracy: 0.1617 - val_loss: 48.5932 - val_accuracy: 0.0444\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48.5054 - accuracy: 0.1617 - val_loss: 48.5261 - val_accuracy: 0.0444\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 48.4420 - accuracy: 0.1617 - val_loss: 48.4635 - val_accuracy: 0.0444\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 4s 913ms/step - loss: 48.3785 - accuracy: 0.1766 - val_loss: 48.4027 - val_accuracy: 0.0444\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48.3154 - accuracy: 0.1667 - val_loss: 48.3423 - val_accuracy: 0.0444\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48.2530 - accuracy: 0.1617 - val_loss: 48.2827 - val_accuracy: 0.0444\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48.1903 - accuracy: 0.1716 - val_loss: 48.2220 - val_accuracy: 0.0444\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48.1271 - accuracy: 0.1617 - val_loss: 48.1611 - val_accuracy: 0.0444\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.0654 - accuracy: 0.1617 - val_loss: 48.1005 - val_accuracy: 0.0444\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48.0024 - accuracy: 0.1617 - val_loss: 48.0395 - val_accuracy: 0.0444\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.9401 - accuracy: 0.1617 - val_loss: 47.9723 - val_accuracy: 0.0444\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 47.8770 - accuracy: 0.1617 - val_loss: 47.9135 - val_accuracy: 0.0444\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 47.8157 - accuracy: 0.1617 - val_loss: 47.8532 - val_accuracy: 0.0444\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47.7518 - accuracy: 0.1617 - val_loss: 47.7919 - val_accuracy: 0.0444\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.6888 - accuracy: 0.1617 - val_loss: 47.7265 - val_accuracy: 0.0444\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47.6253 - accuracy: 0.1617 - val_loss: 47.6591 - val_accuracy: 0.0444\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.5635 - accuracy: 0.1617 - val_loss: 47.5951 - val_accuracy: 0.0444\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.5012 - accuracy: 0.1617 - val_loss: 47.5325 - val_accuracy: 0.0444\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.4397 - accuracy: 0.1617 - val_loss: 47.4691 - val_accuracy: 0.0889\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47.3779 - accuracy: 0.1617 - val_loss: 47.4066 - val_accuracy: 0.0889\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.3157 - accuracy: 0.1617 - val_loss: 47.3436 - val_accuracy: 0.0889\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47.2535 - accuracy: 0.1592 - val_loss: 47.2839 - val_accuracy: 0.0444\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47.1915 - accuracy: 0.1617 - val_loss: 47.2225 - val_accuracy: 0.0444\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47.1296 - accuracy: 0.1617 - val_loss: 47.1597 - val_accuracy: 0.0444\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47.0684 - accuracy: 0.1617 - val_loss: 47.0985 - val_accuracy: 0.0444\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47.0061 - accuracy: 0.1791 - val_loss: 47.0343 - val_accuracy: 0.0444\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.9447 - accuracy: 0.1692 - val_loss: 46.9754 - val_accuracy: 0.0444\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.8825 - accuracy: 0.1617 - val_loss: 46.9147 - val_accuracy: 0.0444\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.8218 - accuracy: 0.1617 - val_loss: 46.8511 - val_accuracy: 0.0444\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.7601 - accuracy: 0.1617 - val_loss: 46.7888 - val_accuracy: 0.0444\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.6985 - accuracy: 0.1617 - val_loss: 46.7282 - val_accuracy: 0.0444\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.6376 - accuracy: 0.1617 - val_loss: 46.6647 - val_accuracy: 0.0444\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5760 - accuracy: 0.1617 - val_loss: 46.6047 - val_accuracy: 0.0444\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.5150 - accuracy: 0.1617 - val_loss: 46.5420 - val_accuracy: 0.0444\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.4539 - accuracy: 0.1617 - val_loss: 46.4854 - val_accuracy: 0.0444\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3924 - accuracy: 0.1617 - val_loss: 46.4297 - val_accuracy: 0.0444\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.3318 - accuracy: 0.1617 - val_loss: 46.3713 - val_accuracy: 0.0444\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.2706 - accuracy: 0.1617 - val_loss: 46.3108 - val_accuracy: 0.0444\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.2101 - accuracy: 0.1667 - val_loss: 46.2493 - val_accuracy: 0.0444\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.1502 - accuracy: 0.1642 - val_loss: 46.1899 - val_accuracy: 0.1556\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.0888 - accuracy: 0.1766 - val_loss: 46.1300 - val_accuracy: 0.1111\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.0277 - accuracy: 0.1766 - val_loss: 46.0693 - val_accuracy: 0.0444\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45.9663 - accuracy: 0.1766 - val_loss: 46.0074 - val_accuracy: 0.0444\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.9063 - accuracy: 0.1741 - val_loss: 45.9386 - val_accuracy: 0.0444\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.8455 - accuracy: 0.1617 - val_loss: 45.8765 - val_accuracy: 0.0444\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45.7854 - accuracy: 0.1617 - val_loss: 45.8148 - val_accuracy: 0.0444\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.7250 - accuracy: 0.1617 - val_loss: 45.7544 - val_accuracy: 0.0444\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.6646 - accuracy: 0.1617 - val_loss: 45.6976 - val_accuracy: 0.0444\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45.6039 - accuracy: 0.1617 - val_loss: 45.6427 - val_accuracy: 0.0444\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5438 - accuracy: 0.1617 - val_loss: 45.5856 - val_accuracy: 0.0444\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.4838 - accuracy: 0.1617 - val_loss: 45.5284 - val_accuracy: 0.0444\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45.4237 - accuracy: 0.1617 - val_loss: 45.4697 - val_accuracy: 0.0444\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.3632 - accuracy: 0.1617 - val_loss: 45.4123 - val_accuracy: 0.0444\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.3032 - accuracy: 0.1617 - val_loss: 45.3493 - val_accuracy: 0.0444\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.2425 - accuracy: 0.1617 - val_loss: 45.2856 - val_accuracy: 0.0444\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1815 - accuracy: 0.1617 - val_loss: 45.2176 - val_accuracy: 0.0444\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.1231 - accuracy: 0.1667 - val_loss: 45.1494 - val_accuracy: 0.0889\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45.0656 - accuracy: 0.1617 - val_loss: 45.0911 - val_accuracy: 0.0889\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45.0069 - accuracy: 0.1617 - val_loss: 45.0327 - val_accuracy: 0.0889\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.9471 - accuracy: 0.1617 - val_loss: 44.9750 - val_accuracy: 0.0444\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.8854 - accuracy: 0.1617 - val_loss: 44.9162 - val_accuracy: 0.0444\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.8255 - accuracy: 0.1617 - val_loss: 44.8588 - val_accuracy: 0.0444\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7650 - accuracy: 0.1617 - val_loss: 44.7982 - val_accuracy: 0.0444\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44.7052 - accuracy: 0.1617 - val_loss: 44.7405 - val_accuracy: 0.0444\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.6465 - accuracy: 0.1617 - val_loss: 44.6847 - val_accuracy: 0.0444\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.5873 - accuracy: 0.1692 - val_loss: 44.6312 - val_accuracy: 0.0444\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.5283 - accuracy: 0.1667 - val_loss: 44.5776 - val_accuracy: 0.0444\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.4688 - accuracy: 0.1617 - val_loss: 44.5160 - val_accuracy: 0.0444\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.4094 - accuracy: 0.1617 - val_loss: 44.4528 - val_accuracy: 0.0444\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.3508 - accuracy: 0.1617 - val_loss: 44.3892 - val_accuracy: 0.0444\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.2920 - accuracy: 0.1617 - val_loss: 44.3292 - val_accuracy: 0.0444\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.2334 - accuracy: 0.1692 - val_loss: 44.2716 - val_accuracy: 0.1333\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.1746 - accuracy: 0.1642 - val_loss: 44.2126 - val_accuracy: 0.1556\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.1163 - accuracy: 0.1617 - val_loss: 44.1530 - val_accuracy: 0.1556\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.0569 - accuracy: 0.1617 - val_loss: 44.0918 - val_accuracy: 0.1333\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.9979 - accuracy: 0.1716 - val_loss: 44.0327 - val_accuracy: 0.0444\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.9387 - accuracy: 0.1617 - val_loss: 43.9741 - val_accuracy: 0.0444\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.8801 - accuracy: 0.1617 - val_loss: 43.9158 - val_accuracy: 0.0444\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.8211 - accuracy: 0.1617 - val_loss: 43.8601 - val_accuracy: 0.0444\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43.7624 - accuracy: 0.1617 - val_loss: 43.8044 - val_accuracy: 0.0444\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43.7032 - accuracy: 0.1617 - val_loss: 43.7431 - val_accuracy: 0.0444\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43.6462 - accuracy: 0.1816 - val_loss: 43.6849 - val_accuracy: 0.1556\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.5877 - accuracy: 0.1617 - val_loss: 43.6238 - val_accuracy: 0.1556\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.5299 - accuracy: 0.1741 - val_loss: 43.5668 - val_accuracy: 0.0444\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.4709 - accuracy: 0.1617 - val_loss: 43.5128 - val_accuracy: 0.0444\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43.4132 - accuracy: 0.1617 - val_loss: 43.4586 - val_accuracy: 0.0444\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.3543 - accuracy: 0.1617 - val_loss: 43.4016 - val_accuracy: 0.0444\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.2958 - accuracy: 0.1617 - val_loss: 43.3400 - val_accuracy: 0.0444\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.2375 - accuracy: 0.1617 - val_loss: 43.2765 - val_accuracy: 0.0444\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.1804 - accuracy: 0.1617 - val_loss: 43.2128 - val_accuracy: 0.0444\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.1218 - accuracy: 0.1617 - val_loss: 43.1519 - val_accuracy: 0.0444\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43.0640 - accuracy: 0.1617 - val_loss: 43.0943 - val_accuracy: 0.0444\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.0095 - accuracy: 0.1617 - val_loss: 43.0391 - val_accuracy: 0.0444\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.9501 - accuracy: 0.1617 - val_loss: 42.9846 - val_accuracy: 0.0444\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.8915 - accuracy: 0.1617 - val_loss: 42.9291 - val_accuracy: 0.0444\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.8338 - accuracy: 0.1617 - val_loss: 42.8723 - val_accuracy: 0.0444\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42.7762 - accuracy: 0.1617 - val_loss: 42.8192 - val_accuracy: 0.0444\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7181 - accuracy: 0.1617 - val_loss: 42.7664 - val_accuracy: 0.0444\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.6605 - accuracy: 0.1617 - val_loss: 42.7089 - val_accuracy: 0.0444\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.6030 - accuracy: 0.1617 - val_loss: 42.6503 - val_accuracy: 0.0444\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.5465 - accuracy: 0.1617 - val_loss: 42.5927 - val_accuracy: 0.0444\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42.4892 - accuracy: 0.1617 - val_loss: 42.5294 - val_accuracy: 0.0444\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.4325 - accuracy: 0.1617 - val_loss: 42.4757 - val_accuracy: 0.0444\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3749 - accuracy: 0.1617 - val_loss: 42.4223 - val_accuracy: 0.0444\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.3181 - accuracy: 0.1617 - val_loss: 42.3685 - val_accuracy: 0.0444\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.2618 - accuracy: 0.1617 - val_loss: 42.3143 - val_accuracy: 0.0444\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.2045 - accuracy: 0.1617 - val_loss: 42.2558 - val_accuracy: 0.0444\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42.1469 - accuracy: 0.1617 - val_loss: 42.1926 - val_accuracy: 0.0444\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.0898 - accuracy: 0.1617 - val_loss: 42.1317 - val_accuracy: 0.0444\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.0327 - accuracy: 0.1617 - val_loss: 42.0731 - val_accuracy: 0.0444\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.9765 - accuracy: 0.1517 - val_loss: 42.0115 - val_accuracy: 0.0889\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.9189 - accuracy: 0.1617 - val_loss: 41.9534 - val_accuracy: 0.0444\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41.8618 - accuracy: 0.1617 - val_loss: 41.8983 - val_accuracy: 0.0444\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.8049 - accuracy: 0.1617 - val_loss: 41.8473 - val_accuracy: 0.0444\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.7482 - accuracy: 0.1617 - val_loss: 41.7958 - val_accuracy: 0.0444\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6918 - accuracy: 0.1617 - val_loss: 41.7348 - val_accuracy: 0.0444\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.6349 - accuracy: 0.1617 - val_loss: 41.6740 - val_accuracy: 0.0444\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.5792 - accuracy: 0.1617 - val_loss: 41.6131 - val_accuracy: 0.0444\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.5234 - accuracy: 0.1617 - val_loss: 41.5568 - val_accuracy: 0.0444\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.4667 - accuracy: 0.1617 - val_loss: 41.5014 - val_accuracy: 0.0444\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41.4100 - accuracy: 0.1617 - val_loss: 41.4491 - val_accuracy: 0.0444\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.3539 - accuracy: 0.1617 - val_loss: 41.3972 - val_accuracy: 0.0444\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.2976 - accuracy: 0.1617 - val_loss: 41.3416 - val_accuracy: 0.0444\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.2415 - accuracy: 0.1617 - val_loss: 41.2850 - val_accuracy: 0.0444\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.1851 - accuracy: 0.1617 - val_loss: 41.2261 - val_accuracy: 0.0444\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.1296 - accuracy: 0.1617 - val_loss: 41.1668 - val_accuracy: 0.0444\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41.0739 - accuracy: 0.1766 - val_loss: 41.1036 - val_accuracy: 0.0444\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.0184 - accuracy: 0.1741 - val_loss: 41.0481 - val_accuracy: 0.0444\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.9627 - accuracy: 0.1617 - val_loss: 40.9978 - val_accuracy: 0.0444\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.9065 - accuracy: 0.1617 - val_loss: 40.9433 - val_accuracy: 0.0444\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.8505 - accuracy: 0.1617 - val_loss: 40.8892 - val_accuracy: 0.0444\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.7953 - accuracy: 0.1617 - val_loss: 40.8369 - val_accuracy: 0.0444\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.7385 - accuracy: 0.1617 - val_loss: 40.7807 - val_accuracy: 0.0444\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6831 - accuracy: 0.1617 - val_loss: 40.7239 - val_accuracy: 0.0444\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.6280 - accuracy: 0.1617 - val_loss: 40.6684 - val_accuracy: 0.0444\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.5729 - accuracy: 0.1617 - val_loss: 40.6139 - val_accuracy: 0.0444\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.5180 - accuracy: 0.1617 - val_loss: 40.5618 - val_accuracy: 0.0444\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.4621 - accuracy: 0.1617 - val_loss: 40.5087 - val_accuracy: 0.0444\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40.4079 - accuracy: 0.1617 - val_loss: 40.4519 - val_accuracy: 0.0444\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.3525 - accuracy: 0.1617 - val_loss: 40.3943 - val_accuracy: 0.0444\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.2970 - accuracy: 0.1617 - val_loss: 40.3361 - val_accuracy: 0.0444\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.2410 - accuracy: 0.1617 - val_loss: 40.2789 - val_accuracy: 0.0444\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.1859 - accuracy: 0.1716 - val_loss: 40.2227 - val_accuracy: 0.0444\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.1307 - accuracy: 0.1766 - val_loss: 40.1718 - val_accuracy: 0.0444\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40.0757 - accuracy: 0.1766 - val_loss: 40.1240 - val_accuracy: 0.0444\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.0202 - accuracy: 0.1617 - val_loss: 40.0716 - val_accuracy: 0.0444\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.9650 - accuracy: 0.1617 - val_loss: 40.0198 - val_accuracy: 0.0444\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.9109 - accuracy: 0.1617 - val_loss: 39.9649 - val_accuracy: 0.0444\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.8557 - accuracy: 0.1617 - val_loss: 39.9096 - val_accuracy: 0.0444\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.8010 - accuracy: 0.1617 - val_loss: 39.8502 - val_accuracy: 0.0444\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 39.7460 - accuracy: 0.1617 - val_loss: 39.7898 - val_accuracy: 0.0444\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.6909 - accuracy: 0.1617 - val_loss: 39.7274 - val_accuracy: 0.0444\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.6370 - accuracy: 0.1617 - val_loss: 39.6676 - val_accuracy: 0.0444\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.5828 - accuracy: 0.1766 - val_loss: 39.6167 - val_accuracy: 0.0444\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.5282 - accuracy: 0.1617 - val_loss: 39.5649 - val_accuracy: 0.0444\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.4728 - accuracy: 0.1617 - val_loss: 39.5083 - val_accuracy: 0.0444\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.4191 - accuracy: 0.1617 - val_loss: 39.4532 - val_accuracy: 0.0444\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.3656 - accuracy: 0.1542 - val_loss: 39.4003 - val_accuracy: 0.0889\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39.3121 - accuracy: 0.1617 - val_loss: 39.3410 - val_accuracy: 0.0889\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.2573 - accuracy: 0.1617 - val_loss: 39.2853 - val_accuracy: 0.0889\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39.2030 - accuracy: 0.1617 - val_loss: 39.2363 - val_accuracy: 0.0444\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.1490 - accuracy: 0.1617 - val_loss: 39.1854 - val_accuracy: 0.0444\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.0944 - accuracy: 0.1617 - val_loss: 39.1308 - val_accuracy: 0.0444\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39.0400 - accuracy: 0.1617 - val_loss: 39.0812 - val_accuracy: 0.0444\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38.9861 - accuracy: 0.1617 - val_loss: 39.0321 - val_accuracy: 0.0444\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.9319 - accuracy: 0.1617 - val_loss: 38.9815 - val_accuracy: 0.0444\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.8775 - accuracy: 0.1617 - val_loss: 38.9264 - val_accuracy: 0.0444\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.8241 - accuracy: 0.1617 - val_loss: 38.8709 - val_accuracy: 0.0444\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.7708 - accuracy: 0.1617 - val_loss: 38.8116 - val_accuracy: 0.0444\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.7161 - accuracy: 0.1617 - val_loss: 38.7565 - val_accuracy: 0.0444\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.6632 - accuracy: 0.1617 - val_loss: 38.7033 - val_accuracy: 0.0444\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.6096 - accuracy: 0.1617 - val_loss: 38.6536 - val_accuracy: 0.0444\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38.5557 - accuracy: 0.1617 - val_loss: 38.6009 - val_accuracy: 0.0444\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.5018 - accuracy: 0.1617 - val_loss: 38.5449 - val_accuracy: 0.0444\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.4482 - accuracy: 0.1617 - val_loss: 38.4878 - val_accuracy: 0.0444\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.3947 - accuracy: 0.1617 - val_loss: 38.4360 - val_accuracy: 0.0444\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.3417 - accuracy: 0.1617 - val_loss: 38.3843 - val_accuracy: 0.0444\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38.2879 - accuracy: 0.1617 - val_loss: 38.3293 - val_accuracy: 0.0444\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.2347 - accuracy: 0.1617 - val_loss: 38.2763 - val_accuracy: 0.0444\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38.1811 - accuracy: 0.1617 - val_loss: 38.2276 - val_accuracy: 0.0444\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38.1288 - accuracy: 0.1617 - val_loss: 38.1743 - val_accuracy: 0.0444\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38.0752 - accuracy: 0.1617 - val_loss: 38.1207 - val_accuracy: 0.0444\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.0214 - accuracy: 0.1617 - val_loss: 38.0628 - val_accuracy: 0.0444\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9683 - accuracy: 0.1617 - val_loss: 38.0034 - val_accuracy: 0.0444\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.9164 - accuracy: 0.1766 - val_loss: 37.9486 - val_accuracy: 0.0889\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37.8644 - accuracy: 0.1617 - val_loss: 37.8979 - val_accuracy: 0.0889\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.8114 - accuracy: 0.1617 - val_loss: 37.8522 - val_accuracy: 0.0444\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.7579 - accuracy: 0.1617 - val_loss: 37.8035 - val_accuracy: 0.0444\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.7046 - accuracy: 0.1617 - val_loss: 37.7542 - val_accuracy: 0.0444\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37.6519 - accuracy: 0.1617 - val_loss: 37.7021 - val_accuracy: 0.0444\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.5990 - accuracy: 0.1617 - val_loss: 37.6519 - val_accuracy: 0.0444\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5462 - accuracy: 0.1617 - val_loss: 37.6040 - val_accuracy: 0.0444\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.4951 - accuracy: 0.1617 - val_loss: 37.5532 - val_accuracy: 0.0444\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.4427 - accuracy: 0.1617 - val_loss: 37.4967 - val_accuracy: 0.0444\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.3908 - accuracy: 0.1617 - val_loss: 37.4359 - val_accuracy: 0.0444\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.3370 - accuracy: 0.1617 - val_loss: 37.3771 - val_accuracy: 0.0444\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.2850 - accuracy: 0.1617 - val_loss: 37.3236 - val_accuracy: 0.0444\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.2325 - accuracy: 0.1617 - val_loss: 37.2723 - val_accuracy: 0.0444\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.1799 - accuracy: 0.1617 - val_loss: 37.2236 - val_accuracy: 0.0444\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37.1285 - accuracy: 0.1617 - val_loss: 37.1792 - val_accuracy: 0.0444\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0759 - accuracy: 0.1617 - val_loss: 37.1240 - val_accuracy: 0.0444\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.0229 - accuracy: 0.1617 - val_loss: 37.0666 - val_accuracy: 0.0444\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.9706 - accuracy: 0.1617 - val_loss: 37.0127 - val_accuracy: 0.0444\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.9191 - accuracy: 0.1741 - val_loss: 36.9568 - val_accuracy: 0.1333\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.8682 - accuracy: 0.1816 - val_loss: 36.9079 - val_accuracy: 0.0444\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.8151 - accuracy: 0.1617 - val_loss: 36.8586 - val_accuracy: 0.0444\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36.7630 - accuracy: 0.1617 - val_loss: 36.8043 - val_accuracy: 0.0444\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36.7111 - accuracy: 0.1617 - val_loss: 36.7522 - val_accuracy: 0.0444\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36.6597 - accuracy: 0.1617 - val_loss: 36.7031 - val_accuracy: 0.0444\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.6082 - accuracy: 0.1766 - val_loss: 36.6517 - val_accuracy: 0.0444\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.5562 - accuracy: 0.1766 - val_loss: 36.5988 - val_accuracy: 0.0444\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5048 - accuracy: 0.1791 - val_loss: 36.5459 - val_accuracy: 0.0444\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.4538 - accuracy: 0.1642 - val_loss: 36.4955 - val_accuracy: 0.0444\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.4007 - accuracy: 0.1617 - val_loss: 36.4401 - val_accuracy: 0.0444\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.3497 - accuracy: 0.1617 - val_loss: 36.3874 - val_accuracy: 0.0444\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.2975 - accuracy: 0.1617 - val_loss: 36.3400 - val_accuracy: 0.0444\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36.2466 - accuracy: 0.1617 - val_loss: 36.2918 - val_accuracy: 0.0444\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36.1952 - accuracy: 0.1617 - val_loss: 36.2443 - val_accuracy: 0.0444\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36.1433 - accuracy: 0.1617 - val_loss: 36.1896 - val_accuracy: 0.0444\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36.0925 - accuracy: 0.1617 - val_loss: 36.1357 - val_accuracy: 0.0444\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36.0415 - accuracy: 0.1617 - val_loss: 36.0846 - val_accuracy: 0.0444\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35.9904 - accuracy: 0.1617 - val_loss: 36.0346 - val_accuracy: 0.0444\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.9401 - accuracy: 0.1617 - val_loss: 35.9870 - val_accuracy: 0.0444\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.8889 - accuracy: 0.1617 - val_loss: 35.9413 - val_accuracy: 0.0444\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.8371 - accuracy: 0.1617 - val_loss: 35.8924 - val_accuracy: 0.0444\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.7869 - accuracy: 0.1617 - val_loss: 35.8450 - val_accuracy: 0.0444\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.7359 - accuracy: 0.1617 - val_loss: 35.7908 - val_accuracy: 0.0444\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35.6846 - accuracy: 0.1617 - val_loss: 35.7348 - val_accuracy: 0.0444\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6337 - accuracy: 0.1617 - val_loss: 35.6784 - val_accuracy: 0.0444\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5831 - accuracy: 0.1617 - val_loss: 35.6272 - val_accuracy: 0.0444\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.5319 - accuracy: 0.1617 - val_loss: 35.5752 - val_accuracy: 0.0444\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4809 - accuracy: 0.1617 - val_loss: 35.5219 - val_accuracy: 0.0444\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.4308 - accuracy: 0.1692 - val_loss: 35.4701 - val_accuracy: 0.0444\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.3804 - accuracy: 0.1667 - val_loss: 35.4250 - val_accuracy: 0.0444\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.3291 - accuracy: 0.1617 - val_loss: 35.3801 - val_accuracy: 0.0444\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35.2787 - accuracy: 0.1617 - val_loss: 35.3314 - val_accuracy: 0.0444\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35.2285 - accuracy: 0.1617 - val_loss: 35.2746 - val_accuracy: 0.0444\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1780 - accuracy: 0.1617 - val_loss: 35.2243 - val_accuracy: 0.0444\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1281 - accuracy: 0.1617 - val_loss: 35.1787 - val_accuracy: 0.0444\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0779 - accuracy: 0.1617 - val_loss: 35.1323 - val_accuracy: 0.0444\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.0279 - accuracy: 0.1617 - val_loss: 35.0843 - val_accuracy: 0.0444\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.9775 - accuracy: 0.1617 - val_loss: 35.0308 - val_accuracy: 0.0444\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34.9278 - accuracy: 0.1617 - val_loss: 34.9687 - val_accuracy: 0.0444\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 34.8768 - accuracy: 0.1716 - val_loss: 34.9137 - val_accuracy: 0.0444\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.8266 - accuracy: 0.1617 - val_loss: 34.8611 - val_accuracy: 0.0444\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34.7766 - accuracy: 0.1617 - val_loss: 34.8121 - val_accuracy: 0.0444\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.7271 - accuracy: 0.1617 - val_loss: 34.7635 - val_accuracy: 0.0444\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.6770 - accuracy: 0.1617 - val_loss: 34.7110 - val_accuracy: 0.0444\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.6269 - accuracy: 0.1617 - val_loss: 34.6633 - val_accuracy: 0.0444\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34.5771 - accuracy: 0.1617 - val_loss: 34.6155 - val_accuracy: 0.0444\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.5272 - accuracy: 0.1617 - val_loss: 34.5685 - val_accuracy: 0.0444\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.4772 - accuracy: 0.1617 - val_loss: 34.5200 - val_accuracy: 0.0444\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.4281 - accuracy: 0.1617 - val_loss: 34.4744 - val_accuracy: 0.0444\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34.3782 - accuracy: 0.1617 - val_loss: 34.4222 - val_accuracy: 0.0444\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34.3287 - accuracy: 0.1617 - val_loss: 34.3708 - val_accuracy: 0.0444\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.2792 - accuracy: 0.1617 - val_loss: 34.3272 - val_accuracy: 0.0444\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34.2294 - accuracy: 0.1617 - val_loss: 34.2782 - val_accuracy: 0.0444\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34.1799 - accuracy: 0.1617 - val_loss: 34.2256 - val_accuracy: 0.0444\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34.1306 - accuracy: 0.1617 - val_loss: 34.1771 - val_accuracy: 0.0444\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 34.0820 - accuracy: 0.1617 - val_loss: 34.1305 - val_accuracy: 0.0444\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.0326 - accuracy: 0.1617 - val_loss: 34.0824 - val_accuracy: 0.0444\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33.9840 - accuracy: 0.1617 - val_loss: 34.0314 - val_accuracy: 0.0444\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.9339 - accuracy: 0.1617 - val_loss: 33.9882 - val_accuracy: 0.0444\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.8843 - accuracy: 0.1617 - val_loss: 33.9337 - val_accuracy: 0.0444\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.8346 - accuracy: 0.1617 - val_loss: 33.8813 - val_accuracy: 0.0444\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.7857 - accuracy: 0.1617 - val_loss: 33.8272 - val_accuracy: 0.0444\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33.7370 - accuracy: 0.1617 - val_loss: 33.7800 - val_accuracy: 0.0444\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.6872 - accuracy: 0.1617 - val_loss: 33.7399 - val_accuracy: 0.0444\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.6388 - accuracy: 0.1617 - val_loss: 33.6996 - val_accuracy: 0.0444\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.5914 - accuracy: 0.1617 - val_loss: 33.6489 - val_accuracy: 0.0444\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 33.5430 - accuracy: 0.1617 - val_loss: 33.5985 - val_accuracy: 0.0444\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.4936 - accuracy: 0.1617 - val_loss: 33.5470 - val_accuracy: 0.0444\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.4442 - accuracy: 0.1617 - val_loss: 33.4884 - val_accuracy: 0.0444\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.3945 - accuracy: 0.1617 - val_loss: 33.4376 - val_accuracy: 0.0444\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.3457 - accuracy: 0.1617 - val_loss: 33.3878 - val_accuracy: 0.0444\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33.2977 - accuracy: 0.1617 - val_loss: 33.3377 - val_accuracy: 0.0444\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 33.2492 - accuracy: 0.1617 - val_loss: 33.2893 - val_accuracy: 0.0444\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 33.2006 - accuracy: 0.1617 - val_loss: 33.2418 - val_accuracy: 0.0444\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.1521 - accuracy: 0.1617 - val_loss: 33.1932 - val_accuracy: 0.0444\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33.1051 - accuracy: 0.1617 - val_loss: 33.1498 - val_accuracy: 0.0444\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 33.0562 - accuracy: 0.1617 - val_loss: 33.1074 - val_accuracy: 0.0444\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.0079 - accuracy: 0.1617 - val_loss: 33.0552 - val_accuracy: 0.0444\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 32.9588 - accuracy: 0.1617 - val_loss: 33.0075 - val_accuracy: 0.0444\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 32.9107 - accuracy: 0.1617 - val_loss: 32.9624 - val_accuracy: 0.0444\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32.8624 - accuracy: 0.1617 - val_loss: 32.9144 - val_accuracy: 0.0444\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 32.8147 - accuracy: 0.1617 - val_loss: 32.8664 - val_accuracy: 0.0444\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 32.7660 - accuracy: 0.1617 - val_loss: 32.8175 - val_accuracy: 0.0444\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 32.7171 - accuracy: 0.1617 - val_loss: 32.7614 - val_accuracy: 0.0444\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32.6707 - accuracy: 0.1617 - val_loss: 32.7048 - val_accuracy: 0.0444\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 32.6232 - accuracy: 0.1667 - val_loss: 32.6548 - val_accuracy: 0.0889\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 32.5751 - accuracy: 0.1617 - val_loss: 32.6083 - val_accuracy: 0.0889\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.5268 - accuracy: 0.1617 - val_loss: 32.5636 - val_accuracy: 0.0889\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.4782 - accuracy: 0.1617 - val_loss: 32.5243 - val_accuracy: 0.0444\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32.4316 - accuracy: 0.1617 - val_loss: 32.4857 - val_accuracy: 0.0444\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.3834 - accuracy: 0.1617 - val_loss: 32.4367 - val_accuracy: 0.0444\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32.3352 - accuracy: 0.1617 - val_loss: 32.3815 - val_accuracy: 0.0444\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32.2873 - accuracy: 0.1617 - val_loss: 32.3278 - val_accuracy: 0.0444\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32.2409 - accuracy: 0.1642 - val_loss: 32.2816 - val_accuracy: 0.0444\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32.1930 - accuracy: 0.1617 - val_loss: 32.2432 - val_accuracy: 0.0444\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.1442 - accuracy: 0.1617 - val_loss: 32.2048 - val_accuracy: 0.0444\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.0977 - accuracy: 0.1617 - val_loss: 32.1600 - val_accuracy: 0.0444\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32.0508 - accuracy: 0.1617 - val_loss: 32.1089 - val_accuracy: 0.0444\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.0026 - accuracy: 0.1617 - val_loss: 32.0540 - val_accuracy: 0.0444\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.9545 - accuracy: 0.1617 - val_loss: 32.0005 - val_accuracy: 0.0444\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.9076 - accuracy: 0.1617 - val_loss: 31.9473 - val_accuracy: 0.0444\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 31.8607 - accuracy: 0.1617 - val_loss: 31.8987 - val_accuracy: 0.0444\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.8134 - accuracy: 0.1617 - val_loss: 31.8517 - val_accuracy: 0.0444\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.7661 - accuracy: 0.1617 - val_loss: 31.8088 - val_accuracy: 0.0444\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31.7192 - accuracy: 0.1617 - val_loss: 31.7711 - val_accuracy: 0.0444\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31.6725 - accuracy: 0.1617 - val_loss: 31.7249 - val_accuracy: 0.0444\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.6256 - accuracy: 0.1617 - val_loss: 31.6714 - val_accuracy: 0.0444\n",
      "========== Fold 10 ==========\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 207.6661 - accuracy: 0.0889 - val_loss: 196.5889 - val_accuracy: 0.0714\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 190.3879 - accuracy: 0.1531 - val_loss: 177.9355 - val_accuracy: 0.0714\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 172.3327 - accuracy: 0.1481 - val_loss: 161.7174 - val_accuracy: 0.0714\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 157.1880 - accuracy: 0.1457 - val_loss: 148.8040 - val_accuracy: 0.0476\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 145.2696 - accuracy: 0.1457 - val_loss: 138.8090 - val_accuracy: 0.0714\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 136.0568 - accuracy: 0.1457 - val_loss: 131.0831 - val_accuracy: 0.0714\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 128.9207 - accuracy: 0.1556 - val_loss: 125.0535 - val_accuracy: 0.0476\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 123.3384 - accuracy: 0.1630 - val_loss: 120.2934 - val_accuracy: 0.1190\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 118.9125 - accuracy: 0.1728 - val_loss: 116.4869 - val_accuracy: 0.0476\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 115.3467 - accuracy: 0.1654 - val_loss: 113.4016 - val_accuracy: 0.0476\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112.4345 - accuracy: 0.1605 - val_loss: 110.8336 - val_accuracy: 0.0476\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 110.0198 - accuracy: 0.1679 - val_loss: 108.6779 - val_accuracy: 0.0238\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 107.9885 - accuracy: 0.1556 - val_loss: 106.8542 - val_accuracy: 0.0714\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 106.2620 - accuracy: 0.1802 - val_loss: 105.2897 - val_accuracy: 0.1429\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 104.7741 - accuracy: 0.1654 - val_loss: 103.9636 - val_accuracy: 0.0476\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 103.4810 - accuracy: 0.1605 - val_loss: 102.7988 - val_accuracy: 0.0714\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 102.3440 - accuracy: 0.1432 - val_loss: 101.7364 - val_accuracy: 0.0714\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 2s 275ms/step - loss: 101.3348 - accuracy: 0.1457 - val_loss: 100.7867 - val_accuracy: 0.0476\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 4s 635ms/step - loss: 100.4324 - accuracy: 0.1654 - val_loss: 99.9443 - val_accuracy: 0.1190\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 99.6242 - accuracy: 0.1605 - val_loss: 99.1822 - val_accuracy: 0.1190\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 3s 795ms/step - loss: 98.8865 - accuracy: 0.1605 - val_loss: 98.5037 - val_accuracy: 0.0476\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 3s 477ms/step - loss: 98.2140 - accuracy: 0.1605 - val_loss: 97.8785 - val_accuracy: 0.0476\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 4s 1s/step - loss: 97.5989 - accuracy: 0.1605 - val_loss: 97.2946 - val_accuracy: 0.0476\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 5s 1s/step - loss: 97.0315 - accuracy: 0.1679 - val_loss: 96.7499 - val_accuracy: 0.0952\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - ETA: 0s - loss: 96.5047 - accuracy: 0.1679"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rnn_optimizer\u001b[39m.\u001b[39;49msearch(X, X_prior, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:226\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:266\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    265\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    267\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    268\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 231\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    233\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    234\u001b[0m     ):\n\u001b[0;32m    235\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    239\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\phoneme_encoder_decoder\\train\\optimize.py:61\u001b[0m, in \u001b[0;36mencDecTuner.run_trial\u001b[1;34m(self, trial, X, X_prior, y, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m model, inf_enc, inf_dec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(hp)\n\u001b[0;32m     60\u001b[0m \u001b[39m# train model over hyperparemters\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m _, _, y_pred, y_test \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, inf_enc, inf_dec,\n\u001b[0;32m     62\u001b[0m                                            X, X_prior, y, \u001b[39m*\u001b[39margs,\n\u001b[0;32m     63\u001b[0m                                            batch_size\u001b[39m=\u001b[39mbatch_hp,\n\u001b[0;32m     64\u001b[0m                                            \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39m# evaluate through validation accuracy\u001b[39;00m\n\u001b[0;32m     66\u001b[0m val_accuracy \u001b[39m=\u001b[39m balanced_accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\phoneme_encoder_decoder\\train\\optimize.py:50\u001b[0m, in \u001b[0;36mencDecHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     45\u001b[0m     \u001b[39m# return train_seq2seq_kfold(model, *args,\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[39m#                            batch_size=hp.Choice('batch_size',\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39m#                                                 values=[32, 64, 128,\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[39m#                                                         160]),\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39m#                            **kwargs)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m train_seq2seq_kfold(model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\phoneme_encoder_decoder\\train\\train.py:123\u001b[0m, in \u001b[0;36mtrain_seq2seq_kfold\u001b[1;34m(train_model, inf_enc, inf_dec, X, X_prior, y, num_folds, batch_size, epochs, early_stop)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39m# reset model weights for current fold (also resets associated\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# inference weights)\u001b[39;00m\n\u001b[0;32m    121\u001b[0m shuffle_weights(train_model, weights\u001b[39m=\u001b[39minit_train_w)\n\u001b[1;32m--> 123\u001b[0m history \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39;49mfit([X_train, X_prior_train], y_train,\n\u001b[0;32m    124\u001b[0m                           batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    125\u001b[0m                           validation_data\u001b[39m=\u001b[39;49m([X_test, X_prior_test],\n\u001b[0;32m    126\u001b[0m                                            y_test),\n\u001b[0;32m    127\u001b[0m                           callbacks\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    129\u001b[0m models[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_model)\n\u001b[0;32m    130\u001b[0m models[\u001b[39m'\u001b[39m\u001b[39minf_enc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(inf_enc)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Duke\\Viventi_Cogan_Lab\\RNN_transfer_learning\\RNN_phoneme_decoding_micro\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_optimizer.search(X, X_prior, y, epochs=800)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.optimizers import Adam\n",
    "from train.train import train_seq2seq_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_folds = 10\n",
    "batch_size = 150\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "\n",
    "train_model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.3715 - accuracy: 0.0846 - val_loss: 2.3586 - val_accuracy: 0.1111\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 2.3656 - accuracy: 0.0846 - val_loss: 2.3528 - val_accuracy: 0.1111\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.3598 - accuracy: 0.0846 - val_loss: 2.3472 - val_accuracy: 0.1111\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.3540 - accuracy: 0.0846 - val_loss: 2.3417 - val_accuracy: 0.1111\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3484 - accuracy: 0.0846 - val_loss: 2.3362 - val_accuracy: 0.1111\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3429 - accuracy: 0.0846 - val_loss: 2.3308 - val_accuracy: 0.1111\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3375 - accuracy: 0.0846 - val_loss: 2.3256 - val_accuracy: 0.1111\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3323 - accuracy: 0.0846 - val_loss: 2.3204 - val_accuracy: 0.1111\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.3271 - accuracy: 0.0846 - val_loss: 2.3153 - val_accuracy: 0.1111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.3221 - accuracy: 0.0846 - val_loss: 2.3103 - val_accuracy: 0.1111\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3171 - accuracy: 0.0846 - val_loss: 2.3054 - val_accuracy: 0.1111\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3123 - accuracy: 0.0920 - val_loss: 2.3005 - val_accuracy: 0.1333\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3076 - accuracy: 0.1045 - val_loss: 2.2957 - val_accuracy: 0.1333\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3029 - accuracy: 0.1095 - val_loss: 2.2910 - val_accuracy: 0.1556\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2984 - accuracy: 0.1095 - val_loss: 2.2864 - val_accuracy: 0.1556\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2940 - accuracy: 0.1095 - val_loss: 2.2818 - val_accuracy: 0.1556\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2897 - accuracy: 0.1070 - val_loss: 2.2773 - val_accuracy: 0.1556\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2855 - accuracy: 0.1070 - val_loss: 2.2730 - val_accuracy: 0.1556\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.2814 - accuracy: 0.1070 - val_loss: 2.2686 - val_accuracy: 0.1556\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2773 - accuracy: 0.1194 - val_loss: 2.2643 - val_accuracy: 0.2000\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2734 - accuracy: 0.1269 - val_loss: 2.2601 - val_accuracy: 0.2000\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2695 - accuracy: 0.1393 - val_loss: 2.2559 - val_accuracy: 0.1778\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2658 - accuracy: 0.1393 - val_loss: 2.2519 - val_accuracy: 0.1778\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2621 - accuracy: 0.1368 - val_loss: 2.2478 - val_accuracy: 0.1778\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2585 - accuracy: 0.1493 - val_loss: 2.2438 - val_accuracy: 0.1778\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2550 - accuracy: 0.1517 - val_loss: 2.2399 - val_accuracy: 0.1556\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2516 - accuracy: 0.1617 - val_loss: 2.2360 - val_accuracy: 0.1111\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2483 - accuracy: 0.1517 - val_loss: 2.2322 - val_accuracy: 0.1556\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2450 - accuracy: 0.1617 - val_loss: 2.2285 - val_accuracy: 0.1778\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2418 - accuracy: 0.1692 - val_loss: 2.2248 - val_accuracy: 0.2222\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2387 - accuracy: 0.1692 - val_loss: 2.2211 - val_accuracy: 0.2222\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2357 - accuracy: 0.1692 - val_loss: 2.2175 - val_accuracy: 0.2222\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2327 - accuracy: 0.1716 - val_loss: 2.2140 - val_accuracy: 0.2222\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2298 - accuracy: 0.1667 - val_loss: 2.2105 - val_accuracy: 0.2222\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2270 - accuracy: 0.1592 - val_loss: 2.2070 - val_accuracy: 0.2222\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2243 - accuracy: 0.1567 - val_loss: 2.2036 - val_accuracy: 0.2444\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2216 - accuracy: 0.1617 - val_loss: 2.2003 - val_accuracy: 0.2444\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2189 - accuracy: 0.1592 - val_loss: 2.1970 - val_accuracy: 0.2444\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2164 - accuracy: 0.1592 - val_loss: 2.1937 - val_accuracy: 0.2444\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2139 - accuracy: 0.1592 - val_loss: 2.1905 - val_accuracy: 0.2444\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2114 - accuracy: 0.1567 - val_loss: 2.1874 - val_accuracy: 0.2444\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.2090 - accuracy: 0.1542 - val_loss: 2.1843 - val_accuracy: 0.2444\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2067 - accuracy: 0.1567 - val_loss: 2.1812 - val_accuracy: 0.2444\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2044 - accuracy: 0.1592 - val_loss: 2.1782 - val_accuracy: 0.2444\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2022 - accuracy: 0.1567 - val_loss: 2.1753 - val_accuracy: 0.2444\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2000 - accuracy: 0.1567 - val_loss: 2.1724 - val_accuracy: 0.2444\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1979 - accuracy: 0.1567 - val_loss: 2.1695 - val_accuracy: 0.2444\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1958 - accuracy: 0.1542 - val_loss: 2.1667 - val_accuracy: 0.2444\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1937 - accuracy: 0.1567 - val_loss: 2.1640 - val_accuracy: 0.2444\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1917 - accuracy: 0.1567 - val_loss: 2.1613 - val_accuracy: 0.2444\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1898 - accuracy: 0.1592 - val_loss: 2.1586 - val_accuracy: 0.2444\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1879 - accuracy: 0.1642 - val_loss: 2.1560 - val_accuracy: 0.2667\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1860 - accuracy: 0.1692 - val_loss: 2.1534 - val_accuracy: 0.2667\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1841 - accuracy: 0.1791 - val_loss: 2.1510 - val_accuracy: 0.2667\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1823 - accuracy: 0.1866 - val_loss: 2.1485 - val_accuracy: 0.2667\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1805 - accuracy: 0.1866 - val_loss: 2.1460 - val_accuracy: 0.2889\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1788 - accuracy: 0.1866 - val_loss: 2.1437 - val_accuracy: 0.2889\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1770 - accuracy: 0.1891 - val_loss: 2.1413 - val_accuracy: 0.3111\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1753 - accuracy: 0.1915 - val_loss: 2.1390 - val_accuracy: 0.3111\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1737 - accuracy: 0.1965 - val_loss: 2.1368 - val_accuracy: 0.3111\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1720 - accuracy: 0.1965 - val_loss: 2.1345 - val_accuracy: 0.3111\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1704 - accuracy: 0.1965 - val_loss: 2.1323 - val_accuracy: 0.3111\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1688 - accuracy: 0.1915 - val_loss: 2.1302 - val_accuracy: 0.3111\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1672 - accuracy: 0.1915 - val_loss: 2.1280 - val_accuracy: 0.3111\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.1656 - accuracy: 0.1940 - val_loss: 2.1259 - val_accuracy: 0.3111\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1640 - accuracy: 0.1965 - val_loss: 2.1238 - val_accuracy: 0.3111\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1625 - accuracy: 0.1965 - val_loss: 2.1218 - val_accuracy: 0.3111\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1609 - accuracy: 0.1965 - val_loss: 2.1197 - val_accuracy: 0.3111\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1594 - accuracy: 0.1965 - val_loss: 2.1177 - val_accuracy: 0.3111\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1579 - accuracy: 0.1965 - val_loss: 2.1156 - val_accuracy: 0.2889\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1564 - accuracy: 0.1915 - val_loss: 2.1136 - val_accuracy: 0.2889\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1549 - accuracy: 0.1940 - val_loss: 2.1116 - val_accuracy: 0.2889\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1534 - accuracy: 0.1965 - val_loss: 2.1096 - val_accuracy: 0.2889\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1520 - accuracy: 0.1965 - val_loss: 2.1076 - val_accuracy: 0.2889\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1505 - accuracy: 0.2015 - val_loss: 2.1056 - val_accuracy: 0.2889\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1490 - accuracy: 0.2015 - val_loss: 2.1036 - val_accuracy: 0.2889\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1476 - accuracy: 0.2040 - val_loss: 2.1016 - val_accuracy: 0.2889\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1461 - accuracy: 0.2015 - val_loss: 2.0995 - val_accuracy: 0.2889\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1447 - accuracy: 0.2040 - val_loss: 2.0975 - val_accuracy: 0.2889\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1432 - accuracy: 0.2040 - val_loss: 2.0954 - val_accuracy: 0.2889\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1418 - accuracy: 0.2040 - val_loss: 2.0934 - val_accuracy: 0.2667\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1403 - accuracy: 0.2040 - val_loss: 2.0913 - val_accuracy: 0.2667\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1389 - accuracy: 0.2065 - val_loss: 2.0892 - val_accuracy: 0.2667\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1374 - accuracy: 0.2040 - val_loss: 2.0871 - val_accuracy: 0.2889\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1359 - accuracy: 0.2065 - val_loss: 2.0850 - val_accuracy: 0.2889\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1345 - accuracy: 0.2065 - val_loss: 2.0828 - val_accuracy: 0.2889\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1330 - accuracy: 0.2065 - val_loss: 2.0807 - val_accuracy: 0.2889\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1315 - accuracy: 0.2040 - val_loss: 2.0785 - val_accuracy: 0.3111\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1301 - accuracy: 0.2090 - val_loss: 2.0763 - val_accuracy: 0.3111\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1286 - accuracy: 0.2090 - val_loss: 2.0741 - val_accuracy: 0.2889\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1271 - accuracy: 0.2065 - val_loss: 2.0719 - val_accuracy: 0.2889\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1255 - accuracy: 0.2065 - val_loss: 2.0697 - val_accuracy: 0.2889\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1240 - accuracy: 0.2065 - val_loss: 2.0674 - val_accuracy: 0.2889\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1225 - accuracy: 0.2090 - val_loss: 2.0651 - val_accuracy: 0.2889\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1209 - accuracy: 0.2114 - val_loss: 2.0628 - val_accuracy: 0.2889\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1193 - accuracy: 0.2114 - val_loss: 2.0606 - val_accuracy: 0.2889\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1178 - accuracy: 0.2114 - val_loss: 2.0582 - val_accuracy: 0.2889\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1161 - accuracy: 0.2114 - val_loss: 2.0559 - val_accuracy: 0.2889\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1145 - accuracy: 0.2114 - val_loss: 2.0535 - val_accuracy: 0.2889\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1129 - accuracy: 0.2164 - val_loss: 2.0511 - val_accuracy: 0.2889\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1112 - accuracy: 0.2214 - val_loss: 2.0487 - val_accuracy: 0.2889\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1095 - accuracy: 0.2214 - val_loss: 2.0462 - val_accuracy: 0.2889\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1078 - accuracy: 0.2239 - val_loss: 2.0437 - val_accuracy: 0.2889\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1060 - accuracy: 0.2264 - val_loss: 2.0412 - val_accuracy: 0.2889\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1043 - accuracy: 0.2289 - val_loss: 2.0387 - val_accuracy: 0.2889\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1025 - accuracy: 0.2313 - val_loss: 2.0361 - val_accuracy: 0.2889\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1006 - accuracy: 0.2388 - val_loss: 2.0335 - val_accuracy: 0.2889\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0988 - accuracy: 0.2438 - val_loss: 2.0308 - val_accuracy: 0.2889\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0969 - accuracy: 0.2388 - val_loss: 2.0281 - val_accuracy: 0.2889\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0950 - accuracy: 0.2388 - val_loss: 2.0253 - val_accuracy: 0.2889\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0930 - accuracy: 0.2388 - val_loss: 2.0225 - val_accuracy: 0.2889\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0910 - accuracy: 0.2388 - val_loss: 2.0196 - val_accuracy: 0.2889\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0890 - accuracy: 0.2338 - val_loss: 2.0166 - val_accuracy: 0.3111\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0869 - accuracy: 0.2363 - val_loss: 2.0136 - val_accuracy: 0.3111\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0848 - accuracy: 0.2363 - val_loss: 2.0105 - val_accuracy: 0.3111\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0826 - accuracy: 0.2363 - val_loss: 2.0074 - val_accuracy: 0.3111\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0804 - accuracy: 0.2388 - val_loss: 2.0041 - val_accuracy: 0.3111\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0782 - accuracy: 0.2363 - val_loss: 2.0008 - val_accuracy: 0.3111\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0759 - accuracy: 0.2413 - val_loss: 1.9975 - val_accuracy: 0.3111\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0736 - accuracy: 0.2413 - val_loss: 1.9940 - val_accuracy: 0.3111\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0712 - accuracy: 0.2413 - val_loss: 1.9905 - val_accuracy: 0.3111\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0688 - accuracy: 0.2438 - val_loss: 1.9868 - val_accuracy: 0.3111\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0664 - accuracy: 0.2438 - val_loss: 1.9831 - val_accuracy: 0.3333\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0639 - accuracy: 0.2463 - val_loss: 1.9793 - val_accuracy: 0.3333\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0613 - accuracy: 0.2488 - val_loss: 1.9755 - val_accuracy: 0.3333\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0587 - accuracy: 0.2512 - val_loss: 1.9715 - val_accuracy: 0.3333\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0561 - accuracy: 0.2587 - val_loss: 1.9675 - val_accuracy: 0.3333\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0534 - accuracy: 0.2587 - val_loss: 1.9634 - val_accuracy: 0.3333\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0507 - accuracy: 0.2587 - val_loss: 1.9592 - val_accuracy: 0.3333\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0479 - accuracy: 0.2612 - val_loss: 1.9549 - val_accuracy: 0.3333\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0451 - accuracy: 0.2587 - val_loss: 1.9505 - val_accuracy: 0.3333\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0423 - accuracy: 0.2612 - val_loss: 1.9461 - val_accuracy: 0.3333\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0394 - accuracy: 0.2637 - val_loss: 1.9415 - val_accuracy: 0.3333\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0365 - accuracy: 0.2637 - val_loss: 1.9370 - val_accuracy: 0.3556\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0335 - accuracy: 0.2662 - val_loss: 1.9323 - val_accuracy: 0.3556\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0306 - accuracy: 0.2687 - val_loss: 1.9276 - val_accuracy: 0.3778\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0276 - accuracy: 0.2736 - val_loss: 1.9228 - val_accuracy: 0.3778\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0246 - accuracy: 0.2736 - val_loss: 1.9180 - val_accuracy: 0.4000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0216 - accuracy: 0.2761 - val_loss: 1.9132 - val_accuracy: 0.4000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0185 - accuracy: 0.2761 - val_loss: 1.9084 - val_accuracy: 0.4000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0155 - accuracy: 0.2786 - val_loss: 1.9035 - val_accuracy: 0.4000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0124 - accuracy: 0.2811 - val_loss: 1.8986 - val_accuracy: 0.4000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0093 - accuracy: 0.2811 - val_loss: 1.8937 - val_accuracy: 0.4000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0063 - accuracy: 0.2811 - val_loss: 1.8889 - val_accuracy: 0.4000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0032 - accuracy: 0.2836 - val_loss: 1.8841 - val_accuracy: 0.4000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0002 - accuracy: 0.2786 - val_loss: 1.8794 - val_accuracy: 0.4000\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9971 - accuracy: 0.2786 - val_loss: 1.8747 - val_accuracy: 0.4222\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9941 - accuracy: 0.2761 - val_loss: 1.8701 - val_accuracy: 0.4222\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9910 - accuracy: 0.2761 - val_loss: 1.8656 - val_accuracy: 0.4222\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.9880 - accuracy: 0.2736 - val_loss: 1.8612 - val_accuracy: 0.4222\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9849 - accuracy: 0.2736 - val_loss: 1.8568 - val_accuracy: 0.4222\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9818 - accuracy: 0.2786 - val_loss: 1.8527 - val_accuracy: 0.4222\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9788 - accuracy: 0.2836 - val_loss: 1.8486 - val_accuracy: 0.4222\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9757 - accuracy: 0.2836 - val_loss: 1.8447 - val_accuracy: 0.4222\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9726 - accuracy: 0.2886 - val_loss: 1.8409 - val_accuracy: 0.4222\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9695 - accuracy: 0.2935 - val_loss: 1.8373 - val_accuracy: 0.4222\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9663 - accuracy: 0.2935 - val_loss: 1.8339 - val_accuracy: 0.4222\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9631 - accuracy: 0.3085 - val_loss: 1.8305 - val_accuracy: 0.4222\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9599 - accuracy: 0.3060 - val_loss: 1.8274 - val_accuracy: 0.4222\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9566 - accuracy: 0.3060 - val_loss: 1.8244 - val_accuracy: 0.4222\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9532 - accuracy: 0.3085 - val_loss: 1.8215 - val_accuracy: 0.4222\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9499 - accuracy: 0.3109 - val_loss: 1.8187 - val_accuracy: 0.4222\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9465 - accuracy: 0.3134 - val_loss: 1.8161 - val_accuracy: 0.4444\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9430 - accuracy: 0.3134 - val_loss: 1.8137 - val_accuracy: 0.4667\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9395 - accuracy: 0.3184 - val_loss: 1.8113 - val_accuracy: 0.4222\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9359 - accuracy: 0.3159 - val_loss: 1.8090 - val_accuracy: 0.4222\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9323 - accuracy: 0.3109 - val_loss: 1.8069 - val_accuracy: 0.4222\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9287 - accuracy: 0.3085 - val_loss: 1.8047 - val_accuracy: 0.4222\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9250 - accuracy: 0.3109 - val_loss: 1.8027 - val_accuracy: 0.4222\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9213 - accuracy: 0.3134 - val_loss: 1.8007 - val_accuracy: 0.4222\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9176 - accuracy: 0.3060 - val_loss: 1.7987 - val_accuracy: 0.3778\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9139 - accuracy: 0.3060 - val_loss: 1.7968 - val_accuracy: 0.3778\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9101 - accuracy: 0.3134 - val_loss: 1.7948 - val_accuracy: 0.3778\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9063 - accuracy: 0.3109 - val_loss: 1.7928 - val_accuracy: 0.3778\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9026 - accuracy: 0.3134 - val_loss: 1.7908 - val_accuracy: 0.3778\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8988 - accuracy: 0.3134 - val_loss: 1.7888 - val_accuracy: 0.3778\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8950 - accuracy: 0.3134 - val_loss: 1.7868 - val_accuracy: 0.3778\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8913 - accuracy: 0.3134 - val_loss: 1.7846 - val_accuracy: 0.3778\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8875 - accuracy: 0.3209 - val_loss: 1.7825 - val_accuracy: 0.3556\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8837 - accuracy: 0.3159 - val_loss: 1.7802 - val_accuracy: 0.3556\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8800 - accuracy: 0.3184 - val_loss: 1.7779 - val_accuracy: 0.3556\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8763 - accuracy: 0.3184 - val_loss: 1.7755 - val_accuracy: 0.3556\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8726 - accuracy: 0.3159 - val_loss: 1.7729 - val_accuracy: 0.3556\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8689 - accuracy: 0.3184 - val_loss: 1.7703 - val_accuracy: 0.3556\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8652 - accuracy: 0.3184 - val_loss: 1.7675 - val_accuracy: 0.3778\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8614 - accuracy: 0.3209 - val_loss: 1.7646 - val_accuracy: 0.3778\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8577 - accuracy: 0.3234 - val_loss: 1.7614 - val_accuracy: 0.3778\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8540 - accuracy: 0.3209 - val_loss: 1.7581 - val_accuracy: 0.3778\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8503 - accuracy: 0.3209 - val_loss: 1.7547 - val_accuracy: 0.3778\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8465 - accuracy: 0.3184 - val_loss: 1.7510 - val_accuracy: 0.3778\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8428 - accuracy: 0.3184 - val_loss: 1.7472 - val_accuracy: 0.3778\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8390 - accuracy: 0.3234 - val_loss: 1.7432 - val_accuracy: 0.3778\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8351 - accuracy: 0.3234 - val_loss: 1.7391 - val_accuracy: 0.3778\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8313 - accuracy: 0.3284 - val_loss: 1.7347 - val_accuracy: 0.3778\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8274 - accuracy: 0.3333 - val_loss: 1.7303 - val_accuracy: 0.4000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8234 - accuracy: 0.3433 - val_loss: 1.7257 - val_accuracy: 0.4000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8195 - accuracy: 0.3433 - val_loss: 1.7210 - val_accuracy: 0.4000\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8155 - accuracy: 0.3507 - val_loss: 1.7162 - val_accuracy: 0.4000\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8114 - accuracy: 0.3483 - val_loss: 1.7113 - val_accuracy: 0.4000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8073 - accuracy: 0.3507 - val_loss: 1.7065 - val_accuracy: 0.4000\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8032 - accuracy: 0.3507 - val_loss: 1.7015 - val_accuracy: 0.4222\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7991 - accuracy: 0.3532 - val_loss: 1.6966 - val_accuracy: 0.4222\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7949 - accuracy: 0.3532 - val_loss: 1.6916 - val_accuracy: 0.4222\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7907 - accuracy: 0.3607 - val_loss: 1.6867 - val_accuracy: 0.4222\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7865 - accuracy: 0.3582 - val_loss: 1.6817 - val_accuracy: 0.4222\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7822 - accuracy: 0.3632 - val_loss: 1.6767 - val_accuracy: 0.4222\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.7778 - accuracy: 0.3657 - val_loss: 1.6718 - val_accuracy: 0.4444\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7735 - accuracy: 0.3682 - val_loss: 1.6669 - val_accuracy: 0.4444\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7691 - accuracy: 0.3682 - val_loss: 1.6619 - val_accuracy: 0.4444\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7646 - accuracy: 0.3706 - val_loss: 1.6570 - val_accuracy: 0.4444\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7601 - accuracy: 0.3706 - val_loss: 1.6520 - val_accuracy: 0.4444\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7555 - accuracy: 0.3731 - val_loss: 1.6471 - val_accuracy: 0.4444\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7509 - accuracy: 0.3806 - val_loss: 1.6420 - val_accuracy: 0.4444\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7462 - accuracy: 0.3831 - val_loss: 1.6370 - val_accuracy: 0.4444\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7415 - accuracy: 0.3856 - val_loss: 1.6319 - val_accuracy: 0.4444\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7367 - accuracy: 0.3881 - val_loss: 1.6267 - val_accuracy: 0.4444\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7318 - accuracy: 0.3905 - val_loss: 1.6214 - val_accuracy: 0.4444\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7269 - accuracy: 0.3930 - val_loss: 1.6161 - val_accuracy: 0.4444\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7219 - accuracy: 0.3930 - val_loss: 1.6107 - val_accuracy: 0.4444\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7169 - accuracy: 0.3930 - val_loss: 1.6051 - val_accuracy: 0.4444\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7118 - accuracy: 0.3905 - val_loss: 1.5995 - val_accuracy: 0.4444\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7066 - accuracy: 0.3881 - val_loss: 1.5937 - val_accuracy: 0.4667\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7013 - accuracy: 0.3905 - val_loss: 1.5879 - val_accuracy: 0.4667\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.6960 - accuracy: 0.3930 - val_loss: 1.5820 - val_accuracy: 0.4667\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6906 - accuracy: 0.3930 - val_loss: 1.5760 - val_accuracy: 0.4667\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6851 - accuracy: 0.3930 - val_loss: 1.5699 - val_accuracy: 0.4667\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6796 - accuracy: 0.3955 - val_loss: 1.5636 - val_accuracy: 0.4667\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6739 - accuracy: 0.3955 - val_loss: 1.5574 - val_accuracy: 0.4667\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6682 - accuracy: 0.4005 - val_loss: 1.5510 - val_accuracy: 0.4667\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6624 - accuracy: 0.4005 - val_loss: 1.5447 - val_accuracy: 0.4667\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6565 - accuracy: 0.4030 - val_loss: 1.5382 - val_accuracy: 0.4667\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6506 - accuracy: 0.4055 - val_loss: 1.5317 - val_accuracy: 0.4667\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6445 - accuracy: 0.4055 - val_loss: 1.5252 - val_accuracy: 0.4667\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6384 - accuracy: 0.4080 - val_loss: 1.5186 - val_accuracy: 0.4889\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6322 - accuracy: 0.4129 - val_loss: 1.5120 - val_accuracy: 0.4889\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.6259 - accuracy: 0.4154 - val_loss: 1.5053 - val_accuracy: 0.5333\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6195 - accuracy: 0.4229 - val_loss: 1.4986 - val_accuracy: 0.5333\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6130 - accuracy: 0.4254 - val_loss: 1.4919 - val_accuracy: 0.5333\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6065 - accuracy: 0.4303 - val_loss: 1.4850 - val_accuracy: 0.5556\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5998 - accuracy: 0.4353 - val_loss: 1.4781 - val_accuracy: 0.5556\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5931 - accuracy: 0.4353 - val_loss: 1.4711 - val_accuracy: 0.5556\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5863 - accuracy: 0.4428 - val_loss: 1.4640 - val_accuracy: 0.5556\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5795 - accuracy: 0.4453 - val_loss: 1.4570 - val_accuracy: 0.5778\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5725 - accuracy: 0.4502 - val_loss: 1.4498 - val_accuracy: 0.5778\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5655 - accuracy: 0.4552 - val_loss: 1.4425 - val_accuracy: 0.5778\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5584 - accuracy: 0.4552 - val_loss: 1.4354 - val_accuracy: 0.5778\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5512 - accuracy: 0.4602 - val_loss: 1.4280 - val_accuracy: 0.5778\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5440 - accuracy: 0.4726 - val_loss: 1.4205 - val_accuracy: 0.5778\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5367 - accuracy: 0.4776 - val_loss: 1.4133 - val_accuracy: 0.5778\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5294 - accuracy: 0.4801 - val_loss: 1.4057 - val_accuracy: 0.5778\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5219 - accuracy: 0.4801 - val_loss: 1.3985 - val_accuracy: 0.5778\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5144 - accuracy: 0.4776 - val_loss: 1.3907 - val_accuracy: 0.5778\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5069 - accuracy: 0.4851 - val_loss: 1.3833 - val_accuracy: 0.5778\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4993 - accuracy: 0.4851 - val_loss: 1.3756 - val_accuracy: 0.6000\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4916 - accuracy: 0.4851 - val_loss: 1.3680 - val_accuracy: 0.6000\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4839 - accuracy: 0.4950 - val_loss: 1.3603 - val_accuracy: 0.6000\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4761 - accuracy: 0.5000 - val_loss: 1.3524 - val_accuracy: 0.6000\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4682 - accuracy: 0.5000 - val_loss: 1.3448 - val_accuracy: 0.6000\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4604 - accuracy: 0.5025 - val_loss: 1.3367 - val_accuracy: 0.6222\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4524 - accuracy: 0.5124 - val_loss: 1.3294 - val_accuracy: 0.6444\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4445 - accuracy: 0.5174 - val_loss: 1.3206 - val_accuracy: 0.6444\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4365 - accuracy: 0.5249 - val_loss: 1.3139 - val_accuracy: 0.6444\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4286 - accuracy: 0.5274 - val_loss: 1.3046 - val_accuracy: 0.6222\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4205 - accuracy: 0.5274 - val_loss: 1.2976 - val_accuracy: 0.6444\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4124 - accuracy: 0.5423 - val_loss: 1.2891 - val_accuracy: 0.6444\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4042 - accuracy: 0.5498 - val_loss: 1.2804 - val_accuracy: 0.6444\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3962 - accuracy: 0.5522 - val_loss: 1.2733 - val_accuracy: 0.6667\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3881 - accuracy: 0.5647 - val_loss: 1.2645 - val_accuracy: 0.6667\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3798 - accuracy: 0.5622 - val_loss: 1.2563 - val_accuracy: 0.6667\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3716 - accuracy: 0.5647 - val_loss: 1.2485 - val_accuracy: 0.6667\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3634 - accuracy: 0.5622 - val_loss: 1.2399 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3552 - accuracy: 0.5697 - val_loss: 1.2321 - val_accuracy: 0.6667\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3468 - accuracy: 0.5672 - val_loss: 1.2235 - val_accuracy: 0.6667\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3384 - accuracy: 0.5721 - val_loss: 1.2152 - val_accuracy: 0.6667\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3301 - accuracy: 0.5721 - val_loss: 1.2074 - val_accuracy: 0.6667\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3217 - accuracy: 0.5697 - val_loss: 1.1988 - val_accuracy: 0.6444\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3132 - accuracy: 0.5672 - val_loss: 1.1904 - val_accuracy: 0.6444\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3047 - accuracy: 0.5697 - val_loss: 1.1821 - val_accuracy: 0.6667\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2962 - accuracy: 0.5746 - val_loss: 1.1739 - val_accuracy: 0.6667\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2876 - accuracy: 0.5771 - val_loss: 1.1654 - val_accuracy: 0.6667\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2791 - accuracy: 0.5697 - val_loss: 1.1571 - val_accuracy: 0.6667\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2705 - accuracy: 0.5771 - val_loss: 1.1487 - val_accuracy: 0.6667\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2618 - accuracy: 0.5796 - val_loss: 1.1403 - val_accuracy: 0.6667\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2530 - accuracy: 0.5771 - val_loss: 1.1317 - val_accuracy: 0.6667\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2443 - accuracy: 0.5821 - val_loss: 1.1234 - val_accuracy: 0.6667\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2355 - accuracy: 0.5846 - val_loss: 1.1150 - val_accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2268 - accuracy: 0.5846 - val_loss: 1.1063 - val_accuracy: 0.6889\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2180 - accuracy: 0.5945 - val_loss: 1.0987 - val_accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2092 - accuracy: 0.5871 - val_loss: 1.0891 - val_accuracy: 0.7111\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2005 - accuracy: 0.6020 - val_loss: 1.0823 - val_accuracy: 0.6889\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1918 - accuracy: 0.5970 - val_loss: 1.0723 - val_accuracy: 0.7111\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1830 - accuracy: 0.6070 - val_loss: 1.0648 - val_accuracy: 0.7111\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.1740 - accuracy: 0.6070 - val_loss: 1.0554 - val_accuracy: 0.7111\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1650 - accuracy: 0.6070 - val_loss: 1.0471 - val_accuracy: 0.7333\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1564 - accuracy: 0.6144 - val_loss: 1.0399 - val_accuracy: 0.7333\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1478 - accuracy: 0.6318 - val_loss: 1.0297 - val_accuracy: 0.7333\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1389 - accuracy: 0.6219 - val_loss: 1.0234 - val_accuracy: 0.7556\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1300 - accuracy: 0.6368 - val_loss: 1.0134 - val_accuracy: 0.7778\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1211 - accuracy: 0.6418 - val_loss: 1.0052 - val_accuracy: 0.8000\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1125 - accuracy: 0.6542 - val_loss: 0.9988 - val_accuracy: 0.7778\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1038 - accuracy: 0.6418 - val_loss: 0.9878 - val_accuracy: 0.7778\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0950 - accuracy: 0.6542 - val_loss: 0.9825 - val_accuracy: 0.7778\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0862 - accuracy: 0.6542 - val_loss: 0.9725 - val_accuracy: 0.8000\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0774 - accuracy: 0.6592 - val_loss: 0.9647 - val_accuracy: 0.8000\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0687 - accuracy: 0.6567 - val_loss: 0.9584 - val_accuracy: 0.8000\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0600 - accuracy: 0.6592 - val_loss: 0.9473 - val_accuracy: 0.8222\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0514 - accuracy: 0.6716 - val_loss: 0.9434 - val_accuracy: 0.8000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0427 - accuracy: 0.6667 - val_loss: 0.9320 - val_accuracy: 0.8000\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0339 - accuracy: 0.6791 - val_loss: 0.9266 - val_accuracy: 0.8000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0252 - accuracy: 0.6741 - val_loss: 0.9179 - val_accuracy: 0.8000\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0166 - accuracy: 0.6816 - val_loss: 0.9100 - val_accuracy: 0.8000\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0079 - accuracy: 0.6891 - val_loss: 0.9042 - val_accuracy: 0.8000\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9993 - accuracy: 0.6915 - val_loss: 0.8942 - val_accuracy: 0.8222\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9907 - accuracy: 0.6965 - val_loss: 0.8902 - val_accuracy: 0.8222\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.9822 - accuracy: 0.7065 - val_loss: 0.8789 - val_accuracy: 0.8222\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9737 - accuracy: 0.7090 - val_loss: 0.8771 - val_accuracy: 0.8222\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9653 - accuracy: 0.7114 - val_loss: 0.8640 - val_accuracy: 0.8444\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9572 - accuracy: 0.7214 - val_loss: 0.8649 - val_accuracy: 0.8222\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9491 - accuracy: 0.7164 - val_loss: 0.8507 - val_accuracy: 0.8444\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9407 - accuracy: 0.7313 - val_loss: 0.8487 - val_accuracy: 0.8222\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9318 - accuracy: 0.7338 - val_loss: 0.8408 - val_accuracy: 0.8222\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9233 - accuracy: 0.7413 - val_loss: 0.8312 - val_accuracy: 0.8444\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9156 - accuracy: 0.7363 - val_loss: 0.8313 - val_accuracy: 0.8222\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9076 - accuracy: 0.7388 - val_loss: 0.8181 - val_accuracy: 0.8444\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8991 - accuracy: 0.7413 - val_loss: 0.8159 - val_accuracy: 0.8222\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8909 - accuracy: 0.7388 - val_loss: 0.8097 - val_accuracy: 0.8444\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8832 - accuracy: 0.7537 - val_loss: 0.8003 - val_accuracy: 0.8667\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8751 - accuracy: 0.7537 - val_loss: 0.7986 - val_accuracy: 0.8444\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8669 - accuracy: 0.7612 - val_loss: 0.7891 - val_accuracy: 0.8667\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8591 - accuracy: 0.7637 - val_loss: 0.7857 - val_accuracy: 0.8667\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8513 - accuracy: 0.7736 - val_loss: 0.7792 - val_accuracy: 0.8667\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8432 - accuracy: 0.7711 - val_loss: 0.7724 - val_accuracy: 0.8667\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8354 - accuracy: 0.7786 - val_loss: 0.7688 - val_accuracy: 0.8889\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8278 - accuracy: 0.7910 - val_loss: 0.7610 - val_accuracy: 0.8889\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8199 - accuracy: 0.7960 - val_loss: 0.7578 - val_accuracy: 0.8889\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8121 - accuracy: 0.8035 - val_loss: 0.7501 - val_accuracy: 0.8889\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8046 - accuracy: 0.8109 - val_loss: 0.7471 - val_accuracy: 0.8889\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7969 - accuracy: 0.8209 - val_loss: 0.7397 - val_accuracy: 0.8889\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7892 - accuracy: 0.8209 - val_loss: 0.7354 - val_accuracy: 0.8889\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7816 - accuracy: 0.8308 - val_loss: 0.7312 - val_accuracy: 0.8889\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7742 - accuracy: 0.8333 - val_loss: 0.7239 - val_accuracy: 0.8889\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7666 - accuracy: 0.8358 - val_loss: 0.7212 - val_accuracy: 0.8889\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7591 - accuracy: 0.8333 - val_loss: 0.7135 - val_accuracy: 0.8889\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7517 - accuracy: 0.8383 - val_loss: 0.7129 - val_accuracy: 0.8889\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7445 - accuracy: 0.8383 - val_loss: 0.7013 - val_accuracy: 0.9111\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7373 - accuracy: 0.8483 - val_loss: 0.7074 - val_accuracy: 0.8889\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7303 - accuracy: 0.8507 - val_loss: 0.6874 - val_accuracy: 0.9111\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7237 - accuracy: 0.8532 - val_loss: 0.7011 - val_accuracy: 0.9111\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7167 - accuracy: 0.8607 - val_loss: 0.6808 - val_accuracy: 0.9111\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7089 - accuracy: 0.8582 - val_loss: 0.6825 - val_accuracy: 0.9111\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7013 - accuracy: 0.8607 - val_loss: 0.6814 - val_accuracy: 0.9111\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6948 - accuracy: 0.8607 - val_loss: 0.6661 - val_accuracy: 0.9111\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6883 - accuracy: 0.8607 - val_loss: 0.6741 - val_accuracy: 0.9111\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6812 - accuracy: 0.8706 - val_loss: 0.6622 - val_accuracy: 0.9111\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6741 - accuracy: 0.8706 - val_loss: 0.6560 - val_accuracy: 0.9111\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6675 - accuracy: 0.8632 - val_loss: 0.6604 - val_accuracy: 0.9111\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6611 - accuracy: 0.8781 - val_loss: 0.6460 - val_accuracy: 0.9111\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6545 - accuracy: 0.8731 - val_loss: 0.6475 - val_accuracy: 0.9111\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6477 - accuracy: 0.8756 - val_loss: 0.6443 - val_accuracy: 0.9111\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6412 - accuracy: 0.8831 - val_loss: 0.6342 - val_accuracy: 0.9111\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6349 - accuracy: 0.8756 - val_loss: 0.6381 - val_accuracy: 0.9111\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6286 - accuracy: 0.8905 - val_loss: 0.6278 - val_accuracy: 0.9111\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6222 - accuracy: 0.8856 - val_loss: 0.6249 - val_accuracy: 0.9111\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6157 - accuracy: 0.8881 - val_loss: 0.6247 - val_accuracy: 0.9111\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6096 - accuracy: 0.9005 - val_loss: 0.6144 - val_accuracy: 0.9111\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6036 - accuracy: 0.8930 - val_loss: 0.6162 - val_accuracy: 0.9111\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5974 - accuracy: 0.9104 - val_loss: 0.6093 - val_accuracy: 0.9111\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5912 - accuracy: 0.9030 - val_loss: 0.6050 - val_accuracy: 0.9111\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5852 - accuracy: 0.9055 - val_loss: 0.6046 - val_accuracy: 0.9111\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5794 - accuracy: 0.9129 - val_loss: 0.5962 - val_accuracy: 0.9111\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5735 - accuracy: 0.9104 - val_loss: 0.5966 - val_accuracy: 0.9111\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5676 - accuracy: 0.9179 - val_loss: 0.5898 - val_accuracy: 0.9111\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5617 - accuracy: 0.9179 - val_loss: 0.5876 - val_accuracy: 0.9111\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5560 - accuracy: 0.9179 - val_loss: 0.5848 - val_accuracy: 0.9111\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5503 - accuracy: 0.9254 - val_loss: 0.5779 - val_accuracy: 0.9111\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5447 - accuracy: 0.9204 - val_loss: 0.5788 - val_accuracy: 0.9111\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5391 - accuracy: 0.9254 - val_loss: 0.5712 - val_accuracy: 0.9111\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5336 - accuracy: 0.9229 - val_loss: 0.5710 - val_accuracy: 0.9111\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5281 - accuracy: 0.9254 - val_loss: 0.5643 - val_accuracy: 0.9111\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5227 - accuracy: 0.9254 - val_loss: 0.5636 - val_accuracy: 0.9111\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5173 - accuracy: 0.9303 - val_loss: 0.5585 - val_accuracy: 0.9111\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5120 - accuracy: 0.9303 - val_loss: 0.5559 - val_accuracy: 0.9333\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5068 - accuracy: 0.9328 - val_loss: 0.5523 - val_accuracy: 0.9333\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5016 - accuracy: 0.9353 - val_loss: 0.5483 - val_accuracy: 0.9333\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4964 - accuracy: 0.9353 - val_loss: 0.5467 - val_accuracy: 0.9333\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4913 - accuracy: 0.9378 - val_loss: 0.5413 - val_accuracy: 0.9333\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4863 - accuracy: 0.9403 - val_loss: 0.5393 - val_accuracy: 0.9333\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4813 - accuracy: 0.9453 - val_loss: 0.5353 - val_accuracy: 0.9333\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4764 - accuracy: 0.9453 - val_loss: 0.5343 - val_accuracy: 0.9333\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4715 - accuracy: 0.9453 - val_loss: 0.5276 - val_accuracy: 0.9333\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4668 - accuracy: 0.9478 - val_loss: 0.5301 - val_accuracy: 0.9333\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4621 - accuracy: 0.9502 - val_loss: 0.5187 - val_accuracy: 0.9333\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4576 - accuracy: 0.9478 - val_loss: 0.5285 - val_accuracy: 0.9333\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4534 - accuracy: 0.9552 - val_loss: 0.5087 - val_accuracy: 0.9333\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4495 - accuracy: 0.9502 - val_loss: 0.5268 - val_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4452 - accuracy: 0.9602 - val_loss: 0.5035 - val_accuracy: 0.9333\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4401 - accuracy: 0.9577 - val_loss: 0.5114 - val_accuracy: 0.9333\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4347 - accuracy: 0.9602 - val_loss: 0.5100 - val_accuracy: 0.9333\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4306 - accuracy: 0.9627 - val_loss: 0.4952 - val_accuracy: 0.9333\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4270 - accuracy: 0.9602 - val_loss: 0.5082 - val_accuracy: 0.9333\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4225 - accuracy: 0.9652 - val_loss: 0.4959 - val_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4177 - accuracy: 0.9627 - val_loss: 0.4894 - val_accuracy: 0.9333\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4138 - accuracy: 0.9652 - val_loss: 0.5000 - val_accuracy: 0.9333\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4101 - accuracy: 0.9677 - val_loss: 0.4847 - val_accuracy: 0.9333\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4058 - accuracy: 0.9677 - val_loss: 0.4860 - val_accuracy: 0.9333\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4015 - accuracy: 0.9677 - val_loss: 0.4894 - val_accuracy: 0.9333\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3979 - accuracy: 0.9677 - val_loss: 0.4762 - val_accuracy: 0.9333\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3941 - accuracy: 0.9701 - val_loss: 0.4810 - val_accuracy: 0.9333\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3899 - accuracy: 0.9677 - val_loss: 0.4798 - val_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3862 - accuracy: 0.9677 - val_loss: 0.4688 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3826 - accuracy: 0.9701 - val_loss: 0.4756 - val_accuracy: 0.9333\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3788 - accuracy: 0.9677 - val_loss: 0.4705 - val_accuracy: 0.9333\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3750 - accuracy: 0.9677 - val_loss: 0.4630 - val_accuracy: 0.9333\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3715 - accuracy: 0.9701 - val_loss: 0.4678 - val_accuracy: 0.9333\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3680 - accuracy: 0.9677 - val_loss: 0.4616 - val_accuracy: 0.9333\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3643 - accuracy: 0.9677 - val_loss: 0.4584 - val_accuracy: 0.9333\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3608 - accuracy: 0.9701 - val_loss: 0.4606 - val_accuracy: 0.9333\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3574 - accuracy: 0.9677 - val_loss: 0.4535 - val_accuracy: 0.9333\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3540 - accuracy: 0.9677 - val_loss: 0.4538 - val_accuracy: 0.9333\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3505 - accuracy: 0.9726 - val_loss: 0.4526 - val_accuracy: 0.9333\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3471 - accuracy: 0.9701 - val_loss: 0.4477 - val_accuracy: 0.9333\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3439 - accuracy: 0.9701 - val_loss: 0.4478 - val_accuracy: 0.9556\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3406 - accuracy: 0.9751 - val_loss: 0.4441 - val_accuracy: 0.9333\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3373 - accuracy: 0.9726 - val_loss: 0.4422 - val_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3342 - accuracy: 0.9726 - val_loss: 0.4421 - val_accuracy: 0.9556\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3311 - accuracy: 0.9751 - val_loss: 0.4368 - val_accuracy: 0.9556\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3279 - accuracy: 0.9751 - val_loss: 0.4373 - val_accuracy: 0.9556\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3248 - accuracy: 0.9751 - val_loss: 0.4350 - val_accuracy: 0.9556\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3218 - accuracy: 0.9751 - val_loss: 0.4310 - val_accuracy: 0.9556\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3187 - accuracy: 0.9751 - val_loss: 0.4323 - val_accuracy: 0.9556\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3158 - accuracy: 0.9751 - val_loss: 0.4286 - val_accuracy: 0.9556\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3128 - accuracy: 0.9751 - val_loss: 0.4254 - val_accuracy: 0.9556\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3099 - accuracy: 0.9776 - val_loss: 0.4269 - val_accuracy: 0.9556\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3070 - accuracy: 0.9776 - val_loss: 0.4223 - val_accuracy: 0.9556\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3041 - accuracy: 0.9776 - val_loss: 0.4209 - val_accuracy: 0.9556\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3013 - accuracy: 0.9801 - val_loss: 0.4209 - val_accuracy: 0.9556\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2985 - accuracy: 0.9776 - val_loss: 0.4158 - val_accuracy: 0.9556\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2958 - accuracy: 0.9801 - val_loss: 0.4163 - val_accuracy: 0.9556\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2931 - accuracy: 0.9826 - val_loss: 0.4145 - val_accuracy: 0.9556\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2904 - accuracy: 0.9801 - val_loss: 0.4121 - val_accuracy: 0.9556\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2877 - accuracy: 0.9826 - val_loss: 0.4110 - val_accuracy: 0.9556\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2851 - accuracy: 0.9826 - val_loss: 0.4090 - val_accuracy: 0.9556\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2825 - accuracy: 0.9851 - val_loss: 0.4072 - val_accuracy: 0.9556\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2799 - accuracy: 0.9851 - val_loss: 0.4056 - val_accuracy: 0.9556\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2774 - accuracy: 0.9851 - val_loss: 0.4050 - val_accuracy: 0.9556\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2748 - accuracy: 0.9851 - val_loss: 0.4015 - val_accuracy: 0.9556\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2724 - accuracy: 0.9900 - val_loss: 0.4013 - val_accuracy: 0.9556\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2699 - accuracy: 0.9900 - val_loss: 0.3997 - val_accuracy: 0.9556\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2675 - accuracy: 0.9900 - val_loss: 0.3968 - val_accuracy: 0.9556\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2651 - accuracy: 0.9900 - val_loss: 0.3971 - val_accuracy: 0.9556\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2627 - accuracy: 0.9900 - val_loss: 0.3946 - val_accuracy: 0.9556\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2604 - accuracy: 0.9900 - val_loss: 0.3930 - val_accuracy: 0.9556\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2580 - accuracy: 0.9900 - val_loss: 0.3917 - val_accuracy: 0.9556\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2558 - accuracy: 0.9900 - val_loss: 0.3897 - val_accuracy: 0.9556\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2535 - accuracy: 0.9925 - val_loss: 0.3891 - val_accuracy: 0.9556\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2512 - accuracy: 0.9950 - val_loss: 0.3865 - val_accuracy: 0.9556\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2490 - accuracy: 0.9950 - val_loss: 0.3859 - val_accuracy: 0.9556\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2468 - accuracy: 0.9950 - val_loss: 0.3846 - val_accuracy: 0.9556\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2447 - accuracy: 0.9950 - val_loss: 0.3822 - val_accuracy: 0.9556\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2425 - accuracy: 0.9950 - val_loss: 0.3824 - val_accuracy: 0.9556\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2404 - accuracy: 0.9950 - val_loss: 0.3803 - val_accuracy: 0.9556\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2383 - accuracy: 0.9950 - val_loss: 0.3785 - val_accuracy: 0.9556\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2363 - accuracy: 0.9950 - val_loss: 0.3778 - val_accuracy: 0.9556\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2342 - accuracy: 0.9950 - val_loss: 0.3756 - val_accuracy: 0.9556\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2322 - accuracy: 0.9950 - val_loss: 0.3747 - val_accuracy: 0.9556\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2302 - accuracy: 0.9950 - val_loss: 0.3740 - val_accuracy: 0.9556\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2282 - accuracy: 0.9950 - val_loss: 0.3720 - val_accuracy: 0.9556\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2263 - accuracy: 0.9950 - val_loss: 0.3710 - val_accuracy: 0.9556\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2243 - accuracy: 0.9950 - val_loss: 0.3700 - val_accuracy: 0.9556\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2224 - accuracy: 0.9950 - val_loss: 0.3685 - val_accuracy: 0.9556\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2205 - accuracy: 0.9950 - val_loss: 0.3673 - val_accuracy: 0.9556\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2187 - accuracy: 0.9950 - val_loss: 0.3659 - val_accuracy: 0.9556\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2168 - accuracy: 0.9950 - val_loss: 0.3650 - val_accuracy: 0.9556\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2150 - accuracy: 0.9950 - val_loss: 0.3634 - val_accuracy: 0.9556\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2132 - accuracy: 0.9950 - val_loss: 0.3630 - val_accuracy: 0.9556\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2114 - accuracy: 0.9950 - val_loss: 0.3616 - val_accuracy: 0.9556\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2097 - accuracy: 0.9950 - val_loss: 0.3600 - val_accuracy: 0.9556\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2079 - accuracy: 0.9950 - val_loss: 0.3592 - val_accuracy: 0.9556\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2062 - accuracy: 0.9950 - val_loss: 0.3575 - val_accuracy: 0.9556\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2045 - accuracy: 0.9950 - val_loss: 0.3568 - val_accuracy: 0.9556\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2028 - accuracy: 0.9950 - val_loss: 0.3557 - val_accuracy: 0.9556\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2011 - accuracy: 0.9950 - val_loss: 0.3548 - val_accuracy: 0.9556\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1995 - accuracy: 0.9950 - val_loss: 0.3534 - val_accuracy: 0.9556\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1979 - accuracy: 0.9950 - val_loss: 0.3524 - val_accuracy: 0.9556\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1962 - accuracy: 0.9950 - val_loss: 0.3521 - val_accuracy: 0.9556\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1947 - accuracy: 0.9950 - val_loss: 0.3497 - val_accuracy: 0.9556\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1931 - accuracy: 0.9950 - val_loss: 0.3497 - val_accuracy: 0.9556\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1915 - accuracy: 0.9950 - val_loss: 0.3478 - val_accuracy: 0.9556\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1900 - accuracy: 0.9950 - val_loss: 0.3465 - val_accuracy: 0.9556\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1885 - accuracy: 0.9950 - val_loss: 0.3470 - val_accuracy: 0.9556\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1869 - accuracy: 0.9950 - val_loss: 0.3448 - val_accuracy: 0.9556\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1855 - accuracy: 0.9950 - val_loss: 0.3439 - val_accuracy: 0.9556\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1840 - accuracy: 0.9950 - val_loss: 0.3438 - val_accuracy: 0.9556\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1825 - accuracy: 0.9950 - val_loss: 0.3425 - val_accuracy: 0.9556\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1811 - accuracy: 0.9950 - val_loss: 0.3408 - val_accuracy: 0.9556\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1796 - accuracy: 0.9950 - val_loss: 0.3403 - val_accuracy: 0.9556\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1782 - accuracy: 0.9950 - val_loss: 0.3395 - val_accuracy: 0.9556\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1768 - accuracy: 0.9950 - val_loss: 0.3384 - val_accuracy: 0.9556\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1755 - accuracy: 0.9950 - val_loss: 0.3385 - val_accuracy: 0.9556\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1741 - accuracy: 0.9950 - val_loss: 0.3361 - val_accuracy: 0.9556\n",
      "========== Fold 2 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.3160 - accuracy: 0.1119 - val_loss: 2.2978 - val_accuracy: 0.1333\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.3134 - accuracy: 0.1194 - val_loss: 2.2939 - val_accuracy: 0.1333\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.3093 - accuracy: 0.1194 - val_loss: 2.2890 - val_accuracy: 0.1333\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3041 - accuracy: 0.1194 - val_loss: 2.2834 - val_accuracy: 0.1333\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.2983 - accuracy: 0.1194 - val_loss: 2.2774 - val_accuracy: 0.1333\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2920 - accuracy: 0.1194 - val_loss: 2.2713 - val_accuracy: 0.1333\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2855 - accuracy: 0.1194 - val_loss: 2.2650 - val_accuracy: 0.1333\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2790 - accuracy: 0.1194 - val_loss: 2.2589 - val_accuracy: 0.1333\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2726 - accuracy: 0.1169 - val_loss: 2.2529 - val_accuracy: 0.1333\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2663 - accuracy: 0.1169 - val_loss: 2.2472 - val_accuracy: 0.1333\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2603 - accuracy: 0.1194 - val_loss: 2.2417 - val_accuracy: 0.1333\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2545 - accuracy: 0.1144 - val_loss: 2.2364 - val_accuracy: 0.1333\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2490 - accuracy: 0.1119 - val_loss: 2.2315 - val_accuracy: 0.1333\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2439 - accuracy: 0.1169 - val_loss: 2.2268 - val_accuracy: 0.1333\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2391 - accuracy: 0.1144 - val_loss: 2.2224 - val_accuracy: 0.1333\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2346 - accuracy: 0.1045 - val_loss: 2.2183 - val_accuracy: 0.1556\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2304 - accuracy: 0.1269 - val_loss: 2.2143 - val_accuracy: 0.1556\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2265 - accuracy: 0.1493 - val_loss: 2.2106 - val_accuracy: 0.1778\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2228 - accuracy: 0.1667 - val_loss: 2.2071 - val_accuracy: 0.1778\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2194 - accuracy: 0.1741 - val_loss: 2.2038 - val_accuracy: 0.1556\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2163 - accuracy: 0.1692 - val_loss: 2.2006 - val_accuracy: 0.1111\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2133 - accuracy: 0.1716 - val_loss: 2.1976 - val_accuracy: 0.0889\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2106 - accuracy: 0.1692 - val_loss: 2.1946 - val_accuracy: 0.0889\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2080 - accuracy: 0.1667 - val_loss: 2.1918 - val_accuracy: 0.0889\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2056 - accuracy: 0.1692 - val_loss: 2.1891 - val_accuracy: 0.0889\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2033 - accuracy: 0.1692 - val_loss: 2.1864 - val_accuracy: 0.0889\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2011 - accuracy: 0.1692 - val_loss: 2.1838 - val_accuracy: 0.0889\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1991 - accuracy: 0.1692 - val_loss: 2.1813 - val_accuracy: 0.0889\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1971 - accuracy: 0.1692 - val_loss: 2.1789 - val_accuracy: 0.0889\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1952 - accuracy: 0.1692 - val_loss: 2.1766 - val_accuracy: 0.0889\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1935 - accuracy: 0.1692 - val_loss: 2.1743 - val_accuracy: 0.0889\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1918 - accuracy: 0.1692 - val_loss: 2.1720 - val_accuracy: 0.0889\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1902 - accuracy: 0.1692 - val_loss: 2.1699 - val_accuracy: 0.0889\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1886 - accuracy: 0.1692 - val_loss: 2.1678 - val_accuracy: 0.0889\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1871 - accuracy: 0.1692 - val_loss: 2.1658 - val_accuracy: 0.1111\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1857 - accuracy: 0.1692 - val_loss: 2.1638 - val_accuracy: 0.1111\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1843 - accuracy: 0.1692 - val_loss: 2.1620 - val_accuracy: 0.1111\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1830 - accuracy: 0.1716 - val_loss: 2.1602 - val_accuracy: 0.1333\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1817 - accuracy: 0.1741 - val_loss: 2.1585 - val_accuracy: 0.1333\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1805 - accuracy: 0.1766 - val_loss: 2.1569 - val_accuracy: 0.1333\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1793 - accuracy: 0.1816 - val_loss: 2.1554 - val_accuracy: 0.1556\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1782 - accuracy: 0.1816 - val_loss: 2.1539 - val_accuracy: 0.1556\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1771 - accuracy: 0.1841 - val_loss: 2.1525 - val_accuracy: 0.1556\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1760 - accuracy: 0.1841 - val_loss: 2.1512 - val_accuracy: 0.1556\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1749 - accuracy: 0.1891 - val_loss: 2.1499 - val_accuracy: 0.1556\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1739 - accuracy: 0.1915 - val_loss: 2.1487 - val_accuracy: 0.1556\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1729 - accuracy: 0.1915 - val_loss: 2.1475 - val_accuracy: 0.1556\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1719 - accuracy: 0.1915 - val_loss: 2.1464 - val_accuracy: 0.1556\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1710 - accuracy: 0.1915 - val_loss: 2.1454 - val_accuracy: 0.1556\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1700 - accuracy: 0.1940 - val_loss: 2.1444 - val_accuracy: 0.1556\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1691 - accuracy: 0.1940 - val_loss: 2.1434 - val_accuracy: 0.1333\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1682 - accuracy: 0.1940 - val_loss: 2.1425 - val_accuracy: 0.1333\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1673 - accuracy: 0.1940 - val_loss: 2.1416 - val_accuracy: 0.1333\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1664 - accuracy: 0.1940 - val_loss: 2.1408 - val_accuracy: 0.1333\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1656 - accuracy: 0.1940 - val_loss: 2.1399 - val_accuracy: 0.1333\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1647 - accuracy: 0.1940 - val_loss: 2.1391 - val_accuracy: 0.1333\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1639 - accuracy: 0.1940 - val_loss: 2.1383 - val_accuracy: 0.1333\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1630 - accuracy: 0.1915 - val_loss: 2.1375 - val_accuracy: 0.1333\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1622 - accuracy: 0.1915 - val_loss: 2.1367 - val_accuracy: 0.1333\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1614 - accuracy: 0.1940 - val_loss: 2.1360 - val_accuracy: 0.1333\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1606 - accuracy: 0.1940 - val_loss: 2.1352 - val_accuracy: 0.1556\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1598 - accuracy: 0.1940 - val_loss: 2.1344 - val_accuracy: 0.1556\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1590 - accuracy: 0.1891 - val_loss: 2.1337 - val_accuracy: 0.1778\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1582 - accuracy: 0.1891 - val_loss: 2.1329 - val_accuracy: 0.1778\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1574 - accuracy: 0.1915 - val_loss: 2.1321 - val_accuracy: 0.1778\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1566 - accuracy: 0.1915 - val_loss: 2.1313 - val_accuracy: 0.1778\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1558 - accuracy: 0.1915 - val_loss: 2.1305 - val_accuracy: 0.1778\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1550 - accuracy: 0.1940 - val_loss: 2.1297 - val_accuracy: 0.1778\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1543 - accuracy: 0.1965 - val_loss: 2.1289 - val_accuracy: 0.1778\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1535 - accuracy: 0.1965 - val_loss: 2.1281 - val_accuracy: 0.1778\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1527 - accuracy: 0.1965 - val_loss: 2.1273 - val_accuracy: 0.1778\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1519 - accuracy: 0.1965 - val_loss: 2.1265 - val_accuracy: 0.1778\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1512 - accuracy: 0.1965 - val_loss: 2.1257 - val_accuracy: 0.1556\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1504 - accuracy: 0.1965 - val_loss: 2.1249 - val_accuracy: 0.1556\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1496 - accuracy: 0.1990 - val_loss: 2.1241 - val_accuracy: 0.1556\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1488 - accuracy: 0.2040 - val_loss: 2.1233 - val_accuracy: 0.1556\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1481 - accuracy: 0.2065 - val_loss: 2.1225 - val_accuracy: 0.1556\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1473 - accuracy: 0.2114 - val_loss: 2.1217 - val_accuracy: 0.1556\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1465 - accuracy: 0.2114 - val_loss: 2.1209 - val_accuracy: 0.1556\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1457 - accuracy: 0.2114 - val_loss: 2.1201 - val_accuracy: 0.1556\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1449 - accuracy: 0.2114 - val_loss: 2.1193 - val_accuracy: 0.1556\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1441 - accuracy: 0.2139 - val_loss: 2.1185 - val_accuracy: 0.1556\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1434 - accuracy: 0.2139 - val_loss: 2.1178 - val_accuracy: 0.1556\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1426 - accuracy: 0.2164 - val_loss: 2.1170 - val_accuracy: 0.1556\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1418 - accuracy: 0.2164 - val_loss: 2.1162 - val_accuracy: 0.1556\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1410 - accuracy: 0.2164 - val_loss: 2.1155 - val_accuracy: 0.1556\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1401 - accuracy: 0.2164 - val_loss: 2.1147 - val_accuracy: 0.1556\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1393 - accuracy: 0.2164 - val_loss: 2.1140 - val_accuracy: 0.1778\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1385 - accuracy: 0.2164 - val_loss: 2.1132 - val_accuracy: 0.1778\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1377 - accuracy: 0.2164 - val_loss: 2.1125 - val_accuracy: 0.1778\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1369 - accuracy: 0.2164 - val_loss: 2.1117 - val_accuracy: 0.1778\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1360 - accuracy: 0.2189 - val_loss: 2.1110 - val_accuracy: 0.1778\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1352 - accuracy: 0.2189 - val_loss: 2.1103 - val_accuracy: 0.1778\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1343 - accuracy: 0.2189 - val_loss: 2.1095 - val_accuracy: 0.1778\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1335 - accuracy: 0.2189 - val_loss: 2.1088 - val_accuracy: 0.1778\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1326 - accuracy: 0.2189 - val_loss: 2.1081 - val_accuracy: 0.1778\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.1317 - accuracy: 0.2189 - val_loss: 2.1073 - val_accuracy: 0.1778\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1308 - accuracy: 0.2189 - val_loss: 2.1066 - val_accuracy: 0.1778\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1300 - accuracy: 0.2189 - val_loss: 2.1058 - val_accuracy: 0.1778\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1291 - accuracy: 0.2189 - val_loss: 2.1051 - val_accuracy: 0.1778\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1282 - accuracy: 0.2189 - val_loss: 2.1043 - val_accuracy: 0.1778\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1272 - accuracy: 0.2189 - val_loss: 2.1036 - val_accuracy: 0.1778\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1263 - accuracy: 0.2189 - val_loss: 2.1028 - val_accuracy: 0.1778\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1254 - accuracy: 0.2164 - val_loss: 2.1020 - val_accuracy: 0.1778\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1244 - accuracy: 0.2164 - val_loss: 2.1012 - val_accuracy: 0.1778\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1235 - accuracy: 0.2164 - val_loss: 2.1004 - val_accuracy: 0.1778\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1225 - accuracy: 0.2189 - val_loss: 2.0996 - val_accuracy: 0.1778\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1216 - accuracy: 0.2189 - val_loss: 2.0988 - val_accuracy: 0.1778\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1206 - accuracy: 0.2189 - val_loss: 2.0980 - val_accuracy: 0.1778\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1196 - accuracy: 0.2214 - val_loss: 2.0972 - val_accuracy: 0.2000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1186 - accuracy: 0.2189 - val_loss: 2.0964 - val_accuracy: 0.2000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1176 - accuracy: 0.2189 - val_loss: 2.0955 - val_accuracy: 0.2000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1165 - accuracy: 0.2189 - val_loss: 2.0947 - val_accuracy: 0.2000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1155 - accuracy: 0.2189 - val_loss: 2.0938 - val_accuracy: 0.2000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1144 - accuracy: 0.2214 - val_loss: 2.0930 - val_accuracy: 0.2222\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1134 - accuracy: 0.2214 - val_loss: 2.0921 - val_accuracy: 0.2000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1123 - accuracy: 0.2214 - val_loss: 2.0912 - val_accuracy: 0.2000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1112 - accuracy: 0.2264 - val_loss: 2.0904 - val_accuracy: 0.2000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1101 - accuracy: 0.2338 - val_loss: 2.0895 - val_accuracy: 0.2000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1090 - accuracy: 0.2338 - val_loss: 2.0886 - val_accuracy: 0.2000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1079 - accuracy: 0.2338 - val_loss: 2.0877 - val_accuracy: 0.2000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1067 - accuracy: 0.2289 - val_loss: 2.0869 - val_accuracy: 0.2000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1056 - accuracy: 0.2289 - val_loss: 2.0860 - val_accuracy: 0.2000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1044 - accuracy: 0.2289 - val_loss: 2.0850 - val_accuracy: 0.2000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1032 - accuracy: 0.2289 - val_loss: 2.0841 - val_accuracy: 0.2000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1020 - accuracy: 0.2264 - val_loss: 2.0832 - val_accuracy: 0.2000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1008 - accuracy: 0.2289 - val_loss: 2.0823 - val_accuracy: 0.2000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0996 - accuracy: 0.2289 - val_loss: 2.0814 - val_accuracy: 0.2222\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0984 - accuracy: 0.2289 - val_loss: 2.0805 - val_accuracy: 0.2222\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0971 - accuracy: 0.2338 - val_loss: 2.0795 - val_accuracy: 0.2222\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0959 - accuracy: 0.2338 - val_loss: 2.0786 - val_accuracy: 0.2222\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0946 - accuracy: 0.2438 - val_loss: 2.0776 - val_accuracy: 0.2222\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0933 - accuracy: 0.2463 - val_loss: 2.0767 - val_accuracy: 0.2222\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0920 - accuracy: 0.2463 - val_loss: 2.0758 - val_accuracy: 0.2444\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0907 - accuracy: 0.2488 - val_loss: 2.0749 - val_accuracy: 0.2667\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0894 - accuracy: 0.2537 - val_loss: 2.0739 - val_accuracy: 0.2667\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0880 - accuracy: 0.2537 - val_loss: 2.0730 - val_accuracy: 0.2667\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0867 - accuracy: 0.2587 - val_loss: 2.0720 - val_accuracy: 0.2667\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0853 - accuracy: 0.2637 - val_loss: 2.0710 - val_accuracy: 0.2667\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0839 - accuracy: 0.2637 - val_loss: 2.0701 - val_accuracy: 0.2667\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0825 - accuracy: 0.2637 - val_loss: 2.0691 - val_accuracy: 0.2667\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0811 - accuracy: 0.2662 - val_loss: 2.0682 - val_accuracy: 0.2667\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0797 - accuracy: 0.2637 - val_loss: 2.0672 - val_accuracy: 0.2667\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0782 - accuracy: 0.2637 - val_loss: 2.0663 - val_accuracy: 0.2667\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0768 - accuracy: 0.2612 - val_loss: 2.0653 - val_accuracy: 0.2667\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0753 - accuracy: 0.2612 - val_loss: 2.0643 - val_accuracy: 0.2444\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0739 - accuracy: 0.2537 - val_loss: 2.0634 - val_accuracy: 0.2444\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0724 - accuracy: 0.2537 - val_loss: 2.0625 - val_accuracy: 0.2444\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0709 - accuracy: 0.2562 - val_loss: 2.0615 - val_accuracy: 0.2444\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0694 - accuracy: 0.2562 - val_loss: 2.0606 - val_accuracy: 0.2444\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0679 - accuracy: 0.2612 - val_loss: 2.0596 - val_accuracy: 0.2444\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0664 - accuracy: 0.2612 - val_loss: 2.0587 - val_accuracy: 0.2444\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0648 - accuracy: 0.2637 - val_loss: 2.0577 - val_accuracy: 0.2444\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0633 - accuracy: 0.2637 - val_loss: 2.0568 - val_accuracy: 0.2444\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0617 - accuracy: 0.2612 - val_loss: 2.0559 - val_accuracy: 0.2444\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0602 - accuracy: 0.2662 - val_loss: 2.0550 - val_accuracy: 0.2444\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0586 - accuracy: 0.2662 - val_loss: 2.0540 - val_accuracy: 0.2444\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0570 - accuracy: 0.2662 - val_loss: 2.0531 - val_accuracy: 0.2444\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0554 - accuracy: 0.2687 - val_loss: 2.0522 - val_accuracy: 0.2444\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0538 - accuracy: 0.2736 - val_loss: 2.0513 - val_accuracy: 0.2444\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0522 - accuracy: 0.2711 - val_loss: 2.0504 - val_accuracy: 0.2444\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0506 - accuracy: 0.2687 - val_loss: 2.0496 - val_accuracy: 0.2222\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0490 - accuracy: 0.2687 - val_loss: 2.0487 - val_accuracy: 0.2222\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0473 - accuracy: 0.2687 - val_loss: 2.0478 - val_accuracy: 0.2222\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0457 - accuracy: 0.2711 - val_loss: 2.0469 - val_accuracy: 0.2222\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0440 - accuracy: 0.2687 - val_loss: 2.0460 - val_accuracy: 0.2222\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0424 - accuracy: 0.2711 - val_loss: 2.0452 - val_accuracy: 0.2222\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0407 - accuracy: 0.2687 - val_loss: 2.0444 - val_accuracy: 0.2222\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0390 - accuracy: 0.2687 - val_loss: 2.0435 - val_accuracy: 0.2222\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0373 - accuracy: 0.2687 - val_loss: 2.0427 - val_accuracy: 0.2222\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0356 - accuracy: 0.2687 - val_loss: 2.0418 - val_accuracy: 0.2222\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0339 - accuracy: 0.2687 - val_loss: 2.0410 - val_accuracy: 0.2222\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0321 - accuracy: 0.2687 - val_loss: 2.0402 - val_accuracy: 0.2222\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0304 - accuracy: 0.2711 - val_loss: 2.0394 - val_accuracy: 0.2222\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0287 - accuracy: 0.2711 - val_loss: 2.0386 - val_accuracy: 0.2222\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0269 - accuracy: 0.2736 - val_loss: 2.0378 - val_accuracy: 0.2222\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0251 - accuracy: 0.2786 - val_loss: 2.0370 - val_accuracy: 0.2222\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0233 - accuracy: 0.2786 - val_loss: 2.0362 - val_accuracy: 0.2222\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0215 - accuracy: 0.2836 - val_loss: 2.0354 - val_accuracy: 0.2222\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0197 - accuracy: 0.2836 - val_loss: 2.0346 - val_accuracy: 0.2444\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0178 - accuracy: 0.2861 - val_loss: 2.0339 - val_accuracy: 0.2444\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0159 - accuracy: 0.2886 - val_loss: 2.0331 - val_accuracy: 0.2444\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0140 - accuracy: 0.2886 - val_loss: 2.0323 - val_accuracy: 0.2444\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0121 - accuracy: 0.2910 - val_loss: 2.0316 - val_accuracy: 0.2444\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0102 - accuracy: 0.2960 - val_loss: 2.0308 - val_accuracy: 0.2444\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0083 - accuracy: 0.2960 - val_loss: 2.0301 - val_accuracy: 0.2444\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0063 - accuracy: 0.2960 - val_loss: 2.0294 - val_accuracy: 0.2444\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0043 - accuracy: 0.2935 - val_loss: 2.0287 - val_accuracy: 0.2444\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0023 - accuracy: 0.2910 - val_loss: 2.0280 - val_accuracy: 0.2444\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0002 - accuracy: 0.2910 - val_loss: 2.0273 - val_accuracy: 0.2444\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9981 - accuracy: 0.2935 - val_loss: 2.0267 - val_accuracy: 0.2444\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9960 - accuracy: 0.2910 - val_loss: 2.0260 - val_accuracy: 0.2444\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9939 - accuracy: 0.2910 - val_loss: 2.0253 - val_accuracy: 0.2444\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9918 - accuracy: 0.2910 - val_loss: 2.0247 - val_accuracy: 0.2444\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9896 - accuracy: 0.2886 - val_loss: 2.0241 - val_accuracy: 0.2444\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9874 - accuracy: 0.2910 - val_loss: 2.0235 - val_accuracy: 0.2444\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9851 - accuracy: 0.2910 - val_loss: 2.0229 - val_accuracy: 0.2667\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9829 - accuracy: 0.2910 - val_loss: 2.0224 - val_accuracy: 0.2444\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9806 - accuracy: 0.2935 - val_loss: 2.0219 - val_accuracy: 0.2444\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9782 - accuracy: 0.2960 - val_loss: 2.0214 - val_accuracy: 0.2444\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9759 - accuracy: 0.2985 - val_loss: 2.0210 - val_accuracy: 0.2444\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9735 - accuracy: 0.2960 - val_loss: 2.0205 - val_accuracy: 0.2444\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9711 - accuracy: 0.2935 - val_loss: 2.0201 - val_accuracy: 0.2444\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9686 - accuracy: 0.2935 - val_loss: 2.0198 - val_accuracy: 0.2444\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9662 - accuracy: 0.2960 - val_loss: 2.0194 - val_accuracy: 0.2444\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9637 - accuracy: 0.2985 - val_loss: 2.0192 - val_accuracy: 0.2444\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9612 - accuracy: 0.3010 - val_loss: 2.0189 - val_accuracy: 0.2444\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9586 - accuracy: 0.3035 - val_loss: 2.0187 - val_accuracy: 0.2444\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9561 - accuracy: 0.3035 - val_loss: 2.0186 - val_accuracy: 0.2444\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9535 - accuracy: 0.3035 - val_loss: 2.0185 - val_accuracy: 0.2444\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9509 - accuracy: 0.3035 - val_loss: 2.0184 - val_accuracy: 0.2444\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9482 - accuracy: 0.3035 - val_loss: 2.0184 - val_accuracy: 0.2444\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9456 - accuracy: 0.3010 - val_loss: 2.0184 - val_accuracy: 0.2444\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9430 - accuracy: 0.3010 - val_loss: 2.0185 - val_accuracy: 0.2667\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.9403 - accuracy: 0.3035 - val_loss: 2.0187 - val_accuracy: 0.2667\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9377 - accuracy: 0.3010 - val_loss: 2.0189 - val_accuracy: 0.2667\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9350 - accuracy: 0.3060 - val_loss: 2.0192 - val_accuracy: 0.2667\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9323 - accuracy: 0.3085 - val_loss: 2.0195 - val_accuracy: 0.2667\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9297 - accuracy: 0.3085 - val_loss: 2.0199 - val_accuracy: 0.2667\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9270 - accuracy: 0.3085 - val_loss: 2.0203 - val_accuracy: 0.2889\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9244 - accuracy: 0.3085 - val_loss: 2.0208 - val_accuracy: 0.2889\n",
      "========== Fold 3 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.3808 - accuracy: 0.0995 - val_loss: 2.3298 - val_accuracy: 0.1556\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.3762 - accuracy: 0.0995 - val_loss: 2.3240 - val_accuracy: 0.1556\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3687 - accuracy: 0.0995 - val_loss: 2.3168 - val_accuracy: 0.1556\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3594 - accuracy: 0.0995 - val_loss: 2.3088 - val_accuracy: 0.1556\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3488 - accuracy: 0.0970 - val_loss: 2.3002 - val_accuracy: 0.1556\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.3376 - accuracy: 0.0970 - val_loss: 2.2916 - val_accuracy: 0.1556\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.3260 - accuracy: 0.0970 - val_loss: 2.2832 - val_accuracy: 0.1556\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3144 - accuracy: 0.0995 - val_loss: 2.2750 - val_accuracy: 0.1556\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3030 - accuracy: 0.0995 - val_loss: 2.2673 - val_accuracy: 0.1111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2921 - accuracy: 0.1119 - val_loss: 2.2602 - val_accuracy: 0.1556\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2816 - accuracy: 0.1269 - val_loss: 2.2536 - val_accuracy: 0.1556\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2718 - accuracy: 0.1468 - val_loss: 2.2477 - val_accuracy: 0.1556\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2627 - accuracy: 0.1418 - val_loss: 2.2424 - val_accuracy: 0.1556\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2542 - accuracy: 0.1443 - val_loss: 2.2378 - val_accuracy: 0.1778\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2464 - accuracy: 0.1443 - val_loss: 2.2337 - val_accuracy: 0.1333\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2393 - accuracy: 0.1517 - val_loss: 2.2302 - val_accuracy: 0.1556\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2329 - accuracy: 0.1443 - val_loss: 2.2272 - val_accuracy: 0.1556\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2271 - accuracy: 0.1418 - val_loss: 2.2246 - val_accuracy: 0.1333\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2219 - accuracy: 0.1418 - val_loss: 2.2225 - val_accuracy: 0.1333\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2172 - accuracy: 0.1343 - val_loss: 2.2207 - val_accuracy: 0.1333\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2131 - accuracy: 0.1368 - val_loss: 2.2192 - val_accuracy: 0.1556\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2093 - accuracy: 0.1542 - val_loss: 2.2179 - val_accuracy: 0.1556\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2060 - accuracy: 0.1741 - val_loss: 2.2168 - val_accuracy: 0.1556\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2030 - accuracy: 0.1667 - val_loss: 2.2158 - val_accuracy: 0.1333\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2003 - accuracy: 0.1716 - val_loss: 2.2149 - val_accuracy: 0.1111\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1979 - accuracy: 0.1692 - val_loss: 2.2141 - val_accuracy: 0.0889\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1957 - accuracy: 0.1667 - val_loss: 2.2133 - val_accuracy: 0.0889\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1937 - accuracy: 0.1542 - val_loss: 2.2125 - val_accuracy: 0.0889\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1918 - accuracy: 0.1592 - val_loss: 2.2116 - val_accuracy: 0.0889\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1900 - accuracy: 0.1592 - val_loss: 2.2106 - val_accuracy: 0.0889\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1883 - accuracy: 0.1592 - val_loss: 2.2096 - val_accuracy: 0.0889\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1867 - accuracy: 0.1592 - val_loss: 2.2085 - val_accuracy: 0.0889\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1851 - accuracy: 0.1617 - val_loss: 2.2073 - val_accuracy: 0.0889\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1836 - accuracy: 0.1617 - val_loss: 2.2059 - val_accuracy: 0.0889\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1821 - accuracy: 0.1592 - val_loss: 2.2046 - val_accuracy: 0.0889\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1806 - accuracy: 0.1592 - val_loss: 2.2031 - val_accuracy: 0.0889\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1791 - accuracy: 0.1592 - val_loss: 2.2015 - val_accuracy: 0.0889\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1777 - accuracy: 0.1592 - val_loss: 2.1999 - val_accuracy: 0.0889\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1763 - accuracy: 0.1617 - val_loss: 2.1983 - val_accuracy: 0.0889\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1749 - accuracy: 0.1617 - val_loss: 2.1965 - val_accuracy: 0.0889\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1735 - accuracy: 0.1617 - val_loss: 2.1948 - val_accuracy: 0.0889\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1722 - accuracy: 0.1617 - val_loss: 2.1931 - val_accuracy: 0.0889\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1708 - accuracy: 0.1642 - val_loss: 2.1914 - val_accuracy: 0.0889\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1695 - accuracy: 0.1642 - val_loss: 2.1896 - val_accuracy: 0.0889\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1683 - accuracy: 0.1642 - val_loss: 2.1879 - val_accuracy: 0.0889\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1670 - accuracy: 0.1642 - val_loss: 2.1863 - val_accuracy: 0.0889\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1658 - accuracy: 0.1617 - val_loss: 2.1846 - val_accuracy: 0.0889\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1647 - accuracy: 0.1642 - val_loss: 2.1830 - val_accuracy: 0.1111\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1635 - accuracy: 0.1716 - val_loss: 2.1814 - val_accuracy: 0.1111\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1624 - accuracy: 0.1766 - val_loss: 2.1799 - val_accuracy: 0.1111\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1613 - accuracy: 0.1791 - val_loss: 2.1784 - val_accuracy: 0.1111\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1602 - accuracy: 0.1791 - val_loss: 2.1770 - val_accuracy: 0.1111\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1592 - accuracy: 0.1816 - val_loss: 2.1757 - val_accuracy: 0.1333\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1582 - accuracy: 0.1816 - val_loss: 2.1743 - val_accuracy: 0.1333\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1572 - accuracy: 0.1816 - val_loss: 2.1730 - val_accuracy: 0.1333\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1562 - accuracy: 0.1816 - val_loss: 2.1718 - val_accuracy: 0.1333\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1552 - accuracy: 0.1816 - val_loss: 2.1707 - val_accuracy: 0.1333\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1542 - accuracy: 0.1841 - val_loss: 2.1695 - val_accuracy: 0.1333\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1533 - accuracy: 0.1841 - val_loss: 2.1684 - val_accuracy: 0.1333\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1523 - accuracy: 0.1866 - val_loss: 2.1674 - val_accuracy: 0.1333\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1514 - accuracy: 0.1915 - val_loss: 2.1663 - val_accuracy: 0.1333\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1505 - accuracy: 0.1990 - val_loss: 2.1654 - val_accuracy: 0.1333\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1495 - accuracy: 0.1965 - val_loss: 2.1644 - val_accuracy: 0.1333\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1486 - accuracy: 0.1990 - val_loss: 2.1635 - val_accuracy: 0.1333\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1477 - accuracy: 0.2015 - val_loss: 2.1626 - val_accuracy: 0.1333\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1467 - accuracy: 0.2040 - val_loss: 2.1617 - val_accuracy: 0.1333\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1458 - accuracy: 0.2090 - val_loss: 2.1608 - val_accuracy: 0.1333\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1449 - accuracy: 0.2114 - val_loss: 2.1600 - val_accuracy: 0.1556\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1440 - accuracy: 0.2114 - val_loss: 2.1591 - val_accuracy: 0.1556\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1430 - accuracy: 0.2114 - val_loss: 2.1582 - val_accuracy: 0.1556\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1421 - accuracy: 0.2114 - val_loss: 2.1574 - val_accuracy: 0.1556\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1411 - accuracy: 0.2164 - val_loss: 2.1566 - val_accuracy: 0.1556\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1402 - accuracy: 0.2164 - val_loss: 2.1558 - val_accuracy: 0.1778\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1393 - accuracy: 0.2214 - val_loss: 2.1549 - val_accuracy: 0.1778\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1383 - accuracy: 0.2189 - val_loss: 2.1540 - val_accuracy: 0.1778\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1373 - accuracy: 0.2189 - val_loss: 2.1532 - val_accuracy: 0.1778\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1364 - accuracy: 0.2189 - val_loss: 2.1523 - val_accuracy: 0.1778\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1354 - accuracy: 0.2189 - val_loss: 2.1515 - val_accuracy: 0.1778\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1344 - accuracy: 0.2239 - val_loss: 2.1506 - val_accuracy: 0.1778\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1334 - accuracy: 0.2239 - val_loss: 2.1497 - val_accuracy: 0.2000\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1324 - accuracy: 0.2239 - val_loss: 2.1488 - val_accuracy: 0.2000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1314 - accuracy: 0.2264 - val_loss: 2.1478 - val_accuracy: 0.2000\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1304 - accuracy: 0.2264 - val_loss: 2.1469 - val_accuracy: 0.2000\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1294 - accuracy: 0.2264 - val_loss: 2.1459 - val_accuracy: 0.2222\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1284 - accuracy: 0.2264 - val_loss: 2.1450 - val_accuracy: 0.2222\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1273 - accuracy: 0.2264 - val_loss: 2.1440 - val_accuracy: 0.2222\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1263 - accuracy: 0.2239 - val_loss: 2.1430 - val_accuracy: 0.2222\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1252 - accuracy: 0.2239 - val_loss: 2.1419 - val_accuracy: 0.2222\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1241 - accuracy: 0.2264 - val_loss: 2.1409 - val_accuracy: 0.2444\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1231 - accuracy: 0.2313 - val_loss: 2.1399 - val_accuracy: 0.2444\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1220 - accuracy: 0.2313 - val_loss: 2.1388 - val_accuracy: 0.2444\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1209 - accuracy: 0.2363 - val_loss: 2.1377 - val_accuracy: 0.2444\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1197 - accuracy: 0.2338 - val_loss: 2.1366 - val_accuracy: 0.2444\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1186 - accuracy: 0.2363 - val_loss: 2.1355 - val_accuracy: 0.2444\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1175 - accuracy: 0.2338 - val_loss: 2.1344 - val_accuracy: 0.2444\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1163 - accuracy: 0.2338 - val_loss: 2.1332 - val_accuracy: 0.2444\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1152 - accuracy: 0.2338 - val_loss: 2.1321 - val_accuracy: 0.2444\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1140 - accuracy: 0.2338 - val_loss: 2.1310 - val_accuracy: 0.2444\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1128 - accuracy: 0.2338 - val_loss: 2.1298 - val_accuracy: 0.2444\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1116 - accuracy: 0.2363 - val_loss: 2.1286 - val_accuracy: 0.2444\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1104 - accuracy: 0.2388 - val_loss: 2.1275 - val_accuracy: 0.2444\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1092 - accuracy: 0.2413 - val_loss: 2.1263 - val_accuracy: 0.2444\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1079 - accuracy: 0.2413 - val_loss: 2.1251 - val_accuracy: 0.2444\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1067 - accuracy: 0.2388 - val_loss: 2.1239 - val_accuracy: 0.2444\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1054 - accuracy: 0.2413 - val_loss: 2.1227 - val_accuracy: 0.2444\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1042 - accuracy: 0.2413 - val_loss: 2.1215 - val_accuracy: 0.2444\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1029 - accuracy: 0.2388 - val_loss: 2.1203 - val_accuracy: 0.2444\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1016 - accuracy: 0.2413 - val_loss: 2.1191 - val_accuracy: 0.2444\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1003 - accuracy: 0.2413 - val_loss: 2.1179 - val_accuracy: 0.2444\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0990 - accuracy: 0.2463 - val_loss: 2.1167 - val_accuracy: 0.2444\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0977 - accuracy: 0.2463 - val_loss: 2.1155 - val_accuracy: 0.2444\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0964 - accuracy: 0.2488 - val_loss: 2.1143 - val_accuracy: 0.2444\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0951 - accuracy: 0.2512 - val_loss: 2.1131 - val_accuracy: 0.2444\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0938 - accuracy: 0.2512 - val_loss: 2.1118 - val_accuracy: 0.2444\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0925 - accuracy: 0.2463 - val_loss: 2.1106 - val_accuracy: 0.2444\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0911 - accuracy: 0.2438 - val_loss: 2.1094 - val_accuracy: 0.2444\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0898 - accuracy: 0.2438 - val_loss: 2.1082 - val_accuracy: 0.2444\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0884 - accuracy: 0.2463 - val_loss: 2.1070 - val_accuracy: 0.2444\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0871 - accuracy: 0.2463 - val_loss: 2.1058 - val_accuracy: 0.2444\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0858 - accuracy: 0.2488 - val_loss: 2.1046 - val_accuracy: 0.2444\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0844 - accuracy: 0.2488 - val_loss: 2.1034 - val_accuracy: 0.2667\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0831 - accuracy: 0.2488 - val_loss: 2.1021 - val_accuracy: 0.2444\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0817 - accuracy: 0.2512 - val_loss: 2.1010 - val_accuracy: 0.2444\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0804 - accuracy: 0.2488 - val_loss: 2.0998 - val_accuracy: 0.2444\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0790 - accuracy: 0.2512 - val_loss: 2.0986 - val_accuracy: 0.2444\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0777 - accuracy: 0.2512 - val_loss: 2.0974 - val_accuracy: 0.2444\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0764 - accuracy: 0.2537 - val_loss: 2.0962 - val_accuracy: 0.2444\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0750 - accuracy: 0.2537 - val_loss: 2.0951 - val_accuracy: 0.2444\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0737 - accuracy: 0.2562 - val_loss: 2.0939 - val_accuracy: 0.2444\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0724 - accuracy: 0.2587 - val_loss: 2.0927 - val_accuracy: 0.2444\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0711 - accuracy: 0.2612 - val_loss: 2.0916 - val_accuracy: 0.2667\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0698 - accuracy: 0.2637 - val_loss: 2.0905 - val_accuracy: 0.2667\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0685 - accuracy: 0.2662 - val_loss: 2.0894 - val_accuracy: 0.2667\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0672 - accuracy: 0.2662 - val_loss: 2.0883 - val_accuracy: 0.2667\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0659 - accuracy: 0.2662 - val_loss: 2.0872 - val_accuracy: 0.2667\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0646 - accuracy: 0.2711 - val_loss: 2.0861 - val_accuracy: 0.2667\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0633 - accuracy: 0.2711 - val_loss: 2.0850 - val_accuracy: 0.2444\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0621 - accuracy: 0.2711 - val_loss: 2.0840 - val_accuracy: 0.2444\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0608 - accuracy: 0.2711 - val_loss: 2.0829 - val_accuracy: 0.2667\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0596 - accuracy: 0.2711 - val_loss: 2.0819 - val_accuracy: 0.2667\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0583 - accuracy: 0.2711 - val_loss: 2.0808 - val_accuracy: 0.2667\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0571 - accuracy: 0.2711 - val_loss: 2.0798 - val_accuracy: 0.2444\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0558 - accuracy: 0.2662 - val_loss: 2.0788 - val_accuracy: 0.2444\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0546 - accuracy: 0.2662 - val_loss: 2.0778 - val_accuracy: 0.2444\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0534 - accuracy: 0.2662 - val_loss: 2.0768 - val_accuracy: 0.2444\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0522 - accuracy: 0.2662 - val_loss: 2.0758 - val_accuracy: 0.2444\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0509 - accuracy: 0.2687 - val_loss: 2.0748 - val_accuracy: 0.2444\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0497 - accuracy: 0.2662 - val_loss: 2.0738 - val_accuracy: 0.2444\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0485 - accuracy: 0.2662 - val_loss: 2.0729 - val_accuracy: 0.2444\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0473 - accuracy: 0.2662 - val_loss: 2.0719 - val_accuracy: 0.2444\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0461 - accuracy: 0.2662 - val_loss: 2.0709 - val_accuracy: 0.2444\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0449 - accuracy: 0.2662 - val_loss: 2.0699 - val_accuracy: 0.2444\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0437 - accuracy: 0.2662 - val_loss: 2.0690 - val_accuracy: 0.2444\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0425 - accuracy: 0.2662 - val_loss: 2.0680 - val_accuracy: 0.2667\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0413 - accuracy: 0.2687 - val_loss: 2.0670 - val_accuracy: 0.2667\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0400 - accuracy: 0.2711 - val_loss: 2.0660 - val_accuracy: 0.2667\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0388 - accuracy: 0.2711 - val_loss: 2.0651 - val_accuracy: 0.2667\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0376 - accuracy: 0.2687 - val_loss: 2.0641 - val_accuracy: 0.2667\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0363 - accuracy: 0.2687 - val_loss: 2.0631 - val_accuracy: 0.2667\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0351 - accuracy: 0.2687 - val_loss: 2.0621 - val_accuracy: 0.2667\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0339 - accuracy: 0.2711 - val_loss: 2.0611 - val_accuracy: 0.2667\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0326 - accuracy: 0.2736 - val_loss: 2.0601 - val_accuracy: 0.2667\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0313 - accuracy: 0.2736 - val_loss: 2.0591 - val_accuracy: 0.2667\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0300 - accuracy: 0.2736 - val_loss: 2.0581 - val_accuracy: 0.2667\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0288 - accuracy: 0.2736 - val_loss: 2.0570 - val_accuracy: 0.2667\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0274 - accuracy: 0.2761 - val_loss: 2.0560 - val_accuracy: 0.2667\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0261 - accuracy: 0.2761 - val_loss: 2.0550 - val_accuracy: 0.2889\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0248 - accuracy: 0.2761 - val_loss: 2.0539 - val_accuracy: 0.2889\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0235 - accuracy: 0.2786 - val_loss: 2.0529 - val_accuracy: 0.2889\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0221 - accuracy: 0.2786 - val_loss: 2.0518 - val_accuracy: 0.2889\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0207 - accuracy: 0.2711 - val_loss: 2.0507 - val_accuracy: 0.2889\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0193 - accuracy: 0.2761 - val_loss: 2.0496 - val_accuracy: 0.2889\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0179 - accuracy: 0.2811 - val_loss: 2.0485 - val_accuracy: 0.2889\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0165 - accuracy: 0.2786 - val_loss: 2.0474 - val_accuracy: 0.2889\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0151 - accuracy: 0.2786 - val_loss: 2.0463 - val_accuracy: 0.2889\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0136 - accuracy: 0.2811 - val_loss: 2.0451 - val_accuracy: 0.2889\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0121 - accuracy: 0.2811 - val_loss: 2.0439 - val_accuracy: 0.2889\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0106 - accuracy: 0.2786 - val_loss: 2.0428 - val_accuracy: 0.2889\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0091 - accuracy: 0.2786 - val_loss: 2.0416 - val_accuracy: 0.2889\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0076 - accuracy: 0.2786 - val_loss: 2.0404 - val_accuracy: 0.2889\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0060 - accuracy: 0.2811 - val_loss: 2.0392 - val_accuracy: 0.2889\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0044 - accuracy: 0.2811 - val_loss: 2.0379 - val_accuracy: 0.2889\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0028 - accuracy: 0.2811 - val_loss: 2.0366 - val_accuracy: 0.2889\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0012 - accuracy: 0.2836 - val_loss: 2.0354 - val_accuracy: 0.2889\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9995 - accuracy: 0.2836 - val_loss: 2.0341 - val_accuracy: 0.2889\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9978 - accuracy: 0.2836 - val_loss: 2.0328 - val_accuracy: 0.2889\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9961 - accuracy: 0.2836 - val_loss: 2.0315 - val_accuracy: 0.2889\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9944 - accuracy: 0.2861 - val_loss: 2.0301 - val_accuracy: 0.2889\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9926 - accuracy: 0.2886 - val_loss: 2.0288 - val_accuracy: 0.2889\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9909 - accuracy: 0.2886 - val_loss: 2.0274 - val_accuracy: 0.2889\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9891 - accuracy: 0.2886 - val_loss: 2.0260 - val_accuracy: 0.2889\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9872 - accuracy: 0.2935 - val_loss: 2.0246 - val_accuracy: 0.2889\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9854 - accuracy: 0.2910 - val_loss: 2.0232 - val_accuracy: 0.2889\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9835 - accuracy: 0.2910 - val_loss: 2.0218 - val_accuracy: 0.2889\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9815 - accuracy: 0.2886 - val_loss: 2.0203 - val_accuracy: 0.2889\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9796 - accuracy: 0.2861 - val_loss: 2.0189 - val_accuracy: 0.2889\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9776 - accuracy: 0.2886 - val_loss: 2.0174 - val_accuracy: 0.2889\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9756 - accuracy: 0.2886 - val_loss: 2.0159 - val_accuracy: 0.2889\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9736 - accuracy: 0.2886 - val_loss: 2.0144 - val_accuracy: 0.2889\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9715 - accuracy: 0.2910 - val_loss: 2.0129 - val_accuracy: 0.2889\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9694 - accuracy: 0.2861 - val_loss: 2.0114 - val_accuracy: 0.2889\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9673 - accuracy: 0.2861 - val_loss: 2.0098 - val_accuracy: 0.3111\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9651 - accuracy: 0.2886 - val_loss: 2.0083 - val_accuracy: 0.3111\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9630 - accuracy: 0.2886 - val_loss: 2.0068 - val_accuracy: 0.3111\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9607 - accuracy: 0.2886 - val_loss: 2.0052 - val_accuracy: 0.3111\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9585 - accuracy: 0.2960 - val_loss: 2.0037 - val_accuracy: 0.3111\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9562 - accuracy: 0.2985 - val_loss: 2.0021 - val_accuracy: 0.3111\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9539 - accuracy: 0.2985 - val_loss: 2.0006 - val_accuracy: 0.3111\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9516 - accuracy: 0.2960 - val_loss: 1.9991 - val_accuracy: 0.3111\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9493 - accuracy: 0.3010 - val_loss: 1.9976 - val_accuracy: 0.3111\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9469 - accuracy: 0.3085 - val_loss: 1.9961 - val_accuracy: 0.3111\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9445 - accuracy: 0.3085 - val_loss: 1.9946 - val_accuracy: 0.3111\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9421 - accuracy: 0.3060 - val_loss: 1.9931 - val_accuracy: 0.3111\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9396 - accuracy: 0.3060 - val_loss: 1.9917 - val_accuracy: 0.3111\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9372 - accuracy: 0.3010 - val_loss: 1.9903 - val_accuracy: 0.3111\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9347 - accuracy: 0.3010 - val_loss: 1.9889 - val_accuracy: 0.3111\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9322 - accuracy: 0.3035 - val_loss: 1.9876 - val_accuracy: 0.3111\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9297 - accuracy: 0.3035 - val_loss: 1.9863 - val_accuracy: 0.3111\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9272 - accuracy: 0.3010 - val_loss: 1.9851 - val_accuracy: 0.3111\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9247 - accuracy: 0.2985 - val_loss: 1.9839 - val_accuracy: 0.3111\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9222 - accuracy: 0.3010 - val_loss: 1.9827 - val_accuracy: 0.3111\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9197 - accuracy: 0.3010 - val_loss: 1.9817 - val_accuracy: 0.3111\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9172 - accuracy: 0.3035 - val_loss: 1.9806 - val_accuracy: 0.2889\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9146 - accuracy: 0.3035 - val_loss: 1.9797 - val_accuracy: 0.3333\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9121 - accuracy: 0.3010 - val_loss: 1.9789 - val_accuracy: 0.3333\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9096 - accuracy: 0.3035 - val_loss: 1.9780 - val_accuracy: 0.3333\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9072 - accuracy: 0.3035 - val_loss: 1.9773 - val_accuracy: 0.3111\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9047 - accuracy: 0.3010 - val_loss: 1.9767 - val_accuracy: 0.2889\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9022 - accuracy: 0.2985 - val_loss: 1.9761 - val_accuracy: 0.2667\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8998 - accuracy: 0.2985 - val_loss: 1.9756 - val_accuracy: 0.2667\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8974 - accuracy: 0.3010 - val_loss: 1.9752 - val_accuracy: 0.2667\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8950 - accuracy: 0.3035 - val_loss: 1.9749 - val_accuracy: 0.2667\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8926 - accuracy: 0.3010 - val_loss: 1.9746 - val_accuracy: 0.2667\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8902 - accuracy: 0.3035 - val_loss: 1.9744 - val_accuracy: 0.2667\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8879 - accuracy: 0.3010 - val_loss: 1.9743 - val_accuracy: 0.2667\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8855 - accuracy: 0.3035 - val_loss: 1.9742 - val_accuracy: 0.2667\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8832 - accuracy: 0.3085 - val_loss: 1.9742 - val_accuracy: 0.2667\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8809 - accuracy: 0.3134 - val_loss: 1.9742 - val_accuracy: 0.2667\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8786 - accuracy: 0.3159 - val_loss: 1.9743 - val_accuracy: 0.2667\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8764 - accuracy: 0.3159 - val_loss: 1.9744 - val_accuracy: 0.2667\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8741 - accuracy: 0.3184 - val_loss: 1.9745 - val_accuracy: 0.2667\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8719 - accuracy: 0.3184 - val_loss: 1.9746 - val_accuracy: 0.2667\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8696 - accuracy: 0.3184 - val_loss: 1.9747 - val_accuracy: 0.2667\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8674 - accuracy: 0.3184 - val_loss: 1.9749 - val_accuracy: 0.2667\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8651 - accuracy: 0.3209 - val_loss: 1.9751 - val_accuracy: 0.2667\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8629 - accuracy: 0.3209 - val_loss: 1.9752 - val_accuracy: 0.2667\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8606 - accuracy: 0.3209 - val_loss: 1.9754 - val_accuracy: 0.2667\n",
      "========== Fold 4 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.3403 - accuracy: 0.0871 - val_loss: 2.3599 - val_accuracy: 0.1333\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.3368 - accuracy: 0.0871 - val_loss: 2.3548 - val_accuracy: 0.1333\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3310 - accuracy: 0.0871 - val_loss: 2.3483 - val_accuracy: 0.1333\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3237 - accuracy: 0.0871 - val_loss: 2.3410 - val_accuracy: 0.1333\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3153 - accuracy: 0.0871 - val_loss: 2.3333 - val_accuracy: 0.1333\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3064 - accuracy: 0.0871 - val_loss: 2.3254 - val_accuracy: 0.1333\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2973 - accuracy: 0.0871 - val_loss: 2.3177 - val_accuracy: 0.1333\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2882 - accuracy: 0.0896 - val_loss: 2.3103 - val_accuracy: 0.1333\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2792 - accuracy: 0.0970 - val_loss: 2.3032 - val_accuracy: 0.1111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2707 - accuracy: 0.1144 - val_loss: 2.2967 - val_accuracy: 0.0444\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2625 - accuracy: 0.1194 - val_loss: 2.2907 - val_accuracy: 0.0667\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2549 - accuracy: 0.1468 - val_loss: 2.2853 - val_accuracy: 0.0667\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2478 - accuracy: 0.1294 - val_loss: 2.2804 - val_accuracy: 0.0889\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2412 - accuracy: 0.1393 - val_loss: 2.2761 - val_accuracy: 0.0889\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2352 - accuracy: 0.1567 - val_loss: 2.2723 - val_accuracy: 0.1556\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2296 - accuracy: 0.1741 - val_loss: 2.2690 - val_accuracy: 0.1556\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2246 - accuracy: 0.1716 - val_loss: 2.2662 - val_accuracy: 0.1556\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2200 - accuracy: 0.1667 - val_loss: 2.2638 - val_accuracy: 0.1556\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2158 - accuracy: 0.1716 - val_loss: 2.2617 - val_accuracy: 0.1556\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2119 - accuracy: 0.1741 - val_loss: 2.2600 - val_accuracy: 0.1556\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2084 - accuracy: 0.1716 - val_loss: 2.2585 - val_accuracy: 0.1556\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2051 - accuracy: 0.1692 - val_loss: 2.2572 - val_accuracy: 0.1556\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2021 - accuracy: 0.1667 - val_loss: 2.2561 - val_accuracy: 0.1556\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1992 - accuracy: 0.1667 - val_loss: 2.2552 - val_accuracy: 0.1556\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1966 - accuracy: 0.1667 - val_loss: 2.2544 - val_accuracy: 0.1556\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1940 - accuracy: 0.1667 - val_loss: 2.2537 - val_accuracy: 0.1556\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1916 - accuracy: 0.1642 - val_loss: 2.2530 - val_accuracy: 0.1556\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1894 - accuracy: 0.1642 - val_loss: 2.2524 - val_accuracy: 0.1556\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1872 - accuracy: 0.1642 - val_loss: 2.2519 - val_accuracy: 0.1556\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1850 - accuracy: 0.1642 - val_loss: 2.2514 - val_accuracy: 0.1556\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1830 - accuracy: 0.1642 - val_loss: 2.2509 - val_accuracy: 0.1556\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1810 - accuracy: 0.1667 - val_loss: 2.2504 - val_accuracy: 0.1556\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1791 - accuracy: 0.1692 - val_loss: 2.2499 - val_accuracy: 0.1556\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1773 - accuracy: 0.1716 - val_loss: 2.2495 - val_accuracy: 0.1556\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1755 - accuracy: 0.1716 - val_loss: 2.2490 - val_accuracy: 0.1556\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1737 - accuracy: 0.1741 - val_loss: 2.2485 - val_accuracy: 0.1556\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1720 - accuracy: 0.1716 - val_loss: 2.2481 - val_accuracy: 0.1556\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1704 - accuracy: 0.1692 - val_loss: 2.2476 - val_accuracy: 0.1556\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1688 - accuracy: 0.1766 - val_loss: 2.2471 - val_accuracy: 0.1556\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1672 - accuracy: 0.1766 - val_loss: 2.2467 - val_accuracy: 0.1556\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1657 - accuracy: 0.1791 - val_loss: 2.2463 - val_accuracy: 0.1556\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1643 - accuracy: 0.1816 - val_loss: 2.2458 - val_accuracy: 0.1556\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1629 - accuracy: 0.1841 - val_loss: 2.2454 - val_accuracy: 0.1556\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1615 - accuracy: 0.1841 - val_loss: 2.2450 - val_accuracy: 0.1556\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1601 - accuracy: 0.1841 - val_loss: 2.2445 - val_accuracy: 0.1556\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1588 - accuracy: 0.1866 - val_loss: 2.2441 - val_accuracy: 0.1556\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1576 - accuracy: 0.1841 - val_loss: 2.2437 - val_accuracy: 0.1556\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1563 - accuracy: 0.1841 - val_loss: 2.2434 - val_accuracy: 0.1556\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1551 - accuracy: 0.1841 - val_loss: 2.2429 - val_accuracy: 0.1556\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1539 - accuracy: 0.1841 - val_loss: 2.2426 - val_accuracy: 0.1556\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1528 - accuracy: 0.1841 - val_loss: 2.2423 - val_accuracy: 0.1556\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1517 - accuracy: 0.1816 - val_loss: 2.2419 - val_accuracy: 0.1556\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1505 - accuracy: 0.1841 - val_loss: 2.2416 - val_accuracy: 0.1556\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1494 - accuracy: 0.1866 - val_loss: 2.2414 - val_accuracy: 0.1556\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1484 - accuracy: 0.1891 - val_loss: 2.2411 - val_accuracy: 0.1556\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.1473 - accuracy: 0.1915 - val_loss: 2.2409 - val_accuracy: 0.1556\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1462 - accuracy: 0.1915 - val_loss: 2.2407 - val_accuracy: 0.1556\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1452 - accuracy: 0.1915 - val_loss: 2.2405 - val_accuracy: 0.1556\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1441 - accuracy: 0.1915 - val_loss: 2.2404 - val_accuracy: 0.1556\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1431 - accuracy: 0.1940 - val_loss: 2.2403 - val_accuracy: 0.1556\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1421 - accuracy: 0.1965 - val_loss: 2.2402 - val_accuracy: 0.1556\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1410 - accuracy: 0.1965 - val_loss: 2.2402 - val_accuracy: 0.1556\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1400 - accuracy: 0.1990 - val_loss: 2.2402 - val_accuracy: 0.1556\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1390 - accuracy: 0.2015 - val_loss: 2.2402 - val_accuracy: 0.1556\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1380 - accuracy: 0.2065 - val_loss: 2.2402 - val_accuracy: 0.1556\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1370 - accuracy: 0.2040 - val_loss: 2.2403 - val_accuracy: 0.1556\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1360 - accuracy: 0.2040 - val_loss: 2.2404 - val_accuracy: 0.1556\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1349 - accuracy: 0.2040 - val_loss: 2.2405 - val_accuracy: 0.1556\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1339 - accuracy: 0.2040 - val_loss: 2.2406 - val_accuracy: 0.1556\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1329 - accuracy: 0.2040 - val_loss: 2.2408 - val_accuracy: 0.1556\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1319 - accuracy: 0.2040 - val_loss: 2.2409 - val_accuracy: 0.1556\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1309 - accuracy: 0.2065 - val_loss: 2.2411 - val_accuracy: 0.1556\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1299 - accuracy: 0.2090 - val_loss: 2.2412 - val_accuracy: 0.1556\n",
      "========== Fold 5 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.2996 - accuracy: 0.0721 - val_loss: 2.2801 - val_accuracy: 0.1111\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.2971 - accuracy: 0.0796 - val_loss: 2.2779 - val_accuracy: 0.1333\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2929 - accuracy: 0.0846 - val_loss: 2.2753 - val_accuracy: 0.1556\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.2874 - accuracy: 0.0945 - val_loss: 2.2724 - val_accuracy: 0.1111\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2812 - accuracy: 0.1219 - val_loss: 2.2694 - val_accuracy: 0.1333\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2746 - accuracy: 0.1418 - val_loss: 2.2664 - val_accuracy: 0.1111\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2677 - accuracy: 0.1418 - val_loss: 2.2637 - val_accuracy: 0.1111\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2608 - accuracy: 0.1418 - val_loss: 2.2613 - val_accuracy: 0.1111\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2541 - accuracy: 0.1418 - val_loss: 2.2592 - val_accuracy: 0.1111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2477 - accuracy: 0.1418 - val_loss: 2.2574 - val_accuracy: 0.1111\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2417 - accuracy: 0.1418 - val_loss: 2.2560 - val_accuracy: 0.1111\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2361 - accuracy: 0.1418 - val_loss: 2.2549 - val_accuracy: 0.1111\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2309 - accuracy: 0.1418 - val_loss: 2.2542 - val_accuracy: 0.1111\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2261 - accuracy: 0.1418 - val_loss: 2.2536 - val_accuracy: 0.1111\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2217 - accuracy: 0.1468 - val_loss: 2.2533 - val_accuracy: 0.1111\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2178 - accuracy: 0.1517 - val_loss: 2.2531 - val_accuracy: 0.1333\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2142 - accuracy: 0.1542 - val_loss: 2.2529 - val_accuracy: 0.1333\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2109 - accuracy: 0.1617 - val_loss: 2.2528 - val_accuracy: 0.1111\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2080 - accuracy: 0.1667 - val_loss: 2.2527 - val_accuracy: 0.1111\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2053 - accuracy: 0.1716 - val_loss: 2.2526 - val_accuracy: 0.1111\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2027 - accuracy: 0.1617 - val_loss: 2.2523 - val_accuracy: 0.1111\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2004 - accuracy: 0.1667 - val_loss: 2.2519 - val_accuracy: 0.1111\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1982 - accuracy: 0.1741 - val_loss: 2.2514 - val_accuracy: 0.1333\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1961 - accuracy: 0.1915 - val_loss: 2.2507 - val_accuracy: 0.1111\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1941 - accuracy: 0.1990 - val_loss: 2.2499 - val_accuracy: 0.1111\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1922 - accuracy: 0.2090 - val_loss: 2.2489 - val_accuracy: 0.1111\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1903 - accuracy: 0.2214 - val_loss: 2.2478 - val_accuracy: 0.1111\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1885 - accuracy: 0.2264 - val_loss: 2.2465 - val_accuracy: 0.1333\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1868 - accuracy: 0.2239 - val_loss: 2.2451 - val_accuracy: 0.1556\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1851 - accuracy: 0.2214 - val_loss: 2.2436 - val_accuracy: 0.1556\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1834 - accuracy: 0.2264 - val_loss: 2.2420 - val_accuracy: 0.1778\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1818 - accuracy: 0.2289 - val_loss: 2.2402 - val_accuracy: 0.1778\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1802 - accuracy: 0.2239 - val_loss: 2.2385 - val_accuracy: 0.1556\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1786 - accuracy: 0.2189 - val_loss: 2.2366 - val_accuracy: 0.1556\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1771 - accuracy: 0.2114 - val_loss: 2.2348 - val_accuracy: 0.1556\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1756 - accuracy: 0.2114 - val_loss: 2.2330 - val_accuracy: 0.1556\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1742 - accuracy: 0.2090 - val_loss: 2.2311 - val_accuracy: 0.1333\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1728 - accuracy: 0.2090 - val_loss: 2.2293 - val_accuracy: 0.1333\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1715 - accuracy: 0.2090 - val_loss: 2.2275 - val_accuracy: 0.1333\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1702 - accuracy: 0.2065 - val_loss: 2.2257 - val_accuracy: 0.1333\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1689 - accuracy: 0.2040 - val_loss: 2.2239 - val_accuracy: 0.1333\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1677 - accuracy: 0.1990 - val_loss: 2.2222 - val_accuracy: 0.1333\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1665 - accuracy: 0.2015 - val_loss: 2.2206 - val_accuracy: 0.1333\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1654 - accuracy: 0.2015 - val_loss: 2.2190 - val_accuracy: 0.1111\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1643 - accuracy: 0.2040 - val_loss: 2.2175 - val_accuracy: 0.1111\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1632 - accuracy: 0.1965 - val_loss: 2.2161 - val_accuracy: 0.1111\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1622 - accuracy: 0.1915 - val_loss: 2.2147 - val_accuracy: 0.1111\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1612 - accuracy: 0.1891 - val_loss: 2.2134 - val_accuracy: 0.1111\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1602 - accuracy: 0.1915 - val_loss: 2.2122 - val_accuracy: 0.1111\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.1592 - accuracy: 0.1915 - val_loss: 2.2110 - val_accuracy: 0.1111\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1582 - accuracy: 0.1915 - val_loss: 2.2098 - val_accuracy: 0.1333\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1573 - accuracy: 0.1915 - val_loss: 2.2088 - val_accuracy: 0.1111\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1563 - accuracy: 0.1915 - val_loss: 2.2077 - val_accuracy: 0.1111\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1554 - accuracy: 0.1940 - val_loss: 2.2068 - val_accuracy: 0.1111\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1545 - accuracy: 0.1940 - val_loss: 2.2059 - val_accuracy: 0.1111\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1536 - accuracy: 0.1940 - val_loss: 2.2050 - val_accuracy: 0.1111\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1527 - accuracy: 0.1965 - val_loss: 2.2042 - val_accuracy: 0.1111\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1518 - accuracy: 0.1940 - val_loss: 2.2034 - val_accuracy: 0.1111\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.1509 - accuracy: 0.1990 - val_loss: 2.2027 - val_accuracy: 0.1111\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1501 - accuracy: 0.1990 - val_loss: 2.2019 - val_accuracy: 0.1111\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1492 - accuracy: 0.2040 - val_loss: 2.2012 - val_accuracy: 0.1111\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1483 - accuracy: 0.2065 - val_loss: 2.2006 - val_accuracy: 0.1111\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1475 - accuracy: 0.2090 - val_loss: 2.1999 - val_accuracy: 0.1111\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1467 - accuracy: 0.2114 - val_loss: 2.1993 - val_accuracy: 0.1111\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1458 - accuracy: 0.2139 - val_loss: 2.1987 - val_accuracy: 0.1111\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1450 - accuracy: 0.2139 - val_loss: 2.1981 - val_accuracy: 0.1111\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1441 - accuracy: 0.2164 - val_loss: 2.1975 - val_accuracy: 0.1111\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1433 - accuracy: 0.2164 - val_loss: 2.1968 - val_accuracy: 0.1111\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1425 - accuracy: 0.2164 - val_loss: 2.1962 - val_accuracy: 0.1111\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1416 - accuracy: 0.2189 - val_loss: 2.1956 - val_accuracy: 0.1111\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1408 - accuracy: 0.2239 - val_loss: 2.1950 - val_accuracy: 0.1111\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1400 - accuracy: 0.2214 - val_loss: 2.1944 - val_accuracy: 0.1111\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.1391 - accuracy: 0.2189 - val_loss: 2.1938 - val_accuracy: 0.1111\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1383 - accuracy: 0.2189 - val_loss: 2.1931 - val_accuracy: 0.1111\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1375 - accuracy: 0.2189 - val_loss: 2.1924 - val_accuracy: 0.1111\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1366 - accuracy: 0.2189 - val_loss: 2.1918 - val_accuracy: 0.1111\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1358 - accuracy: 0.2189 - val_loss: 2.1911 - val_accuracy: 0.1333\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1350 - accuracy: 0.2189 - val_loss: 2.1904 - val_accuracy: 0.1333\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1341 - accuracy: 0.2189 - val_loss: 2.1897 - val_accuracy: 0.1333\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1333 - accuracy: 0.2214 - val_loss: 2.1889 - val_accuracy: 0.1333\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1324 - accuracy: 0.2214 - val_loss: 2.1882 - val_accuracy: 0.1333\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1315 - accuracy: 0.2239 - val_loss: 2.1874 - val_accuracy: 0.1333\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1307 - accuracy: 0.2239 - val_loss: 2.1867 - val_accuracy: 0.1333\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1298 - accuracy: 0.2239 - val_loss: 2.1859 - val_accuracy: 0.1333\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1289 - accuracy: 0.2239 - val_loss: 2.1851 - val_accuracy: 0.1333\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1281 - accuracy: 0.2239 - val_loss: 2.1842 - val_accuracy: 0.1333\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1272 - accuracy: 0.2264 - val_loss: 2.1834 - val_accuracy: 0.1333\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1263 - accuracy: 0.2264 - val_loss: 2.1826 - val_accuracy: 0.1556\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1254 - accuracy: 0.2239 - val_loss: 2.1817 - val_accuracy: 0.1556\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1245 - accuracy: 0.2189 - val_loss: 2.1808 - val_accuracy: 0.1556\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1235 - accuracy: 0.2189 - val_loss: 2.1799 - val_accuracy: 0.1778\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1226 - accuracy: 0.2189 - val_loss: 2.1790 - val_accuracy: 0.1778\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1217 - accuracy: 0.2239 - val_loss: 2.1781 - val_accuracy: 0.1778\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1207 - accuracy: 0.2264 - val_loss: 2.1772 - val_accuracy: 0.1778\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1198 - accuracy: 0.2264 - val_loss: 2.1762 - val_accuracy: 0.1778\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1188 - accuracy: 0.2289 - val_loss: 2.1753 - val_accuracy: 0.1778\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1178 - accuracy: 0.2289 - val_loss: 2.1743 - val_accuracy: 0.2000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1169 - accuracy: 0.2289 - val_loss: 2.1733 - val_accuracy: 0.2000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1159 - accuracy: 0.2289 - val_loss: 2.1723 - val_accuracy: 0.2000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1149 - accuracy: 0.2313 - val_loss: 2.1713 - val_accuracy: 0.2000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1138 - accuracy: 0.2338 - val_loss: 2.1702 - val_accuracy: 0.2000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1128 - accuracy: 0.2338 - val_loss: 2.1692 - val_accuracy: 0.2000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1118 - accuracy: 0.2338 - val_loss: 2.1681 - val_accuracy: 0.2000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1107 - accuracy: 0.2338 - val_loss: 2.1670 - val_accuracy: 0.2000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1096 - accuracy: 0.2363 - val_loss: 2.1659 - val_accuracy: 0.2000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1086 - accuracy: 0.2363 - val_loss: 2.1648 - val_accuracy: 0.2000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1075 - accuracy: 0.2388 - val_loss: 2.1636 - val_accuracy: 0.2000\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1064 - accuracy: 0.2413 - val_loss: 2.1625 - val_accuracy: 0.2222\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1052 - accuracy: 0.2413 - val_loss: 2.1613 - val_accuracy: 0.2222\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1041 - accuracy: 0.2413 - val_loss: 2.1601 - val_accuracy: 0.2222\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1029 - accuracy: 0.2463 - val_loss: 2.1589 - val_accuracy: 0.2222\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1018 - accuracy: 0.2512 - val_loss: 2.1576 - val_accuracy: 0.2222\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1006 - accuracy: 0.2512 - val_loss: 2.1564 - val_accuracy: 0.2222\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0994 - accuracy: 0.2512 - val_loss: 2.1550 - val_accuracy: 0.2222\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0982 - accuracy: 0.2463 - val_loss: 2.1537 - val_accuracy: 0.2222\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0970 - accuracy: 0.2438 - val_loss: 2.1523 - val_accuracy: 0.2000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0957 - accuracy: 0.2488 - val_loss: 2.1510 - val_accuracy: 0.2000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0945 - accuracy: 0.2488 - val_loss: 2.1495 - val_accuracy: 0.2000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0932 - accuracy: 0.2512 - val_loss: 2.1481 - val_accuracy: 0.2000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0919 - accuracy: 0.2537 - val_loss: 2.1466 - val_accuracy: 0.2000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0906 - accuracy: 0.2537 - val_loss: 2.1452 - val_accuracy: 0.2000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0893 - accuracy: 0.2512 - val_loss: 2.1436 - val_accuracy: 0.2000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0879 - accuracy: 0.2562 - val_loss: 2.1420 - val_accuracy: 0.2000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0866 - accuracy: 0.2537 - val_loss: 2.1405 - val_accuracy: 0.2000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0852 - accuracy: 0.2537 - val_loss: 2.1388 - val_accuracy: 0.2000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0838 - accuracy: 0.2562 - val_loss: 2.1372 - val_accuracy: 0.2222\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0824 - accuracy: 0.2562 - val_loss: 2.1355 - val_accuracy: 0.2222\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0810 - accuracy: 0.2587 - val_loss: 2.1338 - val_accuracy: 0.2222\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0795 - accuracy: 0.2587 - val_loss: 2.1320 - val_accuracy: 0.2222\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0781 - accuracy: 0.2612 - val_loss: 2.1302 - val_accuracy: 0.2222\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0766 - accuracy: 0.2612 - val_loss: 2.1284 - val_accuracy: 0.2222\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0751 - accuracy: 0.2612 - val_loss: 2.1266 - val_accuracy: 0.2222\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0736 - accuracy: 0.2587 - val_loss: 2.1247 - val_accuracy: 0.2222\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0721 - accuracy: 0.2587 - val_loss: 2.1228 - val_accuracy: 0.2222\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0705 - accuracy: 0.2587 - val_loss: 2.1208 - val_accuracy: 0.2222\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0690 - accuracy: 0.2587 - val_loss: 2.1188 - val_accuracy: 0.2222\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0674 - accuracy: 0.2587 - val_loss: 2.1168 - val_accuracy: 0.2222\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0658 - accuracy: 0.2587 - val_loss: 2.1148 - val_accuracy: 0.2222\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0642 - accuracy: 0.2537 - val_loss: 2.1127 - val_accuracy: 0.2222\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0626 - accuracy: 0.2512 - val_loss: 2.1106 - val_accuracy: 0.2222\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0609 - accuracy: 0.2512 - val_loss: 2.1084 - val_accuracy: 0.2222\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0593 - accuracy: 0.2537 - val_loss: 2.1063 - val_accuracy: 0.2222\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0576 - accuracy: 0.2512 - val_loss: 2.1041 - val_accuracy: 0.2222\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0559 - accuracy: 0.2537 - val_loss: 2.1019 - val_accuracy: 0.2222\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0542 - accuracy: 0.2562 - val_loss: 2.0996 - val_accuracy: 0.2222\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0524 - accuracy: 0.2562 - val_loss: 2.0973 - val_accuracy: 0.2222\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0507 - accuracy: 0.2587 - val_loss: 2.0950 - val_accuracy: 0.2222\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0489 - accuracy: 0.2587 - val_loss: 2.0927 - val_accuracy: 0.2222\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0472 - accuracy: 0.2587 - val_loss: 2.0903 - val_accuracy: 0.2222\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0454 - accuracy: 0.2637 - val_loss: 2.0879 - val_accuracy: 0.2222\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0435 - accuracy: 0.2612 - val_loss: 2.0855 - val_accuracy: 0.2222\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0417 - accuracy: 0.2612 - val_loss: 2.0830 - val_accuracy: 0.2000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0399 - accuracy: 0.2612 - val_loss: 2.0806 - val_accuracy: 0.1778\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0380 - accuracy: 0.2637 - val_loss: 2.0781 - val_accuracy: 0.1778\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0361 - accuracy: 0.2637 - val_loss: 2.0756 - val_accuracy: 0.1778\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0342 - accuracy: 0.2637 - val_loss: 2.0731 - val_accuracy: 0.1778\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0323 - accuracy: 0.2637 - val_loss: 2.0706 - val_accuracy: 0.2000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0304 - accuracy: 0.2662 - val_loss: 2.0681 - val_accuracy: 0.1778\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0284 - accuracy: 0.2687 - val_loss: 2.0655 - val_accuracy: 0.1778\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0264 - accuracy: 0.2687 - val_loss: 2.0629 - val_accuracy: 0.1778\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0244 - accuracy: 0.2711 - val_loss: 2.0603 - val_accuracy: 0.1778\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0224 - accuracy: 0.2736 - val_loss: 2.0577 - val_accuracy: 0.2000\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0204 - accuracy: 0.2811 - val_loss: 2.0551 - val_accuracy: 0.2222\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0183 - accuracy: 0.2861 - val_loss: 2.0525 - val_accuracy: 0.2222\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0162 - accuracy: 0.2861 - val_loss: 2.0499 - val_accuracy: 0.2222\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0141 - accuracy: 0.2886 - val_loss: 2.0473 - val_accuracy: 0.2222\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0120 - accuracy: 0.2910 - val_loss: 2.0446 - val_accuracy: 0.2222\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0099 - accuracy: 0.2935 - val_loss: 2.0420 - val_accuracy: 0.2222\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0077 - accuracy: 0.2960 - val_loss: 2.0393 - val_accuracy: 0.2222\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0055 - accuracy: 0.2960 - val_loss: 2.0367 - val_accuracy: 0.2444\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0033 - accuracy: 0.2935 - val_loss: 2.0340 - val_accuracy: 0.2444\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0010 - accuracy: 0.2935 - val_loss: 2.0314 - val_accuracy: 0.2222\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9988 - accuracy: 0.2960 - val_loss: 2.0288 - val_accuracy: 0.2222\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9965 - accuracy: 0.2935 - val_loss: 2.0261 - val_accuracy: 0.2222\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9942 - accuracy: 0.2960 - val_loss: 2.0235 - val_accuracy: 0.2222\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9919 - accuracy: 0.2960 - val_loss: 2.0209 - val_accuracy: 0.2444\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9895 - accuracy: 0.2935 - val_loss: 2.0183 - val_accuracy: 0.2667\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9871 - accuracy: 0.2960 - val_loss: 2.0157 - val_accuracy: 0.2444\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9848 - accuracy: 0.2985 - val_loss: 2.0131 - val_accuracy: 0.2667\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9824 - accuracy: 0.2985 - val_loss: 2.0106 - val_accuracy: 0.2667\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9799 - accuracy: 0.2985 - val_loss: 2.0080 - val_accuracy: 0.2667\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9775 - accuracy: 0.3010 - val_loss: 2.0055 - val_accuracy: 0.2667\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9750 - accuracy: 0.3035 - val_loss: 2.0030 - val_accuracy: 0.2667\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9726 - accuracy: 0.2985 - val_loss: 2.0006 - val_accuracy: 0.2667\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9701 - accuracy: 0.2985 - val_loss: 1.9982 - val_accuracy: 0.2667\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9677 - accuracy: 0.3010 - val_loss: 1.9958 - val_accuracy: 0.2667\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9652 - accuracy: 0.3010 - val_loss: 1.9934 - val_accuracy: 0.2667\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9627 - accuracy: 0.3035 - val_loss: 1.9911 - val_accuracy: 0.2667\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9602 - accuracy: 0.3010 - val_loss: 1.9889 - val_accuracy: 0.2667\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9578 - accuracy: 0.3010 - val_loss: 1.9867 - val_accuracy: 0.2667\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9553 - accuracy: 0.3010 - val_loss: 1.9846 - val_accuracy: 0.2667\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9529 - accuracy: 0.3010 - val_loss: 1.9826 - val_accuracy: 0.2667\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.9505 - accuracy: 0.3010 - val_loss: 1.9805 - val_accuracy: 0.2667\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9481 - accuracy: 0.3010 - val_loss: 1.9786 - val_accuracy: 0.2667\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9457 - accuracy: 0.2985 - val_loss: 1.9767 - val_accuracy: 0.2667\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9433 - accuracy: 0.3010 - val_loss: 1.9749 - val_accuracy: 0.2667\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9410 - accuracy: 0.3035 - val_loss: 1.9732 - val_accuracy: 0.2667\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9387 - accuracy: 0.3035 - val_loss: 1.9715 - val_accuracy: 0.2667\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9365 - accuracy: 0.3035 - val_loss: 1.9700 - val_accuracy: 0.2889\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9342 - accuracy: 0.3010 - val_loss: 1.9684 - val_accuracy: 0.2889\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9320 - accuracy: 0.3010 - val_loss: 1.9670 - val_accuracy: 0.2889\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9299 - accuracy: 0.2985 - val_loss: 1.9656 - val_accuracy: 0.2889\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9278 - accuracy: 0.2985 - val_loss: 1.9643 - val_accuracy: 0.2889\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9257 - accuracy: 0.3010 - val_loss: 1.9631 - val_accuracy: 0.2889\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9236 - accuracy: 0.3060 - val_loss: 1.9619 - val_accuracy: 0.2889\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9216 - accuracy: 0.3085 - val_loss: 1.9608 - val_accuracy: 0.2667\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9196 - accuracy: 0.3060 - val_loss: 1.9597 - val_accuracy: 0.2667\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9177 - accuracy: 0.3159 - val_loss: 1.9586 - val_accuracy: 0.2667\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9157 - accuracy: 0.3134 - val_loss: 1.9576 - val_accuracy: 0.2667\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9138 - accuracy: 0.3134 - val_loss: 1.9566 - val_accuracy: 0.2667\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9119 - accuracy: 0.3184 - val_loss: 1.9557 - val_accuracy: 0.2667\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9101 - accuracy: 0.3234 - val_loss: 1.9547 - val_accuracy: 0.2667\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9082 - accuracy: 0.3234 - val_loss: 1.9539 - val_accuracy: 0.2667\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9063 - accuracy: 0.3234 - val_loss: 1.9530 - val_accuracy: 0.2667\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9045 - accuracy: 0.3209 - val_loss: 1.9521 - val_accuracy: 0.2667\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9027 - accuracy: 0.3209 - val_loss: 1.9512 - val_accuracy: 0.2667\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9008 - accuracy: 0.3184 - val_loss: 1.9503 - val_accuracy: 0.2667\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8990 - accuracy: 0.3184 - val_loss: 1.9495 - val_accuracy: 0.2667\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8971 - accuracy: 0.3184 - val_loss: 1.9486 - val_accuracy: 0.2667\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8953 - accuracy: 0.3184 - val_loss: 1.9477 - val_accuracy: 0.2667\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8934 - accuracy: 0.3184 - val_loss: 1.9468 - val_accuracy: 0.2667\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8916 - accuracy: 0.3209 - val_loss: 1.9460 - val_accuracy: 0.2667\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8897 - accuracy: 0.3209 - val_loss: 1.9450 - val_accuracy: 0.2667\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8879 - accuracy: 0.3209 - val_loss: 1.9441 - val_accuracy: 0.2667\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8860 - accuracy: 0.3234 - val_loss: 1.9432 - val_accuracy: 0.2667\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8841 - accuracy: 0.3259 - val_loss: 1.9422 - val_accuracy: 0.2667\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8822 - accuracy: 0.3259 - val_loss: 1.9413 - val_accuracy: 0.2667\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8803 - accuracy: 0.3259 - val_loss: 1.9403 - val_accuracy: 0.2667\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8785 - accuracy: 0.3259 - val_loss: 1.9393 - val_accuracy: 0.2667\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8766 - accuracy: 0.3259 - val_loss: 1.9383 - val_accuracy: 0.2889\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8747 - accuracy: 0.3284 - val_loss: 1.9373 - val_accuracy: 0.2889\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8728 - accuracy: 0.3308 - val_loss: 1.9364 - val_accuracy: 0.2889\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8709 - accuracy: 0.3333 - val_loss: 1.9354 - val_accuracy: 0.2889\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8689 - accuracy: 0.3358 - val_loss: 1.9344 - val_accuracy: 0.2889\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8670 - accuracy: 0.3333 - val_loss: 1.9334 - val_accuracy: 0.2889\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8651 - accuracy: 0.3358 - val_loss: 1.9325 - val_accuracy: 0.2889\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8632 - accuracy: 0.3358 - val_loss: 1.9316 - val_accuracy: 0.2889\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.8612 - accuracy: 0.3333 - val_loss: 1.9307 - val_accuracy: 0.2889\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8593 - accuracy: 0.3333 - val_loss: 1.9299 - val_accuracy: 0.2889\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8573 - accuracy: 0.3333 - val_loss: 1.9289 - val_accuracy: 0.2889\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8554 - accuracy: 0.3383 - val_loss: 1.9281 - val_accuracy: 0.2889\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8534 - accuracy: 0.3408 - val_loss: 1.9273 - val_accuracy: 0.2889\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8514 - accuracy: 0.3433 - val_loss: 1.9265 - val_accuracy: 0.2889\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8494 - accuracy: 0.3433 - val_loss: 1.9258 - val_accuracy: 0.2889\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.8474 - accuracy: 0.3433 - val_loss: 1.9250 - val_accuracy: 0.2889\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8453 - accuracy: 0.3433 - val_loss: 1.9243 - val_accuracy: 0.2889\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8433 - accuracy: 0.3483 - val_loss: 1.9235 - val_accuracy: 0.2889\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8413 - accuracy: 0.3483 - val_loss: 1.9228 - val_accuracy: 0.2889\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8392 - accuracy: 0.3483 - val_loss: 1.9222 - val_accuracy: 0.2889\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.8371 - accuracy: 0.3483 - val_loss: 1.9215 - val_accuracy: 0.2889\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8350 - accuracy: 0.3507 - val_loss: 1.9208 - val_accuracy: 0.2889\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8329 - accuracy: 0.3532 - val_loss: 1.9201 - val_accuracy: 0.2889\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8308 - accuracy: 0.3532 - val_loss: 1.9194 - val_accuracy: 0.2889\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8286 - accuracy: 0.3532 - val_loss: 1.9188 - val_accuracy: 0.2889\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8265 - accuracy: 0.3532 - val_loss: 1.9181 - val_accuracy: 0.2889\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8243 - accuracy: 0.3557 - val_loss: 1.9174 - val_accuracy: 0.2889\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8221 - accuracy: 0.3557 - val_loss: 1.9167 - val_accuracy: 0.2889\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8199 - accuracy: 0.3582 - val_loss: 1.9160 - val_accuracy: 0.2889\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8176 - accuracy: 0.3557 - val_loss: 1.9153 - val_accuracy: 0.2889\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8153 - accuracy: 0.3557 - val_loss: 1.9146 - val_accuracy: 0.2667\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8131 - accuracy: 0.3557 - val_loss: 1.9139 - val_accuracy: 0.2667\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8108 - accuracy: 0.3582 - val_loss: 1.9131 - val_accuracy: 0.2667\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8084 - accuracy: 0.3657 - val_loss: 1.9124 - val_accuracy: 0.2667\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8061 - accuracy: 0.3632 - val_loss: 1.9117 - val_accuracy: 0.2667\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.8037 - accuracy: 0.3632 - val_loss: 1.9110 - val_accuracy: 0.2667\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8013 - accuracy: 0.3632 - val_loss: 1.9102 - val_accuracy: 0.2667\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7989 - accuracy: 0.3632 - val_loss: 1.9094 - val_accuracy: 0.2667\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7964 - accuracy: 0.3632 - val_loss: 1.9086 - val_accuracy: 0.2667\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7939 - accuracy: 0.3632 - val_loss: 1.9079 - val_accuracy: 0.2667\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7914 - accuracy: 0.3607 - val_loss: 1.9071 - val_accuracy: 0.2667\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7889 - accuracy: 0.3607 - val_loss: 1.9063 - val_accuracy: 0.2667\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7863 - accuracy: 0.3632 - val_loss: 1.9055 - val_accuracy: 0.2667\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7837 - accuracy: 0.3632 - val_loss: 1.9047 - val_accuracy: 0.2667\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7811 - accuracy: 0.3632 - val_loss: 1.9039 - val_accuracy: 0.2667\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7784 - accuracy: 0.3632 - val_loss: 1.9030 - val_accuracy: 0.2667\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7757 - accuracy: 0.3632 - val_loss: 1.9022 - val_accuracy: 0.2667\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7730 - accuracy: 0.3607 - val_loss: 1.9014 - val_accuracy: 0.2667\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7702 - accuracy: 0.3607 - val_loss: 1.9005 - val_accuracy: 0.2667\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7674 - accuracy: 0.3632 - val_loss: 1.8996 - val_accuracy: 0.2667\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.7646 - accuracy: 0.3632 - val_loss: 1.8987 - val_accuracy: 0.2667\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7617 - accuracy: 0.3657 - val_loss: 1.8978 - val_accuracy: 0.2667\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7588 - accuracy: 0.3682 - val_loss: 1.8970 - val_accuracy: 0.2667\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7558 - accuracy: 0.3682 - val_loss: 1.8961 - val_accuracy: 0.2667\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7528 - accuracy: 0.3682 - val_loss: 1.8952 - val_accuracy: 0.2667\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7498 - accuracy: 0.3682 - val_loss: 1.8942 - val_accuracy: 0.2667\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7468 - accuracy: 0.3706 - val_loss: 1.8932 - val_accuracy: 0.2667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7436 - accuracy: 0.3706 - val_loss: 1.8923 - val_accuracy: 0.2667\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7405 - accuracy: 0.3706 - val_loss: 1.8914 - val_accuracy: 0.2667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7373 - accuracy: 0.3706 - val_loss: 1.8904 - val_accuracy: 0.2667\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7341 - accuracy: 0.3706 - val_loss: 1.8895 - val_accuracy: 0.2667\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7308 - accuracy: 0.3731 - val_loss: 1.8884 - val_accuracy: 0.2667\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7274 - accuracy: 0.3756 - val_loss: 1.8874 - val_accuracy: 0.2667\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7241 - accuracy: 0.3781 - val_loss: 1.8863 - val_accuracy: 0.2667\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7206 - accuracy: 0.3781 - val_loss: 1.8853 - val_accuracy: 0.2667\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7172 - accuracy: 0.3806 - val_loss: 1.8842 - val_accuracy: 0.2667\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7136 - accuracy: 0.3806 - val_loss: 1.8831 - val_accuracy: 0.2667\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7101 - accuracy: 0.3856 - val_loss: 1.8821 - val_accuracy: 0.2667\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7064 - accuracy: 0.3881 - val_loss: 1.8809 - val_accuracy: 0.2667\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7028 - accuracy: 0.3905 - val_loss: 1.8798 - val_accuracy: 0.2667\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6991 - accuracy: 0.3905 - val_loss: 1.8787 - val_accuracy: 0.2667\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6953 - accuracy: 0.3955 - val_loss: 1.8776 - val_accuracy: 0.2667\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6915 - accuracy: 0.3980 - val_loss: 1.8765 - val_accuracy: 0.2667\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6876 - accuracy: 0.4030 - val_loss: 1.8752 - val_accuracy: 0.2667\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6836 - accuracy: 0.4005 - val_loss: 1.8740 - val_accuracy: 0.2667\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6797 - accuracy: 0.4005 - val_loss: 1.8729 - val_accuracy: 0.2667\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6756 - accuracy: 0.3980 - val_loss: 1.8717 - val_accuracy: 0.2667\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6715 - accuracy: 0.3980 - val_loss: 1.8705 - val_accuracy: 0.2667\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6674 - accuracy: 0.3980 - val_loss: 1.8691 - val_accuracy: 0.2667\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6632 - accuracy: 0.4005 - val_loss: 1.8680 - val_accuracy: 0.2667\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6589 - accuracy: 0.4030 - val_loss: 1.8669 - val_accuracy: 0.2667\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6546 - accuracy: 0.4055 - val_loss: 1.8656 - val_accuracy: 0.2667\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6503 - accuracy: 0.4055 - val_loss: 1.8643 - val_accuracy: 0.2667\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.6459 - accuracy: 0.4055 - val_loss: 1.8629 - val_accuracy: 0.2889\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6414 - accuracy: 0.4104 - val_loss: 1.8618 - val_accuracy: 0.2889\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6369 - accuracy: 0.4104 - val_loss: 1.8606 - val_accuracy: 0.2889\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6323 - accuracy: 0.4154 - val_loss: 1.8591 - val_accuracy: 0.2889\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6277 - accuracy: 0.4154 - val_loss: 1.8576 - val_accuracy: 0.2889\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6230 - accuracy: 0.4154 - val_loss: 1.8564 - val_accuracy: 0.2889\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6183 - accuracy: 0.4204 - val_loss: 1.8551 - val_accuracy: 0.3111\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6135 - accuracy: 0.4279 - val_loss: 1.8538 - val_accuracy: 0.3111\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6086 - accuracy: 0.4254 - val_loss: 1.8522 - val_accuracy: 0.3333\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6037 - accuracy: 0.4254 - val_loss: 1.8507 - val_accuracy: 0.3333\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5988 - accuracy: 0.4279 - val_loss: 1.8495 - val_accuracy: 0.3333\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5938 - accuracy: 0.4303 - val_loss: 1.8481 - val_accuracy: 0.3333\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5888 - accuracy: 0.4378 - val_loss: 1.8466 - val_accuracy: 0.3333\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5837 - accuracy: 0.4378 - val_loss: 1.8449 - val_accuracy: 0.3333\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5785 - accuracy: 0.4378 - val_loss: 1.8434 - val_accuracy: 0.3333\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5733 - accuracy: 0.4353 - val_loss: 1.8421 - val_accuracy: 0.3333\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5681 - accuracy: 0.4328 - val_loss: 1.8403 - val_accuracy: 0.3333\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5628 - accuracy: 0.4353 - val_loss: 1.8386 - val_accuracy: 0.3333\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5574 - accuracy: 0.4378 - val_loss: 1.8371 - val_accuracy: 0.3333\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5520 - accuracy: 0.4378 - val_loss: 1.8354 - val_accuracy: 0.3333\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5466 - accuracy: 0.4428 - val_loss: 1.8336 - val_accuracy: 0.3333\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5411 - accuracy: 0.4453 - val_loss: 1.8318 - val_accuracy: 0.3333\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5356 - accuracy: 0.4478 - val_loss: 1.8301 - val_accuracy: 0.3333\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5300 - accuracy: 0.4527 - val_loss: 1.8283 - val_accuracy: 0.3333\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5244 - accuracy: 0.4577 - val_loss: 1.8265 - val_accuracy: 0.3333\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5188 - accuracy: 0.4602 - val_loss: 1.8245 - val_accuracy: 0.3333\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5131 - accuracy: 0.4627 - val_loss: 1.8227 - val_accuracy: 0.3333\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5074 - accuracy: 0.4751 - val_loss: 1.8208 - val_accuracy: 0.3333\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5016 - accuracy: 0.4726 - val_loss: 1.8184 - val_accuracy: 0.3333\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4959 - accuracy: 0.4776 - val_loss: 1.8167 - val_accuracy: 0.3333\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4900 - accuracy: 0.4776 - val_loss: 1.8146 - val_accuracy: 0.3333\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4842 - accuracy: 0.4826 - val_loss: 1.8122 - val_accuracy: 0.3111\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4783 - accuracy: 0.4826 - val_loss: 1.8103 - val_accuracy: 0.3111\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4723 - accuracy: 0.4876 - val_loss: 1.8082 - val_accuracy: 0.3111\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4664 - accuracy: 0.4925 - val_loss: 1.8057 - val_accuracy: 0.3111\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4603 - accuracy: 0.4925 - val_loss: 1.8037 - val_accuracy: 0.3111\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4543 - accuracy: 0.4925 - val_loss: 1.8012 - val_accuracy: 0.3111\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4482 - accuracy: 0.4876 - val_loss: 1.7988 - val_accuracy: 0.3111\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4421 - accuracy: 0.4900 - val_loss: 1.7967 - val_accuracy: 0.3111\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4359 - accuracy: 0.5000 - val_loss: 1.7941 - val_accuracy: 0.2889\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4298 - accuracy: 0.5075 - val_loss: 1.7919 - val_accuracy: 0.2889\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4235 - accuracy: 0.5075 - val_loss: 1.7892 - val_accuracy: 0.2889\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4173 - accuracy: 0.5050 - val_loss: 1.7872 - val_accuracy: 0.2889\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4110 - accuracy: 0.5025 - val_loss: 1.7840 - val_accuracy: 0.2889\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.4046 - accuracy: 0.5149 - val_loss: 1.7831 - val_accuracy: 0.2889\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3983 - accuracy: 0.5199 - val_loss: 1.7784 - val_accuracy: 0.2889\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3919 - accuracy: 0.5274 - val_loss: 1.7797 - val_accuracy: 0.3111\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3855 - accuracy: 0.5323 - val_loss: 1.7723 - val_accuracy: 0.3111\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3790 - accuracy: 0.5373 - val_loss: 1.7766 - val_accuracy: 0.3111\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3726 - accuracy: 0.5323 - val_loss: 1.7673 - val_accuracy: 0.3111\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3660 - accuracy: 0.5423 - val_loss: 1.7710 - val_accuracy: 0.3111\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3594 - accuracy: 0.5473 - val_loss: 1.7660 - val_accuracy: 0.3111\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3528 - accuracy: 0.5597 - val_loss: 1.7627 - val_accuracy: 0.3111\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3462 - accuracy: 0.5672 - val_loss: 1.7654 - val_accuracy: 0.3111\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3396 - accuracy: 0.5647 - val_loss: 1.7564 - val_accuracy: 0.3111\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3330 - accuracy: 0.5721 - val_loss: 1.7620 - val_accuracy: 0.3111\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3263 - accuracy: 0.5697 - val_loss: 1.7542 - val_accuracy: 0.3111\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3195 - accuracy: 0.5697 - val_loss: 1.7545 - val_accuracy: 0.3111\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3127 - accuracy: 0.5746 - val_loss: 1.7540 - val_accuracy: 0.3111\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3059 - accuracy: 0.5796 - val_loss: 1.7477 - val_accuracy: 0.3333\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2992 - accuracy: 0.5796 - val_loss: 1.7529 - val_accuracy: 0.3333\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.2923 - accuracy: 0.5771 - val_loss: 1.7432 - val_accuracy: 0.3333\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2855 - accuracy: 0.5821 - val_loss: 1.7490 - val_accuracy: 0.3111\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2785 - accuracy: 0.5821 - val_loss: 1.7420 - val_accuracy: 0.3111\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2715 - accuracy: 0.5846 - val_loss: 1.7428 - val_accuracy: 0.3111\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2645 - accuracy: 0.5896 - val_loss: 1.7418 - val_accuracy: 0.3111\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2575 - accuracy: 0.5896 - val_loss: 1.7371 - val_accuracy: 0.3111\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2505 - accuracy: 0.5920 - val_loss: 1.7419 - val_accuracy: 0.3111\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2435 - accuracy: 0.5896 - val_loss: 1.7315 - val_accuracy: 0.3111\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2365 - accuracy: 0.5945 - val_loss: 1.7429 - val_accuracy: 0.3111\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2296 - accuracy: 0.6020 - val_loss: 1.7273 - val_accuracy: 0.3333\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2226 - accuracy: 0.5995 - val_loss: 1.7399 - val_accuracy: 0.2889\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2152 - accuracy: 0.6020 - val_loss: 1.7299 - val_accuracy: 0.3333\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2077 - accuracy: 0.6020 - val_loss: 1.7294 - val_accuracy: 0.3333\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2005 - accuracy: 0.6020 - val_loss: 1.7358 - val_accuracy: 0.2889\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1935 - accuracy: 0.6144 - val_loss: 1.7237 - val_accuracy: 0.3333\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1864 - accuracy: 0.6095 - val_loss: 1.7353 - val_accuracy: 0.3111\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1791 - accuracy: 0.6194 - val_loss: 1.7256 - val_accuracy: 0.3333\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1715 - accuracy: 0.6169 - val_loss: 1.7276 - val_accuracy: 0.3333\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1641 - accuracy: 0.6194 - val_loss: 1.7316 - val_accuracy: 0.3111\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1569 - accuracy: 0.6219 - val_loss: 1.7225 - val_accuracy: 0.3556\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1497 - accuracy: 0.6318 - val_loss: 1.7341 - val_accuracy: 0.3111\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1424 - accuracy: 0.6219 - val_loss: 1.7235 - val_accuracy: 0.3556\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1349 - accuracy: 0.6393 - val_loss: 1.7314 - val_accuracy: 0.3333\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1272 - accuracy: 0.6343 - val_loss: 1.7275 - val_accuracy: 0.3333\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1196 - accuracy: 0.6443 - val_loss: 1.7276 - val_accuracy: 0.3333\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1122 - accuracy: 0.6468 - val_loss: 1.7329 - val_accuracy: 0.3333\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1048 - accuracy: 0.6493 - val_loss: 1.7259 - val_accuracy: 0.3333\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0974 - accuracy: 0.6617 - val_loss: 1.7384 - val_accuracy: 0.3333\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0902 - accuracy: 0.6567 - val_loss: 1.7253 - val_accuracy: 0.3333\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0830 - accuracy: 0.6667 - val_loss: 1.7422 - val_accuracy: 0.3333\n",
      "========== Fold 6 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.3378 - accuracy: 0.1318 - val_loss: 2.2711 - val_accuracy: 0.2000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.3343 - accuracy: 0.1318 - val_loss: 2.2670 - val_accuracy: 0.2000\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.3286 - accuracy: 0.1318 - val_loss: 2.2619 - val_accuracy: 0.2000\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3211 - accuracy: 0.1318 - val_loss: 2.2561 - val_accuracy: 0.2000\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3127 - accuracy: 0.1318 - val_loss: 2.2500 - val_accuracy: 0.2000\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3035 - accuracy: 0.1318 - val_loss: 2.2439 - val_accuracy: 0.2000\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2941 - accuracy: 0.1318 - val_loss: 2.2379 - val_accuracy: 0.2000\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2848 - accuracy: 0.1318 - val_loss: 2.2324 - val_accuracy: 0.2000\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2756 - accuracy: 0.1318 - val_loss: 2.2272 - val_accuracy: 0.2000\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2669 - accuracy: 0.1318 - val_loss: 2.2226 - val_accuracy: 0.2000\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2587 - accuracy: 0.1318 - val_loss: 2.2185 - val_accuracy: 0.2000\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2511 - accuracy: 0.1318 - val_loss: 2.2150 - val_accuracy: 0.2000\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2442 - accuracy: 0.1343 - val_loss: 2.2120 - val_accuracy: 0.2000\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2379 - accuracy: 0.1368 - val_loss: 2.2095 - val_accuracy: 0.2222\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.2322 - accuracy: 0.1393 - val_loss: 2.2074 - val_accuracy: 0.1778\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2271 - accuracy: 0.1567 - val_loss: 2.2056 - val_accuracy: 0.1111\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2225 - accuracy: 0.1517 - val_loss: 2.2042 - val_accuracy: 0.1111\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2185 - accuracy: 0.1294 - val_loss: 2.2029 - val_accuracy: 0.0667\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2149 - accuracy: 0.1219 - val_loss: 2.2018 - val_accuracy: 0.1333\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2116 - accuracy: 0.1219 - val_loss: 2.2007 - val_accuracy: 0.1333\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2087 - accuracy: 0.1294 - val_loss: 2.1997 - val_accuracy: 0.1333\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2060 - accuracy: 0.1294 - val_loss: 2.1986 - val_accuracy: 0.1333\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2035 - accuracy: 0.1343 - val_loss: 2.1975 - val_accuracy: 0.1556\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2011 - accuracy: 0.1294 - val_loss: 2.1963 - val_accuracy: 0.1778\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1989 - accuracy: 0.1343 - val_loss: 2.1948 - val_accuracy: 0.1778\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1967 - accuracy: 0.1343 - val_loss: 2.1934 - val_accuracy: 0.1778\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1946 - accuracy: 0.1343 - val_loss: 2.1918 - val_accuracy: 0.1778\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1925 - accuracy: 0.1343 - val_loss: 2.1900 - val_accuracy: 0.1778\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1904 - accuracy: 0.1343 - val_loss: 2.1881 - val_accuracy: 0.1778\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1884 - accuracy: 0.1393 - val_loss: 2.1862 - val_accuracy: 0.1778\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1865 - accuracy: 0.1393 - val_loss: 2.1842 - val_accuracy: 0.1778\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1846 - accuracy: 0.1418 - val_loss: 2.1822 - val_accuracy: 0.1556\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1827 - accuracy: 0.1493 - val_loss: 2.1802 - val_accuracy: 0.1333\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1809 - accuracy: 0.1493 - val_loss: 2.1781 - val_accuracy: 0.1333\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1791 - accuracy: 0.1592 - val_loss: 2.1761 - val_accuracy: 0.1333\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1774 - accuracy: 0.1741 - val_loss: 2.1741 - val_accuracy: 0.1333\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1757 - accuracy: 0.1841 - val_loss: 2.1721 - val_accuracy: 0.1556\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1741 - accuracy: 0.1965 - val_loss: 2.1702 - val_accuracy: 0.1556\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1726 - accuracy: 0.1990 - val_loss: 2.1684 - val_accuracy: 0.1556\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1712 - accuracy: 0.2114 - val_loss: 2.1667 - val_accuracy: 0.2000\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1698 - accuracy: 0.2189 - val_loss: 2.1651 - val_accuracy: 0.2000\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1684 - accuracy: 0.2164 - val_loss: 2.1635 - val_accuracy: 0.2000\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1671 - accuracy: 0.2189 - val_loss: 2.1621 - val_accuracy: 0.2000\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1658 - accuracy: 0.2114 - val_loss: 2.1607 - val_accuracy: 0.2000\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1646 - accuracy: 0.2114 - val_loss: 2.1594 - val_accuracy: 0.1556\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1634 - accuracy: 0.2164 - val_loss: 2.1582 - val_accuracy: 0.1333\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1622 - accuracy: 0.2139 - val_loss: 2.1571 - val_accuracy: 0.1333\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1611 - accuracy: 0.2114 - val_loss: 2.1561 - val_accuracy: 0.1333\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1600 - accuracy: 0.2090 - val_loss: 2.1552 - val_accuracy: 0.1556\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1588 - accuracy: 0.2090 - val_loss: 2.1543 - val_accuracy: 0.1556\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1577 - accuracy: 0.2114 - val_loss: 2.1535 - val_accuracy: 0.1556\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1566 - accuracy: 0.2114 - val_loss: 2.1528 - val_accuracy: 0.1556\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1556 - accuracy: 0.2090 - val_loss: 2.1521 - val_accuracy: 0.1556\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1545 - accuracy: 0.2090 - val_loss: 2.1515 - val_accuracy: 0.1778\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1534 - accuracy: 0.2090 - val_loss: 2.1509 - val_accuracy: 0.1778\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1524 - accuracy: 0.2139 - val_loss: 2.1504 - val_accuracy: 0.1778\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1513 - accuracy: 0.2189 - val_loss: 2.1499 - val_accuracy: 0.1778\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1503 - accuracy: 0.2189 - val_loss: 2.1494 - val_accuracy: 0.2000\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1492 - accuracy: 0.2214 - val_loss: 2.1490 - val_accuracy: 0.2222\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1482 - accuracy: 0.2239 - val_loss: 2.1487 - val_accuracy: 0.2222\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1471 - accuracy: 0.2264 - val_loss: 2.1483 - val_accuracy: 0.2222\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1461 - accuracy: 0.2313 - val_loss: 2.1480 - val_accuracy: 0.2222\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1451 - accuracy: 0.2289 - val_loss: 2.1476 - val_accuracy: 0.2222\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1441 - accuracy: 0.2313 - val_loss: 2.1473 - val_accuracy: 0.2222\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1431 - accuracy: 0.2338 - val_loss: 2.1470 - val_accuracy: 0.2222\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1420 - accuracy: 0.2363 - val_loss: 2.1467 - val_accuracy: 0.2222\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1410 - accuracy: 0.2338 - val_loss: 2.1463 - val_accuracy: 0.2222\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1400 - accuracy: 0.2313 - val_loss: 2.1460 - val_accuracy: 0.2222\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1390 - accuracy: 0.2289 - val_loss: 2.1457 - val_accuracy: 0.2222\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1380 - accuracy: 0.2289 - val_loss: 2.1453 - val_accuracy: 0.2222\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1370 - accuracy: 0.2313 - val_loss: 2.1450 - val_accuracy: 0.2222\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1360 - accuracy: 0.2313 - val_loss: 2.1446 - val_accuracy: 0.2444\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1349 - accuracy: 0.2338 - val_loss: 2.1442 - val_accuracy: 0.2222\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1339 - accuracy: 0.2313 - val_loss: 2.1438 - val_accuracy: 0.2222\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1329 - accuracy: 0.2313 - val_loss: 2.1434 - val_accuracy: 0.2222\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1318 - accuracy: 0.2313 - val_loss: 2.1430 - val_accuracy: 0.2222\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1308 - accuracy: 0.2289 - val_loss: 2.1426 - val_accuracy: 0.2222\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1298 - accuracy: 0.2289 - val_loss: 2.1421 - val_accuracy: 0.2444\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1287 - accuracy: 0.2363 - val_loss: 2.1417 - val_accuracy: 0.2444\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1276 - accuracy: 0.2413 - val_loss: 2.1412 - val_accuracy: 0.2444\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1266 - accuracy: 0.2463 - val_loss: 2.1408 - val_accuracy: 0.2444\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1255 - accuracy: 0.2463 - val_loss: 2.1403 - val_accuracy: 0.2222\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1244 - accuracy: 0.2463 - val_loss: 2.1398 - val_accuracy: 0.2222\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1233 - accuracy: 0.2463 - val_loss: 2.1393 - val_accuracy: 0.2222\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1222 - accuracy: 0.2463 - val_loss: 2.1389 - val_accuracy: 0.2222\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1210 - accuracy: 0.2463 - val_loss: 2.1384 - val_accuracy: 0.2444\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1199 - accuracy: 0.2488 - val_loss: 2.1379 - val_accuracy: 0.2444\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1187 - accuracy: 0.2512 - val_loss: 2.1374 - val_accuracy: 0.2444\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1176 - accuracy: 0.2537 - val_loss: 2.1369 - val_accuracy: 0.2444\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1164 - accuracy: 0.2512 - val_loss: 2.1365 - val_accuracy: 0.2444\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1152 - accuracy: 0.2512 - val_loss: 2.1360 - val_accuracy: 0.2444\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1140 - accuracy: 0.2512 - val_loss: 2.1355 - val_accuracy: 0.2444\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1128 - accuracy: 0.2512 - val_loss: 2.1351 - val_accuracy: 0.2444\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1116 - accuracy: 0.2512 - val_loss: 2.1346 - val_accuracy: 0.2444\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1103 - accuracy: 0.2587 - val_loss: 2.1341 - val_accuracy: 0.2667\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1091 - accuracy: 0.2587 - val_loss: 2.1336 - val_accuracy: 0.2667\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1078 - accuracy: 0.2587 - val_loss: 2.1332 - val_accuracy: 0.2667\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1065 - accuracy: 0.2612 - val_loss: 2.1327 - val_accuracy: 0.2667\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1052 - accuracy: 0.2587 - val_loss: 2.1323 - val_accuracy: 0.2667\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1039 - accuracy: 0.2612 - val_loss: 2.1318 - val_accuracy: 0.2667\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1025 - accuracy: 0.2587 - val_loss: 2.1313 - val_accuracy: 0.2667\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1011 - accuracy: 0.2587 - val_loss: 2.1309 - val_accuracy: 0.2667\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0998 - accuracy: 0.2587 - val_loss: 2.1304 - val_accuracy: 0.2667\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0984 - accuracy: 0.2587 - val_loss: 2.1299 - val_accuracy: 0.2667\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0969 - accuracy: 0.2612 - val_loss: 2.1295 - val_accuracy: 0.2667\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0955 - accuracy: 0.2662 - val_loss: 2.1290 - val_accuracy: 0.2444\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0941 - accuracy: 0.2711 - val_loss: 2.1285 - val_accuracy: 0.2444\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0926 - accuracy: 0.2711 - val_loss: 2.1281 - val_accuracy: 0.2444\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0911 - accuracy: 0.2736 - val_loss: 2.1276 - val_accuracy: 0.2444\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0896 - accuracy: 0.2736 - val_loss: 2.1271 - val_accuracy: 0.2000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0881 - accuracy: 0.2736 - val_loss: 2.1266 - val_accuracy: 0.2000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0865 - accuracy: 0.2761 - val_loss: 2.1262 - val_accuracy: 0.2000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0850 - accuracy: 0.2761 - val_loss: 2.1257 - val_accuracy: 0.2000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0834 - accuracy: 0.2736 - val_loss: 2.1252 - val_accuracy: 0.2000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0818 - accuracy: 0.2786 - val_loss: 2.1247 - val_accuracy: 0.2000\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0802 - accuracy: 0.2786 - val_loss: 2.1242 - val_accuracy: 0.2000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0786 - accuracy: 0.2836 - val_loss: 2.1237 - val_accuracy: 0.2000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0770 - accuracy: 0.2811 - val_loss: 2.1233 - val_accuracy: 0.2000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0753 - accuracy: 0.2786 - val_loss: 2.1228 - val_accuracy: 0.2000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0737 - accuracy: 0.2861 - val_loss: 2.1223 - val_accuracy: 0.2000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0720 - accuracy: 0.2861 - val_loss: 2.1218 - val_accuracy: 0.2000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0703 - accuracy: 0.2861 - val_loss: 2.1214 - val_accuracy: 0.2000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0687 - accuracy: 0.2811 - val_loss: 2.1209 - val_accuracy: 0.2000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0670 - accuracy: 0.2811 - val_loss: 2.1204 - val_accuracy: 0.2000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0653 - accuracy: 0.2836 - val_loss: 2.1199 - val_accuracy: 0.2000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0635 - accuracy: 0.2861 - val_loss: 2.1195 - val_accuracy: 0.2000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0618 - accuracy: 0.2886 - val_loss: 2.1190 - val_accuracy: 0.2000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0601 - accuracy: 0.2910 - val_loss: 2.1185 - val_accuracy: 0.2000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0583 - accuracy: 0.2910 - val_loss: 2.1181 - val_accuracy: 0.2000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0566 - accuracy: 0.2935 - val_loss: 2.1176 - val_accuracy: 0.2000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0549 - accuracy: 0.2960 - val_loss: 2.1172 - val_accuracy: 0.2000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0531 - accuracy: 0.2935 - val_loss: 2.1168 - val_accuracy: 0.2000\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0514 - accuracy: 0.2935 - val_loss: 2.1164 - val_accuracy: 0.2000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0496 - accuracy: 0.2960 - val_loss: 2.1159 - val_accuracy: 0.1778\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0478 - accuracy: 0.2960 - val_loss: 2.1155 - val_accuracy: 0.2000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0461 - accuracy: 0.2960 - val_loss: 2.1151 - val_accuracy: 0.2000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0443 - accuracy: 0.2960 - val_loss: 2.1146 - val_accuracy: 0.2000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0426 - accuracy: 0.3010 - val_loss: 2.1142 - val_accuracy: 0.2000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0408 - accuracy: 0.2985 - val_loss: 2.1138 - val_accuracy: 0.2000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0390 - accuracy: 0.2935 - val_loss: 2.1135 - val_accuracy: 0.1778\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0373 - accuracy: 0.2960 - val_loss: 2.1130 - val_accuracy: 0.2000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0355 - accuracy: 0.2985 - val_loss: 2.1126 - val_accuracy: 0.2000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0338 - accuracy: 0.2960 - val_loss: 2.1122 - val_accuracy: 0.2000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0320 - accuracy: 0.2960 - val_loss: 2.1118 - val_accuracy: 0.2000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0302 - accuracy: 0.2985 - val_loss: 2.1114 - val_accuracy: 0.2000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0285 - accuracy: 0.2985 - val_loss: 2.1110 - val_accuracy: 0.2000\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0267 - accuracy: 0.2985 - val_loss: 2.1106 - val_accuracy: 0.2000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0249 - accuracy: 0.2985 - val_loss: 2.1102 - val_accuracy: 0.2000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0232 - accuracy: 0.2960 - val_loss: 2.1098 - val_accuracy: 0.2222\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0214 - accuracy: 0.2985 - val_loss: 2.1093 - val_accuracy: 0.2222\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0196 - accuracy: 0.2985 - val_loss: 2.1089 - val_accuracy: 0.2222\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0178 - accuracy: 0.2985 - val_loss: 2.1085 - val_accuracy: 0.2222\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0160 - accuracy: 0.3010 - val_loss: 2.1080 - val_accuracy: 0.2222\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0142 - accuracy: 0.2935 - val_loss: 2.1076 - val_accuracy: 0.2222\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0124 - accuracy: 0.2935 - val_loss: 2.1071 - val_accuracy: 0.2222\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0106 - accuracy: 0.2960 - val_loss: 2.1067 - val_accuracy: 0.2222\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0088 - accuracy: 0.2935 - val_loss: 2.1062 - val_accuracy: 0.2222\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0069 - accuracy: 0.2960 - val_loss: 2.1057 - val_accuracy: 0.2222\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0051 - accuracy: 0.2985 - val_loss: 2.1052 - val_accuracy: 0.2222\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0032 - accuracy: 0.3010 - val_loss: 2.1047 - val_accuracy: 0.2222\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0013 - accuracy: 0.3010 - val_loss: 2.1041 - val_accuracy: 0.2444\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9994 - accuracy: 0.3035 - val_loss: 2.1036 - val_accuracy: 0.2444\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9975 - accuracy: 0.3035 - val_loss: 2.1030 - val_accuracy: 0.2444\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9955 - accuracy: 0.3035 - val_loss: 2.1024 - val_accuracy: 0.2444\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9936 - accuracy: 0.3060 - val_loss: 2.1018 - val_accuracy: 0.2667\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.9916 - accuracy: 0.3060 - val_loss: 2.1012 - val_accuracy: 0.2667\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.9896 - accuracy: 0.3109 - val_loss: 2.1005 - val_accuracy: 0.2667\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9876 - accuracy: 0.3134 - val_loss: 2.0999 - val_accuracy: 0.2667\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9855 - accuracy: 0.3159 - val_loss: 2.0992 - val_accuracy: 0.2667\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9835 - accuracy: 0.3159 - val_loss: 2.0985 - val_accuracy: 0.2667\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9814 - accuracy: 0.3209 - val_loss: 2.0978 - val_accuracy: 0.2444\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9793 - accuracy: 0.3184 - val_loss: 2.0970 - val_accuracy: 0.2444\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9772 - accuracy: 0.3209 - val_loss: 2.0962 - val_accuracy: 0.2444\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9751 - accuracy: 0.3234 - val_loss: 2.0954 - val_accuracy: 0.2444\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9729 - accuracy: 0.3234 - val_loss: 2.0946 - val_accuracy: 0.2444\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9707 - accuracy: 0.3308 - val_loss: 2.0937 - val_accuracy: 0.2444\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9686 - accuracy: 0.3308 - val_loss: 2.0928 - val_accuracy: 0.2667\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9664 - accuracy: 0.3284 - val_loss: 2.0919 - val_accuracy: 0.2667\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9641 - accuracy: 0.3259 - val_loss: 2.0910 - val_accuracy: 0.2667\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9619 - accuracy: 0.3284 - val_loss: 2.0901 - val_accuracy: 0.2889\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9597 - accuracy: 0.3284 - val_loss: 2.0891 - val_accuracy: 0.2889\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9574 - accuracy: 0.3284 - val_loss: 2.0882 - val_accuracy: 0.2889\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9551 - accuracy: 0.3284 - val_loss: 2.0872 - val_accuracy: 0.2889\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9529 - accuracy: 0.3259 - val_loss: 2.0862 - val_accuracy: 0.2889\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9506 - accuracy: 0.3259 - val_loss: 2.0852 - val_accuracy: 0.2889\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9483 - accuracy: 0.3259 - val_loss: 2.0842 - val_accuracy: 0.2889\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9460 - accuracy: 0.3234 - val_loss: 2.0832 - val_accuracy: 0.2889\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9437 - accuracy: 0.3234 - val_loss: 2.0821 - val_accuracy: 0.2889\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9414 - accuracy: 0.3209 - val_loss: 2.0810 - val_accuracy: 0.2889\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9391 - accuracy: 0.3234 - val_loss: 2.0800 - val_accuracy: 0.2889\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9368 - accuracy: 0.3259 - val_loss: 2.0789 - val_accuracy: 0.2889\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9345 - accuracy: 0.3259 - val_loss: 2.0778 - val_accuracy: 0.2889\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9323 - accuracy: 0.3259 - val_loss: 2.0767 - val_accuracy: 0.2889\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9300 - accuracy: 0.3234 - val_loss: 2.0756 - val_accuracy: 0.2889\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9278 - accuracy: 0.3209 - val_loss: 2.0745 - val_accuracy: 0.2889\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9255 - accuracy: 0.3209 - val_loss: 2.0735 - val_accuracy: 0.2889\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9233 - accuracy: 0.3209 - val_loss: 2.0724 - val_accuracy: 0.2889\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9211 - accuracy: 0.3184 - val_loss: 2.0713 - val_accuracy: 0.2889\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9189 - accuracy: 0.3209 - val_loss: 2.0702 - val_accuracy: 0.2889\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9167 - accuracy: 0.3209 - val_loss: 2.0692 - val_accuracy: 0.2889\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.9145 - accuracy: 0.3184 - val_loss: 2.0681 - val_accuracy: 0.2889\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9124 - accuracy: 0.3184 - val_loss: 2.0670 - val_accuracy: 0.2889\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9103 - accuracy: 0.3184 - val_loss: 2.0659 - val_accuracy: 0.2889\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9082 - accuracy: 0.3184 - val_loss: 2.0649 - val_accuracy: 0.2889\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9061 - accuracy: 0.3184 - val_loss: 2.0639 - val_accuracy: 0.2889\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9041 - accuracy: 0.3184 - val_loss: 2.0629 - val_accuracy: 0.2889\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9020 - accuracy: 0.3134 - val_loss: 2.0619 - val_accuracy: 0.2889\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9000 - accuracy: 0.3134 - val_loss: 2.0609 - val_accuracy: 0.2667\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8980 - accuracy: 0.3159 - val_loss: 2.0599 - val_accuracy: 0.2667\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8961 - accuracy: 0.3159 - val_loss: 2.0589 - val_accuracy: 0.2667\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8941 - accuracy: 0.3159 - val_loss: 2.0580 - val_accuracy: 0.2667\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8922 - accuracy: 0.3159 - val_loss: 2.0570 - val_accuracy: 0.2667\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8902 - accuracy: 0.3184 - val_loss: 2.0561 - val_accuracy: 0.2667\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8883 - accuracy: 0.3184 - val_loss: 2.0552 - val_accuracy: 0.2667\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8864 - accuracy: 0.3234 - val_loss: 2.0543 - val_accuracy: 0.2667\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8846 - accuracy: 0.3234 - val_loss: 2.0534 - val_accuracy: 0.2667\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8827 - accuracy: 0.3234 - val_loss: 2.0525 - val_accuracy: 0.2667\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8808 - accuracy: 0.3234 - val_loss: 2.0517 - val_accuracy: 0.2667\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8790 - accuracy: 0.3234 - val_loss: 2.0509 - val_accuracy: 0.2667\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8771 - accuracy: 0.3234 - val_loss: 2.0501 - val_accuracy: 0.2667\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.8753 - accuracy: 0.3259 - val_loss: 2.0493 - val_accuracy: 0.2667\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8734 - accuracy: 0.3259 - val_loss: 2.0485 - val_accuracy: 0.2667\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8716 - accuracy: 0.3259 - val_loss: 2.0478 - val_accuracy: 0.2667\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8697 - accuracy: 0.3284 - val_loss: 2.0470 - val_accuracy: 0.2667\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8679 - accuracy: 0.3259 - val_loss: 2.0463 - val_accuracy: 0.2667\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8660 - accuracy: 0.3259 - val_loss: 2.0455 - val_accuracy: 0.2667\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8641 - accuracy: 0.3234 - val_loss: 2.0448 - val_accuracy: 0.2667\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8623 - accuracy: 0.3234 - val_loss: 2.0441 - val_accuracy: 0.2667\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8604 - accuracy: 0.3234 - val_loss: 2.0434 - val_accuracy: 0.2667\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8585 - accuracy: 0.3234 - val_loss: 2.0427 - val_accuracy: 0.2667\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8567 - accuracy: 0.3234 - val_loss: 2.0421 - val_accuracy: 0.2667\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8548 - accuracy: 0.3234 - val_loss: 2.0414 - val_accuracy: 0.2667\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.8529 - accuracy: 0.3234 - val_loss: 2.0407 - val_accuracy: 0.2667\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8510 - accuracy: 0.3234 - val_loss: 2.0400 - val_accuracy: 0.2667\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8491 - accuracy: 0.3234 - val_loss: 2.0393 - val_accuracy: 0.2667\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8472 - accuracy: 0.3234 - val_loss: 2.0387 - val_accuracy: 0.2667\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8453 - accuracy: 0.3234 - val_loss: 2.0380 - val_accuracy: 0.2667\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8433 - accuracy: 0.3234 - val_loss: 2.0372 - val_accuracy: 0.2667\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8414 - accuracy: 0.3259 - val_loss: 2.0365 - val_accuracy: 0.2667\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8394 - accuracy: 0.3259 - val_loss: 2.0358 - val_accuracy: 0.2667\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8375 - accuracy: 0.3234 - val_loss: 2.0351 - val_accuracy: 0.2667\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8355 - accuracy: 0.3209 - val_loss: 2.0344 - val_accuracy: 0.2667\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8335 - accuracy: 0.3209 - val_loss: 2.0337 - val_accuracy: 0.2667\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.8315 - accuracy: 0.3259 - val_loss: 2.0328 - val_accuracy: 0.2667\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.8295 - accuracy: 0.3259 - val_loss: 2.0320 - val_accuracy: 0.2667\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8275 - accuracy: 0.3259 - val_loss: 2.0312 - val_accuracy: 0.2667\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8254 - accuracy: 0.3284 - val_loss: 2.0304 - val_accuracy: 0.2667\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8234 - accuracy: 0.3284 - val_loss: 2.0296 - val_accuracy: 0.2667\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8213 - accuracy: 0.3284 - val_loss: 2.0287 - val_accuracy: 0.2667\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8192 - accuracy: 0.3284 - val_loss: 2.0279 - val_accuracy: 0.2667\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8171 - accuracy: 0.3284 - val_loss: 2.0270 - val_accuracy: 0.2667\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8150 - accuracy: 0.3259 - val_loss: 2.0261 - val_accuracy: 0.2667\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8129 - accuracy: 0.3259 - val_loss: 2.0252 - val_accuracy: 0.2667\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8107 - accuracy: 0.3284 - val_loss: 2.0242 - val_accuracy: 0.2667\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8086 - accuracy: 0.3308 - val_loss: 2.0233 - val_accuracy: 0.2667\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8064 - accuracy: 0.3284 - val_loss: 2.0223 - val_accuracy: 0.2667\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8042 - accuracy: 0.3308 - val_loss: 2.0214 - val_accuracy: 0.2667\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8019 - accuracy: 0.3308 - val_loss: 2.0204 - val_accuracy: 0.2667\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7997 - accuracy: 0.3333 - val_loss: 2.0194 - val_accuracy: 0.2667\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7974 - accuracy: 0.3333 - val_loss: 2.0185 - val_accuracy: 0.2889\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7951 - accuracy: 0.3358 - val_loss: 2.0174 - val_accuracy: 0.2889\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7928 - accuracy: 0.3358 - val_loss: 2.0164 - val_accuracy: 0.2889\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7905 - accuracy: 0.3383 - val_loss: 2.0153 - val_accuracy: 0.2889\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7881 - accuracy: 0.3383 - val_loss: 2.0142 - val_accuracy: 0.2889\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7857 - accuracy: 0.3358 - val_loss: 2.0132 - val_accuracy: 0.2889\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7833 - accuracy: 0.3383 - val_loss: 2.0122 - val_accuracy: 0.2889\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7808 - accuracy: 0.3383 - val_loss: 2.0111 - val_accuracy: 0.2889\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7784 - accuracy: 0.3408 - val_loss: 2.0099 - val_accuracy: 0.2889\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7758 - accuracy: 0.3408 - val_loss: 2.0088 - val_accuracy: 0.2889\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7733 - accuracy: 0.3408 - val_loss: 2.0077 - val_accuracy: 0.2889\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7708 - accuracy: 0.3433 - val_loss: 2.0066 - val_accuracy: 0.2889\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7682 - accuracy: 0.3458 - val_loss: 2.0055 - val_accuracy: 0.2889\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7655 - accuracy: 0.3532 - val_loss: 2.0044 - val_accuracy: 0.2889\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7629 - accuracy: 0.3557 - val_loss: 2.0032 - val_accuracy: 0.2889\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7602 - accuracy: 0.3582 - val_loss: 2.0021 - val_accuracy: 0.2889\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7574 - accuracy: 0.3607 - val_loss: 2.0009 - val_accuracy: 0.2667\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7547 - accuracy: 0.3607 - val_loss: 1.9997 - val_accuracy: 0.2667\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7519 - accuracy: 0.3657 - val_loss: 1.9985 - val_accuracy: 0.2667\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7490 - accuracy: 0.3657 - val_loss: 1.9973 - val_accuracy: 0.2667\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7462 - accuracy: 0.3657 - val_loss: 1.9960 - val_accuracy: 0.2667\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7433 - accuracy: 0.3657 - val_loss: 1.9948 - val_accuracy: 0.2667\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7403 - accuracy: 0.3682 - val_loss: 1.9935 - val_accuracy: 0.2667\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7373 - accuracy: 0.3682 - val_loss: 1.9922 - val_accuracy: 0.2667\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7343 - accuracy: 0.3682 - val_loss: 1.9908 - val_accuracy: 0.2667\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7312 - accuracy: 0.3657 - val_loss: 1.9896 - val_accuracy: 0.2667\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7281 - accuracy: 0.3657 - val_loss: 1.9882 - val_accuracy: 0.2667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7249 - accuracy: 0.3657 - val_loss: 1.9870 - val_accuracy: 0.2667\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7217 - accuracy: 0.3657 - val_loss: 1.9856 - val_accuracy: 0.2667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7185 - accuracy: 0.3706 - val_loss: 1.9841 - val_accuracy: 0.2667\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.7152 - accuracy: 0.3706 - val_loss: 1.9828 - val_accuracy: 0.2667\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7118 - accuracy: 0.3706 - val_loss: 1.9814 - val_accuracy: 0.2667\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7084 - accuracy: 0.3706 - val_loss: 1.9801 - val_accuracy: 0.2667\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7050 - accuracy: 0.3706 - val_loss: 1.9787 - val_accuracy: 0.2889\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7015 - accuracy: 0.3706 - val_loss: 1.9773 - val_accuracy: 0.2889\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6980 - accuracy: 0.3756 - val_loss: 1.9759 - val_accuracy: 0.3111\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.6944 - accuracy: 0.3806 - val_loss: 1.9746 - val_accuracy: 0.3111\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6908 - accuracy: 0.3831 - val_loss: 1.9732 - val_accuracy: 0.3111\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6871 - accuracy: 0.3856 - val_loss: 1.9718 - val_accuracy: 0.3111\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6834 - accuracy: 0.3856 - val_loss: 1.9706 - val_accuracy: 0.3111\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6797 - accuracy: 0.3831 - val_loss: 1.9692 - val_accuracy: 0.3111\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6759 - accuracy: 0.3831 - val_loss: 1.9677 - val_accuracy: 0.3111\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.6720 - accuracy: 0.3856 - val_loss: 1.9664 - val_accuracy: 0.3111\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6681 - accuracy: 0.3881 - val_loss: 1.9651 - val_accuracy: 0.3111\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6641 - accuracy: 0.3881 - val_loss: 1.9639 - val_accuracy: 0.3111\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6601 - accuracy: 0.3881 - val_loss: 1.9624 - val_accuracy: 0.3111\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6561 - accuracy: 0.3905 - val_loss: 1.9610 - val_accuracy: 0.3111\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6519 - accuracy: 0.3930 - val_loss: 1.9597 - val_accuracy: 0.3111\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.6478 - accuracy: 0.3980 - val_loss: 1.9585 - val_accuracy: 0.3111\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6436 - accuracy: 0.3955 - val_loss: 1.9573 - val_accuracy: 0.3111\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6393 - accuracy: 0.3955 - val_loss: 1.9557 - val_accuracy: 0.3111\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6350 - accuracy: 0.3955 - val_loss: 1.9542 - val_accuracy: 0.3111\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6306 - accuracy: 0.3980 - val_loss: 1.9530 - val_accuracy: 0.3111\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6262 - accuracy: 0.4005 - val_loss: 1.9518 - val_accuracy: 0.3111\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6218 - accuracy: 0.4030 - val_loss: 1.9503 - val_accuracy: 0.3111\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6173 - accuracy: 0.4104 - val_loss: 1.9487 - val_accuracy: 0.3111\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6127 - accuracy: 0.4154 - val_loss: 1.9475 - val_accuracy: 0.3111\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6081 - accuracy: 0.4254 - val_loss: 1.9463 - val_accuracy: 0.3111\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6035 - accuracy: 0.4254 - val_loss: 1.9445 - val_accuracy: 0.3111\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5988 - accuracy: 0.4279 - val_loss: 1.9432 - val_accuracy: 0.3111\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5940 - accuracy: 0.4279 - val_loss: 1.9417 - val_accuracy: 0.3111\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5892 - accuracy: 0.4279 - val_loss: 1.9403 - val_accuracy: 0.3111\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5844 - accuracy: 0.4328 - val_loss: 1.9388 - val_accuracy: 0.3111\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5795 - accuracy: 0.4328 - val_loss: 1.9371 - val_accuracy: 0.3111\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5745 - accuracy: 0.4378 - val_loss: 1.9357 - val_accuracy: 0.3111\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5695 - accuracy: 0.4428 - val_loss: 1.9341 - val_accuracy: 0.3111\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5645 - accuracy: 0.4453 - val_loss: 1.9324 - val_accuracy: 0.3111\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5594 - accuracy: 0.4478 - val_loss: 1.9309 - val_accuracy: 0.3111\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5542 - accuracy: 0.4502 - val_loss: 1.9290 - val_accuracy: 0.3111\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5490 - accuracy: 0.4502 - val_loss: 1.9277 - val_accuracy: 0.3111\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5438 - accuracy: 0.4502 - val_loss: 1.9258 - val_accuracy: 0.3111\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5385 - accuracy: 0.4502 - val_loss: 1.9240 - val_accuracy: 0.3111\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5331 - accuracy: 0.4527 - val_loss: 1.9225 - val_accuracy: 0.3111\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5277 - accuracy: 0.4527 - val_loss: 1.9207 - val_accuracy: 0.3111\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5222 - accuracy: 0.4527 - val_loss: 1.9188 - val_accuracy: 0.3111\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5168 - accuracy: 0.4577 - val_loss: 1.9171 - val_accuracy: 0.3111\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5112 - accuracy: 0.4627 - val_loss: 1.9157 - val_accuracy: 0.3111\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5056 - accuracy: 0.4627 - val_loss: 1.9134 - val_accuracy: 0.3111\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4999 - accuracy: 0.4627 - val_loss: 1.9120 - val_accuracy: 0.3111\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4942 - accuracy: 0.4677 - val_loss: 1.9106 - val_accuracy: 0.3111\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4885 - accuracy: 0.4726 - val_loss: 1.9080 - val_accuracy: 0.3111\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4827 - accuracy: 0.4876 - val_loss: 1.9067 - val_accuracy: 0.3111\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4768 - accuracy: 0.4851 - val_loss: 1.9056 - val_accuracy: 0.2889\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4709 - accuracy: 0.4851 - val_loss: 1.9032 - val_accuracy: 0.2889\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4649 - accuracy: 0.4900 - val_loss: 1.9017 - val_accuracy: 0.2889\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4589 - accuracy: 0.4925 - val_loss: 1.9008 - val_accuracy: 0.2889\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4528 - accuracy: 0.5025 - val_loss: 1.8980 - val_accuracy: 0.2889\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4467 - accuracy: 0.5050 - val_loss: 1.8972 - val_accuracy: 0.2889\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4405 - accuracy: 0.5100 - val_loss: 1.8961 - val_accuracy: 0.2889\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4343 - accuracy: 0.5149 - val_loss: 1.8937 - val_accuracy: 0.2889\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4280 - accuracy: 0.5274 - val_loss: 1.8935 - val_accuracy: 0.2889\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4217 - accuracy: 0.5299 - val_loss: 1.8914 - val_accuracy: 0.2889\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4153 - accuracy: 0.5323 - val_loss: 1.8904 - val_accuracy: 0.2889\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4089 - accuracy: 0.5348 - val_loss: 1.8896 - val_accuracy: 0.2889\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4024 - accuracy: 0.5398 - val_loss: 1.8876 - val_accuracy: 0.2889\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3958 - accuracy: 0.5473 - val_loss: 1.8870 - val_accuracy: 0.2889\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3892 - accuracy: 0.5498 - val_loss: 1.8861 - val_accuracy: 0.2889\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3826 - accuracy: 0.5547 - val_loss: 1.8851 - val_accuracy: 0.2889\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3759 - accuracy: 0.5547 - val_loss: 1.8847 - val_accuracy: 0.2889\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3692 - accuracy: 0.5572 - val_loss: 1.8827 - val_accuracy: 0.2889\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3624 - accuracy: 0.5572 - val_loss: 1.8836 - val_accuracy: 0.3111\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3555 - accuracy: 0.5522 - val_loss: 1.8804 - val_accuracy: 0.3111\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3486 - accuracy: 0.5498 - val_loss: 1.8844 - val_accuracy: 0.3111\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3417 - accuracy: 0.5498 - val_loss: 1.8754 - val_accuracy: 0.3111\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3348 - accuracy: 0.5547 - val_loss: 1.8896 - val_accuracy: 0.3111\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3280 - accuracy: 0.5473 - val_loss: 1.8694 - val_accuracy: 0.3111\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3211 - accuracy: 0.5647 - val_loss: 1.8878 - val_accuracy: 0.3111\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3139 - accuracy: 0.5522 - val_loss: 1.8780 - val_accuracy: 0.3111\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3066 - accuracy: 0.5647 - val_loss: 1.8739 - val_accuracy: 0.2889\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2996 - accuracy: 0.5672 - val_loss: 1.8891 - val_accuracy: 0.2444\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2927 - accuracy: 0.5721 - val_loss: 1.8719 - val_accuracy: 0.2889\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2854 - accuracy: 0.5771 - val_loss: 1.8810 - val_accuracy: 0.2667\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2781 - accuracy: 0.5846 - val_loss: 1.8850 - val_accuracy: 0.2444\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2709 - accuracy: 0.5846 - val_loss: 1.8724 - val_accuracy: 0.3111\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2638 - accuracy: 0.5945 - val_loss: 1.8877 - val_accuracy: 0.2667\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2565 - accuracy: 0.5871 - val_loss: 1.8797 - val_accuracy: 0.2667\n",
      "========== Fold 7 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.3124 - accuracy: 0.0597 - val_loss: 2.3317 - val_accuracy: 0.0444\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.3095 - accuracy: 0.0771 - val_loss: 2.3273 - val_accuracy: 0.0889\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3045 - accuracy: 0.0970 - val_loss: 2.3218 - val_accuracy: 0.0889\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.2981 - accuracy: 0.1070 - val_loss: 2.3155 - val_accuracy: 0.0667\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2907 - accuracy: 0.1020 - val_loss: 2.3088 - val_accuracy: 0.0667\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2829 - accuracy: 0.0896 - val_loss: 2.3021 - val_accuracy: 0.0667\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2750 - accuracy: 0.0995 - val_loss: 2.2955 - val_accuracy: 0.0667\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2670 - accuracy: 0.0970 - val_loss: 2.2893 - val_accuracy: 0.0444\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2594 - accuracy: 0.0995 - val_loss: 2.2835 - val_accuracy: 0.0444\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2521 - accuracy: 0.0970 - val_loss: 2.2782 - val_accuracy: 0.0667\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2453 - accuracy: 0.0995 - val_loss: 2.2733 - val_accuracy: 0.0889\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2389 - accuracy: 0.1020 - val_loss: 2.2690 - val_accuracy: 0.0889\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2330 - accuracy: 0.1045 - val_loss: 2.2652 - val_accuracy: 0.0667\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2276 - accuracy: 0.0945 - val_loss: 2.2617 - val_accuracy: 0.0667\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2226 - accuracy: 0.0995 - val_loss: 2.2587 - val_accuracy: 0.0667\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2181 - accuracy: 0.0995 - val_loss: 2.2561 - val_accuracy: 0.0667\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2139 - accuracy: 0.1070 - val_loss: 2.2537 - val_accuracy: 0.0667\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2101 - accuracy: 0.1144 - val_loss: 2.2517 - val_accuracy: 0.0444\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2066 - accuracy: 0.1244 - val_loss: 2.2498 - val_accuracy: 0.0444\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2034 - accuracy: 0.1219 - val_loss: 2.2481 - val_accuracy: 0.0444\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2004 - accuracy: 0.1219 - val_loss: 2.2466 - val_accuracy: 0.0667\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1977 - accuracy: 0.1194 - val_loss: 2.2452 - val_accuracy: 0.0667\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1951 - accuracy: 0.1244 - val_loss: 2.2439 - val_accuracy: 0.0667\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1926 - accuracy: 0.1294 - val_loss: 2.2427 - val_accuracy: 0.0889\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1903 - accuracy: 0.1343 - val_loss: 2.2416 - val_accuracy: 0.0889\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1881 - accuracy: 0.1368 - val_loss: 2.2405 - val_accuracy: 0.0889\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1860 - accuracy: 0.1318 - val_loss: 2.2394 - val_accuracy: 0.1111\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1840 - accuracy: 0.1393 - val_loss: 2.2385 - val_accuracy: 0.1333\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1821 - accuracy: 0.1542 - val_loss: 2.2375 - val_accuracy: 0.1333\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1803 - accuracy: 0.1617 - val_loss: 2.2366 - val_accuracy: 0.1333\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1786 - accuracy: 0.1542 - val_loss: 2.2358 - val_accuracy: 0.1111\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1769 - accuracy: 0.1493 - val_loss: 2.2350 - val_accuracy: 0.1111\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1753 - accuracy: 0.1567 - val_loss: 2.2342 - val_accuracy: 0.1111\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1738 - accuracy: 0.1592 - val_loss: 2.2335 - val_accuracy: 0.1333\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1723 - accuracy: 0.1741 - val_loss: 2.2328 - val_accuracy: 0.1333\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1709 - accuracy: 0.1716 - val_loss: 2.2322 - val_accuracy: 0.1556\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1695 - accuracy: 0.1741 - val_loss: 2.2316 - val_accuracy: 0.1778\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1682 - accuracy: 0.1741 - val_loss: 2.2311 - val_accuracy: 0.1778\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1670 - accuracy: 0.1791 - val_loss: 2.2306 - val_accuracy: 0.1778\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1658 - accuracy: 0.1791 - val_loss: 2.2302 - val_accuracy: 0.1778\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1646 - accuracy: 0.1816 - val_loss: 2.2297 - val_accuracy: 0.1778\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1635 - accuracy: 0.1816 - val_loss: 2.2294 - val_accuracy: 0.1333\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1624 - accuracy: 0.1866 - val_loss: 2.2290 - val_accuracy: 0.1333\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1613 - accuracy: 0.1866 - val_loss: 2.2288 - val_accuracy: 0.1333\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1603 - accuracy: 0.1866 - val_loss: 2.2285 - val_accuracy: 0.1333\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1593 - accuracy: 0.1891 - val_loss: 2.2283 - val_accuracy: 0.1333\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1583 - accuracy: 0.1891 - val_loss: 2.2280 - val_accuracy: 0.1333\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1574 - accuracy: 0.1891 - val_loss: 2.2278 - val_accuracy: 0.1333\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1564 - accuracy: 0.1891 - val_loss: 2.2276 - val_accuracy: 0.1333\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1555 - accuracy: 0.1891 - val_loss: 2.2275 - val_accuracy: 0.1333\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1546 - accuracy: 0.1891 - val_loss: 2.2273 - val_accuracy: 0.1333\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1537 - accuracy: 0.1915 - val_loss: 2.2272 - val_accuracy: 0.1333\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1529 - accuracy: 0.1940 - val_loss: 2.2270 - val_accuracy: 0.1333\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1520 - accuracy: 0.1940 - val_loss: 2.2269 - val_accuracy: 0.1333\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1512 - accuracy: 0.1965 - val_loss: 2.2267 - val_accuracy: 0.1333\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1503 - accuracy: 0.1965 - val_loss: 2.2266 - val_accuracy: 0.1333\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1495 - accuracy: 0.1965 - val_loss: 2.2264 - val_accuracy: 0.1333\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1487 - accuracy: 0.1990 - val_loss: 2.2263 - val_accuracy: 0.1556\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1479 - accuracy: 0.1990 - val_loss: 2.2261 - val_accuracy: 0.1556\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1471 - accuracy: 0.2015 - val_loss: 2.2259 - val_accuracy: 0.1556\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1463 - accuracy: 0.2015 - val_loss: 2.2258 - val_accuracy: 0.1556\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1456 - accuracy: 0.2015 - val_loss: 2.2256 - val_accuracy: 0.1556\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1448 - accuracy: 0.2015 - val_loss: 2.2254 - val_accuracy: 0.1556\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1440 - accuracy: 0.2015 - val_loss: 2.2252 - val_accuracy: 0.1556\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1433 - accuracy: 0.2040 - val_loss: 2.2250 - val_accuracy: 0.1556\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1425 - accuracy: 0.2040 - val_loss: 2.2247 - val_accuracy: 0.1556\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1418 - accuracy: 0.2040 - val_loss: 2.2245 - val_accuracy: 0.1556\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1410 - accuracy: 0.2040 - val_loss: 2.2242 - val_accuracy: 0.1556\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1403 - accuracy: 0.2040 - val_loss: 2.2240 - val_accuracy: 0.1556\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1396 - accuracy: 0.2040 - val_loss: 2.2237 - val_accuracy: 0.1556\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1388 - accuracy: 0.2040 - val_loss: 2.2234 - val_accuracy: 0.1556\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1381 - accuracy: 0.2040 - val_loss: 2.2232 - val_accuracy: 0.1556\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1374 - accuracy: 0.2065 - val_loss: 2.2229 - val_accuracy: 0.1556\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1366 - accuracy: 0.2065 - val_loss: 2.2226 - val_accuracy: 0.1556\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1359 - accuracy: 0.2065 - val_loss: 2.2222 - val_accuracy: 0.1556\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1352 - accuracy: 0.2114 - val_loss: 2.2219 - val_accuracy: 0.1778\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1344 - accuracy: 0.2114 - val_loss: 2.2216 - val_accuracy: 0.1778\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1337 - accuracy: 0.2139 - val_loss: 2.2212 - val_accuracy: 0.1778\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1329 - accuracy: 0.2139 - val_loss: 2.2209 - val_accuracy: 0.1778\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1322 - accuracy: 0.2139 - val_loss: 2.2205 - val_accuracy: 0.1778\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1315 - accuracy: 0.2164 - val_loss: 2.2201 - val_accuracy: 0.1778\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1307 - accuracy: 0.2189 - val_loss: 2.2197 - val_accuracy: 0.1778\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1299 - accuracy: 0.2189 - val_loss: 2.2193 - val_accuracy: 0.1778\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1292 - accuracy: 0.2214 - val_loss: 2.2190 - val_accuracy: 0.1778\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1284 - accuracy: 0.2214 - val_loss: 2.2185 - val_accuracy: 0.1778\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1277 - accuracy: 0.2214 - val_loss: 2.2181 - val_accuracy: 0.1778\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1269 - accuracy: 0.2214 - val_loss: 2.2177 - val_accuracy: 0.1778\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.1261 - accuracy: 0.2214 - val_loss: 2.2172 - val_accuracy: 0.1778\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1253 - accuracy: 0.2214 - val_loss: 2.2168 - val_accuracy: 0.1778\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1245 - accuracy: 0.2214 - val_loss: 2.2163 - val_accuracy: 0.2000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.1237 - accuracy: 0.2214 - val_loss: 2.2158 - val_accuracy: 0.2000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1229 - accuracy: 0.2239 - val_loss: 2.2153 - val_accuracy: 0.2000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1221 - accuracy: 0.2239 - val_loss: 2.2148 - val_accuracy: 0.2000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1212 - accuracy: 0.2239 - val_loss: 2.2143 - val_accuracy: 0.2222\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1204 - accuracy: 0.2239 - val_loss: 2.2137 - val_accuracy: 0.2222\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1196 - accuracy: 0.2264 - val_loss: 2.2132 - val_accuracy: 0.2222\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1187 - accuracy: 0.2313 - val_loss: 2.2126 - val_accuracy: 0.2222\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1178 - accuracy: 0.2313 - val_loss: 2.2120 - val_accuracy: 0.2222\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1169 - accuracy: 0.2338 - val_loss: 2.2114 - val_accuracy: 0.2222\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1161 - accuracy: 0.2388 - val_loss: 2.2108 - val_accuracy: 0.2222\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1152 - accuracy: 0.2388 - val_loss: 2.2102 - val_accuracy: 0.2222\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1142 - accuracy: 0.2388 - val_loss: 2.2095 - val_accuracy: 0.2222\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1133 - accuracy: 0.2388 - val_loss: 2.2088 - val_accuracy: 0.2222\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1124 - accuracy: 0.2388 - val_loss: 2.2081 - val_accuracy: 0.2222\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1114 - accuracy: 0.2388 - val_loss: 2.2075 - val_accuracy: 0.2222\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.1104 - accuracy: 0.2388 - val_loss: 2.2067 - val_accuracy: 0.2222\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1095 - accuracy: 0.2413 - val_loss: 2.2060 - val_accuracy: 0.2222\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1085 - accuracy: 0.2438 - val_loss: 2.2053 - val_accuracy: 0.2222\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1075 - accuracy: 0.2463 - val_loss: 2.2045 - val_accuracy: 0.2222\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1064 - accuracy: 0.2463 - val_loss: 2.2037 - val_accuracy: 0.2222\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1054 - accuracy: 0.2438 - val_loss: 2.2029 - val_accuracy: 0.2222\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1043 - accuracy: 0.2438 - val_loss: 2.2021 - val_accuracy: 0.2222\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1033 - accuracy: 0.2463 - val_loss: 2.2013 - val_accuracy: 0.2222\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1022 - accuracy: 0.2463 - val_loss: 2.2005 - val_accuracy: 0.2222\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1011 - accuracy: 0.2463 - val_loss: 2.1996 - val_accuracy: 0.2222\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1000 - accuracy: 0.2463 - val_loss: 2.1988 - val_accuracy: 0.2222\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0988 - accuracy: 0.2463 - val_loss: 2.1979 - val_accuracy: 0.2222\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0977 - accuracy: 0.2488 - val_loss: 2.1971 - val_accuracy: 0.2444\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0965 - accuracy: 0.2488 - val_loss: 2.1962 - val_accuracy: 0.2444\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0953 - accuracy: 0.2512 - val_loss: 2.1953 - val_accuracy: 0.2444\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0941 - accuracy: 0.2587 - val_loss: 2.1944 - val_accuracy: 0.2444\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0928 - accuracy: 0.2587 - val_loss: 2.1935 - val_accuracy: 0.2444\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0916 - accuracy: 0.2562 - val_loss: 2.1925 - val_accuracy: 0.2444\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0903 - accuracy: 0.2562 - val_loss: 2.1916 - val_accuracy: 0.2444\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0890 - accuracy: 0.2562 - val_loss: 2.1907 - val_accuracy: 0.2444\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0877 - accuracy: 0.2562 - val_loss: 2.1897 - val_accuracy: 0.2444\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0864 - accuracy: 0.2587 - val_loss: 2.1888 - val_accuracy: 0.2444\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0850 - accuracy: 0.2637 - val_loss: 2.1878 - val_accuracy: 0.2444\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0837 - accuracy: 0.2662 - val_loss: 2.1869 - val_accuracy: 0.2444\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0823 - accuracy: 0.2662 - val_loss: 2.1859 - val_accuracy: 0.2444\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0809 - accuracy: 0.2687 - val_loss: 2.1850 - val_accuracy: 0.2444\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0795 - accuracy: 0.2711 - val_loss: 2.1840 - val_accuracy: 0.2222\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0780 - accuracy: 0.2761 - val_loss: 2.1830 - val_accuracy: 0.2222\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0765 - accuracy: 0.2786 - val_loss: 2.1820 - val_accuracy: 0.2222\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0751 - accuracy: 0.2786 - val_loss: 2.1810 - val_accuracy: 0.2222\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0735 - accuracy: 0.2811 - val_loss: 2.1801 - val_accuracy: 0.2222\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0720 - accuracy: 0.2836 - val_loss: 2.1791 - val_accuracy: 0.2222\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0705 - accuracy: 0.2811 - val_loss: 2.1781 - val_accuracy: 0.2222\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0689 - accuracy: 0.2811 - val_loss: 2.1771 - val_accuracy: 0.2222\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0673 - accuracy: 0.2811 - val_loss: 2.1761 - val_accuracy: 0.2222\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0657 - accuracy: 0.2786 - val_loss: 2.1751 - val_accuracy: 0.2222\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0641 - accuracy: 0.2861 - val_loss: 2.1741 - val_accuracy: 0.2444\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0625 - accuracy: 0.2861 - val_loss: 2.1732 - val_accuracy: 0.2444\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0609 - accuracy: 0.2886 - val_loss: 2.1722 - val_accuracy: 0.2444\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.0592 - accuracy: 0.2935 - val_loss: 2.1713 - val_accuracy: 0.2667\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0575 - accuracy: 0.2935 - val_loss: 2.1703 - val_accuracy: 0.2667\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0559 - accuracy: 0.2960 - val_loss: 2.1694 - val_accuracy: 0.2667\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0542 - accuracy: 0.3010 - val_loss: 2.1684 - val_accuracy: 0.2667\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0525 - accuracy: 0.3010 - val_loss: 2.1675 - val_accuracy: 0.2667\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0508 - accuracy: 0.2985 - val_loss: 2.1666 - val_accuracy: 0.2667\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0490 - accuracy: 0.2985 - val_loss: 2.1657 - val_accuracy: 0.2667\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0473 - accuracy: 0.3035 - val_loss: 2.1649 - val_accuracy: 0.2667\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0456 - accuracy: 0.3035 - val_loss: 2.1640 - val_accuracy: 0.2667\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0438 - accuracy: 0.3035 - val_loss: 2.1632 - val_accuracy: 0.2444\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0421 - accuracy: 0.3085 - val_loss: 2.1624 - val_accuracy: 0.2444\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0404 - accuracy: 0.3085 - val_loss: 2.1616 - val_accuracy: 0.2444\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0386 - accuracy: 0.3060 - val_loss: 2.1608 - val_accuracy: 0.2444\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0369 - accuracy: 0.3035 - val_loss: 2.1601 - val_accuracy: 0.2444\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0351 - accuracy: 0.3035 - val_loss: 2.1593 - val_accuracy: 0.2667\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0334 - accuracy: 0.3060 - val_loss: 2.1586 - val_accuracy: 0.2667\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0316 - accuracy: 0.3060 - val_loss: 2.1579 - val_accuracy: 0.2667\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0299 - accuracy: 0.3010 - val_loss: 2.1572 - val_accuracy: 0.2667\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0281 - accuracy: 0.2985 - val_loss: 2.1566 - val_accuracy: 0.2667\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0264 - accuracy: 0.2985 - val_loss: 2.1559 - val_accuracy: 0.2667\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0247 - accuracy: 0.2935 - val_loss: 2.1553 - val_accuracy: 0.2667\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0229 - accuracy: 0.2935 - val_loss: 2.1547 - val_accuracy: 0.2667\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0212 - accuracy: 0.2960 - val_loss: 2.1541 - val_accuracy: 0.2667\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0195 - accuracy: 0.2985 - val_loss: 2.1535 - val_accuracy: 0.2667\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0177 - accuracy: 0.2985 - val_loss: 2.1530 - val_accuracy: 0.2667\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0160 - accuracy: 0.2960 - val_loss: 2.1524 - val_accuracy: 0.2667\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0143 - accuracy: 0.2935 - val_loss: 2.1519 - val_accuracy: 0.2667\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0126 - accuracy: 0.2985 - val_loss: 2.1513 - val_accuracy: 0.2667\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0109 - accuracy: 0.2985 - val_loss: 2.1508 - val_accuracy: 0.2667\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0091 - accuracy: 0.2960 - val_loss: 2.1502 - val_accuracy: 0.2667\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0074 - accuracy: 0.2935 - val_loss: 2.1497 - val_accuracy: 0.2667\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0057 - accuracy: 0.2985 - val_loss: 2.1491 - val_accuracy: 0.2667\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0039 - accuracy: 0.2985 - val_loss: 2.1485 - val_accuracy: 0.2667\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0022 - accuracy: 0.2960 - val_loss: 2.1480 - val_accuracy: 0.2667\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0005 - accuracy: 0.2960 - val_loss: 2.1474 - val_accuracy: 0.2889\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9987 - accuracy: 0.2935 - val_loss: 2.1468 - val_accuracy: 0.2889\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9969 - accuracy: 0.2935 - val_loss: 2.1463 - val_accuracy: 0.2889\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9952 - accuracy: 0.2960 - val_loss: 2.1457 - val_accuracy: 0.2889\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9934 - accuracy: 0.2960 - val_loss: 2.1450 - val_accuracy: 0.2889\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9916 - accuracy: 0.2960 - val_loss: 2.1443 - val_accuracy: 0.2667\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9898 - accuracy: 0.2960 - val_loss: 2.1437 - val_accuracy: 0.2667\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9879 - accuracy: 0.2935 - val_loss: 2.1430 - val_accuracy: 0.2667\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9861 - accuracy: 0.2985 - val_loss: 2.1422 - val_accuracy: 0.2667\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9842 - accuracy: 0.3035 - val_loss: 2.1415 - val_accuracy: 0.2889\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9823 - accuracy: 0.3035 - val_loss: 2.1408 - val_accuracy: 0.2889\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9804 - accuracy: 0.3035 - val_loss: 2.1399 - val_accuracy: 0.2889\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9785 - accuracy: 0.3010 - val_loss: 2.1391 - val_accuracy: 0.2889\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9765 - accuracy: 0.3060 - val_loss: 2.1383 - val_accuracy: 0.2889\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9745 - accuracy: 0.3159 - val_loss: 2.1375 - val_accuracy: 0.2889\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9725 - accuracy: 0.3159 - val_loss: 2.1366 - val_accuracy: 0.2889\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9705 - accuracy: 0.3109 - val_loss: 2.1357 - val_accuracy: 0.2889\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9685 - accuracy: 0.3159 - val_loss: 2.1347 - val_accuracy: 0.2889\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9664 - accuracy: 0.3159 - val_loss: 2.1337 - val_accuracy: 0.2889\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9644 - accuracy: 0.3209 - val_loss: 2.1327 - val_accuracy: 0.2889\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9623 - accuracy: 0.3209 - val_loss: 2.1318 - val_accuracy: 0.2889\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9602 - accuracy: 0.3284 - val_loss: 2.1307 - val_accuracy: 0.2889\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9580 - accuracy: 0.3333 - val_loss: 2.1296 - val_accuracy: 0.2889\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9559 - accuracy: 0.3308 - val_loss: 2.1286 - val_accuracy: 0.2889\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9537 - accuracy: 0.3308 - val_loss: 2.1274 - val_accuracy: 0.2889\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9515 - accuracy: 0.3308 - val_loss: 2.1263 - val_accuracy: 0.2889\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9493 - accuracy: 0.3234 - val_loss: 2.1251 - val_accuracy: 0.2889\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9471 - accuracy: 0.3284 - val_loss: 2.1240 - val_accuracy: 0.2889\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9449 - accuracy: 0.3308 - val_loss: 2.1228 - val_accuracy: 0.2889\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9427 - accuracy: 0.3308 - val_loss: 2.1216 - val_accuracy: 0.2889\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9404 - accuracy: 0.3333 - val_loss: 2.1204 - val_accuracy: 0.2889\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9382 - accuracy: 0.3308 - val_loss: 2.1191 - val_accuracy: 0.2889\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9359 - accuracy: 0.3308 - val_loss: 2.1178 - val_accuracy: 0.2667\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9337 - accuracy: 0.3333 - val_loss: 2.1166 - val_accuracy: 0.2667\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9314 - accuracy: 0.3358 - val_loss: 2.1153 - val_accuracy: 0.2667\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9292 - accuracy: 0.3358 - val_loss: 2.1140 - val_accuracy: 0.2667\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9269 - accuracy: 0.3333 - val_loss: 2.1127 - val_accuracy: 0.2667\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9246 - accuracy: 0.3333 - val_loss: 2.1114 - val_accuracy: 0.2444\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.9224 - accuracy: 0.3308 - val_loss: 2.1101 - val_accuracy: 0.2444\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9201 - accuracy: 0.3259 - val_loss: 2.1088 - val_accuracy: 0.2444\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9179 - accuracy: 0.3234 - val_loss: 2.1074 - val_accuracy: 0.2444\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9157 - accuracy: 0.3234 - val_loss: 2.1061 - val_accuracy: 0.2444\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9135 - accuracy: 0.3259 - val_loss: 2.1048 - val_accuracy: 0.2444\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.9112 - accuracy: 0.3308 - val_loss: 2.1035 - val_accuracy: 0.2444\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9091 - accuracy: 0.3284 - val_loss: 2.1021 - val_accuracy: 0.2667\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9069 - accuracy: 0.3284 - val_loss: 2.1008 - val_accuracy: 0.2667\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9047 - accuracy: 0.3234 - val_loss: 2.0994 - val_accuracy: 0.2667\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9026 - accuracy: 0.3259 - val_loss: 2.0980 - val_accuracy: 0.2667\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9004 - accuracy: 0.3259 - val_loss: 2.0967 - val_accuracy: 0.2667\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8983 - accuracy: 0.3259 - val_loss: 2.0953 - val_accuracy: 0.2444\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8962 - accuracy: 0.3259 - val_loss: 2.0940 - val_accuracy: 0.2444\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8941 - accuracy: 0.3234 - val_loss: 2.0926 - val_accuracy: 0.2667\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8920 - accuracy: 0.3209 - val_loss: 2.0912 - val_accuracy: 0.2667\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.8899 - accuracy: 0.3259 - val_loss: 2.0898 - val_accuracy: 0.2667\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8879 - accuracy: 0.3259 - val_loss: 2.0884 - val_accuracy: 0.2667\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8859 - accuracy: 0.3284 - val_loss: 2.0870 - val_accuracy: 0.2667\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8838 - accuracy: 0.3234 - val_loss: 2.0855 - val_accuracy: 0.2667\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8818 - accuracy: 0.3234 - val_loss: 2.0841 - val_accuracy: 0.2667\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.8798 - accuracy: 0.3259 - val_loss: 2.0826 - val_accuracy: 0.2667\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8777 - accuracy: 0.3284 - val_loss: 2.0812 - val_accuracy: 0.2667\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8757 - accuracy: 0.3308 - val_loss: 2.0796 - val_accuracy: 0.2667\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8737 - accuracy: 0.3308 - val_loss: 2.0781 - val_accuracy: 0.2667\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8717 - accuracy: 0.3308 - val_loss: 2.0766 - val_accuracy: 0.2667\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.8697 - accuracy: 0.3333 - val_loss: 2.0750 - val_accuracy: 0.2667\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8676 - accuracy: 0.3333 - val_loss: 2.0735 - val_accuracy: 0.2667\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8656 - accuracy: 0.3333 - val_loss: 2.0718 - val_accuracy: 0.2667\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8636 - accuracy: 0.3333 - val_loss: 2.0702 - val_accuracy: 0.2667\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8615 - accuracy: 0.3333 - val_loss: 2.0686 - val_accuracy: 0.2667\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8595 - accuracy: 0.3333 - val_loss: 2.0670 - val_accuracy: 0.2667\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.8574 - accuracy: 0.3358 - val_loss: 2.0653 - val_accuracy: 0.2667\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8553 - accuracy: 0.3358 - val_loss: 2.0637 - val_accuracy: 0.2667\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8533 - accuracy: 0.3383 - val_loss: 2.0621 - val_accuracy: 0.2667\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8512 - accuracy: 0.3433 - val_loss: 2.0604 - val_accuracy: 0.2667\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8491 - accuracy: 0.3433 - val_loss: 2.0588 - val_accuracy: 0.2667\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8470 - accuracy: 0.3433 - val_loss: 2.0571 - val_accuracy: 0.2667\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8448 - accuracy: 0.3483 - val_loss: 2.0555 - val_accuracy: 0.2667\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8427 - accuracy: 0.3458 - val_loss: 2.0539 - val_accuracy: 0.2667\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8406 - accuracy: 0.3483 - val_loss: 2.0522 - val_accuracy: 0.2667\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8384 - accuracy: 0.3458 - val_loss: 2.0506 - val_accuracy: 0.2667\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8362 - accuracy: 0.3483 - val_loss: 2.0490 - val_accuracy: 0.2667\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8340 - accuracy: 0.3507 - val_loss: 2.0474 - val_accuracy: 0.2667\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8318 - accuracy: 0.3507 - val_loss: 2.0458 - val_accuracy: 0.2667\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8296 - accuracy: 0.3507 - val_loss: 2.0442 - val_accuracy: 0.2667\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8273 - accuracy: 0.3532 - val_loss: 2.0426 - val_accuracy: 0.2667\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8250 - accuracy: 0.3507 - val_loss: 2.0410 - val_accuracy: 0.2667\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8228 - accuracy: 0.3507 - val_loss: 2.0394 - val_accuracy: 0.2667\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8204 - accuracy: 0.3507 - val_loss: 2.0378 - val_accuracy: 0.2667\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8181 - accuracy: 0.3507 - val_loss: 2.0363 - val_accuracy: 0.2667\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8158 - accuracy: 0.3483 - val_loss: 2.0347 - val_accuracy: 0.2667\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8134 - accuracy: 0.3507 - val_loss: 2.0330 - val_accuracy: 0.2667\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8110 - accuracy: 0.3557 - val_loss: 2.0314 - val_accuracy: 0.2667\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8086 - accuracy: 0.3557 - val_loss: 2.0298 - val_accuracy: 0.2667\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8061 - accuracy: 0.3532 - val_loss: 2.0281 - val_accuracy: 0.2667\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8037 - accuracy: 0.3532 - val_loss: 2.0265 - val_accuracy: 0.2667\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8012 - accuracy: 0.3557 - val_loss: 2.0248 - val_accuracy: 0.2667\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7986 - accuracy: 0.3582 - val_loss: 2.0231 - val_accuracy: 0.2667\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7961 - accuracy: 0.3582 - val_loss: 2.0215 - val_accuracy: 0.2667\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7935 - accuracy: 0.3607 - val_loss: 2.0198 - val_accuracy: 0.2667\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7909 - accuracy: 0.3632 - val_loss: 2.0181 - val_accuracy: 0.2667\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7883 - accuracy: 0.3657 - val_loss: 2.0164 - val_accuracy: 0.2667\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7857 - accuracy: 0.3657 - val_loss: 2.0147 - val_accuracy: 0.2667\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7830 - accuracy: 0.3657 - val_loss: 2.0130 - val_accuracy: 0.2667\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7803 - accuracy: 0.3657 - val_loss: 2.0113 - val_accuracy: 0.2667\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7775 - accuracy: 0.3657 - val_loss: 2.0096 - val_accuracy: 0.2667\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7748 - accuracy: 0.3607 - val_loss: 2.0079 - val_accuracy: 0.2667\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7720 - accuracy: 0.3607 - val_loss: 2.0062 - val_accuracy: 0.2667\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7691 - accuracy: 0.3632 - val_loss: 2.0045 - val_accuracy: 0.2667\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7663 - accuracy: 0.3657 - val_loss: 2.0028 - val_accuracy: 0.2667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7634 - accuracy: 0.3682 - val_loss: 2.0011 - val_accuracy: 0.2667\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7605 - accuracy: 0.3682 - val_loss: 1.9994 - val_accuracy: 0.2667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7575 - accuracy: 0.3682 - val_loss: 1.9976 - val_accuracy: 0.2667\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7545 - accuracy: 0.3682 - val_loss: 1.9958 - val_accuracy: 0.2667\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7515 - accuracy: 0.3657 - val_loss: 1.9941 - val_accuracy: 0.2667\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7484 - accuracy: 0.3682 - val_loss: 1.9923 - val_accuracy: 0.2667\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7453 - accuracy: 0.3682 - val_loss: 1.9905 - val_accuracy: 0.2667\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7422 - accuracy: 0.3682 - val_loss: 1.9887 - val_accuracy: 0.2667\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7390 - accuracy: 0.3682 - val_loss: 1.9869 - val_accuracy: 0.2667\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7358 - accuracy: 0.3657 - val_loss: 1.9850 - val_accuracy: 0.2667\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7326 - accuracy: 0.3657 - val_loss: 1.9831 - val_accuracy: 0.2667\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7293 - accuracy: 0.3706 - val_loss: 1.9812 - val_accuracy: 0.2667\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7259 - accuracy: 0.3731 - val_loss: 1.9793 - val_accuracy: 0.2667\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7226 - accuracy: 0.3756 - val_loss: 1.9774 - val_accuracy: 0.2667\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7192 - accuracy: 0.3756 - val_loss: 1.9754 - val_accuracy: 0.2667\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7157 - accuracy: 0.3781 - val_loss: 1.9735 - val_accuracy: 0.2667\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7122 - accuracy: 0.3831 - val_loss: 1.9714 - val_accuracy: 0.2667\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7087 - accuracy: 0.3831 - val_loss: 1.9694 - val_accuracy: 0.2667\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7052 - accuracy: 0.3831 - val_loss: 1.9674 - val_accuracy: 0.2667\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7015 - accuracy: 0.3856 - val_loss: 1.9654 - val_accuracy: 0.2667\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6979 - accuracy: 0.3806 - val_loss: 1.9633 - val_accuracy: 0.2667\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.6942 - accuracy: 0.3831 - val_loss: 1.9612 - val_accuracy: 0.2667\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6905 - accuracy: 0.3856 - val_loss: 1.9592 - val_accuracy: 0.2667\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6867 - accuracy: 0.3856 - val_loss: 1.9570 - val_accuracy: 0.2667\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.6829 - accuracy: 0.3856 - val_loss: 1.9549 - val_accuracy: 0.2667\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6790 - accuracy: 0.3831 - val_loss: 1.9527 - val_accuracy: 0.2667\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6751 - accuracy: 0.3856 - val_loss: 1.9506 - val_accuracy: 0.2667\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6711 - accuracy: 0.3905 - val_loss: 1.9483 - val_accuracy: 0.2667\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6671 - accuracy: 0.3881 - val_loss: 1.9461 - val_accuracy: 0.2667\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6631 - accuracy: 0.3881 - val_loss: 1.9439 - val_accuracy: 0.2667\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.6590 - accuracy: 0.3955 - val_loss: 1.9418 - val_accuracy: 0.2667\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6548 - accuracy: 0.4005 - val_loss: 1.9395 - val_accuracy: 0.2667\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6506 - accuracy: 0.4030 - val_loss: 1.9372 - val_accuracy: 0.2667\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6464 - accuracy: 0.4080 - val_loss: 1.9349 - val_accuracy: 0.2667\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6421 - accuracy: 0.4104 - val_loss: 1.9327 - val_accuracy: 0.2667\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6378 - accuracy: 0.4104 - val_loss: 1.9304 - val_accuracy: 0.2667\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6334 - accuracy: 0.4154 - val_loss: 1.9281 - val_accuracy: 0.2667\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6290 - accuracy: 0.4179 - val_loss: 1.9259 - val_accuracy: 0.2667\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.6245 - accuracy: 0.4154 - val_loss: 1.9236 - val_accuracy: 0.2667\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6200 - accuracy: 0.4179 - val_loss: 1.9213 - val_accuracy: 0.2667\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6154 - accuracy: 0.4229 - val_loss: 1.9190 - val_accuracy: 0.2667\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6108 - accuracy: 0.4254 - val_loss: 1.9168 - val_accuracy: 0.2667\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6062 - accuracy: 0.4303 - val_loss: 1.9145 - val_accuracy: 0.2667\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6014 - accuracy: 0.4279 - val_loss: 1.9122 - val_accuracy: 0.2889\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.5967 - accuracy: 0.4303 - val_loss: 1.9100 - val_accuracy: 0.2889\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5918 - accuracy: 0.4378 - val_loss: 1.9079 - val_accuracy: 0.2889\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5870 - accuracy: 0.4428 - val_loss: 1.9057 - val_accuracy: 0.2889\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5820 - accuracy: 0.4428 - val_loss: 1.9035 - val_accuracy: 0.2889\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5771 - accuracy: 0.4453 - val_loss: 1.9014 - val_accuracy: 0.2889\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5720 - accuracy: 0.4478 - val_loss: 1.8993 - val_accuracy: 0.2889\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5669 - accuracy: 0.4552 - val_loss: 1.8972 - val_accuracy: 0.3111\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5618 - accuracy: 0.4577 - val_loss: 1.8951 - val_accuracy: 0.3111\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5566 - accuracy: 0.4627 - val_loss: 1.8930 - val_accuracy: 0.3111\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5513 - accuracy: 0.4602 - val_loss: 1.8910 - val_accuracy: 0.3111\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5460 - accuracy: 0.4627 - val_loss: 1.8890 - val_accuracy: 0.3111\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5407 - accuracy: 0.4701 - val_loss: 1.8872 - val_accuracy: 0.3111\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5352 - accuracy: 0.4726 - val_loss: 1.8852 - val_accuracy: 0.3111\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5297 - accuracy: 0.4701 - val_loss: 1.8832 - val_accuracy: 0.2889\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5242 - accuracy: 0.4726 - val_loss: 1.8813 - val_accuracy: 0.2889\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5185 - accuracy: 0.4776 - val_loss: 1.8794 - val_accuracy: 0.2889\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5129 - accuracy: 0.4826 - val_loss: 1.8775 - val_accuracy: 0.2889\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5071 - accuracy: 0.4826 - val_loss: 1.8757 - val_accuracy: 0.2889\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5013 - accuracy: 0.4876 - val_loss: 1.8737 - val_accuracy: 0.2667\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4954 - accuracy: 0.4900 - val_loss: 1.8719 - val_accuracy: 0.2667\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4895 - accuracy: 0.4950 - val_loss: 1.8701 - val_accuracy: 0.2667\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4835 - accuracy: 0.5000 - val_loss: 1.8682 - val_accuracy: 0.2667\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4774 - accuracy: 0.5025 - val_loss: 1.8664 - val_accuracy: 0.2667\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4713 - accuracy: 0.5025 - val_loss: 1.8646 - val_accuracy: 0.2667\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4651 - accuracy: 0.5025 - val_loss: 1.8627 - val_accuracy: 0.2667\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4588 - accuracy: 0.5050 - val_loss: 1.8609 - val_accuracy: 0.2667\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4524 - accuracy: 0.5100 - val_loss: 1.8592 - val_accuracy: 0.2667\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4461 - accuracy: 0.5100 - val_loss: 1.8575 - val_accuracy: 0.2667\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4396 - accuracy: 0.5100 - val_loss: 1.8558 - val_accuracy: 0.2667\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4331 - accuracy: 0.5149 - val_loss: 1.8541 - val_accuracy: 0.2667\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4265 - accuracy: 0.5199 - val_loss: 1.8525 - val_accuracy: 0.2667\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4198 - accuracy: 0.5299 - val_loss: 1.8511 - val_accuracy: 0.2667\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4131 - accuracy: 0.5299 - val_loss: 1.8496 - val_accuracy: 0.2667\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4064 - accuracy: 0.5398 - val_loss: 1.8479 - val_accuracy: 0.2667\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3996 - accuracy: 0.5299 - val_loss: 1.8472 - val_accuracy: 0.2667\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3929 - accuracy: 0.5398 - val_loss: 1.8456 - val_accuracy: 0.2667\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3861 - accuracy: 0.5398 - val_loss: 1.8451 - val_accuracy: 0.2667\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3791 - accuracy: 0.5448 - val_loss: 1.8433 - val_accuracy: 0.2667\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3719 - accuracy: 0.5572 - val_loss: 1.8425 - val_accuracy: 0.2667\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3648 - accuracy: 0.5597 - val_loss: 1.8422 - val_accuracy: 0.2667\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.3579 - accuracy: 0.5647 - val_loss: 1.8407 - val_accuracy: 0.2889\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3509 - accuracy: 0.5622 - val_loss: 1.8408 - val_accuracy: 0.2889\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3436 - accuracy: 0.5672 - val_loss: 1.8395 - val_accuracy: 0.2889\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3362 - accuracy: 0.5647 - val_loss: 1.8390 - val_accuracy: 0.2889\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3290 - accuracy: 0.5672 - val_loss: 1.8396 - val_accuracy: 0.2889\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3219 - accuracy: 0.5697 - val_loss: 1.8385 - val_accuracy: 0.2889\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3148 - accuracy: 0.5622 - val_loss: 1.8395 - val_accuracy: 0.2667\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3075 - accuracy: 0.5746 - val_loss: 1.8381 - val_accuracy: 0.2889\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3000 - accuracy: 0.5746 - val_loss: 1.8389 - val_accuracy: 0.2667\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2924 - accuracy: 0.5796 - val_loss: 1.8388 - val_accuracy: 0.2667\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2850 - accuracy: 0.5846 - val_loss: 1.8390 - val_accuracy: 0.2667\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2776 - accuracy: 0.5846 - val_loss: 1.8400 - val_accuracy: 0.2667\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2703 - accuracy: 0.5920 - val_loss: 1.8394 - val_accuracy: 0.2889\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2631 - accuracy: 0.5896 - val_loss: 1.8422 - val_accuracy: 0.2667\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2562 - accuracy: 0.5896 - val_loss: 1.8409 - val_accuracy: 0.2889\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2491 - accuracy: 0.5871 - val_loss: 1.8437 - val_accuracy: 0.2667\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2415 - accuracy: 0.5945 - val_loss: 1.8423 - val_accuracy: 0.2889\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2332 - accuracy: 0.5995 - val_loss: 1.8435 - val_accuracy: 0.2889\n",
      "========== Fold 8 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.3300 - accuracy: 0.1393 - val_loss: 2.2807 - val_accuracy: 0.1333\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3263 - accuracy: 0.1393 - val_loss: 2.2762 - val_accuracy: 0.1333\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3201 - accuracy: 0.1393 - val_loss: 2.2706 - val_accuracy: 0.1333\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3122 - accuracy: 0.1393 - val_loss: 2.2645 - val_accuracy: 0.1333\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.3033 - accuracy: 0.1393 - val_loss: 2.2581 - val_accuracy: 0.1333\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2938 - accuracy: 0.1393 - val_loss: 2.2519 - val_accuracy: 0.1333\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2842 - accuracy: 0.1393 - val_loss: 2.2462 - val_accuracy: 0.1333\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2748 - accuracy: 0.1393 - val_loss: 2.2411 - val_accuracy: 0.1333\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2658 - accuracy: 0.1393 - val_loss: 2.2366 - val_accuracy: 0.1333\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.2574 - accuracy: 0.1393 - val_loss: 2.2329 - val_accuracy: 0.1333\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2497 - accuracy: 0.1393 - val_loss: 2.2300 - val_accuracy: 0.1333\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2426 - accuracy: 0.1393 - val_loss: 2.2278 - val_accuracy: 0.1333\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.2363 - accuracy: 0.1418 - val_loss: 2.2263 - val_accuracy: 0.1333\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.2307 - accuracy: 0.1468 - val_loss: 2.2254 - val_accuracy: 0.1556\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.2258 - accuracy: 0.1542 - val_loss: 2.2250 - val_accuracy: 0.2000\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2215 - accuracy: 0.1617 - val_loss: 2.2250 - val_accuracy: 0.2000\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.2177 - accuracy: 0.1567 - val_loss: 2.2254 - val_accuracy: 0.2222\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2144 - accuracy: 0.1642 - val_loss: 2.2260 - val_accuracy: 0.2000\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.2114 - accuracy: 0.1592 - val_loss: 2.2267 - val_accuracy: 0.1778\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.2088 - accuracy: 0.1542 - val_loss: 2.2275 - val_accuracy: 0.1778\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2064 - accuracy: 0.1517 - val_loss: 2.2282 - val_accuracy: 0.2000\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2042 - accuracy: 0.1493 - val_loss: 2.2288 - val_accuracy: 0.2000\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2022 - accuracy: 0.1517 - val_loss: 2.2293 - val_accuracy: 0.2222\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2002 - accuracy: 0.1542 - val_loss: 2.2296 - val_accuracy: 0.1778\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1983 - accuracy: 0.1816 - val_loss: 2.2298 - val_accuracy: 0.1778\n",
      "========== Fold 9 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 2.3504 - accuracy: 0.1244 - val_loss: 2.3911 - val_accuracy: 0.1111\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.3471 - accuracy: 0.1244 - val_loss: 2.3835 - val_accuracy: 0.1111\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.3415 - accuracy: 0.1244 - val_loss: 2.3737 - val_accuracy: 0.1111\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.3344 - accuracy: 0.1244 - val_loss: 2.3624 - val_accuracy: 0.1111\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3262 - accuracy: 0.1269 - val_loss: 2.3499 - val_accuracy: 0.1111\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3173 - accuracy: 0.1269 - val_loss: 2.3369 - val_accuracy: 0.1111\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.3081 - accuracy: 0.1269 - val_loss: 2.3236 - val_accuracy: 0.1111\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.2988 - accuracy: 0.1269 - val_loss: 2.3102 - val_accuracy: 0.1111\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2896 - accuracy: 0.1343 - val_loss: 2.2972 - val_accuracy: 0.1333\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2808 - accuracy: 0.1269 - val_loss: 2.2846 - val_accuracy: 0.1556\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2725 - accuracy: 0.1368 - val_loss: 2.2725 - val_accuracy: 0.1556\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.2646 - accuracy: 0.1393 - val_loss: 2.2612 - val_accuracy: 0.1556\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2573 - accuracy: 0.1393 - val_loss: 2.2506 - val_accuracy: 0.1556\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2507 - accuracy: 0.1393 - val_loss: 2.2408 - val_accuracy: 0.1556\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2446 - accuracy: 0.1393 - val_loss: 2.2317 - val_accuracy: 0.1556\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2391 - accuracy: 0.1393 - val_loss: 2.2235 - val_accuracy: 0.1556\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2342 - accuracy: 0.1517 - val_loss: 2.2160 - val_accuracy: 0.1778\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2298 - accuracy: 0.1493 - val_loss: 2.2093 - val_accuracy: 0.1778\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2258 - accuracy: 0.1567 - val_loss: 2.2033 - val_accuracy: 0.1556\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.2222 - accuracy: 0.1667 - val_loss: 2.1979 - val_accuracy: 0.1778\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2190 - accuracy: 0.1517 - val_loss: 2.1932 - val_accuracy: 0.1778\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.2161 - accuracy: 0.1567 - val_loss: 2.1890 - val_accuracy: 0.1556\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2134 - accuracy: 0.1567 - val_loss: 2.1853 - val_accuracy: 0.1556\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2109 - accuracy: 0.1642 - val_loss: 2.1820 - val_accuracy: 0.1333\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2085 - accuracy: 0.1567 - val_loss: 2.1792 - val_accuracy: 0.1333\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.2063 - accuracy: 0.1592 - val_loss: 2.1767 - val_accuracy: 0.1778\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2042 - accuracy: 0.1567 - val_loss: 2.1745 - val_accuracy: 0.2000\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2021 - accuracy: 0.1617 - val_loss: 2.1726 - val_accuracy: 0.2000\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2001 - accuracy: 0.1517 - val_loss: 2.1710 - val_accuracy: 0.1778\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1982 - accuracy: 0.1493 - val_loss: 2.1696 - val_accuracy: 0.1778\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1963 - accuracy: 0.1393 - val_loss: 2.1684 - val_accuracy: 0.2000\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1944 - accuracy: 0.1368 - val_loss: 2.1673 - val_accuracy: 0.2000\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1926 - accuracy: 0.1368 - val_loss: 2.1665 - val_accuracy: 0.2000\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1908 - accuracy: 0.1443 - val_loss: 2.1658 - val_accuracy: 0.1778\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1891 - accuracy: 0.1468 - val_loss: 2.1651 - val_accuracy: 0.2000\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1874 - accuracy: 0.1542 - val_loss: 2.1646 - val_accuracy: 0.2000\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1858 - accuracy: 0.1567 - val_loss: 2.1641 - val_accuracy: 0.2222\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1843 - accuracy: 0.1617 - val_loss: 2.1637 - val_accuracy: 0.2222\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1828 - accuracy: 0.1642 - val_loss: 2.1634 - val_accuracy: 0.2222\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1814 - accuracy: 0.1766 - val_loss: 2.1631 - val_accuracy: 0.2222\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1800 - accuracy: 0.1766 - val_loss: 2.1628 - val_accuracy: 0.2222\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1787 - accuracy: 0.1841 - val_loss: 2.1624 - val_accuracy: 0.2000\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1775 - accuracy: 0.1891 - val_loss: 2.1621 - val_accuracy: 0.2222\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1762 - accuracy: 0.1915 - val_loss: 2.1617 - val_accuracy: 0.2000\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1751 - accuracy: 0.1990 - val_loss: 2.1613 - val_accuracy: 0.2000\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1740 - accuracy: 0.1990 - val_loss: 2.1609 - val_accuracy: 0.2000\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1729 - accuracy: 0.1990 - val_loss: 2.1604 - val_accuracy: 0.2000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1718 - accuracy: 0.1990 - val_loss: 2.1598 - val_accuracy: 0.2000\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1708 - accuracy: 0.1990 - val_loss: 2.1592 - val_accuracy: 0.2222\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1698 - accuracy: 0.1990 - val_loss: 2.1585 - val_accuracy: 0.2444\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1688 - accuracy: 0.2065 - val_loss: 2.1578 - val_accuracy: 0.2444\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1678 - accuracy: 0.2065 - val_loss: 2.1570 - val_accuracy: 0.2444\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1668 - accuracy: 0.2090 - val_loss: 2.1562 - val_accuracy: 0.2222\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1659 - accuracy: 0.2164 - val_loss: 2.1553 - val_accuracy: 0.2444\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1649 - accuracy: 0.2139 - val_loss: 2.1544 - val_accuracy: 0.2444\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1640 - accuracy: 0.2164 - val_loss: 2.1535 - val_accuracy: 0.2444\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1631 - accuracy: 0.2164 - val_loss: 2.1525 - val_accuracy: 0.2444\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1622 - accuracy: 0.2164 - val_loss: 2.1515 - val_accuracy: 0.2444\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.1613 - accuracy: 0.2139 - val_loss: 2.1505 - val_accuracy: 0.2222\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1604 - accuracy: 0.2239 - val_loss: 2.1495 - val_accuracy: 0.2444\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1595 - accuracy: 0.2264 - val_loss: 2.1485 - val_accuracy: 0.2444\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1586 - accuracy: 0.2264 - val_loss: 2.1476 - val_accuracy: 0.2444\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1578 - accuracy: 0.2264 - val_loss: 2.1466 - val_accuracy: 0.2444\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1569 - accuracy: 0.2264 - val_loss: 2.1457 - val_accuracy: 0.2444\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1560 - accuracy: 0.2313 - val_loss: 2.1447 - val_accuracy: 0.2444\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1552 - accuracy: 0.2313 - val_loss: 2.1438 - val_accuracy: 0.2444\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1543 - accuracy: 0.2289 - val_loss: 2.1429 - val_accuracy: 0.2222\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.1534 - accuracy: 0.2338 - val_loss: 2.1421 - val_accuracy: 0.2222\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1526 - accuracy: 0.2313 - val_loss: 2.1413 - val_accuracy: 0.2222\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1517 - accuracy: 0.2289 - val_loss: 2.1405 - val_accuracy: 0.2222\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1509 - accuracy: 0.2289 - val_loss: 2.1397 - val_accuracy: 0.2222\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.1500 - accuracy: 0.2264 - val_loss: 2.1390 - val_accuracy: 0.2222\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1492 - accuracy: 0.2338 - val_loss: 2.1384 - val_accuracy: 0.2222\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1483 - accuracy: 0.2338 - val_loss: 2.1377 - val_accuracy: 0.2222\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1474 - accuracy: 0.2338 - val_loss: 2.1371 - val_accuracy: 0.2222\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1466 - accuracy: 0.2363 - val_loss: 2.1365 - val_accuracy: 0.2222\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1457 - accuracy: 0.2338 - val_loss: 2.1359 - val_accuracy: 0.2222\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1448 - accuracy: 0.2338 - val_loss: 2.1353 - val_accuracy: 0.2222\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1439 - accuracy: 0.2363 - val_loss: 2.1348 - val_accuracy: 0.2222\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1431 - accuracy: 0.2363 - val_loss: 2.1342 - val_accuracy: 0.2222\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1422 - accuracy: 0.2388 - val_loss: 2.1337 - val_accuracy: 0.2222\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1413 - accuracy: 0.2363 - val_loss: 2.1332 - val_accuracy: 0.2222\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1404 - accuracy: 0.2338 - val_loss: 2.1327 - val_accuracy: 0.2222\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1395 - accuracy: 0.2338 - val_loss: 2.1322 - val_accuracy: 0.2222\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1385 - accuracy: 0.2313 - val_loss: 2.1317 - val_accuracy: 0.2000\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1376 - accuracy: 0.2313 - val_loss: 2.1312 - val_accuracy: 0.2000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1367 - accuracy: 0.2338 - val_loss: 2.1307 - val_accuracy: 0.2000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1357 - accuracy: 0.2338 - val_loss: 2.1302 - val_accuracy: 0.2000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1348 - accuracy: 0.2313 - val_loss: 2.1297 - val_accuracy: 0.2000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1338 - accuracy: 0.2338 - val_loss: 2.1292 - val_accuracy: 0.2000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1328 - accuracy: 0.2338 - val_loss: 2.1287 - val_accuracy: 0.2000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.1319 - accuracy: 0.2363 - val_loss: 2.1281 - val_accuracy: 0.2000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1309 - accuracy: 0.2363 - val_loss: 2.1276 - val_accuracy: 0.2000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1299 - accuracy: 0.2338 - val_loss: 2.1271 - val_accuracy: 0.2000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1288 - accuracy: 0.2338 - val_loss: 2.1265 - val_accuracy: 0.2000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1278 - accuracy: 0.2338 - val_loss: 2.1259 - val_accuracy: 0.2000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1268 - accuracy: 0.2363 - val_loss: 2.1253 - val_accuracy: 0.2000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1257 - accuracy: 0.2363 - val_loss: 2.1248 - val_accuracy: 0.2000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1246 - accuracy: 0.2388 - val_loss: 2.1241 - val_accuracy: 0.2000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1236 - accuracy: 0.2413 - val_loss: 2.1236 - val_accuracy: 0.2000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1225 - accuracy: 0.2438 - val_loss: 2.1229 - val_accuracy: 0.2000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1213 - accuracy: 0.2463 - val_loss: 2.1223 - val_accuracy: 0.2000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1202 - accuracy: 0.2488 - val_loss: 2.1217 - val_accuracy: 0.2000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1191 - accuracy: 0.2537 - val_loss: 2.1210 - val_accuracy: 0.2000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1179 - accuracy: 0.2537 - val_loss: 2.1204 - val_accuracy: 0.2000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1168 - accuracy: 0.2537 - val_loss: 2.1198 - val_accuracy: 0.2000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1156 - accuracy: 0.2463 - val_loss: 2.1191 - val_accuracy: 0.2000\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1144 - accuracy: 0.2488 - val_loss: 2.1185 - val_accuracy: 0.2000\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1132 - accuracy: 0.2488 - val_loss: 2.1178 - val_accuracy: 0.2000\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1119 - accuracy: 0.2463 - val_loss: 2.1172 - val_accuracy: 0.2000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1107 - accuracy: 0.2463 - val_loss: 2.1165 - val_accuracy: 0.2000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1094 - accuracy: 0.2463 - val_loss: 2.1159 - val_accuracy: 0.2000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.1082 - accuracy: 0.2488 - val_loss: 2.1152 - val_accuracy: 0.2000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1069 - accuracy: 0.2512 - val_loss: 2.1146 - val_accuracy: 0.2000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.1056 - accuracy: 0.2537 - val_loss: 2.1139 - val_accuracy: 0.2000\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1042 - accuracy: 0.2562 - val_loss: 2.1132 - val_accuracy: 0.2000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1029 - accuracy: 0.2587 - val_loss: 2.1125 - val_accuracy: 0.2000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1016 - accuracy: 0.2562 - val_loss: 2.1118 - val_accuracy: 0.2000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1002 - accuracy: 0.2562 - val_loss: 2.1111 - val_accuracy: 0.2000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0988 - accuracy: 0.2587 - val_loss: 2.1104 - val_accuracy: 0.2000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0974 - accuracy: 0.2587 - val_loss: 2.1097 - val_accuracy: 0.2000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0960 - accuracy: 0.2637 - val_loss: 2.1090 - val_accuracy: 0.2000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0946 - accuracy: 0.2612 - val_loss: 2.1083 - val_accuracy: 0.2000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0932 - accuracy: 0.2562 - val_loss: 2.1076 - val_accuracy: 0.2000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0918 - accuracy: 0.2562 - val_loss: 2.1069 - val_accuracy: 0.1778\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0903 - accuracy: 0.2587 - val_loss: 2.1062 - val_accuracy: 0.1778\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0889 - accuracy: 0.2587 - val_loss: 2.1054 - val_accuracy: 0.2000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0874 - accuracy: 0.2587 - val_loss: 2.1047 - val_accuracy: 0.2000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0860 - accuracy: 0.2612 - val_loss: 2.1040 - val_accuracy: 0.2000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0845 - accuracy: 0.2612 - val_loss: 2.1033 - val_accuracy: 0.2000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0830 - accuracy: 0.2587 - val_loss: 2.1026 - val_accuracy: 0.2000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.0815 - accuracy: 0.2587 - val_loss: 2.1019 - val_accuracy: 0.2222\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0800 - accuracy: 0.2562 - val_loss: 2.1011 - val_accuracy: 0.2222\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0785 - accuracy: 0.2587 - val_loss: 2.1005 - val_accuracy: 0.2444\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0770 - accuracy: 0.2587 - val_loss: 2.0998 - val_accuracy: 0.2444\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0755 - accuracy: 0.2587 - val_loss: 2.0991 - val_accuracy: 0.2444\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.0740 - accuracy: 0.2537 - val_loss: 2.0984 - val_accuracy: 0.2444\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0725 - accuracy: 0.2537 - val_loss: 2.0977 - val_accuracy: 0.2444\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0710 - accuracy: 0.2537 - val_loss: 2.0970 - val_accuracy: 0.2444\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0695 - accuracy: 0.2537 - val_loss: 2.0963 - val_accuracy: 0.2444\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.0680 - accuracy: 0.2537 - val_loss: 2.0957 - val_accuracy: 0.2444\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0665 - accuracy: 0.2537 - val_loss: 2.0950 - val_accuracy: 0.2444\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0650 - accuracy: 0.2512 - val_loss: 2.0944 - val_accuracy: 0.2889\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0635 - accuracy: 0.2537 - val_loss: 2.0938 - val_accuracy: 0.2889\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0620 - accuracy: 0.2537 - val_loss: 2.0932 - val_accuracy: 0.2889\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0605 - accuracy: 0.2512 - val_loss: 2.0925 - val_accuracy: 0.2889\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0590 - accuracy: 0.2537 - val_loss: 2.0920 - val_accuracy: 0.2889\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0576 - accuracy: 0.2512 - val_loss: 2.0913 - val_accuracy: 0.2889\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0561 - accuracy: 0.2537 - val_loss: 2.0908 - val_accuracy: 0.2889\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0546 - accuracy: 0.2612 - val_loss: 2.0902 - val_accuracy: 0.2889\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0531 - accuracy: 0.2612 - val_loss: 2.0897 - val_accuracy: 0.2889\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0517 - accuracy: 0.2612 - val_loss: 2.0891 - val_accuracy: 0.2889\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0502 - accuracy: 0.2612 - val_loss: 2.0886 - val_accuracy: 0.2889\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0487 - accuracy: 0.2612 - val_loss: 2.0881 - val_accuracy: 0.2889\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0473 - accuracy: 0.2612 - val_loss: 2.0875 - val_accuracy: 0.2889\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0458 - accuracy: 0.2612 - val_loss: 2.0871 - val_accuracy: 0.2889\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0444 - accuracy: 0.2687 - val_loss: 2.0866 - val_accuracy: 0.2889\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0429 - accuracy: 0.2662 - val_loss: 2.0861 - val_accuracy: 0.2889\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0414 - accuracy: 0.2662 - val_loss: 2.0857 - val_accuracy: 0.2889\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.0400 - accuracy: 0.2662 - val_loss: 2.0852 - val_accuracy: 0.2889\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0385 - accuracy: 0.2612 - val_loss: 2.0848 - val_accuracy: 0.2889\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0371 - accuracy: 0.2562 - val_loss: 2.0843 - val_accuracy: 0.2889\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0356 - accuracy: 0.2562 - val_loss: 2.0839 - val_accuracy: 0.2889\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0341 - accuracy: 0.2612 - val_loss: 2.0834 - val_accuracy: 0.2889\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0326 - accuracy: 0.2612 - val_loss: 2.0830 - val_accuracy: 0.2889\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0311 - accuracy: 0.2587 - val_loss: 2.0826 - val_accuracy: 0.2667\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.0296 - accuracy: 0.2612 - val_loss: 2.0822 - val_accuracy: 0.2667\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0281 - accuracy: 0.2612 - val_loss: 2.0818 - val_accuracy: 0.2667\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0266 - accuracy: 0.2687 - val_loss: 2.0814 - val_accuracy: 0.2667\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0250 - accuracy: 0.2662 - val_loss: 2.0809 - val_accuracy: 0.2667\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0235 - accuracy: 0.2637 - val_loss: 2.0805 - val_accuracy: 0.2667\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0219 - accuracy: 0.2637 - val_loss: 2.0801 - val_accuracy: 0.2667\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0203 - accuracy: 0.2662 - val_loss: 2.0797 - val_accuracy: 0.2667\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0187 - accuracy: 0.2662 - val_loss: 2.0792 - val_accuracy: 0.2667\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0171 - accuracy: 0.2662 - val_loss: 2.0788 - val_accuracy: 0.2667\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0155 - accuracy: 0.2662 - val_loss: 2.0783 - val_accuracy: 0.2889\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0138 - accuracy: 0.2687 - val_loss: 2.0779 - val_accuracy: 0.2889\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0122 - accuracy: 0.2711 - val_loss: 2.0774 - val_accuracy: 0.2889\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0105 - accuracy: 0.2736 - val_loss: 2.0770 - val_accuracy: 0.2889\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0088 - accuracy: 0.2662 - val_loss: 2.0765 - val_accuracy: 0.2667\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0070 - accuracy: 0.2662 - val_loss: 2.0760 - val_accuracy: 0.2667\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0053 - accuracy: 0.2662 - val_loss: 2.0755 - val_accuracy: 0.2667\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0035 - accuracy: 0.2687 - val_loss: 2.0750 - val_accuracy: 0.2667\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0017 - accuracy: 0.2662 - val_loss: 2.0745 - val_accuracy: 0.2667\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.9999 - accuracy: 0.2662 - val_loss: 2.0739 - val_accuracy: 0.2889\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9980 - accuracy: 0.2711 - val_loss: 2.0734 - val_accuracy: 0.2889\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9961 - accuracy: 0.2761 - val_loss: 2.0728 - val_accuracy: 0.2889\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9942 - accuracy: 0.2786 - val_loss: 2.0723 - val_accuracy: 0.2667\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9923 - accuracy: 0.2786 - val_loss: 2.0717 - val_accuracy: 0.2667\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9904 - accuracy: 0.2811 - val_loss: 2.0711 - val_accuracy: 0.2667\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.9884 - accuracy: 0.2811 - val_loss: 2.0705 - val_accuracy: 0.2667\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9864 - accuracy: 0.2836 - val_loss: 2.0699 - val_accuracy: 0.2667\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9844 - accuracy: 0.2836 - val_loss: 2.0692 - val_accuracy: 0.2667\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.9823 - accuracy: 0.2836 - val_loss: 2.0686 - val_accuracy: 0.2667\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9803 - accuracy: 0.2861 - val_loss: 2.0680 - val_accuracy: 0.2667\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9782 - accuracy: 0.2910 - val_loss: 2.0673 - val_accuracy: 0.2667\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9760 - accuracy: 0.2960 - val_loss: 2.0667 - val_accuracy: 0.2667\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9739 - accuracy: 0.2960 - val_loss: 2.0660 - val_accuracy: 0.2667\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9717 - accuracy: 0.2985 - val_loss: 2.0653 - val_accuracy: 0.2889\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9695 - accuracy: 0.3060 - val_loss: 2.0647 - val_accuracy: 0.2889\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9673 - accuracy: 0.3085 - val_loss: 2.0640 - val_accuracy: 0.2889\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9651 - accuracy: 0.3109 - val_loss: 2.0633 - val_accuracy: 0.2889\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9628 - accuracy: 0.3085 - val_loss: 2.0626 - val_accuracy: 0.2667\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9606 - accuracy: 0.3085 - val_loss: 2.0619 - val_accuracy: 0.2667\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9583 - accuracy: 0.3085 - val_loss: 2.0612 - val_accuracy: 0.2667\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9560 - accuracy: 0.3085 - val_loss: 2.0605 - val_accuracy: 0.2667\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9536 - accuracy: 0.3109 - val_loss: 2.0599 - val_accuracy: 0.2667\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9513 - accuracy: 0.3109 - val_loss: 2.0592 - val_accuracy: 0.2667\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9489 - accuracy: 0.3134 - val_loss: 2.0585 - val_accuracy: 0.2444\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9466 - accuracy: 0.3134 - val_loss: 2.0578 - val_accuracy: 0.2222\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9442 - accuracy: 0.3109 - val_loss: 2.0572 - val_accuracy: 0.2222\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9418 - accuracy: 0.3085 - val_loss: 2.0565 - val_accuracy: 0.2222\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9394 - accuracy: 0.3060 - val_loss: 2.0558 - val_accuracy: 0.2444\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9370 - accuracy: 0.3060 - val_loss: 2.0552 - val_accuracy: 0.2444\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.9346 - accuracy: 0.3060 - val_loss: 2.0546 - val_accuracy: 0.2222\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9321 - accuracy: 0.3085 - val_loss: 2.0540 - val_accuracy: 0.2222\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9297 - accuracy: 0.3060 - val_loss: 2.0534 - val_accuracy: 0.2222\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.9273 - accuracy: 0.3060 - val_loss: 2.0528 - val_accuracy: 0.2222\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9249 - accuracy: 0.3060 - val_loss: 2.0523 - val_accuracy: 0.2222\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9225 - accuracy: 0.3010 - val_loss: 2.0517 - val_accuracy: 0.2222\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9201 - accuracy: 0.3035 - val_loss: 2.0512 - val_accuracy: 0.2222\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9176 - accuracy: 0.3035 - val_loss: 2.0507 - val_accuracy: 0.2222\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9152 - accuracy: 0.3035 - val_loss: 2.0502 - val_accuracy: 0.2444\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.9129 - accuracy: 0.3035 - val_loss: 2.0498 - val_accuracy: 0.2444\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9105 - accuracy: 0.3085 - val_loss: 2.0494 - val_accuracy: 0.2444\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.9081 - accuracy: 0.3085 - val_loss: 2.0491 - val_accuracy: 0.2444\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.9058 - accuracy: 0.3109 - val_loss: 2.0487 - val_accuracy: 0.2444\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.9034 - accuracy: 0.3085 - val_loss: 2.0484 - val_accuracy: 0.2444\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.9011 - accuracy: 0.3109 - val_loss: 2.0481 - val_accuracy: 0.2444\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8988 - accuracy: 0.3109 - val_loss: 2.0478 - val_accuracy: 0.2444\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8965 - accuracy: 0.3109 - val_loss: 2.0476 - val_accuracy: 0.2444\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8942 - accuracy: 0.3134 - val_loss: 2.0474 - val_accuracy: 0.2444\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8919 - accuracy: 0.3159 - val_loss: 2.0472 - val_accuracy: 0.2444\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8896 - accuracy: 0.3184 - val_loss: 2.0471 - val_accuracy: 0.2444\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8874 - accuracy: 0.3184 - val_loss: 2.0469 - val_accuracy: 0.2444\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8851 - accuracy: 0.3184 - val_loss: 2.0468 - val_accuracy: 0.2444\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8829 - accuracy: 0.3159 - val_loss: 2.0466 - val_accuracy: 0.2444\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8807 - accuracy: 0.3159 - val_loss: 2.0465 - val_accuracy: 0.2444\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8785 - accuracy: 0.3184 - val_loss: 2.0464 - val_accuracy: 0.2444\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8763 - accuracy: 0.3184 - val_loss: 2.0463 - val_accuracy: 0.2444\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.8741 - accuracy: 0.3259 - val_loss: 2.0461 - val_accuracy: 0.2444\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8719 - accuracy: 0.3259 - val_loss: 2.0460 - val_accuracy: 0.2444\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8697 - accuracy: 0.3308 - val_loss: 2.0458 - val_accuracy: 0.2667\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8676 - accuracy: 0.3284 - val_loss: 2.0457 - val_accuracy: 0.2667\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8654 - accuracy: 0.3259 - val_loss: 2.0456 - val_accuracy: 0.2667\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8632 - accuracy: 0.3209 - val_loss: 2.0454 - val_accuracy: 0.2667\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.8610 - accuracy: 0.3209 - val_loss: 2.0452 - val_accuracy: 0.2667\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8588 - accuracy: 0.3209 - val_loss: 2.0450 - val_accuracy: 0.2667\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8566 - accuracy: 0.3209 - val_loss: 2.0448 - val_accuracy: 0.2667\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8544 - accuracy: 0.3184 - val_loss: 2.0445 - val_accuracy: 0.2667\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8522 - accuracy: 0.3184 - val_loss: 2.0443 - val_accuracy: 0.2667\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8500 - accuracy: 0.3209 - val_loss: 2.0440 - val_accuracy: 0.2667\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8478 - accuracy: 0.3209 - val_loss: 2.0438 - val_accuracy: 0.2667\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8456 - accuracy: 0.3209 - val_loss: 2.0435 - val_accuracy: 0.2667\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8434 - accuracy: 0.3234 - val_loss: 2.0432 - val_accuracy: 0.2667\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8411 - accuracy: 0.3259 - val_loss: 2.0430 - val_accuracy: 0.2667\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8389 - accuracy: 0.3259 - val_loss: 2.0427 - val_accuracy: 0.2667\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8366 - accuracy: 0.3284 - val_loss: 2.0424 - val_accuracy: 0.2667\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8343 - accuracy: 0.3284 - val_loss: 2.0421 - val_accuracy: 0.2667\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8320 - accuracy: 0.3284 - val_loss: 2.0418 - val_accuracy: 0.2667\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8297 - accuracy: 0.3284 - val_loss: 2.0416 - val_accuracy: 0.2667\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8274 - accuracy: 0.3284 - val_loss: 2.0413 - val_accuracy: 0.2667\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8251 - accuracy: 0.3259 - val_loss: 2.0410 - val_accuracy: 0.2444\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.8227 - accuracy: 0.3259 - val_loss: 2.0408 - val_accuracy: 0.2444\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8204 - accuracy: 0.3259 - val_loss: 2.0405 - val_accuracy: 0.2444\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8180 - accuracy: 0.3234 - val_loss: 2.0402 - val_accuracy: 0.2444\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.8156 - accuracy: 0.3234 - val_loss: 2.0399 - val_accuracy: 0.2444\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8132 - accuracy: 0.3234 - val_loss: 2.0396 - val_accuracy: 0.2444\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8108 - accuracy: 0.3284 - val_loss: 2.0394 - val_accuracy: 0.2444\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8083 - accuracy: 0.3358 - val_loss: 2.0390 - val_accuracy: 0.2444\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8059 - accuracy: 0.3358 - val_loss: 2.0388 - val_accuracy: 0.2444\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8034 - accuracy: 0.3358 - val_loss: 2.0385 - val_accuracy: 0.2444\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8009 - accuracy: 0.3383 - val_loss: 2.0382 - val_accuracy: 0.2222\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7984 - accuracy: 0.3383 - val_loss: 2.0380 - val_accuracy: 0.2222\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7958 - accuracy: 0.3408 - val_loss: 2.0377 - val_accuracy: 0.2222\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7933 - accuracy: 0.3433 - val_loss: 2.0375 - val_accuracy: 0.2222\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7907 - accuracy: 0.3433 - val_loss: 2.0372 - val_accuracy: 0.2222\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7881 - accuracy: 0.3433 - val_loss: 2.0369 - val_accuracy: 0.2222\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7854 - accuracy: 0.3433 - val_loss: 2.0366 - val_accuracy: 0.2222\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7828 - accuracy: 0.3433 - val_loss: 2.0363 - val_accuracy: 0.2222\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7801 - accuracy: 0.3458 - val_loss: 2.0361 - val_accuracy: 0.2222\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7774 - accuracy: 0.3433 - val_loss: 2.0358 - val_accuracy: 0.2222\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7747 - accuracy: 0.3433 - val_loss: 2.0355 - val_accuracy: 0.2222\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7719 - accuracy: 0.3483 - val_loss: 2.0351 - val_accuracy: 0.2222\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7692 - accuracy: 0.3483 - val_loss: 2.0348 - val_accuracy: 0.2222\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7664 - accuracy: 0.3507 - val_loss: 2.0345 - val_accuracy: 0.2222\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7635 - accuracy: 0.3507 - val_loss: 2.0343 - val_accuracy: 0.2222\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7607 - accuracy: 0.3557 - val_loss: 2.0339 - val_accuracy: 0.2222\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7578 - accuracy: 0.3557 - val_loss: 2.0335 - val_accuracy: 0.2222\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7548 - accuracy: 0.3557 - val_loss: 2.0332 - val_accuracy: 0.2222\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7519 - accuracy: 0.3557 - val_loss: 2.0328 - val_accuracy: 0.2222\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7489 - accuracy: 0.3532 - val_loss: 2.0324 - val_accuracy: 0.2222\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.7459 - accuracy: 0.3532 - val_loss: 2.0320 - val_accuracy: 0.2222\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7429 - accuracy: 0.3582 - val_loss: 2.0316 - val_accuracy: 0.2222\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7398 - accuracy: 0.3607 - val_loss: 2.0312 - val_accuracy: 0.2222\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7367 - accuracy: 0.3632 - val_loss: 2.0308 - val_accuracy: 0.2222\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7336 - accuracy: 0.3657 - val_loss: 2.0303 - val_accuracy: 0.2222\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7304 - accuracy: 0.3657 - val_loss: 2.0299 - val_accuracy: 0.2222\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7272 - accuracy: 0.3657 - val_loss: 2.0295 - val_accuracy: 0.2222\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7240 - accuracy: 0.3731 - val_loss: 2.0290 - val_accuracy: 0.2222\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7207 - accuracy: 0.3731 - val_loss: 2.0285 - val_accuracy: 0.2222\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7174 - accuracy: 0.3731 - val_loss: 2.0280 - val_accuracy: 0.2222\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7141 - accuracy: 0.3781 - val_loss: 2.0275 - val_accuracy: 0.2444\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7108 - accuracy: 0.3781 - val_loss: 2.0270 - val_accuracy: 0.2444\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7074 - accuracy: 0.3806 - val_loss: 2.0265 - val_accuracy: 0.2444\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7039 - accuracy: 0.3831 - val_loss: 2.0260 - val_accuracy: 0.2444\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.7005 - accuracy: 0.3806 - val_loss: 2.0255 - val_accuracy: 0.2444\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6970 - accuracy: 0.3831 - val_loss: 2.0249 - val_accuracy: 0.2444\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6935 - accuracy: 0.3856 - val_loss: 2.0244 - val_accuracy: 0.2444\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6899 - accuracy: 0.3881 - val_loss: 2.0240 - val_accuracy: 0.2444\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6863 - accuracy: 0.3881 - val_loss: 2.0235 - val_accuracy: 0.2444\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6827 - accuracy: 0.3881 - val_loss: 2.0231 - val_accuracy: 0.2444\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6790 - accuracy: 0.3881 - val_loss: 2.0225 - val_accuracy: 0.2444\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.6753 - accuracy: 0.3905 - val_loss: 2.0220 - val_accuracy: 0.2444\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6716 - accuracy: 0.3930 - val_loss: 2.0216 - val_accuracy: 0.2444\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6679 - accuracy: 0.3955 - val_loss: 2.0211 - val_accuracy: 0.2444\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6641 - accuracy: 0.3980 - val_loss: 2.0207 - val_accuracy: 0.2444\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6602 - accuracy: 0.3980 - val_loss: 2.0202 - val_accuracy: 0.2444\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6564 - accuracy: 0.4005 - val_loss: 2.0199 - val_accuracy: 0.2222\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6525 - accuracy: 0.4055 - val_loss: 2.0195 - val_accuracy: 0.2222\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6486 - accuracy: 0.4179 - val_loss: 2.0192 - val_accuracy: 0.2222\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6447 - accuracy: 0.4179 - val_loss: 2.0190 - val_accuracy: 0.2222\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6407 - accuracy: 0.4254 - val_loss: 2.0187 - val_accuracy: 0.2222\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6367 - accuracy: 0.4254 - val_loss: 2.0186 - val_accuracy: 0.2222\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6327 - accuracy: 0.4328 - val_loss: 2.0184 - val_accuracy: 0.2222\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6286 - accuracy: 0.4328 - val_loss: 2.0182 - val_accuracy: 0.2222\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6245 - accuracy: 0.4328 - val_loss: 2.0182 - val_accuracy: 0.2222\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.6204 - accuracy: 0.4353 - val_loss: 2.0182 - val_accuracy: 0.2222\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6163 - accuracy: 0.4353 - val_loss: 2.0183 - val_accuracy: 0.2222\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6121 - accuracy: 0.4353 - val_loss: 2.0183 - val_accuracy: 0.2222\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6079 - accuracy: 0.4328 - val_loss: 2.0184 - val_accuracy: 0.2444\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.6037 - accuracy: 0.4428 - val_loss: 2.0185 - val_accuracy: 0.2667\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5994 - accuracy: 0.4378 - val_loss: 2.0188 - val_accuracy: 0.2667\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5951 - accuracy: 0.4378 - val_loss: 2.0190 - val_accuracy: 0.2889\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5908 - accuracy: 0.4453 - val_loss: 2.0192 - val_accuracy: 0.2889\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5865 - accuracy: 0.4478 - val_loss: 2.0195 - val_accuracy: 0.2889\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5821 - accuracy: 0.4478 - val_loss: 2.0201 - val_accuracy: 0.2889\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5777 - accuracy: 0.4552 - val_loss: 2.0205 - val_accuracy: 0.2889\n",
      "========== Fold 10 ==========\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.3134 - accuracy: 0.1259 - val_loss: 2.3408 - val_accuracy: 0.0952\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.3109 - accuracy: 0.1259 - val_loss: 2.3367 - val_accuracy: 0.0952\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.3066 - accuracy: 0.1309 - val_loss: 2.3314 - val_accuracy: 0.0952\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3010 - accuracy: 0.1309 - val_loss: 2.3253 - val_accuracy: 0.1190\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.2944 - accuracy: 0.1358 - val_loss: 2.3186 - val_accuracy: 0.1190\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2873 - accuracy: 0.1383 - val_loss: 2.3117 - val_accuracy: 0.1429\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2799 - accuracy: 0.1481 - val_loss: 2.3046 - val_accuracy: 0.1429\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.2724 - accuracy: 0.1481 - val_loss: 2.2976 - val_accuracy: 0.1429\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2650 - accuracy: 0.1457 - val_loss: 2.2908 - val_accuracy: 0.1190\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2578 - accuracy: 0.1432 - val_loss: 2.2843 - val_accuracy: 0.1429\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2509 - accuracy: 0.1457 - val_loss: 2.2782 - val_accuracy: 0.1190\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2444 - accuracy: 0.1481 - val_loss: 2.2724 - val_accuracy: 0.1190\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2384 - accuracy: 0.1481 - val_loss: 2.2670 - val_accuracy: 0.1190\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.2327 - accuracy: 0.1432 - val_loss: 2.2620 - val_accuracy: 0.1190\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.2275 - accuracy: 0.1506 - val_loss: 2.2574 - val_accuracy: 0.1190\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2228 - accuracy: 0.1457 - val_loss: 2.2532 - val_accuracy: 0.1190\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.2184 - accuracy: 0.1506 - val_loss: 2.2494 - val_accuracy: 0.1190\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2144 - accuracy: 0.1556 - val_loss: 2.2459 - val_accuracy: 0.1429\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2108 - accuracy: 0.1852 - val_loss: 2.2427 - val_accuracy: 0.1667\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.2075 - accuracy: 0.1802 - val_loss: 2.2398 - val_accuracy: 0.1429\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2044 - accuracy: 0.1827 - val_loss: 2.2372 - val_accuracy: 0.1429\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2016 - accuracy: 0.1827 - val_loss: 2.2349 - val_accuracy: 0.1429\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1990 - accuracy: 0.1852 - val_loss: 2.2327 - val_accuracy: 0.1429\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1966 - accuracy: 0.1827 - val_loss: 2.2307 - val_accuracy: 0.1429\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1943 - accuracy: 0.1827 - val_loss: 2.2290 - val_accuracy: 0.1429\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1921 - accuracy: 0.1852 - val_loss: 2.2274 - val_accuracy: 0.1429\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1900 - accuracy: 0.1852 - val_loss: 2.2260 - val_accuracy: 0.1429\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1881 - accuracy: 0.1728 - val_loss: 2.2247 - val_accuracy: 0.1905\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1861 - accuracy: 0.1753 - val_loss: 2.2236 - val_accuracy: 0.2143\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1843 - accuracy: 0.1753 - val_loss: 2.2226 - val_accuracy: 0.2143\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1825 - accuracy: 0.1753 - val_loss: 2.2217 - val_accuracy: 0.2143\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1808 - accuracy: 0.1753 - val_loss: 2.2210 - val_accuracy: 0.2143\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1791 - accuracy: 0.1778 - val_loss: 2.2204 - val_accuracy: 0.2143\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1775 - accuracy: 0.1827 - val_loss: 2.2199 - val_accuracy: 0.1905\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1759 - accuracy: 0.1802 - val_loss: 2.2195 - val_accuracy: 0.1667\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1744 - accuracy: 0.1901 - val_loss: 2.2192 - val_accuracy: 0.1429\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.1729 - accuracy: 0.1926 - val_loss: 2.2190 - val_accuracy: 0.1429\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1715 - accuracy: 0.1926 - val_loss: 2.2189 - val_accuracy: 0.1429\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1702 - accuracy: 0.1901 - val_loss: 2.2188 - val_accuracy: 0.1429\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1689 - accuracy: 0.1951 - val_loss: 2.2188 - val_accuracy: 0.1429\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1676 - accuracy: 0.1975 - val_loss: 2.2189 - val_accuracy: 0.1429\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1664 - accuracy: 0.1951 - val_loss: 2.2190 - val_accuracy: 0.1429\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1653 - accuracy: 0.2000 - val_loss: 2.2191 - val_accuracy: 0.1429\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1642 - accuracy: 0.2074 - val_loss: 2.2193 - val_accuracy: 0.1429\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.1631 - accuracy: 0.2099 - val_loss: 2.2195 - val_accuracy: 0.1429\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1620 - accuracy: 0.2099 - val_loss: 2.2197 - val_accuracy: 0.1429\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1610 - accuracy: 0.2123 - val_loss: 2.2198 - val_accuracy: 0.1429\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1600 - accuracy: 0.2123 - val_loss: 2.2200 - val_accuracy: 0.1429\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1591 - accuracy: 0.2148 - val_loss: 2.2202 - val_accuracy: 0.1429\n"
     ]
    }
   ],
   "source": [
    "models, histories, y_pred_all, y_test_all = train_seq2seq_kfold(train_model, inf_enc, inf_dec, X, X_prior, y, num_folds=num_folds, batch_size=batch_size, epochs=epochs, early_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from visualization.plot_model_performance import extend_history_lists\n",
    "\n",
    "histories = extend_history_lists(histories, epochs=epochs)\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(np.array(histories['loss']).T, color='blue', alpha=0.35)\n",
    "ax1.plot(np.mean(histories['loss'], axis=0), color='blue', label='Train')\n",
    "ax1.plot(np.array(histories['val_loss']).T, color='orange', alpha=0.35)\n",
    "ax1.plot(np.mean(histories['val_loss'], axis=0), color='orange', label='Test')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('RNN Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(np.array(histories['accuracy']).T, color='blue', alpha=0.35)\n",
    "ax2.plot(np.mean(histories['accuracy'], axis=0), color='blue', label='Train')\n",
    "ax2.plot(np.array(histories['val_accuracy']).T, color='orange', alpha=0.35)\n",
    "ax2.plot(np.mean(histories['val_accuracy'], axis=0), color='orange', label='Test')\n",
    "# ax2.axhline(1/(n_output-1), color='gray', linestyle='--', label='Chance')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('RNN Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 has more than 100 epochs. Pleaseextend histories lists to a value greater than or equalto the maximum number of epochs for any fold.\n",
      "Fold 0 has more than 100 epochs. Pleaseextend histories lists to a value greater than or equalto the maximum number of epochs for any fold.\n",
      "Fold 0 has more than 100 epochs. Pleaseextend histories lists to a value greater than or equalto the maximum number of epochs for any fold.\n",
      "Fold 0 has more than 100 epochs. Pleaseextend histories lists to a value greater than or equalto the maximum number of epochs for any fold.\n"
     ]
    }
   ],
   "source": [
    "from visualization.plot_model_performance import plot_accuracy_loss\n",
    "\n",
    "plot_accuracy_loss(histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
