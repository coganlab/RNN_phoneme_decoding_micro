{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in Data from .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from processing_utils.feature_data_from_mat import load_subject_high_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_trace, hg_map, phon_labels = load_subject_high_gamma('S14', sig_channel=False, zscore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hg_trace.shape)\n",
    "print(hg_map.shape)\n",
    "print(phon_labels.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(hg_trace, axis=0), 'grey')\n",
    "plt.plot(np.mean(np.mean(hg_trace, axis=0), axis=1), 'black')\n",
    "plt.title('HG Trace by Channel')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data for use with 1/3 D CNN Bidirectional LSTM seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from processing_utils.sequence_processing import pad_sequence_teacher_forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hg_trace  # use HG traces (n_trials, n_channels, n_timepoints) for 1D CNN\n",
    "# X = hg_map  # use HG channel map stack (n_trials, n_channels_x, n_channels_y, n_timepoints) for 1D CNN\n",
    "X_prior, y, prior_labels, seq_labels = pad_sequence_teacher_forcing(phon_labels, n_output)  # first 2 outputs one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_prior.shape, y.shape, prior_labels.shape, seq_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 1D CNN Bidirectional LSTM seq2seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from seq2seq_models.rnn_models import (lstm_1Dcnn_model, gru_1Dcnn_model, \n",
    "                                       lstm_3Dcnn_model, gru_3Dcnn_model,\n",
    "                                       stacked_lstm_1Dcnn_model,\n",
    "                                       stacked_gru_1Dcnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# 1D CNN\n",
    "n_input_time = X.shape[1]\n",
    "n_input_channel = X.shape[2]\n",
    "filter_size = 10\n",
    "\n",
    "# 3D CNN\n",
    "# n_input_channel = [X.shape[1], X.shape[2]]\n",
    "# n_input_time = X.shape[3]\n",
    "# filter_size = 2\n",
    "\n",
    "n_filters = 50\n",
    "n_units = 200\n",
    "n_layers = 3\n",
    "reg_lambda = 1e-6\n",
    "dropout = 0.0\n",
    "bidir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model, inf_enc, inf_dec = lstm_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir, dropout=dropout)\n",
    "# train_model, inf_enc, inf_dec = lstm_3Dcnn_model(n_input_time, n_input_x, n_input_y, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = gru_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = gru_3Dcnn_model(n_input_time, n_input_x, n_input_y, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir)\n",
    "# train_model, inf_enc, inf_dec = stacked_lstm_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_layers, n_units, reg_lambda, bidir=bidir, dropout=dropout)\n",
    "train_model, inf_enc, inf_dec = stacked_gru_1Dcnn_model(n_input_time, n_input_channel, n_output, n_filters, filter_size, n_layers, n_units, reg_lambda, bidir=bidir, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_model.summary())\n",
    "print(train_model.layers[-1].summary())\n",
    "print(inf_enc.summary())\n",
    "print(inf_enc.layers[-1].summary())\n",
    "print(inf_dec.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model, new_enc, new_dec = lstm_1Dcnn_model(n_input_time, 256, n_output, n_filters, filter_size, n_units, reg_lambda, bidir=bidir, dropout=dropout)\n",
    "for layer in new_model.layers:\n",
    "        try:\n",
    "            layer.set_weights(train_model.get_layer(name=layer.name).get_weights())\n",
    "        except:\n",
    "            print(\"Could not transfer weights for layer {}\".format(layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lstm_w = new_model.layers[-1].layers[1].get_weights()[0]\n",
    "old_lstm_w = train_model.layers[-1].layers[1].get_weights()[0]\n",
    "print(np.array_equal(new_lstm_w, old_lstm_w))\n",
    "print(new_lstm_w)\n",
    "print(old_lstm_w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from train.optimize import encDecHyperModel, encDecTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = ShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
    "train_idx, test_idx = next(data_split.split(X))\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "X_prior_train, X_prior_test = X_prior[train_idx], X_prior[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_trials = 100\n",
    "hyper_model = encDecHyperModel(lstm_1Dcnn_model, n_input_time, n_input_channel, n_output)\n",
    "rnn_optimizer = encDecTuner(hypermodel=hyper_model,\n",
    "                            oracle=kt.oracles.RandomSearchOracle(objective=kt.Objective('val_accuracy', direction='max'),\n",
    "                                                                 max_trials=optim_trials),\n",
    "                            directory='data/rnn_tuning', project_name='S14_1Dcnn_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_optimizer.search(X_train, X_prior_train, y_train, epochs=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_optimizer.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = rnn_optimizer.get_best_hyperparameters(num_trials=10)[0].values\n",
    "print(optim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optim_model, optim_enc, optim_dec = lstm_1Dcnn_model(n_input_time, n_input_channel,\n",
    "                                                     n_output, n_filters=optim_params['num_filts'],\n",
    "                                                     filter_size=10, n_units=optim_params['rnn_units'],\n",
    "                                                     reg_lambda=optim_params['reg_lambda'])\n",
    "\n",
    "learning_rate = 5e-4\n",
    "optim_model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.train import train_seq2seq, decode_seq2seq\n",
    "\n",
    "_, histories = train_seq2seq(optim_model, X_train, X_prior_train, y_train, epochs=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred_optim, y_test_optim = decode_seq2seq(optim_enc, optim_dec, X_test, y_test)\n",
    "print(f'Hyperparameter Optimized Balanced Accuracy: {balanced_accuracy_score(y_test_optim, y_pred_optim)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from train.train import train_seq2seq_kfold, train_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_folds = 10\n",
    "num_reps = 1\n",
    "batch_size = 200\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.seq2seq_predict_callback import seq2seq_predict_callback\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "data_split = ShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
    "train_idx, test_idx = next(data_split.split(X))\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "X_prior_train, X_prior_test = X_prior[train_idx], X_prior[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "s2s_cb = seq2seq_predict_callback(train_model, inf_enc, inf_dec, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history = train_seq2seq(train_model, X_train, X_prior_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=([X_test, X_prior_test], y_test), callbacks=[s2s_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], color='blue', label='Train')\n",
    "ax1.plot(history.history['val_loss'], color='orange', label='Validation')\n",
    "ax1.plot(history.history['seq2seq_val_loss'], color='red', label='Seq2seq Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('RNN Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='blue', label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], color='orange', label='Validation')\n",
    "ax2.plot(history.history['seq2seq_val_accuracy'], color='red', label='Seq2seq Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('RNN Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "histories, y_pred_all, y_test_all = train_seq2seq_kfold(train_model, inf_enc, inf_dec, X, X_prior, y,\n",
    "                                                        num_folds=num_folds, num_reps=num_reps,\n",
    "                                                        batch_size=batch_size, \n",
    "                                                        epochs=epochs, early_stop=False)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time to train {num_folds} folds: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.plot_model_performance import extend_history_lists\n",
    "\n",
    "histories = extend_history_lists(histories, epochs=epochs)\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(np.array(histories['loss']).T, color='blue', alpha=0.35)\n",
    "ax1.plot(np.mean(histories['loss'], axis=0), color='blue', label='Train')\n",
    "ax1.plot(np.array(histories['val_loss']).T, color='orange', alpha=0.35)\n",
    "ax1.plot(np.mean(histories['val_loss'], axis=0), color='orange', label='Validation')\n",
    "ax1.plot(np.array(histories['seq2seq_val_loss']).T, color='red', alpha=0.35)\n",
    "ax1.plot(np.mean(histories['seq2seq_val_loss'], axis=0), color='red', label='Seq2seq Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('RNN Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(np.array(histories['accuracy']).T, color='blue', alpha=0.35)\n",
    "ax2.plot(np.mean(histories['accuracy'], axis=0), color='blue', label='Train')\n",
    "ax2.plot(np.array(histories['val_accuracy']).T, color='orange', alpha=0.35)\n",
    "ax2.plot(np.mean(histories['val_accuracy'], axis=0), color='orange', label='Validation')\n",
    "ax2.plot(np.array(histories['seq2seq_val_accuracy']).T, color='red', alpha=0.35)\n",
    "ax2.plot(np.mean(histories['seq2seq_val_accuracy'], axis=0), color='red', label='Seq2seq Validation')\n",
    "# ax2.axhline(1/(n_output-1), color='gray', linestyle='--', label='Chance')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('RNN Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "print(f'Balanced Accuracy: {balanced_accuracy_score(y_test_all, y_pred_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.plot_model_performance import plot_accuracy_loss\n",
    "\n",
    "plot_accuracy_loss(histories, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70ea75fe4d4912c04c5b3d05361445264347b81ab4a9aec88659d0b476cbe73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
